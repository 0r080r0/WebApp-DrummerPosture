{"version":3,"file":"static/js/60.865fd63a.chunk.js","mappings":";w1iBA6CM,MAAOA,EAIXC,WAAAA,CAAoBC,EAAgCC,GAAhC,KAAAD,QAAAA,EAAgC,KAAAC,UAAAA,EAH5C,KAAAC,KAAO,IAAIC,QACX,KAAAC,aAAe,CAEoD,CAE3EC,GAAAA,CAAIC,GAIF,OAHKC,KAAKL,KAAKM,IAAIF,IACjBC,KAAKN,UAAUQ,SAASF,KAAKP,QAASM,GAEjCC,KAAKL,KAAKG,IAAIC,EACvB,CAEAI,GAAAA,CAAIJ,EAAgBK,GAClBJ,KAAKH,eACLG,KAAKL,KAAKQ,IAAIJ,EAAQK,EACxB,CAEAH,GAAAA,CAAIF,GACF,OAAOC,KAAKL,KAAKM,IAAIF,EACvB,CAEAM,OAAON,GAEL,OADAC,KAAKH,eACEG,KAAKL,KAAKU,OAAON,EAC1B,CAEAO,UAAAA,GACE,OAAON,KAAKH,YACd,EAwBI,MAAOU,EACXC,QAAAA,CAAST,GACP,OAAOU,EAAkB,WAC3B,CACAC,MAAAA,CAAOX,GACL,OAAOU,EAAkB,SAC3B,CACAE,cAAAA,GACE,OAAO,CACT,CACAC,IAAAA,CAAKC,GACH,OAAOJ,EAAkB,OAC3B,CACAK,IAAAA,CAAKf,GACH,OAAOU,EAAkB,OAC3B,CACAM,QAAAA,CAAShB,GACP,OAAOU,EAAkB,WAC3B,CACAO,SAAAA,CAAUjB,EAAgBkB,GACxB,OAAOR,EAAkB,YAC3B,CACAH,UAAAA,GACE,OAAOG,EAAkB,aAC3B,CACAS,WAAAA,CAAYnB,EAAgBoB,GAC1B,OAAOV,EAAkB,cAC3B,CACAW,KAAAA,CAAMC,EAAuBC,EAAiBC,GAC5C,OAAOd,EAAkB,QAC3B,CACAe,IAAAA,CACIzB,EAAgBsB,EAAuBC,EAAiBC,EACxDf,GACF,OAAOC,EAAkB,OAC3B,CACAgB,MAAAA,GACE,OAAOhB,EAAkB,SAC3B,CAEAiB,cAAAA,GACE,OAAOjB,EAAkB,iBAC3B,CAEAkB,OAAAA,GACE,OAAiC,KAA1B3B,KAAK0B,iBA3He,KACA,IA2H7B,CACAE,OAAAA,GACE,OAAOnB,EAAkB,UAC3B,EAGF,SAASA,EAAkBoB,GACzB,MAAM,IAAIC,MACN,IAAAC,OAAIF,EAAU,+HAEpB,CCzHM,SAAUG,EAAQC,GAEtB,IAAIC,EAAUD,EAAME,OAChBC,EAAQ,EAEZ,KAAOF,EAAU,GAEfE,EAASC,KAAKC,SAAWJ,EAAW,EAEpCA,IAEAK,EAAKN,EAAOC,EAASE,EAEzB,CAkBM,SAAUI,EAEZP,EAEAQ,GACF,GAAIR,EAAME,SAAWM,EAAON,OAC1B,MAAM,IAAIL,MACN,4EAAAC,OAC0BE,EAAME,QAAQ,2BAAAJ,OACbU,EAAON,SAExC,IAAID,EAAUD,EAAME,OAChBC,EAAQ,EAEZ,KAAOF,EAAU,GAEfE,EAASC,KAAKC,SAAWJ,EAAW,EAEpCA,IAEAK,EAAKN,EAAOC,EAASE,GACrBG,EAAKE,EAAQP,EAASE,EAE1B,CAGM,SAAUM,EAAMC,EAAaC,EAAWC,GAC5C,OAAOR,KAAKQ,IAAIF,EAAKN,KAAKM,IAAIC,EAAGC,GACnC,CAEM,SAAUC,EAAkBC,GAChC,OAAOA,EAAM,IAAM,EAAIA,EAAMA,EAAM,CACrC,CAEM,SAAUR,EACZS,EAA8BC,EAAcC,GAC9C,MAAMC,EAAOH,EAAOC,GACpBD,EAAOC,GAAQD,EAAOE,GACtBF,EAAOE,GAASC,CAClB,CAEM,SAAUC,EAAIC,GAClB,IAAID,EAAM,EACV,IAAK,IAAIE,EAAI,EAAGA,EAAID,EAAIlB,OAAQmB,IAC9BF,GAAOC,EAAIC,GAEb,OAAOF,CACT,CASM,SAAUG,EAAYC,EAAWC,GACrC,MAAMC,EAAIrB,KAAKC,SACf,OAAQmB,EAAIC,GAAM,EAAIA,GAAKF,CAC7B,CAGM,SAAUG,EAAYH,EAAeC,GACzC,IAAIG,EAAS,EACb,IAAK,IAAIN,EAAI,EAAGA,EAAIE,EAAErB,OAAQmB,IAAK,CACjC,MAAMO,EAAOC,OAAON,EAAEF,IAAMQ,OAAOL,EAAEH,IACrCM,GAAUC,EAAOA,C,CAEnB,OAAOD,CACT,CAiBM,SAAUG,EAAOC,EAAeC,GACpC,IAAKD,EACH,MAAM,IAAIlC,MAAqB,kBAARmC,EAAmBA,EAAMA,IAEpD,CAEM,SAAUC,EACZC,EAAkBC,GAAyC,IAAvBC,EAAkBC,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,GAC3DP,EACIS,GAAYL,EAAQC,GACpB,IAAMC,EAAqB,WAAHtC,OAAcoC,EAAM,SAAApC,OAAQqC,EAAM,eAChE,CAEM,SAAUK,EAAcjB,GAC5BO,EACS,MAALP,EACA,IAAM,gEACZ,CAqBM,SACNkB,GACIrB,GAAkE,IAAxCO,EAAAU,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAc,GAAIK,EAAcL,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,IAAAA,UAAA,GAI5D,GAHc,MAAVV,IACFA,EAAS,IAEPgB,MAAMC,QAAQxB,IAAQyB,GAAazB,KAASsB,EAC9C,IAAK,IAAIrB,EAAI,EAAGA,EAAID,EAAIlB,SAAUmB,EAChCoB,GAAQrB,EAAIC,GAAIM,EAAQe,QAG1Bf,EAAOmB,KAAK1B,GAEd,OAAOO,CACT,CAaM,SAAUoB,GAAc1D,GAC5B,GAAqB,IAAjBA,EAAMa,OAER,OAAO,EAET,IAAI8C,EAAO3D,EAAM,GACjB,IAAK,IAAIgC,EAAI,EAAGA,EAAIhC,EAAMa,OAAQmB,IAChC2B,GAAQ3D,EAAMgC,GAEhB,OAAO2B,CACT,CAEM,SAAUC,GAAc5D,GAC5B,OAAwB,IAAjBA,EAAMa,MACf,CAEM,SAAUqC,GAAYW,EAAgBC,GAC1C,GAAID,IAAOC,EACT,OAAO,EAET,GAAU,MAAND,GAAoB,MAANC,EAChB,OAAO,EAGT,GAAID,EAAGhD,SAAWiD,EAAGjD,OACnB,OAAO,EAET,IAAK,IAAImB,EAAI,EAAGA,EAAI6B,EAAGhD,OAAQmB,IAC7B,GAAI6B,EAAG7B,KAAO8B,EAAG9B,GACf,OAAO,EAGX,OAAO,CACT,CAEM,SAAU+B,GAAM7B,GACpB,OAAOA,EAAI,IAAM,CACnB,CAEM,SAAU8B,GAAK1C,GAEnB,GAA0B,MAArBP,KAAaiD,KAEhB,OAAQjD,KAAaiD,KAAK1C,GAE5B,GAAIA,IAAM2C,IACR,OAAO,EACF,GAAI3C,KAAO2C,IAChB,OAAQ,EACH,CACL,MAAMC,EAAMnD,KAAKoD,IAAI,EAAI7C,GACzB,OAAQ4C,EAAM,IAAMA,EAAM,E,CAE9B,CAEM,SAAUE,GAAoBT,GAClC,MAAMU,EAAQtD,KAAKuD,KAAKvD,KAAKwD,KAAKZ,IAClC,MAAO,CAACU,EAAOtD,KAAKuD,KAAKX,EAAOU,GAClC,CAcM,SAAUG,GAAsBC,GACpC,MAAMC,EAAkB,IAAIC,YAAYF,GACxC,IAAK,IAAIzC,EAAI,EAAGA,EAAIyC,IAAKzC,EACvB0C,EAAgB1C,GAAKA,EAGvB,OADAtB,EAAQgE,GACDA,CACT,CAEM,SAAUE,GAAS1C,EAAWyB,GAClC,OAAIA,GAAQzB,EAAErB,OACLqB,EAEFA,EAAI,IAAI2C,OAAOlB,EAAOzB,EAAErB,OACjC,CAEM,SAAUiE,GACZC,GAGc,IAHUC,EAAAhC,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAWpC,GAAoB,EACvDqE,EAAmBjC,UAAAnC,OAAA,EAAAmC,UAAA,QAAAC,EACnBiC,EAAAlC,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GACImC,WACN,OAAO,IAAIC,QAAc,CAACC,EAASC,KACjC,IAAIC,EAAW,EAEf,MAAMC,EAAQA,KACZ,GAAIT,IAEF,YADAM,IAIFE,IAEA,MAAME,EAAcT,EAAQO,GAEV,MAAdN,GAAsBM,GAAYN,EACpCK,IAGFJ,EAAWM,EAAOC,IAGpBD,KAEJ,CAWM,SAAUE,GACZ1F,EAAiB2D,GACnB,IAAIgC,EAAY,EACZC,GAAe,EAEnB,IAAK,IAAI5D,EAAI,EAAGA,EAAIhC,EAAMa,SAAUmB,EAClC,GAAIhC,EAAMgC,IAAM,EACd2D,GAAa3F,EAAMgC,QACd,IAAkB,IAAdhC,EAAMgC,GAAW,CAC1B,IAAqB,IAAjB4D,EACF,MAAMpF,MACF,4DAAAC,OACmBmF,EAAW,aAAAnF,OAAYuB,IAEhD4D,EAAc5D,C,MACT,GAAIhC,EAAMgC,GAAK,EACpB,MAAMxB,MAAM,gCAADC,OAAiCT,EAAMgC,GAAE,YAAAvB,OAAWuB,IAInE,IAAqB,IAAjB4D,EAAoB,CACtB,GAAIjC,EAAO,GAAKA,IAASgC,EACvB,MAAMnF,MAAM,QAADC,OAASkD,EAAI,sCAAAlD,OAAqCT,IAE/D,OAAOA,C,CAGT,GAAkB,IAAd2F,EACF,MAAMnF,MACF,qCAAAC,OAAqCT,EAAK,mCAGhD,GAAI2D,EAAOgC,IAAc,EACvB,MAAMnF,MACF,2DAAAC,OACOkD,EAAI,OAAAlD,OAAMkF,IAGvB,MAAME,EAAW7F,EAAM8F,QAEvB,OADAD,EAASD,GAAejC,EAAOgC,EACxBE,CACT,CAEM,SAAUE,GACZC,EAAuBhG,GACzB,MAAMiG,EAAOjG,EAAMa,OAmBnB,OAbA4B,GAHAuD,EAAe,MAARA,EAAehG,EAAMkG,IAAI,CAACC,EAAGnE,IAAMA,GAAK,GAAGvB,OAAOuF,IAIhDI,MAAMC,GAAMA,IAAOJ,GAAQI,EAAKJ,GACrC,IACI,+CAAAxF,OAA+CwF,EAAI,MAAAxF,OAAKwF,EAAI,sBAAAxF,OAChDuF,IAGpBvD,EACIuD,EAAKI,MAAMC,GAAMtC,GAAMsC,IACvB,IAAM,6DAAA5F,OACUuF,IAGbA,EAAKE,IAAIhE,GAAKA,EAAI,EAAI+D,EAAO/D,EAAIA,EAC1C,CAGM,SAAUoE,GAAatG,EAAiBgG,GAE5C,MAAMH,EAAqB,GACrBU,EAAqB,GACrBC,EAAuB,MAARR,GAAgB1C,MAAMC,QAAQyC,IAAyB,IAAhBA,EAAKnF,OAC3D4F,EAAgB,MAART,GAAgBQ,EAC1B,KACAT,GAAeC,EAAMhG,GAAO0G,OAChC,IAAIC,EAAI,EACR,IAAK,IAAI3E,EAAI,EAAGA,EAAIhC,EAAMa,SAAUmB,EAAG,CACrC,GAAY,MAARyE,EAAc,CAChB,GAAIA,EAAKE,KAAO3E,GAAkB,IAAbhC,EAAMgC,GACzB,MAAM,IAAIxB,MAAM,sBAADC,OACWuB,EAAC,oBAAAvB,OAAmBT,EAAMgC,GAAE,gBAExC,MAAXyE,EAAKE,IAAcF,EAAKE,GAAK3E,IAAmB,IAAbhC,EAAMgC,KAC5C6D,EAASpC,KAAKzD,EAAMgC,IACpBuE,EAAS9C,KAAKzB,IAEZyE,EAAKE,IAAM3E,GACb2E,G,CAGa,IAAb3G,EAAMgC,KACR6D,EAASpC,KAAKzD,EAAMgC,IACpBuE,EAAS9C,KAAKzB,G,CAGlB,MAAO,CAAC6D,WAAUU,WACpB,CAEM,SAAUK,GACZ3G,EAAU0D,GACZ,IAAI5D,EAAS,KACb,GAAa,MAATE,GAA2B,YAAVA,EACnBF,EAAS,IAAI8G,aAAalD,QACrB,GAAc,UAAV1D,EACTF,EAAS,IAAI+G,WAAWnD,OACnB,IAAc,SAAV1D,EAGT,MAAM,IAAIO,MAAM,qBAADC,OAAsBR,IAFrCF,EAAS,IAAIgH,WAAWpD,E,CAI1B,OAAO5D,CACT,CAEM,SAAUiH,GACZ/G,EAAU0D,GACZ,IAAI5D,EAAS,KACb,GAAa,MAATE,GAA2B,YAAVA,EACnBF,EAAS,IAAI8G,aAAalD,QACrB,GAAc,UAAV1D,EACTF,EAAS,IAAI+G,WAAWnD,QACnB,GAAc,SAAV1D,EACTF,EAAS,IAAIgH,WAAWpD,OACnB,IAAc,WAAV1D,EAGT,MAAM,IAAIO,MAAM,qBAADC,OAAsBR,IAFrCF,EAAS,IAAIuD,MAAgBK,E,CAI/B,OAAO5D,CACT,CAEM,SAAUkH,GACZC,EAA+BjH,GACjC,IAAK,IAAI+B,EAAI,EAAGA,EAAIkF,EAAKrG,OAAQmB,IAAK,CACpC,MAAMmF,EAAMD,EAAKlF,GACjB,GAAIoF,MAAMD,KAASE,SAASF,GAC1B,MAAM3G,MAAM,oBAADC,OAAqBR,EAAK,6BAAAQ,OAA4B0G,EAAG,K,CAG1E,CAGM,SAAUG,GAAarH,GAC3B,MAAiB,SAAVA,GAA8B,cAAVA,GAAmC,YAAVA,GACtC,UAAVA,GAA+B,WAAVA,CAC3B,CAMM,SAAUsH,GAAgBC,EAAmBC,GACjD,MAAgB,cAAZA,KAGY,YAAZA,GAAqC,cAAZD,MAGb,UAAZC,GAAmC,YAAZD,GAAqC,cAAZA,KAGpC,SAAZC,GAAkC,SAAZD,IAI5B,CAEM,SAAUhE,GAAatB,GAE3B,OAAOA,aAAa2E,cAAgB3E,aAAa4E,YAC7C5E,aAAa6E,YAAc7E,aAAawF,iBAC9C,CAEM,SAAUC,GAAgB1H,GAC9B,GAAc,YAAVA,GAAiC,UAAVA,EACzB,OAAO,EACF,GAAc,cAAVA,EACT,OAAO,EACF,GAAc,SAAVA,EACT,OAAO,EAEP,MAAM,IAAIO,MAAM,iBAADC,OAAkBR,GAErC,CAQM,SAAU2H,GAAqB7F,GACnC,GAAW,MAAPA,EACF,OAAO,EAET,IAAI8F,EAAQ,EAEZ,OADA9F,EAAI+F,QAAQxG,GAAKuG,GAASvG,EAAET,QACrBgH,CACT,CAGM,SAAUE,GAASjJ,GACvB,MAAwB,kBAAVA,GAAsBA,aAAiBkJ,MACvD,CAEM,SAAUC,GAAUnJ,GACxB,MAAwB,mBAAVA,CAChB,CAEM,SAAUoJ,GAASpJ,GACvB,MAAwB,kBAAVA,CAChB,CAEM,SAAUqJ,GAAWpI,GACzB,OAAIuD,MAAMC,QAAQxD,GACToI,GAAWpI,EAAO,IAEvBA,aAAkB8G,aACb,UAEL9G,aAAkB+G,YAAc/G,aAAkBgH,YAClDhH,aAAkB2H,kBACb,QACEQ,GAASnI,GACX,UACEgI,GAAShI,GACX,SACEkI,GAAUlI,GACZ,OAEF,SACT,CAEM,SAAUqI,GAAW7I,GACzB,SAAUA,GAAKA,EAAErB,aAAeqB,EAAE8I,MAAQ9I,EAAE+I,MAC9C,CAEM,SAAUC,GAAe5E,EAAc6E,GAC3C,IAAK,IAAIxG,EAAIwG,EAAOxG,EAAI2B,IAAQ3B,EAC9B,GAAI2B,EAAO3B,IAAM,EACf,OAAOA,EAGX,OAAO2B,CACT,CAEM,SAAU8E,GAAezI,GAC7B,MAAMiG,EAAOjG,EAAMa,OACnB,GAAIoF,EAAO,EACT,MAAO,GAKT,MAAMyC,EAAU,IAAIpF,MAAM2C,EAAO,GACjCyC,EAAQzC,EAAO,GAAKjG,EAAMiG,EAAO,GACjC,IAAK,IAAIjE,EAAIiE,EAAO,EAAGjE,GAAK,IAAKA,EAC/B0G,EAAQ1G,GAAK0G,EAAQ1G,EAAI,GAAKhC,EAAMgC,EAAI,GAE1C,OAAO0G,CACT,CAEA,SAASC,GACLC,EAAgB5I,EAAiBkC,GAAgC,IAAjB2G,EAAS7F,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,IAAAA,UAAA,GAC3D,MAAM8F,EAAM,IAAIxF,MAChB,GAAqB,IAAjBtD,EAAMa,OAAc,CACtB,MAAMkI,EAAI/I,EAAM,IAAM6I,EAAY,EAAI,GACtC,IAAK,IAAI7G,EAAI,EAAGA,EAAI+G,EAAG/G,IACrB8G,EAAI9G,GAAKE,EAAE0G,EAAS5G,E,KAEjB,CACL,MAAM+G,EAAI/I,EAAM,GACVgJ,EAAOhJ,EAAM8F,MAAM,GACnBmD,EAAMD,EAAKE,OAAO,CAACC,EAAKC,IAAMD,EAAMC,IAAMP,EAAY,EAAI,GAChE,IAAK,IAAI7G,EAAI,EAAGA,EAAI+G,EAAG/G,IACrB8G,EAAI9G,GAAK2G,GAAkBC,EAAS5G,EAAIiH,EAAKD,EAAM9G,EAAG2G,E,CAG1D,OAAOC,CACT,CAGM,SAAUO,GACZrJ,EAAiBkC,GAAgC,IAAjB2G,EAAS7F,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,IAAAA,UAAA,GAC3C,GAAqB,IAAjBhD,EAAMa,OAER,OAAOqB,EAAE,GAEX,MAAMyB,EAAO3D,EAAMkJ,OAAO,CAACC,EAAKC,IAAMD,EAAMC,IAAMP,EAAY,EAAI,GAClE,GAAa,IAATlF,EAEF,MAAO,GAET,GAAIA,IAASzB,EAAErB,OACb,MAAM,IAAIL,MAAM,IAADC,OAAKT,EAAK,oCAAAS,OAAmCyB,EAAErB,QAAMJ,OAChEoI,EAAY,wBAA0B,GAAE,MAG9C,OAAOF,GAAkB,EAAG3I,EAAOkC,EAAG2G,EACxC,CAEM,SAAUS,GACZ3F,EAAc1D,GAChB,MAAMU,EAAQ4I,GAAoB5F,EAAM1D,GACxC,IAAK,IAAI+B,EAAI,EAAGA,EAAIrB,EAAME,OAAQmB,IAChCrB,EAAMqB,GAAK,EAEb,OAAOrB,CACT,CAEM,SAAU4I,GACZ5F,EAAc1D,GAChB,GAAa,MAATA,GAA2B,YAAVA,GAAiC,cAAVA,EAC1C,OAAO,IAAI4G,aAAalD,GACnB,GAAc,UAAV1D,EACT,OAAO,IAAI6G,WAAWnD,GACjB,GAAc,SAAV1D,EACT,OAAO,IAAI8G,WAAWpD,GAEtB,MAAM,IAAInD,MAAM,qBAADC,OAAsBR,GAEzC,CAOM,SAAUuJ,GACZxJ,EAAiBC,GACnB,MAAM0D,EAAO3D,EAAMkJ,OAAO,CAACO,EAAMC,IAASD,EAAOC,EAAM,GACvD,GAAa,MAATzJ,GAA2B,YAAVA,EACnB,OAAOoJ,GAAcrJ,EAAO,IAAI6G,aAAalD,IACxC,GAAc,UAAV1D,EACT,OAAOoJ,GAAcrJ,EAAO,IAAI8G,WAAWnD,IACtC,GAAc,SAAV1D,EACT,OAAOoJ,GAAcrJ,EAAO,IAAI+G,WAAWpD,IAE3C,MAAM,IAAInD,MAAM,qBAADC,OAAsBR,GAEzC,CAEM,SAAU0J,GAAmC3J,GACjDA,EAAM8H,QAAQ8B,IACZnH,EACID,OAAOqH,UAAUD,IAAYA,GAAW,EACxC,IACI,6EAAAnJ,OACUT,EAAK,QAE3B,CAUM,SAAU8J,GACZC,EAAgB9D,EAAcyC,GAChC,GAAa,IAATzC,EACF,OAAO,EACF,GAAa,IAATA,EACT,OAAO8D,EAAK,GAEd,IAAIjJ,EAAQiJ,EAAKA,EAAKlJ,OAAS,GAC/B,IAAK,IAAImB,EAAI,EAAGA,EAAI+H,EAAKlJ,OAAS,IAAKmB,EACrClB,GAAS4H,EAAQ1G,GAAK+H,EAAK/H,GAE7B,OAAOlB,CACT,CAUM,SAAUkJ,GACZlJ,EAAemF,EAAcyC,GAC/B,GAAa,IAATzC,EACF,MAAO,GACF,GAAa,IAATA,EACT,MAAO,CAACnF,GAEV,MAAMiJ,EAAiB,IAAIzG,MAAM2C,GACjC,IAAK,IAAIjE,EAAI,EAAGA,EAAI+H,EAAKlJ,OAAS,IAAKmB,EACrC+H,EAAK/H,GAAKjB,KAAKkJ,MAAMnJ,EAAQ4H,EAAQ1G,IACrClB,GAASiJ,EAAK/H,GAAK0G,EAAQ1G,GAG7B,OADA+H,EAAKA,EAAKlJ,OAAS,GAAKC,EACjBiJ,CACT,CAOM,SAAUG,GAAUxI,GAOxB,OAAOA,GAAUA,EAAOyI,MAA+B,oBAAhBzI,EAAOyI,IAChD,CC3tBA,MAAMC,GAA4B,YAmB5B,MAAOC,GAaXnM,WAAAA,CAAmBoM,GAAA,KAAAA,OAAAA,EAZX,KAAAC,MAAe,CAAC,EAChB,KAAAC,aAAwD,CAAC,EAEzD,KAAAC,SAAkB,CAAC,EAM3B,KAAAC,eAAiBA,GAIfhM,KAAKiM,kBACP,CAEAC,WAAAA,CAAYC,EAAsBC,GACX,MAAjBpM,KAAKoM,WACDC,KAAMC,QAAQ,YAAcD,KAAMC,QAAQ,SAC9CC,QAAQC,KACJ,YAAAzK,OAAY/B,KAAKmM,aAAY,4DAAApK,OACIoK,EAAY,OAGrDnM,KAAKmM,aAAeA,EACpBnM,KAAKoM,SAAWA,CAClB,CAEAK,YAAAA,CACIC,EAAkBC,EAClBC,GAKF,GAJA5M,KAAK8L,aAAaY,GAAY,CAACC,eAAcC,WAId,MAA3B5M,KAAK+L,SAASW,GAAmB,CACnC,MAAMG,EAAY7M,KAAK+L,SAASW,GAC1BL,KAAMC,QAAQ,YAAcD,KAAMC,QAAQ,SAC9CC,QAAQC,KAAK,qCAADzK,OAC6B2K,EAAQ,MAAA3K,OAAK8K,EAAS,MAEjE7M,KAAKG,IAAIuM,EAAUG,E,CAEvB,CAEA,cAAMC,CAASJ,GACb,OAAIA,KAAY1M,KAAK6L,QAIrB7L,KAAK6L,MAAMa,SAAkB1M,KAAK+M,aAAaL,IAHtC1M,KAAK6L,MAAMa,EAKtB,CAEA5M,GAAAA,CAAI4M,GACF,GAAIA,KAAY1M,KAAK6L,MACnB,OAAO7L,KAAK6L,MAAMa,GAGpB,MAAMG,EAAY7M,KAAK+M,aAAaL,GACpC,GAAIlB,GAAUqB,GACZ,MAAM,IAAI/K,MACN,QAAAC,OAAQ2K,EAAQ,0EAKtB,OADA1M,KAAK6L,MAAMa,GAAYG,EAChB7M,KAAK6L,MAAMa,EACpB,CAEAM,SAAAA,CAAUN,GACR,OAAO1M,KAAKF,IAAI4M,EAClB,CAEAJ,OAAAA,CAAQI,GACN,OAAO1M,KAAKF,IAAI4M,EAClB,CAEAO,QAAAA,GACE,OAAOjN,KAAK6L,KACd,CAEA,YAAIqB,GACF,OAAOlN,KAAK6L,KACd,CAEA1L,GAAAA,CAAIuM,EAAkBtM,GACpB,GAAmC,MAA/BJ,KAAK8L,aAAaY,GACpB,MAAM,IAAI5K,MAAM,mBAADC,OACQ2K,EAAQ,oCAEjC1M,KAAK6L,MAAMa,GAAYtM,EACoB,MAAvCJ,KAAK8L,aAAaY,GAAUE,SAC9B5M,KAAK8L,aAAaY,GAAUE,QAAQxM,EAExC,CAEQ2M,YAAAA,CAAaL,GACnB,GAAmC,MAA/B1M,KAAK8L,aAAaY,GACpB,MAAM,IAAI5K,MAAM,yBAADC,OACc2K,EAAQ,qCAEvC,OAAO1M,KAAK8L,aAAaY,GAAUC,cACrC,CAEAQ,QAAAA,CAAStB,GACP7L,KAAK6L,MAAQuB,OAAOC,OAAO,CAAC,EAAGxB,EACjC,CAEAyB,KAAAA,GACEtN,KAAK6L,MAAQ,CAAC,EACd7L,KAAK+L,SAAW,CAAC,EACjB/L,KAAKiM,kBACP,CAEQA,gBAAAA,GACN,GAA2B,qBAAhBjM,KAAK4L,QACoB,qBAAzB5L,KAAK4L,OAAO2B,UACoB,qBAAhCvN,KAAK4L,OAAO2B,SAASC,OAC9B,OAGF,MAAMC,EAAYzN,KAAKgM,eAAehM,KAAK4L,OAAO2B,SAASC,QAC3D,GAAI9B,MAA6B+B,EAAW,CACxBA,EAAU/B,IAA2BgC,MAAM,KACnDtE,QAAQuE,IAChB,MAAOC,EAAKxN,GAASuN,EAASD,MAAM,KACpC1N,KAAK+L,SAAS6B,GAoBtB,SAAoBlB,EAAkBtM,GAEpC,GAAc,UADdA,EAAQA,EAAMyN,gBACoB,UAAVzN,EACtB,MAAiB,SAAVA,EACF,GAAI,GAAA2B,QAAK3B,KAAYA,EAC1B,OAAQA,EAEV,MAAM,IAAI0B,MAAM,oCAADC,OACyB3B,EAAK,cAAA2B,OAAa2K,EAAQ,KACpE,CA7B6BoB,CAAWF,EAAKxN,I,CAG3C,EAGI,SAAU4L,GAAe+B,GAC7B,MAAMC,EAAS,CAAC,EAKhB,OAJAD,EAAYE,QAAQ,8BAA+B,SAACxG,GAAW,QAAAyG,EAAA5J,UAAAnC,OAALgM,EAAC,IAAAvJ,MAAAsJ,EAAA,EAAAA,EAAA,KAAAE,EAAA,EAAAA,EAAAF,EAAAE,IAADD,EAACC,EAAA,GAAA9J,UAAA8J,GAEzD,OAKJ,SACIJ,EAAiCK,EAAcjO,GACjD4N,EAAOM,mBAAmBD,IAASC,mBAAmBlO,GAAS,GACjE,CATImO,CAAYP,EAAQG,EAAE,GAAIA,EAAE,IACrBA,EAAEK,KAAK,IAChB,GACOR,CACT,CA0BM,SAAU3B,KACd,OAAOoC,EACT,CAEO,IC9LHC,GD8LOD,GAAmB,KC5LxB,SAAUE,KACd,GAAuB,MAAnBD,GAAyB,CAE3B,IAAIE,EACJ,GAAwB,qBAAZC,OACVD,EAAKC,YACA,GAAwB,qBAAZjD,EAAAA,EACjBgD,EAAKhD,EAAAA,OACA,GAAyB,qBAAbkD,QACjBF,EAAKE,YACA,IAAsB,qBAAVC,KAGjB,MAAM,IAAIjN,MAAM,kCAFhB8M,EAAKG,I,CAIPL,GAAkBE,C,CAEpB,OAAOF,EACT,CAkBM,SAAUM,GAAapB,EAAaqB,GACxC,MAAMC,EAhBR,WACE,MAAMN,EAAKD,KAIX,OAHqB,MAAjBC,EAAGO,aACLP,EAAGO,WAAa,IAAIC,KAEfR,EAAGO,UACZ,CAUoBE,GAClB,GAAIH,EAAUjP,IAAI2N,GAChB,OAAOsB,EAAUpP,IAAI8N,GAChB,CACL,MAAM0B,EAAYL,IAElB,OADAC,EAAU/O,IAAIyN,EAAK0B,GACZJ,EAAUpP,IAAI8N,E,CAEzB,CC3CO,MAAM2B,GAAM,MAGNC,GAAO,OAGPC,GAAQ,QAGRC,GAAM,MAGNC,GAAO,OAGPC,GAAM,MAONC,GAAM,MAONC,GAAS,SAMTC,GAAS,SAMTC,GAAO,OAGPC,GAAQ,QAGRC,GAAO,OAGPC,GAAQ,QAGRC,GAAQ,QAGRC,GAAU,UASVC,GAAc,cAQdC,GAAY,YAUZC,GAAgB,gBAShBC,GAAc,cAOdC,GAAiB,iBASjBC,GAAW,WAMXC,GAAc,cAOdC,GAAgB,gBAGhBC,GAAO,OAMPC,GAAO,OAGPC,GAAc,cAOdC,GAAU,UAGVC,GAAa,aAGbC,GAAS,SAMTC,GAAS,SAUTC,GAAuB,uBAUvBC,GAAsB,sBAUtBC,GAAS,SASTC,GAAyB,yBASzBC,GAAwB,wBASxBC,GAAM,MAGNC,GAAO,OAGPC,GAAU,UAQVC,GAAS,SAQTC,GAAgB,gBAShBC,GAAgB,gBAOhBC,GAAe,eAOfC,GAAwB,wBAWxBC,GACT,sCAWSC,GACT,qCAWSC,GAAO,OAGPC,GAAa,aAQbC,GAA0B,0BAI1BC,GAA2B,2BAI3BC,GAAU,UAGVC,GAAS,SAMTC,GAAM,MAGNC,GAAU,UAGVC,GAAM,MAGNC,GAAQ,QAGRC,GAAM,MAGNC,GAAa,aAMbC,GAAQ,QAGRC,GAAM,MAGNC,GAAO,OAOPC,GAAgB,gBAGhBC,GAAQ,QAGRC,GAAW,WAGXC,GAAiB,iBAOjBC,GAAW,WAOXC,GAAW,WAGXC,GAAU,UAGVC,GAAe,eAGfC,GAAW,WAGXC,GAAO,OAGPC,GAAO,OAGPC,GAAW,WAGXC,GAAQ,QAGRC,GAAQ,QAGRC,GAAY,YAMZC,GAAO,OAGPC,GAAY,YAGZC,GAAW,WAMXC,GAAM,MAGNC,GAAQ,QAGRC,GAAa,aAGbC,GAAa,aAGbC,GAAY,YAGZC,GAAa,aAGbC,GAAa,aAMbC,GAAa,aAIbC,GAAM,MASNC,GAAU,UASVC,GAAM,MAONC,GAAU,UAGVC,GAAU,UASVC,GAAc,cASdC,GAAY,YAUZC,GAAgB,gBAUhBC,GAAoB,oBASpBC,GAAO,OAOPC,GAAM,MAONC,GAAU,UAGVC,GAAY,YAOZC,GAAM,MAGNC,GAAc,cAQdC,GAAW,WAGXC,GAAM,MAGNC,GAAW,WAGXC,GAAsB,sBAStBC,GAAsB,sBAUtBC,GAAsB,sBAUtBC,GAAW,WAGXC,GAAS,SASTC,GAAO,OAMPC,GAAQ,QAORC,GAAO,OAGPC,GAAM,MAGNC,GAAQ,QAGRC,GAAO,OAOPC,GAAe,eAQfC,GAAuB,uBAQvBC,GAAQ,QAQRC,GAAO,OAGPC,GAAa,aAGbC,GAAO,OAGPC,GAAU,UAMVC,GAAwB,wBAQxBC,GAA4B,4BAK5BC,GAAiB,iBAQjBC,GAAqB,qBAIrBC,GAAQ,QAGRC,GAAU,UAMVC,GAAQ,QAGRC,GAAQ,QAGRC,GAAY,YAMZC,GAAe,eAOfC,GAAS,SAGTC,GAAO,OAGPC,GAAQ,QAMRC,GAAM,MAGNC,GAAO,OAGPC,GAAO,OAGPC,GAAU,UAGVC,GAAW,WAGXC,GAAO,OAGPC,GAAM,MAONC,GAAiB,iBAOjBC,GAAS,SAOTC,GAAU,UAMVC,GAAsB,sBAItBC,GAAgB,gBAIhBC,GAAoB,oBAIpBC,GAAmB,mBAInBC,GAAgB,gBAOhBC,GAAoB,oBAGpBC,GAAS,SAGTC,GAAe,eAafC,GAAe,eAWfC,GAAc,cAMdC,GAAyB,yBAMzBC,GAAM,MAGNC,GAAM,MAGNC,GAAO,OAGPC,GAAO,OAMPC,GAAO,OAOPC,GAAY,YASZC,GAAY,YAMZC,GAAS,SAQTC,GAAS,SAMTC,GAAqB,qBAOrBC,GAAa,aAIbC,GAAY,YAMZC,GAAO,OAMPC,GAAa,aASbC,GAAmB,mBAQnBC,GAAe,eAgBfC,GAAc,cAiBdC,GAAuB,uBCp9B9B,SAAU5N,KACRH,KAAMC,QAAQ,YAAcD,KAAMC,QAAQ,SAC9CC,QAAQC,QAAKlI,UAEjB,CAEM,SAAU+V,KACRhO,KAAMC,QAAQ,YAAcD,KAAMC,QAAQ,SAC9CC,QAAQ8N,OAAI/V,UAEhB,CCNA,MAAMgW,GACFtL,GAAU,iBAAkB,IAAM,IAAII,KACpCmL,GACFvL,GAAU,eAAgB,IAAM,IAAII,KAoElC,SAAUoL,GACZ3Y,EAAoB4Y,GACtB,MAAM7M,EAAM8M,GAAQ7Y,EAAY4Y,GAChC,OAAOH,GAAexa,IAAI8N,EAC5B,CAMM,SAAU+M,GAAY9Y,GAC1B,OAAO0Y,GAAaza,IAAI+B,EAC1B,CAEM,SAAU+Y,GAAqBH,GACnC,MAAMI,EAAKP,GAAeQ,UACpBlX,EAAyB,GAE/B,OAAa,CACX,MAAM,KAACmX,EAAI,MAAE3a,GAASya,EAAGG,OACzB,GAAID,EACF,MAEF,MAAOnN,EAAKqN,GAAU7a,GACfX,GAAamO,EAAIF,MAAM,KAC1BjO,IAAYgb,GACd7W,EAAOmB,KAAKkW,E,CAGhB,OAAOrX,CACT,CAaM,SAAUsX,GAAeD,GAC7B,MAAM,WAACpZ,EAAU,YAAE4Y,GAAeQ,EAC5BrN,EAAM8M,GAAQ7Y,EAAY4Y,GAC5BH,GAAera,IAAI2N,IACrByM,GACI,eAAAtY,OAAeF,EAAU,sBAAAE,OACrB0Y,EAAW,4BAErBH,GAAena,IAAIyN,EAAKqN,EAC1B,CAUM,SAAUE,GAAiBF,GAC/B,MAAM,WAACpZ,GAAcoZ,EAEjBV,GAAata,IAAI4B,IAGfwK,KAAMC,QAAQ,UAChB+N,GAAS,gCAADtY,OAAiCF,EAAU,MAGvD0Y,GAAapa,IAAI0B,EAAYoZ,EAC/B,CASM,SAAUG,GACZvZ,EAAoB4Y,GACtB,MAAM7M,EAAM8M,GAAQ7Y,EAAY4Y,GAChC,IAAKH,GAAera,IAAI2N,GACtB,MAAM,IAAI9L,MACN,eAAAC,OAAeF,EAAU,sBAAAE,OACrB0Y,EAAW,wBAErBH,GAAeja,OAAOuN,EACxB,CAGM,SAAUyN,GAAmBxZ,GACjC,IAAK0Y,GAAata,IAAI4B,GACpB,MAAM,IAAIC,MAAM,iBAADC,OACMF,EAAU,oCAEjC0Y,GAAala,OAAOwB,EACtB,CAQM,SAAUyZ,GACZC,EAA+BC,GACjBZ,GAAqBW,GAC7BnS,QAAQqS,IAGdP,GADI9N,OAAOC,OAAO,CAAC,EAAGoO,EAAc,CAAChB,YAAae,MAGtD,CAEA,SAASd,GAAQ7Y,EAAoB4Y,GACnC,MAAO,GAAP1Y,OAAU0Y,EAAW,KAAA1Y,OAAIF,EAC3B,C,cClMA,MAAM6Z,G,OAEDC,IAA+BA,GAE9B,SAAUC,GAAUC,GACxB,OAAOH,GAAKI,WAAWD,GAAK,EAAM,GACpC,CAIA,MAAME,GAAWH,GAAU,oBAErBI,GAAWJ,GAAU,oBAErBK,GAAWL,GAAU,oBAE3B,SAASM,GAASnZ,GAChB,OAAOA,EAAIoZ,IAAIpZ,EAAIqZ,KAAK,IAC1B,CAEA,SAASC,GAAM5U,EAAeyC,EAAgBoS,GAC5C,MAAMnT,EAAQ1B,EAAEL,MAAM8C,EAAQA,EAASoS,GACvC,OAAOZ,GAAKa,UAAU3X,MAAM4X,KAAKrT,IAAQ,GAAM,EACjD,CAEA,SAASsT,GAAQhV,EAAeyC,GAC9B,OAAOmS,GAAM5U,EAAGyC,EAAQ,EAC1B,CAEA,SAASwS,GAAQjV,EAAeyC,GAC9B,OAAOmS,GAAM5U,EAAGyC,EAAQ,EAC1B,CAEA,SAASyS,GAAS5Z,EAAW6Z,GAE3B,OAAiB,IAAVA,EAAc7Z,EAAMA,EAAIqZ,KAAKQ,GAAOC,GAAG9Z,EAAI+Z,IAAI,GAAKF,GAC7D,CAEA,SAASG,GAAUC,EAASC,GAA4C,IAAnCC,EAAG5Y,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAGsX,GAAU,oBAE/CpY,EAAIwZ,EAAEb,IAAIc,GAAGC,IAAIA,GACrB1Z,EAAIA,EAAE2Y,IAAI3Y,EAAE4Y,KAAK,KACjB,IAAI3Y,EAAIwZ,EAAEd,IAAI3Y,GAAG0Z,IAAIA,GAGrB,OAFAzZ,EAAIA,EAAE0Y,IAAI1Y,EAAE2Y,KAAK,KACjB3Y,EAAIA,EAAEyZ,IAAIA,GACHzZ,CACT,CAeA,SAAS0Z,GACL1V,EAAeyC,EAAgB1G,EAASC,GAC1C,OAbF,SACI2Z,EAASxa,EAASya,EAASC,EAAS9Z,EAASC,GAC/CD,EAAIA,EAAE+Z,IAAIH,GACV3Z,EAAIkZ,GAASlZ,EAAE8Z,IAAI/Z,GAAG+Z,IAAID,GAAI,IAC9B,MAAM5S,EAAIlH,EAIV,OAFAA,GADAA,EAAIA,EAAE+Z,IAAI3a,IACJ2a,IAAIF,GACV5Z,EAAIA,EAAE8Z,IAAIZ,GAASnZ,EAAG,KACf,CAACA,EAAE+Z,IAAID,GAAI7Z,EAAE8Z,IAAI7S,GAC1B,CAIS8S,CACHf,GAAQhV,EAAGyC,GAASuS,GAAQhV,EAAGyC,EAAS,GAAIuS,GAAQhV,EAAGyC,EAAS,IAChEuS,GAAQhV,EAAGyC,EAAS,IAAK1G,EAAGC,EAClC,CAuDM,SAAUga,GAAchW,GAA6B,IAAd8C,EAAGjG,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAGmD,EAAEtF,OACnD,MAAMub,EAAahC,GAAKiC,WAAW,IAAI,GACvC,GAAIpT,GAAO,GACT,OAAIA,GAAO,GAxDf,SAAsB9C,GAA6B,IAAd8C,EAAGjG,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAGmD,EAAEtF,OAC3C,GAAIoI,GAAO,EAAG,CACZ,MAAM2S,EAAMjB,GAAGsB,IAAU,EAANhT,GACb/G,EAAIiZ,GAAQhV,EAAG,GAAG8V,IAAItB,IACtBxY,EAAIgZ,GAAQhV,EAAG8C,EAAM,GAG3B,OAAOwS,GAFGJ,GAASlZ,EAAG,IAAIyZ,IAAIA,GAAKK,IAAI/Z,GAC7BmZ,GAASnZ,EAAG,IAAI+Z,IAAI9Z,GAAGyZ,IAAIA,GACdA,E,CAEzB,GAAI3S,GAAO,EAAG,CACZ,MAAM2S,EAAMjB,GAAGsB,IAAU,EAANhT,GAEnB,OAAOwS,GADGL,GAAQjV,EAAG,GACFqV,IAAI,GAAGS,IAAIhT,GAAMmS,GAAQjV,EAAG8C,EAAM,GAAI2S,E,CAE3D,GAAI3S,EAAM,EAAG,CACX,MAGM8S,EAHI5V,EAAE,IACFA,EAAE8C,GAAO,IAEC,GACd+S,EAAI/S,GAFA9C,EAAE8C,EAAM,IAEI,GACtB,OAAO2R,GAASD,GAAGiB,IAAIG,GAAGlB,IAAIJ,GAAGmB,IAAII,KAAKJ,IAAIjB,G,CAEhD,OAAOA,EACT,CAkCa2B,CAAanW,EAAG8C,GAhC7B,SAAuB9C,GAA6B,IAAd8C,EAAGjG,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAGmD,EAAEtF,OAC5C,MAAM+a,EAAMjB,GAAGsB,IAAU,EAANhT,GACb/G,EAAIiZ,GAAQhV,EAAG,GAAGyV,IAAIlB,IACtBvY,EAAIgZ,GAAQhV,EAAG,GACfiD,EAAI+R,GAAQhV,EAAG8C,EAAM,GAAG2S,IAAIA,GAC5B7S,EAAIoS,GAAQhV,EAAG8C,EAAM,IAAI2S,IAAIjB,IACnC,OAAOc,GACHJ,GAASnZ,EAAE+Z,IAAI9Z,GAAI,IAAI8Z,IAAIZ,GAASjS,EAAG,KAAK6S,IAAIlT,GAChD7G,EAAE+Z,IAAIZ,GAASlZ,EAAE8Z,IAAItB,IAAK,KAAKsB,IAAI7S,GAAIwS,EAC7C,CAyBaW,CAAcpW,EAAG8C,GAErB,GAAIA,GAAO,GAChB,OA1BJ,SAAuB9C,GAA6B,IAAd8C,EAAGjG,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAGmD,EAAEtF,OAC5C,MAAM+a,EAAMjB,GAAGsB,IAAU,EAANhT,GACb/G,EAAIiZ,GAAQhV,EAAG,GAAGyV,IAAIjB,IACtBxY,EAAIgZ,GAAQhV,EAAG,GACfiD,EAAI+R,GAAQhV,EAAG8C,EAAM,GAAG2S,IAAIA,GAC5B7S,EAAIoS,GAAQhV,EAAG8C,EAAM,IAAI2S,IAAIjB,IAC7BoB,EAAIV,GAASnZ,EAAE+Z,IAAI9Z,GAAI,IAAI8Z,IAAIZ,GAASjS,EAAG,KAAK6S,IAAIlT,GACpDiT,EAAIP,GAAUM,EAAG7Z,EAAE+Z,IAAIZ,GAASlZ,EAAE8Z,IAAItB,IAAK,KAAKsB,IAAI7S,GAAIwS,GACxDY,EAAIrB,GAAQhV,EAAG,IAAIyV,IAAIA,GACvBrc,EAAI4b,GAAQhV,EAAG,IACfsW,EAAIV,EAAEE,IAAId,GAAQhV,EAAG8C,EAAM,KAAK2S,IAAIA,GACpCc,EAAIV,EAAEC,IAAId,GAAQhV,EAAG8C,EAAM,KAAK2S,IAAIA,GAC1C,OAAOH,GACHJ,GAASmB,EAAEP,IAAI1c,GAAI,IAAI0c,IAAIZ,GAASoB,EAAG,KAAKR,IAAIS,GAChDF,EAAEP,IAAIZ,GAAS9b,EAAE0c,IAAI/Z,GAAI,KAAK+Z,IAAIQ,GAAIb,EAC5C,CAWWe,CAAcxW,EAAG8C,GAK1B,IAAI3H,EAAI8a,EACJL,EAAIK,EAAKR,IAAIlB,IAAIuB,IAAI,KAErBD,EAAIpB,GAASmB,EAAEH,IAAIjB,IAAIsB,IAAI,MAAML,IAAIjB,IACrCgB,EAAI,CAACvB,GAAKwC,MAAOxC,GAAKwC,OACtBd,EAAI,CAAC1B,GAAKwC,MAAOxC,GAAKwC,OAC1Btb,EAAIA,EAAEsa,IAAIjB,IAAIsB,IAAId,GAAQhV,EAAG,IAE7B,IAAIyC,EAAS,EAEb,MAAMiU,EAAyB,IAAjB5T,EAAM,GAAM,GACpB6T,EAASD,GAAQ5T,EAAM,EAAK,IAAM,GAExC,GACE3H,EAAI+Z,GAAS/Z,EAAE2a,IAAIF,GAAGE,IAAIN,EAAE,IAAIM,IAAId,GAAQhV,EAAGyC,EAAS,IAAK,IAAIgT,IAAIlB,IACrEqB,EAAIV,GAASU,EAAEE,IAAIN,EAAE,IAAIM,IAAId,GAAQhV,EAAGyC,EAAS,KAAM,IAAIgT,IAAIlB,IAC/DpZ,EAAIA,EAAEuZ,IAAIiB,EAAE,IACZC,EAAIA,EAAEE,IAAIN,EAAE,IAAIM,IAAId,GAAQhV,EAAGyC,EAAS,KACxCoT,EAAIX,GAASW,EAAEC,IAAIH,EAAE,IAAK,IAAIF,IAAIlB,IAClCiB,EAAIE,GAA0B1V,EAAGyC,EAAQ+S,EAAE,GAAGC,IAAIlB,IAAKpZ,EAAE2a,IAAIH,EAAE,KAC/DA,EAAID,GACA1V,EAAGyC,EAAS,GAAIoT,EAAEC,IAAIH,EAAE,IAAKC,EAAEE,IAAId,GAAQhV,EAAGyC,EAAS,OAE1DoT,EAAG1a,GAAK,CAACA,EAAG0a,GACbpT,GAAU,SACHA,IAAWiU,GACpB,MAAMjB,EAAMlB,GAAGuB,IAAID,EAAEe,IAAI,KAAMvB,IAAI,IAmBnC,OAjBA5S,EAASkU,EAEThB,EAAE,GAAKA,EAAE,GAAGG,IAAKhT,EAAM,EAAK,IAC5B0S,EAAE,GAAKA,EAAE,GAAGM,IAAIH,EAAE,IAClBA,EAAE,GAAKA,EAAE,GAAGG,IAAIN,EAAE,IAElBra,EAAI+Z,GAAS/Z,EAAE2a,IAAIF,GAAGE,IAAIN,EAAE,IAAIM,IAAId,GAAQhV,EAAGyC,EAAS,IAAK,IAAIgT,IAAIA,GACrEG,EAAIV,GAASU,EAAEE,IAAIN,EAAE,IAAIM,IAAId,GAAQhV,EAAGyC,EAAS,KAAM,IAAIgT,IAAIA,GAC/Dta,EAAIA,EAAEuZ,IAAIiB,EAAE,GAAGF,IAAI,IACnBG,EAAIA,EAAEE,IAAIN,EAAE,GAAGC,IAAI,GAAGK,IAAId,GAAQhV,EAAGyC,EAAS,MAC9CoT,EAAIX,GAASW,EAAEC,IAAIH,EAAE,IAAK,IAAIF,IAAIA,GAClCD,EAAIE,GAA0B1V,EAAGyC,EAAQ+S,EAAE,GAAGC,IAAIA,GAAMta,EAAE2a,IAAIH,EAAE,KAChEA,EAAID,GACA1V,EAAGyC,EAAS,GAAIoT,EAAEC,IAAIH,EAAE,IAAKC,EAAEE,IAAId,GAAQhV,EAAGyC,EAAS,OAE1DoT,EAAG1a,GAAK,CAACA,EAAG0a,GAENP,GACHA,GAAUE,EAAE,GAAIG,EAAE,GAAIF,GAAKK,IAAIrB,GAASmB,GAAGH,IAAInB,KAAKwB,IAAID,GACxDP,GAAUE,EAAE,GAAIG,EAAE,GAAIF,GAAKK,IAAI3a,GAAIsa,EACzC,CCjLM,SAAUoB,GACZle,EAAiBmB,GACnB,MAAc,WAAVA,EACKgd,GAAane,GAGfoe,GAAa,CAACpe,GAAQmB,EAC/B,CAQM,SAAUid,GAAahb,EAAejC,GAC1C,GAAc,WAAVA,EACF,MAAM,IAAIO,MAAM,6CASlB,GAPI8C,MAAMC,QAAQrB,KAChBA,EAAIib,GAAajb,IAGf6I,KAAMC,QAAQ,UAChBmS,GAA8Bjb,EAAejC,GAfjD,SAA4BiC,EAAejC,GACzC,OAAQiC,aAAa2E,cAA0B,YAAV5G,GAChCiC,aAAa4E,YAAwB,UAAV7G,GAC3BiC,aAAa6E,YAAwB,SAAV9G,CAClC,CAaMmd,CAAmBlb,EAAGjC,GACxB,OAAOiC,EAET,GAAa,MAATjC,GAA2B,YAAVA,GAAiC,cAAVA,EAC1C,OAAO,IAAI4G,aAAa3E,GACnB,GAAc,UAAVjC,EACT,OAAO,IAAI6G,WAAW5E,GACjB,GAAc,SAAVjC,EAAkB,CAC3B,MAAMod,EAAO,IAAItW,WAAY7E,EAAerB,QAC5C,IAAK,IAAImB,EAAI,EAAGA,EAAIqb,EAAKxc,SAAUmB,EACM,IAAnCjB,KAAKuc,MAAOpb,EAAeF,MAC7Bqb,EAAKrb,GAAK,GAGd,OAAOqb,C,CAEP,MAAM,IAAI7c,MAAM,qBAADC,OAAsBR,GAEzC,CAaM,SAAUsd,KACd,OAAOxS,KAAMD,SAASyS,KACxB,CAkBM,SAAUxC,GACZyC,EAAcC,GAChB,OAAO1S,KAAMD,SAASiQ,MAAMyC,EAAMC,EACpC,CAUM,SAAUR,GAAa9W,GAA6B,IAAlBuX,EAAQ1a,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,QAEjD,OADA0a,EAAWA,GAAY,QAChB3S,KAAMD,SAAS6S,OAAOxX,EAAGuX,EAClC,CAUM,SAAUE,GAAa/V,GAAqC,IAAlB6V,EAAQ1a,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,QAEzD,OADA0a,EAAWA,GAAY,QAChB3S,KAAMD,SAAS+S,OAAOhW,EAAO6V,EACtC,CCpGM,MAAOI,GACX5f,WAAAA,CAAoB6f,EAAoCC,GAApC,KAAAD,aAAAA,EAAoC,KAAAC,OAAAA,EACxC,MAAVA,IACFtf,KAAKsf,OAAS,IAAIC,GAEtB,CAEAC,aAAAA,CAAc3d,EAAoB4d,EAAwB5e,GAExD,IAAI6e,EACJ,MAAMC,EAAsBA,KAC1BD,EAAU7e,KAEZ,IAAI+e,EACJ,MAAM9V,EAAQ+V,KACd,GAAI7f,KAAKqf,aAAa1e,iBACpBif,EAAQ5f,KAAKqf,aAAaze,KAAK+e,OAC1B,CACLA,IACA,IAAK,MAAMG,KAAUJ,EACnBI,EAAOC,WAETH,EAAQlZ,QAAQC,QAAQ,CAACqZ,SAAUH,KAAa/V,G,CAElD,GAAIuC,KAAMC,QAAQ,gCAChB,IAAK,IAAIhJ,EAAI,EAAGA,EAAIoc,EAAQvd,OAAQmB,IAAK,CACvC,MAAMwc,EAASJ,EAAQpc,GAGvBwc,EAAOngB,OAAO8L,KAAKwU,IACjBC,GAA0BD,EAAYH,EAAOve,MAAOM,I,CAe1D,MAVsB,CACpBA,aACA6d,UACAD,SACAU,OAAQP,EAAMnU,KAAK2U,GAAUA,EAAOJ,UACpCK,UAAWT,EAAMnU,KACb2U,GAAwC,MAA9BA,EAAOE,oBACbF,EAAOE,sBACP,IAGZ,CAEAC,gBAAAA,CAAiBC,GACf,MAAM,WAAC3e,EAAU,QAAE6d,EAAO,OAAES,EAAM,OAAEV,EAAM,UAAEY,GAAaG,EAEzDd,EAAQtW,QAAQxF,IACd8C,QAAQ+Z,IAAI,CAAC7c,EAAOjE,OAAQwgB,EAAQE,IAAY5U,KAAKiV,IACnD1gB,KAAKsf,OAAOiB,iBACR1e,EAAY+B,EAAQ8c,EAAe,GAAIA,EAAe,GAAIjB,EAC1DiB,EAAe,OAGzB,EAGI,SAAUR,GACZ1X,EAAsBjH,EAAUM,GAClC,GAAc,YAAVN,EAEF,OAAO,EAET,IAAK,IAAI+B,EAAI,EAAGA,EAAIkF,EAAKrG,OAAQmB,IAAK,CACpC,MAAMmF,EAAMD,EAAKlF,GACjB,GAAIoF,MAAMD,KAASE,SAASF,GAG1B,OADA8D,QAAQC,KAAK,SAADzK,OAAU0G,EAAG,uBAAA1G,OAAsBF,EAAU,OAClD,C,CAGX,OAAO,CACT,CAEM,MAAO0d,GACXgB,gBAAAA,CACIlS,EAAczK,EAAgB4E,EAC9B2X,EAAgCV,EAChCY,GACF,MAAMzf,EAAyB,kBAAXuf,EAAsBN,GAAc,GAAD9d,OAAIoe,EAAM,MAAM,GAC7BA,EAAc,MAClDQ,EAAad,GAAcxR,EAAM,IACjC9G,EAAO3D,EAAO2D,KACdtC,EAAOrB,EAAOqB,KACd3D,EAAQue,GAAcjc,EAAOtC,MAAMsf,WAAY,IACrD,IAAIC,EAAyB,GAE7B,IAAK,MAAMxS,KAAQoR,EAAQ,CACzB,MAAMqB,EAAQrB,EAAOpR,GACrB,GAAa,MAATyS,EAAe,CAGjB,MAAMC,EAAaD,EAAMxf,OAASsC,EAAOtC,MACnC0f,EAAYD,EAAW5e,OAC7B0e,GAAsB,GAAA9e,OACfsM,EAAI,MAAAtM,OAAKif,EAAS,MAAAjf,OAAKif,EAAY,EAAID,EAAa,GAAE,I,EAIjExU,QAAQ8N,IAAI,KAADtY,OACF4e,EAAU,QAAA5e,OAAOnB,EAAI,QAAAmB,OAAOwF,EAAI,MAAAxF,OAAKT,EAAK,QAAAS,OAAOkD,EAAI,QAAAlD,OACtD8e,EAAsB,QAAA9e,OAAOse,GACjC,mBAAoB,YAAa,aAAc,gBAC/C,eAAgB,mBACtB,ECjHI,SAAUY,GACZzY,EAA2BlH,EAAiBC,EAC5C2f,GACF,MAAMlX,EAAUD,GAAezI,GACzB6f,EAcR,SACI3Y,EAA2BlH,EAAiBC,EAC5CyI,GACF,MAAMjE,EAAIf,GAAc1D,GAClB8f,EAAUpX,EAAQA,EAAQ7H,OAAS,GACnCgf,EAAY,IAAIvc,MAAMwc,GAASC,KAAK,GACpC9Z,EAAOjG,EAAMa,OACbmf,EACQ,cAAV/f,EAAwBggB,GAAoB/Y,GAAQA,EAExD,GAAIjB,EAAO,EACT,IAAK,IAAIia,EAAM,EAAGA,EAAMzb,EAAIqb,EAASI,IAAO,CAC1C,MAAMtX,EAASsX,EAAMJ,EACrB,IAAK,IAAInZ,EAAI,EAAGA,EAAImZ,EAASnZ,IAC3BkZ,EAAUlZ,GAAK5F,KAAKQ,IAChBse,EAAUlZ,GACVwZ,GAAYH,EAAepX,EAASjC,GAAI,EAAG1G,GAAOY,O,CAI5D,OAAOgf,CACT,CAnCoBO,CAAwBlZ,EAAMlH,EAAOC,EAAOyI,GACxDzC,EAAOjG,EAAMa,OACbwf,EAAYC,GAAkBpZ,EAAMlH,EAAOC,EAAOyI,EAASmX,GAC3DU,EAAQ,CAAC,UAQf,OAPIX,IACFW,EAAM9c,KAAK,YAADhD,OAAaR,IACvBsgB,EAAM9c,KAAK,WAADhD,OAAYwF,IACtBsa,EAAM9c,KAAK,aAADhD,OAAcT,EAAK,MAC7BugB,EAAM9c,KAAK,cAEb8c,EAAM9c,KAAK4c,EAAUna,IAAIsa,GAAK,OAASA,GAAGtT,KAAK,OACxCqT,EAAMrT,KAAK,KACpB,CAyBA,SAASiT,GACL1e,EAAqCgf,EAAaxgB,GACpD,IAAIygB,EAYJ,OAVEA,EADEpd,MAAMC,QAAQ9B,GACP,GAAAhB,OAAGkgB,WAAWlf,EAAI,GAAGmf,QA/CJ,IA+CmC,UAAAngB,OACtDkgB,WAAWlf,EAAI,GAAGmf,QAhDC,IAgD8B,KAC/C7Y,GAAStG,GACT,IAAHhB,OAAOgB,EAAG,KACG,SAAVxB,EACA4gB,GAAgBpf,GAEhBkf,WAAWlf,EAAImf,QAtDE,IAsD8BtB,WAGnD1a,GAAS8b,EAAQD,EAC1B,CAEA,SAASI,GAAgBlF,GACvB,OAAa,IAANA,EAAU,QAAU,MAC7B,CAEA,SAAS2E,GACLpZ,EAA2BlH,EAAiBC,EAC5CyI,EAAmBmX,GAAkC,IAAbiB,IAAM9d,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,KAAAA,UAAA,GAChD,MAAM+d,EAA8B,cAAV9gB,EAAwB,EAAI,EAEhD0D,EAAO3D,EAAM,GACbiG,EAAOjG,EAAMa,OACnB,GAAa,IAAToF,EAAY,CACd,GAAc,cAAVhG,EAAuB,CAEzB,MAAO,CAACkgB,GADaF,GAAoB/Y,GACR,GAAI,EAAGjH,G,CAE1C,MAAc,SAAVA,EACK,CAAC4gB,GAAgB3Z,EAAK,KAExB,CAACA,EAAK,GAAGoY,W,CAGlB,GAAa,IAATrZ,EAAY,CACd,GAAItC,EAvFsB,GAuFQ,CAChC,MAAMqd,EAtFuB,EAsFsBD,EAEnD,IAAIE,EAAY3d,MAAM4X,KAClBhU,EAAKpB,MAAM,EAAGkb,IACdE,EAAW5d,MAAM4X,KAAqChU,EAAKpB,OAC1DnC,EA3FwB,GA2Faod,EACtCpd,EAAOod,IAKX,MAJc,cAAV9gB,IACFghB,EAAYhB,GAAoBgB,GAChCC,EAAWjB,GAAoBiB,IAE1B,CACL,IACAD,EAAU/a,IAAI,CAAC5E,EAAGU,IAAMme,GAAY7e,EAAGue,EAAU7d,GAAI/B,IAChDiN,KAAK,MACV,UACAgU,EACKhb,IACG,CAAC5E,EAAGU,IAAMme,GACN7e,EAAGue,EAAUlc,EAzGE,EAyGkC3B,GAAI/B,IAC5DiN,KAAK,MACV,I,CAOJ,MAAO,CACL,KAJY,cAAVjN,EAAwBggB,GAAoB/Y,GACpB5D,MAAM4X,KAAoBhU,IAIxChB,IAAI,CAAC5E,EAAGU,IAAMme,GAAY7e,EAAGue,EAAU7d,GAAI/B,IAClDiN,KAAK,MACV,I,CAKJ,MAAMiU,EAAWnhB,EAAM8F,MAAM,GACvBsb,EAAa1Y,EAAQ5C,MAAM,GAC3Bub,EAAS3Y,EAAQ,GAAKqY,EACtBR,EAAkB,GACxB,GAAI5c,EAjIwB,GAiIM,CAChC,IAAK,IAAI3B,EAAI,EAAGA,EAhIe,EAgIiBA,IAAK,CACnD,MAAMwG,EAAQxG,EAAIqf,EACZxE,EAAMrU,EAAQ6Y,EACpBd,EAAM9c,QAAQ6c,GACVpZ,EAAKpB,MAAM0C,EAAOqU,GAAMsE,EAAUlhB,EAAOmhB,EAAYvB,GACrD,G,CAENU,EAAM9c,KAAK,OACX,IAAK,IAAIzB,EAAI2B,EAxIkB,EAwIiB3B,EAAI2B,EAAM3B,IAAK,CAC7D,MAAMwG,EAAQxG,EAAIqf,EACZxE,EAAMrU,EAAQ6Y,EACpBd,EAAM9c,QAAQ6c,GACVpZ,EAAKpB,MAAM0C,EAAOqU,GAAMsE,EAAUlhB,EAAOmhB,EAAYvB,EACrD7d,IAAM2B,EAAO,G,OAGnB,IAAK,IAAI3B,EAAI,EAAGA,EAAI2B,EAAM3B,IAAK,CAC7B,MAAMwG,EAAQxG,EAAIqf,EACZxE,EAAMrU,EAAQ6Y,EACpBd,EAAM9c,QAAQ6c,GACVpZ,EAAKpB,MAAM0C,EAAOqU,GAAMsE,EAAUlhB,EAAOmhB,EAAYvB,EACrD7d,IAAM2B,EAAO,G,CAGrB,MAAM2d,EAAe,IAATrb,EAAa,IAAM,GAC/Bsa,EAAM,GAAK,IAAMA,EAAM,GAAKe,EAC5B,IAAK,IAAItf,EAAI,EAAGA,EAAIue,EAAM1f,OAAS,EAAGmB,IACpCue,EAAMve,GAAK,IAAMue,EAAMve,GAAKsf,EAE9B,IAAIC,EAAa,MACjB,IAAK,IAAIvf,EAAI,EAAGA,EAAIiE,EAAMjE,IACxBuf,GAAc,KAIhB,OAFAhB,EAAMA,EAAM1f,OAAS,GACjB,IAAM0f,EAAMA,EAAM1f,OAAS,GAAK,KAAOigB,EAAS,GAAKS,GAClDhB,CACT,CAEA,SAASN,GAAoB/Y,GAE3B,MAAMsa,EAAyC,GAC/C,IAAK,IAAIxf,EAAI,EAAGA,EAAIkF,EAAKrG,OAAQmB,GAAK,EACpCwf,EAAc/d,KAAK,CAACyD,EAAKlF,GAAIkF,EAAKlF,EAAI,KAExC,OAAOwf,CACT,CCzJM,MAAOC,GAMXvjB,WAAAA,CAAY8B,EAA2BC,EAAUF,GAI/C,GAJqC,KAAAE,MAAAA,EACrCvB,KAAKsB,MAAQA,EAAM8F,QACnBpH,KAAKiF,KAAO4a,GAAmBve,GAEjB,MAAVD,EAAgB,CAClB,MAAM0E,EAAI1E,EAAOc,OACjB0d,EACI9Z,IAAM/F,KAAKiF,KACX,IAAM,qBAAAlD,OAAqBgE,EAAC,wDAAAhE,OACE/B,KAAKiF,KAAI,M,CAE7C,GAAc,cAAV1D,EACF,MAAM,IAAIO,MACN,8JAIN9B,KAAKqB,OAASA,GAAUwe,GAAuBte,EAAOvB,KAAKiF,MAC3DjF,KAAKgK,QAAUD,GAAezI,EAChC,CAUAnB,GAAAA,CAAIC,GAA2C,QAAA8N,EAAA5J,UAAAnC,OAAdkJ,EAAc,IAAAzG,MAAAsJ,EAAA,EAAAA,EAAA,KAAAE,EAAA,EAAAA,EAAAF,EAAAE,IAAd/C,EAAc+C,EAAA,GAAA9J,UAAA8J,GACzB,IAAhB/C,EAAKlJ,SACPkJ,EAAO,CAAC,IAEVwU,EACIxU,EAAKlJ,SAAWnC,KAAKuH,KACrB,IAAM,uCAAAxF,OAAuCsJ,EAAKlJ,OAAM,8BAAAJ,OACjC/B,KAAKuH,KAAI,MAEpC,MAAMnF,EAAQpC,KAAKoL,WAAWC,GAC9BrL,KAAKqB,OAAOe,GAAShC,CACvB,CASAN,GAAAA,GAAqB,QAAAkjB,EAAA1e,UAAAnC,OAAdkJ,EAAc,IAAAzG,MAAAoe,GAAAC,EAAA,EAAAA,EAAAD,EAAAC,IAAd5X,EAAc4X,GAAA3e,UAAA2e,GACC,IAAhB5X,EAAKlJ,SACPkJ,EAAO,CAAC,IAEV,IAAI/H,EAAI,EACR,IAAK,MAAM4f,KAAO7X,EAAM,CACtB,GAAI6X,EAAM,GAAKA,GAAOljB,KAAKsB,MAAMgC,GAAI,CACnC,MAAMW,EAAM,qCAAAlC,OAAqCsJ,EAAI,wBAAAtJ,OAC/B/B,KAAKsB,OAC3B,MAAM,IAAIQ,MAAMmC,E,CAElBX,G,CAEF,IAAIlB,EAAQiJ,EAAKA,EAAKlJ,OAAS,GAC/B,IAAK,IAAImB,EAAI,EAAGA,EAAI+H,EAAKlJ,OAAS,IAAKmB,EACrClB,GAASpC,KAAKgK,QAAQ1G,GAAK+H,EAAK/H,GAElC,OAAOtD,KAAKqB,OAAOe,EACrB,CAEAgJ,UAAAA,CAAWC,GACT,GAAkB,IAAdrL,KAAKuH,KACP,OAAO,EACF,GAAkB,IAAdvH,KAAKuH,KACd,OAAO8D,EAAK,GAEd,IAAIjJ,EAAQiJ,EAAKA,EAAKlJ,OAAS,GAC/B,IAAK,IAAImB,EAAI,EAAGA,EAAI+H,EAAKlJ,OAAS,IAAKmB,EACrClB,GAASpC,KAAKgK,QAAQ1G,GAAK+H,EAAK/H,GAElC,OAAOlB,CACT,CAEAkJ,UAAAA,CAAWlJ,GACT,GAAkB,IAAdpC,KAAKuH,KACP,MAAO,GACF,GAAkB,IAAdvH,KAAKuH,KACd,MAAO,CAACnF,GAEV,MAAMiJ,EAAiB,IAAIzG,MAAM5E,KAAKsB,MAAMa,QAC5C,IAAK,IAAImB,EAAI,EAAGA,EAAI+H,EAAKlJ,OAAS,IAAKmB,EACrC+H,EAAK/H,GAAKjB,KAAKkJ,MAAMnJ,EAAQpC,KAAKgK,QAAQ1G,IAC1ClB,GAASiJ,EAAK/H,GAAKtD,KAAKgK,QAAQ1G,GAGlC,OADA+H,EAAKA,EAAKlJ,OAAS,GAAKC,EACjBiJ,CACT,CAEA,QAAI9D,GACF,OAAOvH,KAAKsB,MAAMa,MACpB,CAOAghB,QAAAA,GACE,OAAOC,KAAYC,WAAWrjB,KAAKqB,OAAQrB,KAAKsB,MAAOtB,KAAKuB,MAE9D,EA8CF,IAAI6hB,GAAiC,KAEjCE,GAAuB,KAEvBC,GAA8C,KA0D5C,MAAOC,GA6BXhkB,WAAAA,CAAY8B,EAAoBC,EAAiBxB,EAAgB0jB,GAXjE,KAAAC,MAAO,EAgLG,KAAAC,oBAAqB,EApK7B3jB,KAAKsB,MAAQA,EAAM8F,QACnBpH,KAAKuB,MAAQA,GAAS,UACtBvB,KAAKiF,KAAO4a,GAAmBve,GAC/BtB,KAAKgK,QAAUD,GAAezI,GAC9BtB,KAAKD,OAASA,EACdC,KAAKyjB,GAAKA,EACVzjB,KAAK4jB,SAAY5jB,KAAKuH,KAAO,EAAIvH,KAAKuH,KAAKqZ,WAAa,QAC1D,CAEA,QAAIrZ,GACF,OAAOvH,KAAKsB,MAAMa,MACpB,CAOA,YAAM0hB,GACJ,MAAMrb,QAAaxI,KAAKL,OACxB,OAAO2jB,GAAUO,OAAO7jB,KAAKsB,MAAOtB,KAAKuB,MAAYiH,EACvD,CAMAsb,UAAAA,GACE,OAAOR,GAAUO,OAAO7jB,KAAKsB,MAAOtB,KAAKuB,MAAYvB,KAAK+f,WAC5D,CAQA,WAAM9d,GACJ,MAAMuG,QAAaxI,KAAKL,OACxB,OAAOgL,GAAc3K,KAAKsB,MAAOkH,EAAqB,cAAfxI,KAAKuB,MAE9C,CAQAwiB,SAAAA,GACE,OAAOpZ,GACI3K,KAAKsB,MAAOtB,KAAK+f,WAA2B,cAAf/f,KAAKuB,MAE/C,CAQA,UAAM5B,GACJK,KAAKgkB,kBACL,MAAMrkB,EAAOyjB,KAAYtiB,KAAKd,KAAKD,QACnC,GAAmB,WAAfC,KAAKuB,MAAoB,CAC3B,MAAM4H,QAAcxJ,EACpB,IACE,OAAOwJ,EAAM3B,IAAI/D,GAAKoc,GAAkBpc,G,CACxC,MAAAwgB,GACA,MAAM,IAAIniB,MACN,gG,EAIR,OAAOnC,CACT,CAsCAukB,SAAAA,CAAUjjB,GAER,OADAjB,KAAKgkB,kBACEZ,KAAYpiB,UAAUhB,KAAKD,OAAQkB,EAC5C,CAQA8e,QAAAA,GACE/f,KAAKgkB,kBACL,MAAMrkB,EAAOyjB,KAAYriB,SAASf,KAAKD,QACvC,GAAmB,WAAfC,KAAKuB,MACP,IACE,OAAQ5B,EAAsB6H,IAAI/D,GAAKoc,GAAkBpc,G,CAEzD,MAAAwgB,GACA,MAAM,IAAIniB,MACN,gG,CAIR,OAAOnC,CACT,CAGA,WAAMwJ,GACJnJ,KAAKgkB,kBACL,MAAMrkB,QAAayjB,KAAYtiB,KAAKd,KAAKD,QACzC,MAAmB,WAAfC,KAAKuB,MACA5B,EAEA,IAAI0I,WAAY1I,EAAoBkkB,OAE/C,CAOAjiB,OAAAA,GACM5B,KAAKmkB,aAGTf,KAAYgB,cAAcpkB,MAC1BA,KAAK2jB,oBAAqB,EAC5B,CAGA,cAAIQ,GACF,OAAOnkB,KAAK2jB,kBACd,CAEAK,eAAAA,GACE,GAAIhkB,KAAKmkB,WACP,MAAM,IAAIriB,MAAM,sBAEpB,CAUAuiB,KAAAA,GAAqB,IAAfnD,EAAO5c,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,IAAAA,UAAA,GACX,OAAOgf,GAAUe,MAAMrkB,KAAMkhB,EAC/B,CAMAoD,KAAAA,GAEE,OADAtkB,KAAKgkB,kBACEV,GAAUgB,MAAMtkB,KACzB,CAOA4gB,QAAAA,GAAwB,IAAfM,EAAO5c,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,IAAAA,UAAA,GAEd,OAAO2c,GADMjhB,KAAK+f,WACU/f,KAAKsB,MAAOtB,KAAKuB,MAAO2f,EACtD,CAEAqD,IAAAA,CAAqBhjB,GAEnB,OADAvB,KAAKgkB,kBACEV,GAAUiB,KAAKvkB,KAAWuB,EACnC,CACAijB,QAAAA,GAA0D,IAAjDC,IAASngB,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,KAAAA,UAAA,GAAS+J,EAAa/J,UAAAnC,OAAA,EAAAmC,UAAA,QAAAC,EAAEhD,EAAgB+C,UAAAnC,OAAA,EAAAmC,UAAA,QAAAC,EAExD,OADAvE,KAAKgkB,kBACEZ,KAAYsB,aAAa1kB,KAAMykB,EAAWpW,EAAM9M,EAEzD,EAGF6L,OAAOuX,eAAenB,GAAQoB,OAAOC,YAAa,CAChDzkB,MAAQ0kB,KAMGA,GAA6B,MAAjBA,EAASnlB,MAAqC,MAArBmlB,EAAS/E,UACvB,MAA5B+E,EAASd,kBAQRhV,GAAU,SAAU,IAClBwU,IAwCL,MAAOuB,WAAwCvB,GAGnDhkB,WAAAA,CACIwlB,EAAgCP,EAAoBpW,EACpD4W,GACFC,MACIF,EAAa1jB,MAAO0jB,EAAazjB,MAAOyjB,EAAajlB,OAAQklB,GAH/B,KAAAR,UAAAA,EAIlCzkB,KAAKqO,KAAOA,CACd,CAUAhB,MAAAA,CAAO8X,GACL,GAAIA,EAAS5jB,QAAUvB,KAAKuB,MAC1B,MAAM,IAAIO,MACN,2BAAAC,OAA2BojB,EAAS5jB,MAAK,6BAAAQ,OACtB/B,KAAKuB,MAAK,iBAEnC,IAAKse,GAAiBsF,EAAS7jB,MAAOtB,KAAKsB,OACzC,MAAM,IAAIQ,MACN,2BAAAC,OAA2BojB,EAAS7jB,MAAK,6BAAAS,OACtB/B,KAAKsB,MAAK,iBAEnC8hB,KAAYgB,cAAcpkB,MAC1BA,KAAKD,OAASolB,EAASplB,OACvBqjB,KAAY1iB,OAAOV,KAAM,KAC3B,CAEA4B,OAAAA,GACEwhB,KAAYgC,gBAAgBplB,MAC5BA,KAAK2jB,oBAAqB,CAC5B,EChiBK,IAAK0B,GAqBPC,GAOAC,GAOAC,GAOAC,GDyfLrY,OAAOuX,eAAeI,GAAUH,OAAOC,YAAa,CAClDzkB,MAAQ0kB,GACCA,aAAoBtB,IAA6B,MAAnBsB,EAASzX,QAC1CyX,EAASzX,kBAAkBqY,WCtiBnC,SAAYL,GACVA,EAAA,QACAA,EAAA,QACAA,EAAA,QACAA,EAAA,QACAA,EAAA,QACAA,EAAA,QACAA,EAAA,OACD,CARD,CAAYA,KAAAA,GAAI,KAqBhB,SAAKC,GACHA,EAAA,kBACAA,EAAA,cACAA,EAAA,aACAA,EAAA,qBACD,CALD,CAAKA,KAAAA,GAAiB,KAOtB,SAAKC,GACHA,EAAA,kBACAA,EAAA,cACAA,EAAA,YACAA,EAAA,qBACD,CALD,CAAKA,KAAAA,GAAgB,KAOrB,SAAKC,GACHA,EAAA,kBACAA,EAAA,gBACAA,EAAA,eACAA,EAAA,qBACD,CALD,CAAKA,KAAAA,GAAmB,KAOxB,SAAKC,GACHA,EAAA,oBACAA,EAAA,kBACAA,EAAA,iBACAA,EAAA,qBACD,CALD,CAAKA,KAAAA,GAAqB,KAO1B,MAAME,GAAgB,CACpB,QAAWH,GACX,MAASF,GACT,KAAQC,GACR,UAAaE,IAGT,SAAUG,GAAWC,EAAiBC,GAC1C,GAAc,WAAVD,GAAgC,WAAVC,EAAoB,CAC5C,GAAc,WAAVD,GAAgC,WAAVC,EACxB,MAAO,SAET,MAAM,IAAIhkB,MAAM,kBAADC,OAAmB8jB,EAAK,UAAA9jB,OAAS+jB,G,CAElD,OAAOH,GAAcE,GAAOC,EAC9B,CAGM,SAAUC,GAAWC,GACzB,OAAOJ,GAAWI,EAAM,QAC1B,CC/GM,SAAUC,GAAiCziB,EAAMC,GACrD,GAAID,EAAEjC,QAAUkC,EAAElC,MAChB,MAAO,CAACiC,EAAGC,GAEb,MAAMlC,EAAQqkB,GAAWpiB,EAAEjC,MAAOkC,EAAElC,OACpC,MAAO,CAACiC,EAAE+gB,KAAKhjB,GAAQkC,EAAE8gB,KAAKhjB,GAChC,CAEM,SAAU2kB,GAAiB1iB,EAAWC,GAC1CM,EACIP,EAAEjC,QAAUkC,EAAElC,MACd,IAAM,2BAAAQ,OAA2ByB,EAAEjC,MAAK,oBAAAQ,OACzB0B,EAAElC,MAAK,sBAC5B,CAEM,SAAU4kB,GAAeC,EAAgBC,GAC7C,OAAOA,EAAWC,KAAK1jB,GAAKA,EAAE6gB,KAAO2C,EAAO3C,GAC9C,CAcM,SAAU8C,GAAsB3iB,GACpC,MAAM4iB,EAAiB,GAGvB,OADAC,GAAoB7iB,EAAQ4iB,EADf,IAAIE,KAEVF,CACT,CAEA,SAASC,GACLE,EAA4BH,EAAgBI,GAC9C,GAAiB,MAAbD,EACF,OAEF,GAAIA,aAAqBnD,GAEvB,YADAgD,EAAKzhB,KAAK4hB,GAGZ,GAekBE,EAfFF,GAgBT/hB,MAAMC,QAAQgiB,IAAuB,kBAARA,EAflC,OAcJ,IAAoBA,EAXlB,MAAMC,EAAWH,EACjB,IAAK,MAAMI,KAAKD,EAAU,CACxB,MAAM/jB,EAAM+jB,EAASC,GAChBH,EAAK3mB,IAAI8C,KACZ6jB,EAAKrJ,IAAIxa,GACT0jB,GAAoB1jB,EAAKyjB,EAAMI,G,CAGrC,CCoBA,SAASI,GAELC,GAGF,OAAyE,MAAjEA,EAAmDplB,UAC7D,CAEA,MAAMqlB,GAAN1nB,WAAAA,GAEE,KAAA2nB,oBAAwC,CAAC,EAEzC,KAAAC,eAAiB,EACjB,KAAA9K,SAAW,EACX,KAAA+K,WAAa,EACb,KAAAC,iBAAmB,EACnB,KAAAC,eAAiB,EAMjB,KAAAC,cAAgB,EAGhB,KAAAC,YAAc,EAId,KAAAC,WAA2B,GAK3B,KAAAC,kBAA8B,GAC9B,KAAAC,YAAc,EAEd,KAAAC,WAAa,IAAIjoB,QAOjB,KAAAkoB,WAAY,EACZ,KAAAC,cAA6B,CAC3BC,SAAU,EACVC,WAAY,EACZC,UAAW,EACXC,QAAS,GACTvkB,OAAQ,KACR,eAAIwkB,GAEE,OAAOxjB,MAAM4X,KAAK,IAAIkK,IAAI1mB,KAAKmoB,QAAQ3gB,IAAIuf,GAAKA,EAAE1Y,OACpD,EAQR,CALEzM,OAAAA,GACE,IAAK,MAAMymB,KAAgBroB,KAAKmnB,oBAC9BnnB,KAAKmnB,oBAAoBkB,GAAczmB,SAE3C,EAGI,MAAO0mB,GAgBX9oB,WAAAA,CAAmBiP,GAAA,KAAAA,IAAAA,EAbnB,KAAA8Z,SAA0C,CAAC,EAC3C,KAAAC,gBAKI,CAAC,EAKG,KAAAC,qBAAuB,EAG7BzoB,KAAK0oB,MAAQ,IAAIxB,EACnB,CAEA,WAAMyB,GACJ,GAA+B,MAA3B3oB,KAAK4oB,mBACP,OAAO5oB,KAAK4oB,mBAAmBnd,KAAK,QAEtC,GAA4B,MAAxBzL,KAAK6oB,gBACP,OAEF,MAAMC,EAAiB9oB,KAAK+oB,oBAE5B,IAAK,IAAIzlB,EAAI,EAAGA,EAAIwlB,EAAe3mB,OAAQmB,IAAK,CAC9C,MAAMmX,EAAcqO,EAAexlB,GAEnC,SADsBtD,KAAKgpB,kBAAkBvO,GAAawO,QAGxD,kBADMjpB,KAAKkpB,WAAWzO,E,CAK1B,MAAM,IAAI3Y,MACN,yEAEN,CAEA,WAAIrC,GACF,GAA+B,MAA3BO,KAAK4oB,mBACP,MAAM,IAAI9mB,MACN,YAAAC,OAAY/B,KAAKya,YAAW,yCAA5B,kFAIN,GAA4B,MAAxBza,KAAK6oB,gBAAyB,CAChC,MAAM,KAACxa,EAAI,UAAE8a,GAAanpB,KAAKopB,kCAC/B,GAAID,EACF,MAAM,IAAIrnB,MACN,iCAAAC,OAAiCsM,EAAI,uBAArC,oGAINrO,KAAKkpB,WAAW7a,E,CAElB,OAAOrO,KAAK6oB,eACd,CAEAQ,YAAAA,GACE,OAAOjc,OAAOkc,KAAKtpB,KAAKwoB,gBAC1B,CAEAe,WAAAA,CAAY9O,GACV,KAAMA,KAAeza,KAAKuoB,UAAW,CAGnC,KAAI9N,KAAeza,KAAKwoB,iBAOtB,OAAO,KAPgC,CACvC,MAAM,UAACW,GAAanpB,KAAKgpB,kBAAkBvO,GAC3C,GAAI0O,EAEF,OAAO,I,EAMb,OAAOnpB,KAAKuoB,SAAS9N,EACvB,CAEA+O,kBAAAA,CAAmB/O,GAEjB,OAAMA,KAAeza,KAAKwoB,gBAGnBxoB,KAAKwoB,gBAAgB/N,GAAagP,QAFhC,IAGX,CAEAC,eAAAA,CACIjP,EACAgP,GACY,IAAZE,EAAQrlB,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,EACb,OAAImW,KAAeza,KAAKwoB,iBACtBnO,GACI,GAAAtY,OAAG0Y,EAAW,2EAEX,IAETza,KAAKwoB,gBAAgB/N,GAAe,CAACgP,UAASE,aACvC,EACT,CAEA,gBAAMT,CAAWzO,GACf,GAAyC,MAArCza,KAAKwoB,gBAAgB/N,GACvB,MAAM,IAAI3Y,MAAM,iBAADC,OAAkB0Y,EAAW,4BAG9C,GADAza,KAAKya,YAAcA,EACe,MAA9Bza,KAAKuoB,SAAS9N,GAAsB,CACtCza,KAAK6oB,gBAAkB,KACvB,MAAM,QAACI,EAAO,UAAEE,GAAanpB,KAAKgpB,kBAAkBvO,GAEpD,KADe0O,QAAkBF,EAAUA,GAEzC,OAAO,C,CAQX,OALAjpB,KAAK6oB,gBAAkB7oB,KAAKuoB,SAAS9N,GACrCza,KAAK4pB,yBAEL5pB,KAAK6pB,SAAW,IAAIzK,GAASpf,KAAK6oB,kBAE3B,CACT,CAEQe,sBAAAA,GACUhP,GAAqB5a,KAAKya,aAClCrR,QAAQ0gB,IACU,MAApBA,EAAOC,WACTD,EAAOC,UAAU/pB,KAAK6oB,kBAG5B,CAEQmB,wBAAAA,CAAyBvP,GACfG,GAAqBH,GAC7BrR,QAAQ0gB,IACY,MAAtBA,EAAOG,aACTH,EAAOG,YAAYjqB,KAAKuoB,SAAS9N,KAGvC,CAQQuO,iBAAAA,CAAkBvO,GAExB,MAAMyP,EAAuBlqB,KAAKwoB,gBAAgB/N,GAClD,GAA4B,MAAxByP,EACF,MAAM,IAAIpoB,MAAM,6BAADC,OACkB0Y,EAAW,6BAG9C,IACE,MAAMhb,EAAUyqB,EAAqBT,UAMrC,IAAIhqB,GAAaA,aAAmBc,GACR,oBAAjBd,EAAQgM,KA2BjB,OADAzL,KAAKuoB,SAAS9N,GAAehb,EACtB,CAACwpB,SAAS,EAAME,WAAW,GA3BI,CACtC,MAAMgB,IAAcnqB,KAAKyoB,qBACnBQ,EACFxpB,EACKgM,KAAKod,KAEAsB,EAAYnqB,KAAKyoB,wBAGrBzoB,KAAKuoB,SAAS9N,GAAeoO,EAC7B7oB,KAAK4oB,mBAAqB,MACnB,IAERwB,MAAMC,IAEDF,EAAYnqB,KAAKyoB,uBAGrBzoB,KAAK4oB,mBAAqB,KAC1BvO,GAAS,6BAADtY,OAA8B0Y,EAAW,YACjDJ,GAASgQ,EAAIC,OAASD,EAAIE,WAJjB,IAQnB,OADAvqB,KAAK4oB,mBAAqBK,EACnB,CAACA,UAASE,WAAW,E,EAK9B,MAAOkB,GAGP,OAFAhQ,GAAS,6BAADtY,OAA8B0Y,EAAW,YACjDJ,GAASgQ,EAAIC,OAASD,EAAIE,SACnB,CAACtB,SAAS,EAAOE,WAAW,E,CAEvC,CAEAqB,aAAAA,CAAc/P,GACZ,KAAMA,KAAeza,KAAKwoB,iBACxB,MAAM,IAAI1mB,MAAM,GAADC,OAAI0Y,EAAW,mCAE5Bza,KAAKya,cAAgBA,GAA0C,MAA3Bza,KAAK4oB,oBAG3C5oB,KAAKyoB,uBAGHhO,KAAeza,KAAKuoB,WACtBvoB,KAAKgqB,yBAAyBvP,GAC9Bza,KAAKuoB,SAAS9N,GAAa7Y,iBACpB5B,KAAKuoB,SAAS9N,WAGhBza,KAAKwoB,gBAAgB/N,GAGxBza,KAAKya,cAAgBA,IACvBza,KAAK4oB,mBAAqB,KAC1B5oB,KAAKya,YAAc,KACnBza,KAAK6oB,gBAAkB,KAE3B,CAEQE,iBAAAA,GACN,GAAiD,IAA7C3b,OAAOkc,KAAKtpB,KAAKwoB,iBAAiBrmB,OACpC,MAAM,IAAIL,MAAM,iCAElB,OAAOsL,OAAOkc,KAAKtpB,KAAKwoB,iBAAiBxgB,KAAK,CAACxE,EAAWC,IAEjDzD,KAAKwoB,gBAAgB/kB,GAAGkmB,SAC3B3pB,KAAKwoB,gBAAgBhlB,GAAGmmB,SAEhC,CAEQP,+BAAAA,GAEN,MAAMN,EAAiB9oB,KAAK+oB,oBAE5B,IAAK,IAAIzlB,EAAI,EAAGA,EAAIwlB,EAAe3mB,OAAQmB,IAAK,CAC9C,MAAMmX,EAAcqO,EAAexlB,IAC7B,QAAC2lB,EAAO,UAAEE,GAAanpB,KAAKgpB,kBAAkBvO,GACpD,GAAI0O,GAAaF,EACf,MAAO,CAAC5a,KAAMoM,EAAa0O,Y,CAG/B,MAAM,IAAIrnB,MACN,yEAEN,CAEA5B,QAAAA,CAAST,EAAwBM,GAC/B,MAAM0qB,EAAOzqB,KAAK0oB,MAAMb,WAAW/nB,IAAIC,GACjC2qB,EAAaD,EAAKhrB,QAClB4B,EAASrB,KAAKe,SAAShB,GACvBS,EAAWkqB,EAAWlqB,SAAST,GAGrC2qB,EAAWxpB,YAAYnB,GAAQ,GAC/B0qB,EAAKhrB,QAAUA,EACfA,EAAQ+B,KAAKzB,EAAQsB,EAAQopB,EAAKnpB,MAAOmpB,EAAKlpB,MAAOf,GACjDR,KAAK2qB,0BAGP3qB,KAAK0oB,MAAMf,kBAAkB3nB,KAAK0oB,MAAMf,kBAAkBxlB,OAAS,IAEvE,CAEAyoB,IAAAA,CAAgCC,EAA6BC,GAE3D,IAuBIlnB,EAvBAyK,EAAe,KACnB,GAAU,MAANyc,EAAY,CAEd,GAAwB,oBAAbD,EACT,MAAM,IAAI/oB,MAAM,uCAElBgpB,EAAKD,C,KACA,CAEL,GAAwB,kBAAbA,KAA2BA,aAAoBvhB,QACxD,MAAM,IAAIxH,MACN,kFAGN,GAAkB,oBAAPgpB,EACT,MAAM,IAAIhpB,MACN,kFAGNuM,EAAOwc,C,CAKT,OAAO7qB,KAAK+qB,UACR,IAAM/qB,KAAKgrB,WAAW3c,GAAO,IAAMrO,KAAKirB,SAASrnB,GAAS,KACxDA,EAASknB,IACLlnB,aAAkB8C,SACpB6F,QAAQ2e,MAAM,2CAETtnB,GAEf,CAEQmnB,SAAAA,CAAajhB,EAAmBqU,EAAiBtd,GACvDiJ,IACA,IACE,MAAMqhB,EAAMtqB,IAEZ,OADAsd,IACOgN,C,CACP,MAAOC,GAEP,MADAjN,IACMiN,C,CAEV,CAGQC,YAAAA,GACN,OAAO/C,GAAO+C,cAChB,CAGQC,cAAAA,GACN,OAAOhD,GAAOgD,gBAChB,CAQQhH,KAAAA,CAAM1hB,GACZ,MAAMya,EAAYkO,GAAOC,UAAU7X,GAAU,CAAC/Q,MACxC6c,EAAS,CAAC7c,KAehB,OADA5C,KAAKyrB,YAAYzrB,KAAK0oB,MAAMgD,YAAYrd,KAAMoR,EAAQ,CAACpC,GAbzCsO,IAAU,CACtB/oB,EAAGA,KACD,MACMgpB,EAAa,CAAChpB,EAAG+oB,GACjBE,EAAQ,CAACtqB,MAFD,WAId,OAAOgqB,GAAOC,UACH1a,GAAM8a,EAENC,MAGS,GACgD,CAAC,GAClExO,CACT,CAeAmO,SAAAA,CACI3pB,EAAoB4d,EAAwBoM,GACtB,MAApB7rB,KAAKya,aAMPza,KAAKP,QAGP,KAD6D,MAA3C+a,GAAU3Y,EAAY7B,KAAKya,cAE3C,MAAM,IAAI3Y,MAAM,WAADC,OAAYF,EAAU,kCAAAE,OACjC/B,KAAKya,YAAW,MAEtB,OAAOza,KAAK8rB,cAAc,CAACjqB,aAAY4d,SAAQoM,SACjD,CAEQlB,sBAAAA,GACN,OAAO3qB,KAAKyO,IAAInC,QAAQ,UAC1B,CAEQyf,qBAAAA,CACJlqB,EAAoBmqB,EACpBC,GACF,MAAMC,EAAkBlsB,KAAKP,QAAQa,aAGrC,IAAI6rB,EAAmB,EACvBF,EAAS7iB,QAAQqhB,IAGf0B,GAAoC,cAAf1B,EAAKlpB,MAAwB,EAAI,IAQxD,MAAM6qB,EACFpsB,KAAK0oB,MAAMf,kBAAkB3nB,KAAK0oB,MAAMf,kBAAkBxlB,OAAS,GACjEkqB,EACFH,EAAkBF,EAAmBG,EAAmBC,EAC5D,GAAIC,EAAgB,EAClB,MAAM,IAAIvqB,MACN,YAAAC,OAAY/B,KAAKya,YAAW,sCAAA1Y,OACxBsqB,EAAa,8BAAAtqB,OAA6BF,EAAU,KAEhE,CAOQiqB,aAAAA,CACJQ,GAEF,IAAI5M,EACA6M,EAAkB,GACtB,MAAMC,EAAWxsB,KAAKwsB,WAEhBC,EAAoBzsB,KAAK0oB,MAAMpM,SAC/BoQ,EAAqB1sB,KAAK0oB,MAAMrB,WAMtC,IAAIsF,EAUAC,EAdA5sB,KAAK2qB,0BACP3qB,KAAK0oB,MAAMf,kBAAkB5iB,KAAK,GAIZ,MAApB/E,KAAKya,aAMPza,KAAKP,QAKP,MAAMotB,EAAoB7F,GAA6BsF,GACnDA,EAAazqB,WACa,MAA1B7B,KAAK0oB,MAAMgD,YAAsB1rB,KAAK0oB,MAAMgD,YAAYrd,KAAO,GAMnE,GAAI2Y,GAA6BsF,GAAe,CAC9C,MAAM,WAACzqB,EAAU,OAAE4d,EAAM,MAAEoM,GAASS,EACZ,MAApBtsB,KAAKya,aAMPza,KAAKP,QAEP,MAAMqqB,EAAStP,GAAU3Y,EAAY7B,KAAKya,aAC1CoF,EACc,MAAViK,EACA,IAAM,kCAAN/nB,OAAwCF,EAAU,mBAAAE,OAC9C/B,KAAKya,YAAW,MAExBkS,EAAaA,KACX,MAAMX,EAAmBhsB,KAAKP,QAAQa,aACtCssB,EAAM9C,EAAO6C,WAAW,CAAClN,SAAQoM,QAAOpsB,QAASO,KAAKP,UACtD,MAAMwsB,EAAWrnB,MAAMC,QAAQ+nB,GAAOA,EAAM,CAACA,GACzC5sB,KAAK2qB,0BACP3qB,KAAK+rB,sBAAsBlqB,EAAYmqB,EAAkBC,GAG3D,MAAMa,EAAab,EAASzkB,IAAKulB,GAIC,MAA3BA,EAAmBxlB,KACfwlB,EAEF/sB,KAAKgtB,yBAAyBD,IAQvC,GAAIP,EAAU,CACZ,MAAMS,EACFjtB,KAAKktB,sBAAsBrrB,EAAY4d,EAAQqN,GACnDP,EAAQvsB,KAAKmtB,2BAA2BF,E,CAE1C,OAAOH,E,KAEJ,CACL,MAAM,YAACM,GAAed,EAEhBe,EAA0BC,IAIzBd,IAGLD,EAAQe,EAAQ9lB,IAAI4e,GAAUpmB,KAAKutB,KAAKvtB,KAAKskB,MAAM8B,OAGrDuG,EAAaA,KACX,MAAMX,EAAmBhsB,KAAKP,QAAQa,aACtCssB,EAAM5sB,KAAK4qB,KAAK,IAAMwC,EAAYptB,KAAKP,QAAS4tB,IAChD,MAAMG,EAAQ5oB,MAAMC,QAAQ+nB,GAAOA,EAAM,CAACA,GAK1C,OAJI5sB,KAAK2qB,0BAEP3qB,KAAK+rB,sBAAsBc,EAAmBb,EAAkBwB,GAE3DA,E,CAOX,MAAM,OAAC/N,EAAM,MAAEoM,GAASS,EAClBmB,EAAgBzG,GAA6BsF,GAC/C,KACAA,EAAamB,cAEjB,IAAIjN,EAmCJ,OAlCAxgB,KAAK+qB,UAED,IAAM/qB,KAAK0oB,MAAMjB,cAAe,IAAMznB,KAAK0oB,MAAMjB,cAAe,KACzDznB,KAAKyO,IAAInC,QAAQ,UAAatM,KAAK0oB,MAAMZ,WAG5CtH,EAAgBxgB,KAAK6pB,SAASrK,cAC1BqN,EAAmBpN,EAAQ,IAAMkN,KACjC3sB,KAAKyO,IAAInC,QAAQ,UACnBtM,KAAK6pB,SAAStJ,iBAAiBC,GAEjCd,EAAUc,EAAcd,SAPxBA,EAAUiN,MAWdH,GACFxsB,KAAKyrB,YACDoB,EAAmBpN,EAAQC,EAAS+N,EAAelB,EAAOV,GAG5D7rB,KAAK0oB,MAAMZ,WACb9nB,KAAK0oB,MAAMX,cAAcI,QAAQpjB,KAAK,CACpCsJ,KAAMwe,EACNa,WAAY1tB,KAAK0oB,MAAMpM,SAAWmQ,EAClCkB,mBAAoB3tB,KAAK0oB,MAAMpM,SAC/BsR,aAAc5tB,KAAK0oB,MAAMrB,WAAaqF,EACtCmB,qBAAsB7tB,KAAK0oB,MAAMrB,WACjCyG,YAAa1gB,OAAOkc,KAAK7J,GAAQjY,IAC7BoG,GAAsB,MAAf6R,EAAO7R,GAAe6R,EAAO7R,GAAKtM,MAAQ,MACrDysB,aAAcrO,EAAQlY,IAAIwmB,GAAQA,EAAK1sB,OACvC2sB,aAAczN,EAAcL,OAC5BE,UAAWG,EAAcH,YAGrBzb,MAAMC,QAAQ+nB,GAAOlN,EAAUA,EAAQ,EACjD,CAOQyN,0BAAAA,CAA2BG,GACjC,MAAMf,EAAQe,EAAQ9lB,IAAI4e,GAAUpmB,KAAKutB,KAAKvtB,KAAKskB,MAAM8B,KACzD,OAAOmG,CACT,CASQW,qBAAAA,CACJrrB,EAAoB4d,EACpBC,GACF,MAAMwO,EAAavT,GAAY9Y,GAC/B,GAAkB,MAAdqsB,EAAoB,CACtB,MAAMC,EAAyBD,EAAWC,cAAgB,GACpDC,EAA2BF,EAAWE,eAAiB,GAI7D,IAAIC,EACAH,EAAWI,eACbzO,EACIjb,MAAMC,QAAQ4a,GACd,IAAM,0DAEV4O,EAAqBjhB,OAAOkc,KAAK7J,GAAQjY,IAAKoG,GAAQ6R,EAAO7R,KAE7DygB,EAAqBF,EAAa3mB,IAAK+mB,GAAc9O,EAAO8O,IAG9D,MAAMC,EACF9O,EAAQ+O,OAAO,CAACC,EAAGprB,IAAM8qB,EAAc9qB,IAE3C,OAAO+qB,EAAmBtsB,OAAOysB,E,CAQnC,MAAO,EACT,CAOAnL,UAAAA,CACIhiB,EAAoBC,EAAiBC,EACrC9B,GACF,GAAc,MAAV4B,EACF,MAAM,IAAIS,MAAM,iDAElBP,EAAQA,GAAS,UACjB9B,EAAUA,GAAWO,KAAKP,QAC1B,IAAIkvB,EAActtB,EACJ,WAAVE,GAAsBse,GAAcxe,EAAO,MAC7CstB,EAAettB,EAAoBmG,IAAI6C,GAAKwV,GAAkBxV,KAEhE,MAAMtK,EAASN,EAAQ2B,MAAMutB,EAAartB,EAAOC,GAC3C4M,EAAI,IAAIqV,GAAOliB,EAAOC,EAAOxB,EAAQC,KAAKqrB,gBAIhD,GAHArrB,KAAK4uB,YAAYzgB,EAAG1O,GAGN,WAAV8B,EAAoB,CACtB,MAAMkpB,EAAOzqB,KAAK0oB,MAAMb,WAAW/nB,IAAIC,GACjCioB,EAAW9e,GAAqBylB,GACtC3uB,KAAK0oB,MAAMpM,UAAY0L,EAAWyC,EAAKthB,MACvCshB,EAAKthB,MAAQ6e,C,CAEf,OAAO7Z,CACT,CAQA0gB,oBAAAA,CACE9uB,EAAgBuB,EAAiBC,EACjC9B,GAEA,MAAMooB,EAAyB,CAAC9nB,SAAQuB,QAAOC,MAD/CA,EAAQA,GAAS,WAEjB,OAAOvB,KAAKgtB,yBAAyBnF,EAAYpoB,EACnD,CAOAutB,wBAAAA,CAAyBnF,EAAwBpoB,GAE/C,MAAM,OAACM,EAAM,MAAEuB,EAAK,MAAEC,GAASsmB,EACzB1Z,EAAI,IAAIqV,GAAOliB,EAAOC,EAAOxB,EAAQC,KAAKqrB,gBAEhD,OADArrB,KAAK4uB,YAAYzgB,EAAG1O,GACb0O,CACT,CAEAuW,YAAAA,CACIM,GACgB,IADMP,IAASngB,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,KAAAA,UAAA,GAAS+J,EAAa/J,UAAAnC,OAAA,EAAAmC,UAAA,QAAAC,EACrDhD,EAAgB+C,UAAAnC,OAAA,EAAAmC,UAAA,QAAAC,EAClB8J,EAAOA,GAAQrO,KAAKsrB,iBAAiB1K,WACxB,MAATrf,GAAiBA,IAAUyjB,EAAazjB,QAC1CyjB,EAAeA,EAAaT,KAAKhjB,IAEnC,MAAM0b,EAAI,IAAI8H,GAASC,EAAcP,EAAWpW,EAAMrO,KAAKqrB,gBAC3D,GAA8C,MAA1CrrB,KAAK0oB,MAAMvB,oBAAoBlK,EAAE5O,MACnC,MAAM,IAAIvM,MAAM,sBAADC,OAAuBkb,EAAE5O,KAAI,4BAI9C,OAFArO,KAAK0oB,MAAMvB,oBAAoBlK,EAAE5O,MAAQ4O,EACzCjd,KAAKU,OAAOuc,EAAGjd,KAAKP,SACbwd,CACT,CAEA2R,WAAAA,CAAYprB,EAAW/D,GACrBO,KAAK0oB,MAAMrB,aACK,WAAZ7jB,EAAEjC,OACJvB,KAAK0oB,MAAMpB,mBAIb,IAAIne,EAAQ,EACI,cAAZ3F,EAAEjC,OAAqC,WAAZiC,EAAEjC,QAC/B4H,EAAQ3F,EAAEyB,KAAO4a,GAAqBrc,EAAEjC,QAE1CvB,KAAK0oB,MAAMpM,UAAYnT,EAElBnJ,KAAK0oB,MAAMb,WAAW5nB,IAAIuD,EAAEzD,UAC/BC,KAAK0oB,MAAMnB,iBACXvnB,KAAK0oB,MAAMb,WAAW1nB,IAAIqD,EAAEzD,OAAQ,CAClCN,QAASA,GAAWO,KAAKP,QACzB8B,MAAOiC,EAAEjC,MACTD,MAAOkC,EAAElC,MACT6H,WAIE3F,aAAauhB,IACjB/kB,KAAK8uB,MAAMtrB,EAEf,CAOA9C,MAAAA,CAAO8C,EAAW/D,GAChBO,KAAK4uB,YAAYprB,EAAG/D,GACpBO,KAAKP,QAAQiB,OAAO8C,EAAEzD,OACxB,CAEAgvB,YAAAA,CAAahvB,EAAgBN,GACvBO,KAAK0oB,MAAMb,WAAW5nB,IAAIF,IAC1BC,KAAK0oB,MAAMb,WAAW/nB,IAAIC,GAAQN,UAAYA,IAChDO,KAAK0oB,MAAMb,WAAWxnB,OAAON,GAC7BC,KAAK0oB,MAAMnB,iBAEf,CACAnD,aAAAA,CAAc5gB,GACZ,IAAKxD,KAAK0oB,MAAMb,WAAW5nB,IAAIuD,EAAEzD,QAC/B,OAEF,MAAM0qB,EAAOzqB,KAAK0oB,MAAMb,WAAW/nB,IAAI0D,EAAEzD,QASzC,GAPAC,KAAK0oB,MAAMrB,aACK,WAAZ7jB,EAAEjC,QACJvB,KAAK0oB,MAAMpB,mBACXtnB,KAAK0oB,MAAMpM,UAAYmO,EAAKthB,OAId,cAAZ3F,EAAEjC,OAAqC,WAAZiC,EAAEjC,MAAoB,CACnD,MAAM4H,EAAQ3F,EAAEyB,KAAO4a,GAAqBrc,EAAEjC,OAC9CvB,KAAK0oB,MAAMpM,UAAYnT,C,CAIrBshB,EAAKhrB,QAAQyB,YAAYsC,EAAEzD,SAC7BC,KAAK+uB,aAAavrB,EAAEzD,OAAQ0qB,EAAKhrB,QAMrC,CAEAuvB,gBAAAA,GACE,IAAK,MAAMC,KAAWjvB,KAAK0oB,MAAMvB,oBAAqB,CACpD,MAAMlK,EAAIjd,KAAK0oB,MAAMvB,oBAAoB8H,GACzCjvB,KAAKolB,gBAAgBnI,E,CAEzB,CAEAmI,eAAAA,CAAgBnI,GACdjd,KAAKokB,cAAcnH,GAC2B,MAA1Cjd,KAAK0oB,MAAMvB,oBAAoBlK,EAAE5O,cAC5BrO,KAAK0oB,MAAMvB,oBAAoBlK,EAAE5O,KAE5C,CAEA5M,MAAAA,GACE,MAAMgpB,EAAOzqB,KAAKP,QAAQgC,SAa1B,OAZAgpB,EAAKpD,WAAarnB,KAAK0oB,MAAMrB,WAC7BoD,EAAKlD,eAAiBvnB,KAAK0oB,MAAMnB,eACjCkD,EAAKnO,SAAWtc,KAAK0oB,MAAMpM,SACvBtc,KAAK0oB,MAAMpB,iBAAmB,IAChCmD,EAAKyE,YAAa,EACE,MAAhBzE,EAAK0E,UACP1E,EAAK0E,QAAU,IAEjB1E,EAAK0E,QAAQpqB,KACT,0EAGC0lB,CACT,CAEA,aAAM2E,CAAQC,GAEZrvB,KAAK0oB,MAAMZ,WAAY,EAEvB,MAAMwH,EAAatvB,KAAK0oB,MAAMpM,SACxBiT,EAAkBvvB,KAAK0oB,MAAMrB,WAEnCrnB,KAAK0oB,MAAMX,cAAcI,QAAU,GACnCnoB,KAAK0oB,MAAMX,cAAcnkB,aAAeyrB,IAExCrvB,KAAK0oB,MAAMZ,WAAY,EAEvB9nB,KAAK0oB,MAAMX,cAAcG,UAAY7lB,KAAKQ,OACnC7C,KAAK0oB,MAAMX,cAAcI,QAAQ3gB,IAAI6C,GAAKA,EAAEsjB,qBACnD3tB,KAAK0oB,MAAMX,cAAcC,SAAWhoB,KAAK0oB,MAAMpM,SAAWgT,EAC1DtvB,KAAK0oB,MAAMX,cAAcE,WACrBjoB,KAAK0oB,MAAMrB,WAAakI,EAC5B,IAAK,MAAMzF,KAAU9pB,KAAK0oB,MAAMX,cAAcI,QAC5C2B,EAAOmE,mBAAqBnE,EAAOmE,aACnCnE,EAAOzJ,gBAAkByJ,EAAOzJ,UAElC,OAAOrgB,KAAK0oB,MAAMX,aACpB,CAEAyE,QAAAA,GACE,OAAOxsB,KAAK0oB,MAAMlB,cAAgB,GAAgC,IAA3BxnB,KAAK0oB,MAAMjB,WACpD,CAEQgE,WAAAA,CACJ5pB,EAAoB4d,EAAwBC,EAC5C8P,EAAyBjD,EAAiBV,GAC5C,MAAM4D,EACF,CAAChM,GAAIzjB,KAAK0oB,MAAMtB,iBAAkBvlB,aAAY4d,SAAQC,UAAS6M,SAE7D2B,EAAavT,GAAY9Y,GACb,MAAdqsB,IACFsB,EAAgBtB,EAAWwB,UAER,MAAjBF,IACFC,EAASE,SAAYC,IAGnBA,EAAMA,EAAIpoB,IAAI,CAACmkB,EAAIroB,KACjB,GAAU,MAANqoB,EAAY,CACd,MAAM7L,EAASJ,EAAQpc,GACjBkF,EAAOqX,GAAyBC,EAAO7a,KAAM6a,EAAOve,OAC1D,OAAOvB,KAAKqjB,WAAW7a,EAAMsX,EAAOxe,MAAOwe,EAAOve,M,CAEpD,OAAOoqB,IAIF6D,EAAcI,EAAIztB,OAAS,EAAIytB,EAAMA,EAAI,GAAIrD,EAAOV,KAG/D7rB,KAAK0oB,MAAMmH,WAAW9qB,KAAK0qB,EAC7B,CAEAlC,IAAAA,CAAuB3pB,GAErB,OADAA,EAAO8f,MAAO,EACP9f,CACT,CAEQksB,SAAAA,GAC2B,IAA7B9vB,KAAK0oB,MAAMlB,gBACbxnB,KAAK0oB,MAAMmH,WAAa,IAE1B7vB,KAAK0oB,MAAMlB,eACb,CAEQuI,OAAAA,GACN/vB,KAAK0oB,MAAMlB,eACb,CAMAwD,UAAAA,CAAW3c,GACT,MAAM2hB,EAAwB,CAC5BlB,MAAO,GACPzgB,KAAM,gBACNoV,GAAIzjB,KAAK0oB,MAAMd,eAEbvZ,IACF2hB,EAAU3hB,KAAOA,GAEnBrO,KAAK0oB,MAAMhB,WAAW3iB,KAAKirB,GAC3BhwB,KAAK0oB,MAAMgD,YAAcsE,CAC3B,CAMA/E,QAAAA,CAASrnB,GACP,MAAMqsB,EAAyB1J,GAAsB3iB,GAC/CssB,EACF,IAAIxJ,IAAIuJ,EAAuBzoB,IAAI2G,GAAKA,EAAEsV,KAG9C,IAAK,IAAIngB,EAAI,EAAGA,EAAItD,KAAK0oB,MAAMgD,YAAYoD,MAAM3sB,OAAQmB,IAAK,CAC5D,MAAM8iB,EAASpmB,KAAK0oB,MAAMgD,YAAYoD,MAAMxrB,GACvC8iB,EAAO1C,MAASwM,EAA0BjwB,IAAImmB,EAAO3C,KACxD2C,EAAOxkB,S,CAIX,MAAMuuB,EAAWnwB,KAAK0oB,MAAMhB,WAAW0I,MACvCpwB,KAAK0oB,MAAMgD,YAA+C,IAAjC1rB,KAAK0oB,MAAMhB,WAAWvlB,OAC3C,KACAnC,KAAK0oB,MAAMhB,WAAW1nB,KAAK0oB,MAAMhB,WAAWvlB,OAAS,GAGzD8tB,EAAuB7mB,QAAQgd,IAGxBA,EAAO1C,MAAQ0C,EAAOiK,UAAYF,EAAS1M,IAC9CzjB,KAAK8uB,MAAM1I,IAGjB,CAQAkK,SAAAA,CACIzvB,EAAY0vB,EAAc5E,GACF,IAAxB6E,EAAgBlsB,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,IAAAA,UAAA,GAGlB,GAFAub,EACI0Q,EAAGpuB,OAAS,EAAG,IAAM,6CACf,MAANwpB,GAA2B,YAAbA,EAAGpqB,MACnB,MAAM,IAAIO,MAAM,0CAADC,OAA2C4pB,EAAGpqB,MAAK,MAGpE,MAAM8b,EAAIrd,KAAK+qB,UACX,IAAM/qB,KAAK8vB,YAAa,IAAM9vB,KAAK+vB,UACnC,IAAM/vB,KAAK4qB,KAAK,UAAW/pB,IAE/Bgf,EACIxC,aAAamG,GACb,IAAM,kDAEV,MAAMiN,ECnjCJ,SACFC,EAAkBH,EAAclT,GAGlC,MAAMsT,EAA8C,CAAC,EAC/CC,EAA0C,CAAC,EACjD,IAAK,IAAIttB,EAAI,EAAGA,EAAIitB,EAAGpuB,OAAQmB,IAC7BqtB,EAAaJ,EAAGjtB,GAAGmgB,KAAM,EAG3B,IAAK,IAAIngB,EAAI,EAAGA,EAAIotB,EAAKvuB,OAAQmB,IAAK,CACpC,MAAMutB,EAAOH,EAAKptB,GACZwtB,EAAaD,EAAKpR,OACxB,IAAK,MAAM8O,KAAauC,EAAY,CAClC,MAAMhQ,EAAQgQ,EAAWvC,GAEzB,IAAIwC,GAAgB,EACpB,IAAK,IAAI9oB,EAAI,EAAGA,EAAIsoB,EAAGpuB,OAAQ8F,IAC7B,GAAI0oB,EAAa7P,EAAM2C,IAAK,CAC1BoN,EAAKnR,QAAQtW,QAAQ0W,GAAU6Q,EAAa7Q,EAAO2D,KAAM,GACzDsN,GAAgB,EAChBH,EAAWC,EAAKpN,KAAM,EACtB,K,CAIJ,GAAIsN,EACF,K,EAMN,MAAMC,EAAgD,CAAC,EACvDA,EAAe3T,EAAEoG,KAAM,EACvB,MAAMwN,EAAwC,CAAC,EAE/C,IAAK,IAAI3tB,EAAIotB,EAAKvuB,OAAS,EAAGmB,GAAK,EAAGA,IAAK,CACzC,MAAMutB,EAAOH,EAAKptB,GACZwtB,EAAaD,EAAKpR,OAGxB,IAAK,IAAIxX,EAAI,EAAGA,EAAI4oB,EAAKnR,QAAQvd,OAAQ8F,IACvC,GAAI+oB,EAAeH,EAAKnR,QAAQzX,GAAGwb,IAAK,CACtC,IAAK,MAAM8K,KAAauC,EACtBE,EAAeF,EAAWvC,GAAW9K,KAAM,EAC3CwN,EAASJ,EAAKpN,KAAM,EAEtB,K,EAMN,MAAMgN,EAA2B,GACjC,IAAK,IAAIntB,EAAI,EAAGA,EAAIotB,EAAKvuB,OAAQmB,IAAK,CACpC,MAAMutB,EAAOH,EAAKptB,GAElB,GAAIstB,EAAWC,EAAKpN,KAAOwN,EAASJ,EAAKpN,IAAK,CAE5C,MAAMyN,EAA8C,CAAC,EACrD,IAAK,MAAM3C,KAAasC,EAAKpR,OAAQ,CACnC,MAAM0R,EAAYN,EAAKpR,OAAO8O,GAC1BoC,EAAaQ,EAAU1N,MACzByN,EAAa3C,GAAa4C,E,CAK9B,MAAMC,EAAahkB,OAAOC,OAAO,CAAC,EAAGwjB,GACrCO,EAAW3R,OAASyR,EACpBE,EAAW1R,QAAUmR,EAAKnR,QAE1B+Q,EAAa1rB,KAAKqsB,E,EAItB,OAAOX,CACT,CDq+ByBY,CAAqBrxB,KAAK0oB,MAAMmH,WAAYU,EAAIlT,GACrE,IAAKmT,GAA4C,IAAxBC,EAAatuB,QAAgBouB,EAAGpuB,OAAS,EAChE,MAAM,IAAIL,MACN,uIAKN,OAAO9B,KAAK4qB,KAAK,WAAY,KAC3B,MAAM0G,EAAuD,CAAC,EAC9DA,EAAuBjU,EAAEoG,IAAa,MAANkI,EAwJtC,SAAcrqB,GACZ,MAAMD,EAASuJ,GAAmB5F,GAAc1D,GAAQ,WACxD,OAAOiqB,GAAOlI,WAAWhiB,EAAQC,EAAO,UAC1C,CA3JoDiwB,CAAKlU,EAAE/b,OAASqqB,ECt+B9D,SACF6F,EACAf,EAA0B7F,EAC1BrN,GAEF,IAAK,IAAIja,EAAImtB,EAAatuB,OAAS,EAAGmB,GAAK,EAAGA,IAAK,CACjD,MAAMutB,EAAOJ,EAAantB,GAEpBssB,EAAgB,GAYtB,GAXAiB,EAAKnR,QAAQtW,QAAQqoB,IACnB,MAAMC,EAAaF,EAA6BC,EAAEhO,IAChC,MAAdiO,EACF9B,EAAI7qB,KAAK2sB,GAIT9B,EAAI7qB,KAAK,QAIQ,MAAjB8rB,EAAKlB,SACP,MAAM,IAAI7tB,MACN,+DAAAC,OACO8uB,EAAKhvB,WAAU,MAI5B,MAAM8vB,EAAiBd,EAAKlB,SAASC,GAErC,IAAK,MAAMrB,KAAasC,EAAKpR,OAAQ,CACnC,KAAM8O,KAAaoD,GACjB,MAAM,IAAI7vB,MACN,iCAAAC,OAAiCwsB,EAAS,oCAAAxsB,OACZqL,OAAOkc,KAAKqI,GAAe,MAI/D,MAAMC,EAAKhH,EAAK,IAAM+G,EAAepD,MACrC,GAAiB,YAAbqD,EAAGrwB,MACL,MAAM,IAAIO,MACN,4BAAAC,OACI8uB,EAAKhvB,WAAU,+BAAAE,OAChBwsB,EAAS,yCAAAxsB,OAAwC6vB,EAAGrwB,MAAK,MAElE,MAAMqB,EAAIiuB,EAAKpR,OAAO8O,GACtB,IAAK1O,GAAiB+R,EAAGtwB,MAAOsB,EAAEtB,OAChC,MAAM,IAAIQ,MACN,4BAAAC,OACI8uB,EAAKhvB,WAAU,gCAAAE,OACfwsB,EAAS,iBAAAxsB,OAAgB6vB,EAAGtwB,MAAK,4BAA0B,2BAAAS,OACpCa,EAAEtB,MAAK,MAGxC,GAA0C,MAAtCkwB,EAA6B5uB,EAAE6gB,IACjC+N,EAA6B5uB,EAAE6gB,IAAMmO,MAChC,CACL,MAAMC,EAAcL,EAA6B5uB,EAAE6gB,IACnD+N,EAA6B5uB,EAAE6gB,IAAMlG,EAAIsU,EAAaD,GACtDC,EAAYjwB,S,GAIpB,CD26BMkwB,CACIR,EAAwBb,EAExB5vB,GAAKb,KAAK4qB,KAAK/pB,GAEf0c,IACJ,MAAMwU,EAAQxB,EAAG/oB,IAAI5E,GAAK0uB,EAAuB1uB,EAAE6gB,KAYnD,OAViC,IAA7BzjB,KAAK0oB,MAAMlB,gBAGbxnB,KAAK0oB,MAAMmH,WAAWzmB,QAAQynB,IAC5B,IAAK,MAAMzK,KAAUyK,EAAKtE,MACxBnG,EAAOxkB,YAGX5B,KAAK0oB,MAAMmH,WAAa,MAEnB,CAACzvB,MAAOid,EAAG0U,UAEtB,CAEAC,UAAAA,CAA6BnxB,GAAwB,IAAAoxB,EAAA,KAKnD,OAHApS,EACIA,GAAgBhf,GAChB,IAAM,qDACH,WAA2B,QAAAqN,EAAA5J,UAAAnC,OAAvBsd,EAAgB,IAAA7a,MAAAsJ,GAAAE,EAAA,EAAAA,EAAAF,EAAAE,IAAhBqR,EAAgBrR,GAAA9J,UAAA8J,GAMzB,IAAI+c,EALJtL,EACIJ,EAAO/X,MAAMyG,GAAKA,aAAaqV,IAC/B,IAAM,oEAOV,MAAM0O,EAA2B,CAAC,EAClCzS,EAAOrW,QAAQ,CAAC0X,EAAOxd,KACrB4uB,EAAS5uB,GAAKwd,IAoChB,OAAOmR,EAAKnG,cAAc,CACxBsB,YAlCkCA,CAACsB,EAAGyD,KACtChH,EAAMtqB,KAAS4e,EAAQ0S,GACvBtS,EACIsL,EAAI/qB,iBAAiBojB,GACrB,IAAM,8FAEV3D,EACIA,GAAgBsL,EAAIuE,UACpB,IAAM,oGAEHvE,EAAI/qB,OAyBXqtB,cAtBoBA,CAAC9B,EAAOY,KAC5B,MAAM6F,EAAUjH,EAAIuE,SAAS/D,EAAIY,GAC3BwF,EAAkBntB,MAAMC,QAAQutB,GAAWA,EAAU,CAACA,GAC5DvS,EACIkS,EAAM5vB,SAAWsd,EAAOtd,OACxB,IAAM,uKAGV0d,EACIkS,EAAMrqB,MAAMyG,GAAKA,aAAaqV,IAC9B,IAAM,wIAGV,MAAM6O,EAAyC,CAAC,EAIhD,OAHAN,EAAM3oB,QAAQ,CAACkpB,EAAMhvB,KACnB+uB,EAAQ/uB,GAAK,IAAMgvB,IAEdD,GAMP5S,OAAQyS,GAEZ,CACF,CAEAnxB,QAAAA,CAAShB,GAGP,OADaC,KAAK0oB,MAAMb,WAAW/nB,IAAIC,GAC3BN,QAAQsB,SAAShB,EAC/B,CACAe,IAAAA,CAAKf,GAGH,OADaC,KAAK0oB,MAAMb,WAAW/nB,IAAIC,GAC3BN,QAAQqB,KAAKf,EAC3B,CAEAiB,SAAAA,CAAUjB,EAAgBkB,GAGxB,OADajB,KAAK0oB,MAAMb,WAAW/nB,IAAIC,GAC3BN,QAAQuB,UAAUjB,EAAQkB,EACxC,CAEA,UAAML,CAAKyuB,GACT,MAAMvlB,EAAQ+U,KACR0T,QAAmBvyB,KAAKP,QAAQmB,KAAKyuB,GAE3C,OADAkD,EAAWC,OAAS3T,KAAQ/U,EACrByoB,CACT,CAQQzD,KAAAA,CAAwBlrB,GAM9B,OAL8B,MAA1B5D,KAAK0oB,MAAMgD,cACb9nB,EAAOysB,QAAUrwB,KAAK0oB,MAAMgD,YAAYjI,GACxCzjB,KAAK0oB,MAAMgD,YAAYoD,MAAM/pB,KAAKnB,IAG7BA,CACT,CAEA,uBAAIujB,GACF,OAAOnnB,KAAK0oB,MAAMvB,mBACpB,CAMA7Z,KAAAA,GAEEtN,KAAKyoB,uBAELzoB,KAAK0oB,MAAM9mB,UACX5B,KAAKyO,IAAInB,QACTtN,KAAK0oB,MAAQ,IAAIxB,GAEjB,IAAK,MAAMzM,KAAeza,KAAKuoB,SAC7BvoB,KAAKgqB,yBAAyBvP,GAC9Bza,KAAKuoB,SAAS9N,GAAa7Y,iBACpB5B,KAAKuoB,SAAS9N,GAEvBza,KAAKya,YAAc,KACnBza,KAAK6oB,gBAAkB,KACvB7oB,KAAK4oB,mBAAqB,IAC5B,EAQI,SAAU6J,KACd,MAAM7jB,EAAKD,KACX,GAAoB,MAAhBC,EAAG8jB,UAAmB,CACxB,MAAMC,EAAc,IAAIhnB,GAAYiD,GACpCA,EAAG8jB,UAAY,IAAIpK,GAAOqK,E,CZrjCxB,IAA+BA,EY4jCnC,OZ5jCmCA,EYujCd/jB,EAAG8jB,UAAUjkB,IZtjClCA,GAAMkkB,ESONvP,GGmjCiB,IAAMxU,EAAG8jB,UACnB9jB,EAAG8jB,SACZ,CA3yBiBpK,GAAA+C,aAAe,EAKf/C,GAAAgD,eAAiB,EAwyB3B,MAAMC,GAASkH,KAQhB,SAAUlV,GAAI/Z,EAAWC,GAE7B,MAAMgc,EAAS,CAACjc,IAAGC,KACnB,OAAO8nB,GAAOC,UAAU9b,GAAK+P,EAC/B,CEzwCA,IAAImT,GAEE,SAAUC,GAAazyB,GAC3BwyB,GAAoBxyB,CACtB,CAEM,SAAU0yB,GAASC,GACvB,QAA0BxuB,IAAtBquB,GACF,OAAOA,GAET,GAAIG,GAbwB,qBAAdC,WAA0C,MAAbA,UAaT,CAIhC,GAHKD,IACHA,EAAMC,WAEY,gBAAhBD,EAAIE,QACN,OAAO,EAGT,MAAMzvB,EAAIuvB,EAAIG,WAAaH,EAAII,SAER,qBAAXtkB,OAA0BA,OAAeukB,MAAQ,IAE7D,IAAK5vB,EAAG,CAEN,MAAM6vB,EAASN,EACf,OAAOM,EAAOC,eAAiBD,EAAOC,cAAcC,M,CAGtD,MAAO,2TACKC,KAAKhwB,IAEb,0kDACKgwB,KAAKhwB,EAAEiwB,OAAO,EAAG,G,CAE5B,OAAO,CACT,CAEM,SAAUC,KACd,MAA0B,qBAAX7kB,QAA6C,MAAnBA,OAAO8kB,UAEd,qBAAtBC,iBACd,CC1CA,MAAMnlB,GAAMpC,KCEN,SAAUwnB,GAAW9wB,EAAiBxB,GAC1C,IAAIuyB,EAAwB/wB,EAE5B,GAAI+B,GAAa/B,GACf,MAAiB,WAAVxB,EAAqB,GAAK,CAACwB,EAAIZ,QAExC,IAAKyC,MAAMC,QAAQ9B,GACjB,MAAO,GAET,MAAMzB,EAAkB,GAExB,KAAOsD,MAAMC,QAAQivB,IACdhvB,GAAagvB,IAAwB,WAAVvyB,GAChCD,EAAMyD,KAAK+uB,EAAU3xB,QACrB2xB,EAAYA,EAAU,GAOxB,OALIlvB,MAAMC,QAAQ9B,IACdsJ,KAAMC,QAAQ,uCAChBynB,GAA2BhxB,EAAKzB,EAAO,IAGlCA,CACT,CAEA,SAASyyB,GACLhxB,EAAiBzB,EAAiB0yB,GAEpC,GADAA,EAAUA,GAAW,IACfpvB,MAAMC,QAAQ9B,KAAU+B,GAAa/B,GAKzC,YAJAgB,EACqB,IAAjBzC,EAAMa,OACN,IAAM,eAAAJ,OAAeiyB,EAAQxlB,KAAK,MAAK,8DAAAzM,OACKT,EAAM,GAAE,cAG1DyC,EACIzC,EAAMa,OAAS,EACf,IAAM,eAAAJ,OAAeiyB,EAAQxlB,KAAK,MAAK,mDAAAzM,OACbgB,EAAIZ,OAAM,cACxC4B,EACIhB,EAAIZ,SAAWb,EAAM,GACrB,IAAM,eAAAS,OAAeiyB,EAAQxlB,KAAK,MAAK,kBAAAzM,OAAiBT,EAAM,GAAE,0BAAAS,OACvCgB,EAAIZ,OAAM,cACvC,MAAM8xB,EAAW3yB,EAAM8F,MAAM,GAC7B,IAAK,IAAI9D,EAAI,EAAGA,EAAIP,EAAIZ,SAAUmB,EAChCywB,GAA2BhxB,EAAIO,GAAI2wB,EAAUD,EAAQjyB,OAAOuB,GAEhE,CAEA,SAAS4wB,GACLC,EACAC,EAAuBC,EAAiBC,GAC1C,GAAsB,sBAAlBH,EAAJ,CAGA,GAAqB,MAAjBA,EACF,MAAM,IAAIryB,MAAM,kCAElB,GAAsB,YAAlBqyB,GAA+BA,IAAkBC,GAC/B,YAAlBD,GAA+C,WAAhBC,EACjC,MAAM,IAAItyB,MACN,aAAAC,OAAasyB,EAAO,iBAAAtyB,OAAgBuyB,EAAY,iBAAAvyB,OAC1CoyB,EAAa,qBAAApyB,OAAoBqyB,EAAW,W,CAE1D,CAEM,SAAUG,GACZ3xB,EAAiByxB,EAAiBC,GAC8B,IAAhEE,EAAAlwB,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAuD,UACzD,GAAI1B,aAAa4gB,GAEf,OADA0Q,GAAYM,EAAc5xB,EAAErB,MAAO8yB,EAASC,GACrC1xB,EAET,IAAI6xB,EAAgBhrB,GAAW7G,GAS/B,GANsB,WAAlB6xB,GACA,CAAC,OAAQ,QAAS,WAAWC,QAAQF,IAAiB,IACxDC,EAAgBD,GAElBN,GAAYM,EAAcC,EAAeJ,EAASC,GAExC,MAAL1xB,IACCkC,GAAalC,KAAOgC,MAAMC,QAAQjC,IAAmB,kBAANA,GACnC,mBAANA,GAAgC,kBAANA,EAAiB,CACrD,MAAMojB,EAAY,MAALpjB,EAAY,OAAUA,EAASpD,YAAY6O,KACxD,MAAM,IAAIvM,MACN,aAAAC,OAAasyB,EAAO,iBAAAtyB,OAAgBuyB,EAAY,kDAAAvyB,OACdikB,EAAI,K,CAE5C,MAAM2O,EAAgBd,GAAWjxB,EAAG6xB,GAC/B3vB,GAAalC,IAAOgC,MAAMC,QAAQjC,KACrCA,EAAI,CAACA,IAEP,MACMvB,EAA2B,WAAlBozB,EACXjW,GAAa5b,EAAG6xB,GAChB/vB,GAAQ9B,EAAe,IAHJ,GAIvB,OAAO2oB,GAAOlI,WAAWhiB,EAAQszB,EAAeF,EAClD,CAEM,SAAUG,GACZC,EAA0BR,EAAiBC,GACqB,IAAhEE,EAAAlwB,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAuD,UACzD,IAAKM,MAAMC,QAAQgwB,GACjB,MAAM,IAAI/yB,MACN,YAAAC,OAAYsyB,EAAO,eAAAtyB,OAAcuyB,EAAY,eAC7C,gCAGN,OADgBO,EACDrtB,IACX,CAAC2G,EAAG7K,IACAixB,GAAgBpmB,EAAG,GAAFpM,OAAKsyB,EAAO,KAAAtyB,OAAIuB,EAAC,KAAKgxB,EAAcE,GAC/D,CD3GA/lB,GAAIhC,aAAa,QAAS,KAAM,EAAOqoB,IACjCA,GACFvoB,QAAQC,KACJ,iJAORiC,GAAIhC,aAAa,aAAc,IAAMsoB,MAGrCtmB,GAAIhC,aACA,UACA,IAA0B,qBAAZqC,SACmB,qBAArBA,QAAQkmB,UACkB,qBAA1BlmB,QAAQkmB,SAASnE,MAGjCpiB,GAAIhC,aACA,YACA,IAA2B,qBAAdumB,WAA0C,MAAbA,WACf,MAAvBA,UAAUE,WAAqB,SAASM,KAAKR,UAAUE,YACvD,aAAaM,KAAKR,UAAUG,SAMpC1kB,GAAIhC,aAAa,OAAQ,KAAM,GAM/BgC,GAAIhC,aACA,qCAAsC,IAAMgC,GAAInC,QAAQ,UAG5DmC,GAAIhC,aAAa,+BAAgC,KAAM,GAGvDgC,GAAIhC,aAAa,UAAW,KAAM,GAGlCgC,GAAIhC,aAAa,+BAAgC,KAAM,GAGvDgC,GAAIhC,aAAa,sBAAuB,KAAM,GAG9CgC,GAAIhC,aAAa,sBAAuB,KAAM,GAG9CgC,GAAIhC,aAAa,wCAAyC,KAAM,GAGhEgC,GAAIhC,aAAa,uBAAwB,KAAM,GEnExC,MAAMwoB,GAAkB,OAOzB,SAAUC,GAAuBr0B,GACrC,MAAMyoB,EAAOlc,OAAOkc,KAAKzoB,GACzB,GAAoB,IAAhByoB,EAAKnnB,OACP,MAAM,IAAIL,MACN,yGAC6D,GAAAC,OAC1DunB,EAAKnnB,OAAM,WAGpB,IAAIgzB,EAAS7L,EAAK,GAClB,MAAMwB,EAAKjqB,EAAEs0B,GAGTA,EAAOC,SAAS,OAClBD,EAASA,EAAOE,UAAU,EAAGF,EAAOhzB,OAAS,IAI/CgzB,GAAkBF,GAGlB,MAAMK,EAAK,WACT/J,GAAOP,WAAWmK,GAClB,IACE,MAAMvxB,EAASknB,KAAGxmB,WAKlB,OAJIkH,GAAU5H,IACZ2I,QAAQ2e,MAAM,2CAEhBK,GAAON,SAASrnB,GACTA,C,CACP,MAAOwnB,GAEP,MADAG,GAAON,SAAS,MACVG,C,CAEV,EAIA,OAHAhe,OAAOuX,eAAe2Q,EAAI,OAAQ,CAACl1B,MAAO+0B,EAAQI,cAAc,IAGzDD,CACT,CCPO,MAAME,GAAUN,GAAG,CAACO,SAZ3B,SAAoCC,EAAoBC,GACtD,MAAMC,EAAQrB,GAAgBmB,EAAM,OAAQ,WACtCG,EAAQtB,GAAgBoB,EAAM,OAAQ,WAC5C9V,EACI+V,EAAMt0B,MAAOu0B,EAAMv0B,MACnB,yBAAAS,OAAyB6zB,EAAMt0B,MAAK,SAAAS,OAAQ8zB,EAAMv0B,MAAK,6CAG3D,MAAMme,EAAwB,CAACiW,KAAME,EAAOD,KAAME,GAClD,OAAOtK,GAAOC,UAAUva,GAASwO,EACnC,IChCM,SAAU4D,GACZhiB,EAAoBC,EAAiBqzB,EACrCpzB,GAIF,GAHa,MAATA,IACFA,EAAQkI,GAAWpI,IAEP,cAAVE,EACF,MAAM,IAAIO,MACN,oFAGN,IAAKgD,GAAazD,KAAYuD,MAAMC,QAAQxD,IACtB,kBAAXA,GAAyC,mBAAXA,GACnB,kBAAXA,EACT,MAAM,IAAIS,MACN,4HAGN,GAAa,MAATR,EAAe,CACjB2J,GAAmC3J,GAEnC,MAAMw0B,EAAe9wB,GAAc1D,GAC7By0B,EAAe/wB,GAAc2vB,GACnC5wB,EACI+xB,IAAiBC,EACjB,IACI,iCAAAh0B,OAAiCT,EAAK,iCAAAS,OACnC+zB,EAAY,oBAAA/zB,OAAmBg0B,IAE1C,IAAK,IAAIzyB,EAAI,EAAGA,EAAIqxB,EAAcxyB,SAAUmB,EAAG,CAC7C,MAAM0yB,EAAWrB,EAAcrxB,GACzB2yB,EAAoB3yB,IAAMqxB,EAAcxyB,OAAS,GACnD6zB,IAAahxB,GAAc1D,EAAM8F,MAAM9D,IAE3CS,EACI4wB,EAAcrxB,KAAOhC,EAAMgC,KAAO2yB,EAClC,IAAM,mDAAAl0B,OACE4yB,EAAa,kCAAgC,UAAA5yB,OACvCT,EAAK,O,EAY3B,OARKwD,GAAazD,IAAYuD,MAAMC,QAAQxD,KAC1CA,EAAS,CAACA,IAGZC,EAAQA,GAASqzB,EACjBtzB,EAAmB,WAAVE,EACLid,GAAand,EAAQE,GACrBmD,GAAQrD,EAAoB,IAAI,GAC7BkqB,GAAOlI,WAAWhiB,EAAsBC,EAAOC,EACxD,CCvBM,SAAU6kB,GACZ/kB,EAAoBC,EAAqBC,GAE3C,OAAO8hB,GAAWhiB,EAAQC,EADJuyB,GAAWxyB,EAAQE,GACOA,EAClD,CClCO,MAAM20B,GAAkD,CAC7D,QAAW,EACX,QAAW,EACX,MAAS,EACT,OAAU,EACV,MAAS,EACT,KAAQ,EACR,UAAa,GCHTC,GAA0B,EAmBzBC,eAAeC,GAClB/I,EAAuCgJ,GAGzC,MAAMC,EAAgC,GAChCC,EAA2C,GAE3CC,EAAkB7xB,MAAMC,QAAQyoB,GAClCA,EAAQ9lB,IAAI4e,GAAUA,EAAO/X,MAC7BjB,OAAOkc,KAAKgE,GAEhB,IAAK,IAAIhqB,EAAI,EAAGA,EAAImzB,EAAMt0B,SAAUmB,EAAG,CACrC,MAAM+K,EAAOooB,EAAMnzB,GACb6K,EAAIvJ,MAAMC,QAAQyoB,GAAWA,EAAQhqB,GAAG8iB,OAASkH,EAAQjf,GAC/D,GAAgB,YAAZF,EAAE5M,OAAmC,UAAZ4M,EAAE5M,OAAiC,SAAZ4M,EAAE5M,OACtC,WAAZ4M,EAAE5M,OAAkC,cAAZ4M,EAAE5M,MAC5B,MAAM,IAAIO,MAAM,gCAADC,OAAiCsM,EAAI,OAAAtM,OAAMoM,EAAE5M,QAE9D,MAAMm1B,EAA6B,CAACroB,OAAM/M,MAAO6M,EAAE7M,MAAOC,MAAO4M,EAAE5M,OACnE,GAAgB,WAAZ4M,EAAE5M,MAAoB,CACxB,MAAMo1B,EAAY,IAAIjwB,QAAoB0vB,UACxC,MAAM5tB,QAAa2F,EAAEhF,QACfytB,EAAgBpuB,EAAKgC,OAAO,CAACqsB,EAAGnsB,IAAMmsB,EAAInsB,EAAEvI,OAAQ,GACtDg0B,GAA0B3tB,EAAKrG,OAC7BgH,EAAQ,IAAId,WAAWuuB,GAC7B,IAAI1sB,EAAS,EACb,IAAK,IAAI5G,EAAI,EAAGA,EAAIkF,EAAKrG,OAAQmB,IAAK,CACpC,MAAMP,EAAMyF,EAAKlF,GACXwzB,EACF,IAAIzuB,WAAW,IAAIpC,YAAY,CAAClD,EAAIZ,SAAS0hB,QACjD1a,EAAMhJ,IAAI22B,EAAe5sB,GACzBA,GAAUisB,GACVhtB,EAAMhJ,IAAI4C,EAAKmH,GACfA,GAAUnH,EAAIZ,M,CAEhBwE,EAAQwC,KAEVqtB,EAAazxB,KAAK4xB,E,MAElBH,EAAazxB,KAAKoJ,EAAExO,QAET,MAAT22B,IACFI,EAAKJ,MAAQA,GAEfC,EAAMxxB,KAAK2xB,E,CAIb,MAAO,CAAC/2B,KAAMo3B,SADarwB,QAAQ+Z,IAAI+V,IACaD,QACtD,CAiBM,SAAUS,GACZnT,EAAqB0S,GAEvB,MAAM3J,EAAsB,CAAC,EAC7B,IAAIqK,EACA/sB,EAAS,EACb,IAAK,MAAMwsB,KAAQH,EAAO,CACxB,MAAMloB,EAAOqoB,EAAKroB,KACZ9M,EAAQm1B,EAAKn1B,MACbD,EAAQo1B,EAAKp1B,MACb2D,EAAOD,GAAc1D,GAC3B,IAAID,EAEJ,GAAI,iBAAkBq1B,EAAM,CAC1B,MAAMQ,EAAeR,EAAKQ,aAC1B,GAA2B,UAAvBA,EAAa31B,OAA4C,WAAvB21B,EAAa31B,OACjD,KAAM,QAAS21B,MAAgB,UAAWA,GACxC,MAAM,IAAIp1B,MACN,UAAAC,OAAU20B,EAAKroB,KAAI,uBAAAtM,OAAsBm1B,EAAa31B,MAAK,+DAG5D,IAA2B,YAAvB21B,EAAa31B,MAOtB,MAAM,IAAIO,MACN,UAAAC,OAAU20B,EAAKroB,KAAI,uCAAAtM,OACGm1B,EAAa31B,MAAK,MADxC,wEAPJ,GAAc,YAAVA,EACF,MAAM,IAAIO,MACN,UAAAC,OAAU20B,EAAKroB,KAAI,uBAAAtM,OAAsBm1B,EAAa31B,MAAK,wDAAAQ,OACRR,EAAK,K,CAShE,MAAM41B,EAAyBjB,GAAqBgB,EAAa31B,OAC3D61B,EACFvT,EAAOzc,MAAM8C,EAAQA,EAASjF,EAAOkyB,GACnCE,EAAyC,UAAvBH,EAAa31B,MACjC,IAAI8G,WAAW+uB,GACf,IAAIE,YAAYF,GACpB,GAAc,YAAV71B,EACF,GAA2B,UAAvB21B,EAAa31B,OAA4C,WAAvB21B,EAAa31B,MAAoB,CACrEF,EAAS,IAAI8G,aAAakvB,EAAel1B,QACzC,IAAK,IAAImB,EAAI,EAAGA,EAAI+zB,EAAel1B,OAAQmB,IAAK,CAC9C,MAAM2Z,EAAIoa,EAAe/zB,GACzBjC,EAAOiC,GAAK2Z,EAAIia,EAAaK,MAAQL,EAAav0B,G,MAE/C,IAA2B,YAAvBu0B,EAAa31B,MAMtB,MAAM,IAAIO,MACN,iCAAAC,OAAiCm1B,EAAa31B,MAAK,sCANjCgD,IAAlB0yB,IACFA,EAAgBO,MAElBn2B,EAAS41B,EAAcI,E,KAMpB,IAAc,UAAV91B,EAYT,MAAM,IAAIO,MAAM,gCAADC,OAAiCsM,EAAI,OAAAtM,OAAMR,IAX1D,GAA2B,UAAvB21B,EAAa31B,OAA4C,WAAvB21B,EAAa31B,MACjD,MAAM,IAAIO,MACN,iCAAAC,OAAiCm1B,EAAa31B,MAAK,+BAGzDF,EAAS,IAAI+G,WAAWivB,EAAel1B,QACvC,IAAK,IAAImB,EAAI,EAAGA,EAAI+zB,EAAel1B,OAAQmB,IAAK,CAC9C,MAAM2Z,EAAIoa,EAAe/zB,GACzBjC,EAAOiC,GAAKjB,KAAKuc,MAAM3B,EAAIia,EAAaK,MAAQL,EAAav0B,I,EAKjEuH,GAAUjF,EAAOkyB,C,MACZ,GAAc,WAAV51B,EAAoB,CAC7B,MAAM0D,EAAOD,GAAc0xB,EAAKp1B,OAChCD,EAAS,GACT,IAAK,IAAIiC,EAAI,EAAGA,EAAI2B,EAAM3B,IAAK,CAC7B,MAAMm0B,EAAa,IAAIxxB,YACnB4d,EAAOzc,MAAM8C,EAAQA,EAASisB,KAA0B,GAC5DjsB,GAAUisB,GACV,MAAMhtB,EAAQ,IAAId,WAAWwb,EAAOzc,MAAM8C,EAAQA,EAASutB,IAC1Dp2B,EAAwB0D,KAAKoE,GAC9Be,GAAUutB,C,MAEP,CACL,MAAMC,EAAcxB,GAAqB30B,GACnC61B,EAAavT,EAAOzc,MAAM8C,EAAQA,EAASjF,EAAOyyB,GAExD,GAAc,YAAVn2B,EACFF,EAAS,IAAI8G,aAAaivB,QACrB,GAAc,UAAV71B,EACTF,EAAS,IAAI+G,WAAWgvB,QACnB,GAAc,SAAV71B,EACTF,EAAS,IAAIgH,WAAW+uB,OACnB,IAAc,cAAV71B,EAcT,MAAM,IAAIO,MAAM,gCAADC,OAAiCsM,EAAI,OAAAtM,OAAMR,IAd1B,CAChCF,EAAS,IAAI8G,aAAaivB,GAC1B,MAAM1B,EAAO,IAAIvtB,aAAa9G,EAAOc,OAAS,GACxCw1B,EAAQ,IAAIxvB,aAAa9G,EAAOc,OAAS,GAC/C,IAAK,IAAImB,EAAI,EAAGA,EAAIoyB,EAAKvzB,OAAQmB,IAC/BoyB,EAAKpyB,GAAKjC,EAAW,EAAJiC,GACjBq0B,EAAMr0B,GAAKjC,EAAW,EAAJiC,EAAQ,GAE5B,MAAMs0B,EAAaxR,GAAOsP,EAAMp0B,EAAO,WACjCu2B,EAAczR,GAAOuR,EAAOr2B,EAAO,WACzCsrB,EAAIve,GAAQmnB,GAAQoC,EAAYC,GAChCD,EAAWh2B,UACXi2B,EAAYj2B,S,EAIdsI,GAAUjF,EAAOyyB,C,CAEL,cAAVn2B,IACFqrB,EAAIve,GAAQ+X,GAAO/kB,EAAQC,EAAOC,G,CAGtC,OAAOqrB,CACT,CAKM,SAAUmK,GAAuBxG,GAErC,GAAW,OAAPA,EACF,MAAM,IAAIzuB,MAAM,wBAADC,OAAyB+1B,KAAKC,UAAUxH,KAGzD,IAAIyH,EAAkB,EAStB,MAAMC,EAA6B,GACnC1H,EAAGnnB,QAASxG,IAMV,GALAo1B,GAAmBp1B,EAAE60B,WAErBQ,EAAalzB,KACTnC,EAAE60B,aAAe70B,EAAEihB,OAAO4T,WAAa70B,EACA,IAAKA,EAAEpD,YAAoBoD,MAChEA,aAAoBuF,cAAgBvF,aAAoBwF,YACxDxF,aAAoByF,YACxB,MAAM,IAAIvG,MAAM,mCAADC,OAAoCa,EAAEpD,YAAY6O,SAKrE,MAAMgP,EAAI,IAAIhV,WAAW2vB,GACzB,IAAI9tB,EAAS,EAMb,OALA+tB,EAAa7uB,QAASxG,IACpBya,EAAEld,IAAI,IAAIkI,WAAWzF,EAAEihB,QAAS3Z,GAChCA,GAAUtH,EAAE60B,aAGPpa,EAAEwG,MACX,CAGA,MAAMqU,GAAkC,qBAAXC,SACR,qBAATC,MAAwC,qBAATC,MACtB,qBAATC,MAWN,SAAUC,GAAiBC,GAC/B,OAAIN,GACKC,OAAOV,WAAWe,GAEpB,IAAIJ,KAAK,CAACI,IAAMvzB,IACzB,CA6CM,SAAUwzB,GAAwBC,GACtC,GAAuB,IAAnBA,EAAQv2B,OACV,OAAOu2B,EAAQ,GAGjB,IAAIV,EAAkB,EACtBU,EAAQtvB,QAASya,IACfmU,GAAmBnU,EAAO4T,aAG5B,MAAMt0B,EAAO,IAAIkF,WAAW2vB,GAC5B,IAAI9tB,EAAS,EAKb,OAJAwuB,EAAQtvB,QAASya,IACf1gB,EAAKhD,IAAI,IAAIkI,WAAWwb,GAAS3Z,GACjCA,GAAU2Z,EAAO4T,aAEZt0B,EAAK0gB,MACd,CASM,SAAU8U,GAAS7Z,GAGvB,IADAA,EAAOA,EAAK8Z,OACL9Z,EAAKsW,SAFM,MAGhBtW,EAAOA,EAAK1X,MAAM,EAAG0X,EAAK3c,OAAS,GAErC,MAAM02B,EAAQ/Z,EAAKpR,MALD,KAMlB,OAAOmrB,EAAMA,EAAM12B,OAAS,EAC9B,CAWM,SAAU22B,GACZC,EAA2BC,GAC7B,MAAMp1B,EAAoB,CACxBq1B,cAAeF,EAAUE,cACzBC,OAAQH,EAAUG,OAClBC,YAAaJ,EAAUI,YACvBC,YAAaL,EAAUK,YACvBC,gBAAiBL,GAcnB,OAZ2B,MAAvBD,EAAUO,YACZ11B,EAAO01B,UAAYP,EAAUO,WAEM,MAAjCP,EAAUQ,sBACZ31B,EAAO21B,oBAAsBR,EAAUQ,qBAEP,MAA9BR,EAAUS,mBACZ51B,EAAO41B,iBAAmBT,EAAUS,kBAEN,MAA5BT,EAAUU,iBACZ71B,EAAO61B,eAAiBV,EAAUU,gBAE7B71B,CACT,CAaM,SAAU81B,GACZC,EAAsBC,EACtBC,GAEF,MAAMC,EAAiC,CACrCb,cAAeU,EAAUV,cACzBC,OAAQS,EAAUT,OAClBC,YAAaQ,EAAUR,YACvBC,YAAaO,EAAUP,aAMzB,GAHgC,MAA5BO,EAAUF,iBACZK,EAAeL,eAAiBE,EAAUF,gBAEX,MAA7BE,EAAUN,gBAAyB,CACrC,IAAKO,EACH,MAAM,IAAI93B,MAAM,yDAElB,IAAK+3B,EACH,MAAM,IAAI/3B,MAAM,wDAElBg4B,EAAeF,YAAcA,EAC7BE,EAAeD,WAAaA,C,CAY9B,OAV2B,MAAvBF,EAAUL,YACZQ,EAAeR,UAAYK,EAAUL,WAEF,MAAjCK,EAAUJ,sBACZO,EAAeP,oBAAsBI,EAAUJ,qBAEf,MAA9BI,EAAUH,mBACZM,EAAeN,iBAAmBG,EAAUH,kBAGvCM,CACT,CAWO1D,eAAe2D,GAClBJ,EACAK,GAGF,IAAIJ,EACAC,EAMJ,OAJiC,MAA7BF,EAAUN,mBACXO,EAAaC,SAAoBG,EAAYL,EAAUN,kBAGnDK,GAA6BC,EAAWC,EAAaC,EAC9D,CAOM,SAAUI,GAA6BH,GAE3C,GAAIA,EAAeb,yBAAyBiB,YAC1C,MAAM,IAAIp4B,MAAM,uDAGlB,MAAO,CACLq4B,UAAW,IAAIC,KACfC,kBAAmB,OACnBC,mBAAoD,MAAhCR,EAAeb,cAC/B,EACAV,GAAiBT,KAAKC,UAAU+B,EAAeb,gBACnDsB,iBAAgD,MAA9BT,EAAeF,YAC7B,EACArB,GAAiBT,KAAKC,UAAU+B,EAAeF,cACnDY,gBAA8C,MAA7BV,EAAeD,WAC5B,EACAC,EAAeD,WAAWpC,WAElC,CASM,SAAUgD,GAAepB,GAE7B,MAAMO,EAAsC,GAC5C,IAAK,MAAMc,KAASrB,EAClBO,EAAY70B,QAAQ21B,EAAMC,SAE5B,OAAOf,CACT,CAmFM,SAAUpC,KAKd,MAAMoD,EAhFR,WACE,MAAMC,EAAmBv3B,IACvB,IAAIw3B,EAAIx3B,GAAK,GACTwa,EAAI,EAER,KAA4B,KAAhB,QAAJgd,IACNhd,GAAK,QACLgd,IAAM,EAKR,OAHAA,IAAK,QACLhd,GAAK,UAEEgd,EAAIhd,GAGP8c,EAAe,IAAI30B,YAAY,MAErC20B,EAAa,GAAK,EAClB,IAAK,IAAIt3B,EAAI,EAAGA,EAAI,KAAMA,IACxBs3B,EAAat3B,GAAKu3B,EAAgBv3B,GAEpC,IAAK,IAAIA,EAAI,KAAMA,EAAI,KAAMA,IAC3Bs3B,EAAat3B,GAAK,WAAeA,EAAI,MAAS,IAGhD,OAAOs3B,CACT,CAsDuBG,GACfC,EA/CR,WACE,MAAMA,EAAgB,IAAI/0B,YAAY,IAEtC+0B,EAAc,GAAK,EACnBA,EAAc,IAAM,WACpBA,EAAc,IAAM,WACpBA,EAAc,IAAM,WACpB,IAAK,IAAI13B,EAAI,EAAGA,EAAI,GAAIA,IACtB03B,EAAc13B,GAAKA,GAAK,GAE1B,IAAK,IAAIA,EAAI,GAAIA,EAAI,GAAIA,IACvB03B,EAAc13B,GAAK,YAAeA,EAAI,IAAO,IAG/C,OAAO03B,CACT,CAgCwBC,GAChBC,EAzBR,WACE,MAAMA,EAAc,IAAIj1B,YAAY,IAEpC,IAAK,IAAI3C,EAAI,EAAGA,EAAI,GAAIA,IACtB43B,EAAY53B,GAAK,KAInB,OAFA43B,EAAY,GAAKA,EAAY,IAAM,EAE5BA,CACT,CAgBsBC,GAEpB,OAAQ9D,IACN,MAAMxT,EAAS,IAAIqW,YAAY,EAAI7C,EAAel1B,QAC5Ci5B,EAAmB,IAAIn1B,YAAY4d,GACzC,IAAK,IAAIzhB,EAAQ,EAAGA,EAAQi1B,EAAel1B,OAAQC,IAAS,CAC1D,MAAMi5B,EAAchE,EAAej1B,GAC7Bk5B,EACFV,EAAaM,EAAYG,GAAe,KAAqB,KAAdA,IAC/CL,EAAcK,GAAe,IACjCD,EAAiBh5B,GAASk5B,C,CAE5B,OAAO,IAAInzB,aAAa0b,GAE5B,CCtlBM,MAAO0X,GAOX/7B,WAAAA,GACEQ,KAAKw7B,YAAc,GACnBx7B,KAAKy7B,YAAc,EACrB,CAEQ,kBAAOC,GAIb,OAHiC,MAA7BH,GAAiBzW,WACnByW,GAAiBzW,SAAW,IAAIyW,IAE3BA,GAAiBzW,QAC1B,CAQA,yBAAO6W,CAAmBC,GACxBL,GAAiBG,cAAcF,YAAYz2B,KAAK62B,EAClD,CAQA,yBAAOC,CAAmBC,GACxBP,GAAiBG,cAAcD,YAAY12B,KAAK+2B,EAClD,CAUA,sBAAOC,CAAgBC,GACrB,OAAOT,GAAiBU,YAAYD,EAAK,OAC3C,CAUA,sBAAOE,CAAgBF,EAAsBG,GAE3C,OAAOZ,GAAiBU,YAAYD,EAAK,OAAQG,EACnD,CAEQ,kBAAOF,CACXD,EAAsBI,EACtBD,GACF,MAAME,EAA6B,GAUnC,OATgC,SAAhBD,EACZb,GAAiBG,cAAcD,YAC/BF,GAAiBG,cAAcF,aAC3BpyB,QAAQkzB,IACd,MAAMC,EAAUD,EAAON,EAAKG,GACZ,OAAZI,GACFF,EAAct3B,KAAKw3B,KAGhBF,CACT,EAGK,MAAMV,GAAsBa,GAC/BjB,GAAiBI,mBAAmBa,GAC3BX,GAAsBW,GAC/BjB,GAAiBM,mBAAmBW,GAC3BT,GAAmBC,GAC5BT,GAAiBQ,gBAAgBC,GACxBE,GACTA,CAACF,EAAsBG,IACnBZ,GAAiBW,gBAAgBF,EAAKG,GCtFxCM,GAAgB,eAMhBC,GAAmB,eAInBC,GAAkB,mBAexB,SAASC,KACP,IAAKvwB,KAAMC,QAAQ,cAIjB,MAAM,IAAIxK,MACN,2FAIN,MAAM+6B,EAAmC,qBAAXhuB,OAAyBE,KAAOF,OACxD4a,EAAUoT,EAAUC,WAAaD,EAAUE,cAC7CF,EAAUG,iBAAmBH,EAAUI,aACvCJ,EAAUK,cACd,GAAe,MAAXzT,EACF,MAAM,IAAI3nB,MACN,6DAEN,OAAO2nB,CACT,CAEA,SAAS0T,GAAcC,GACrB,MAAMC,EAAKD,EAAYx5B,OACvBy5B,EAAGC,kBAAkBZ,GAAkB,CAACa,QAAS,cACjDF,EAAGC,kBAAkBX,GAAiB,CAACY,QAAS,aAClD,CAOM,MAAOC,GAMXh+B,WAAAA,CAAYi+B,GAGV,GAFAz9B,KAAK88B,UAAYF,KAEA,MAAba,IAAsBA,EACxB,MAAM,IAAI37B,MACN,kEAEN9B,KAAKy9B,UAAYA,CACnB,CAEA,UAAMtL,CAAK2H,GAET,GAAIA,EAAeb,yBAAyBiB,YAC1C,MAAM,IAAIp4B,MACN,4FAIN,OAAO9B,KAAK09B,eAAe19B,KAAKy9B,UAAW3D,EAE7C,CAEA,UAAM6D,GACJ,OAAO39B,KAAK09B,eAAe19B,KAAKy9B,UAClC,CAgBQC,cAAAA,CAAeD,EAAmB3D,GAExC,OAAO,IAAIpzB,QAAmC,CAACC,EAASC,KACtD,MAAMw2B,EAAcp9B,KAAK88B,UAAUc,KAAKnB,GAzGrB,GA0GnBW,EAAYS,gBAAkB,IAAMV,GAAcC,GAElDA,EAAYU,UAAY,KACtB,MAAMT,EAAKD,EAAYx5B,OAEvB,GAAsB,MAAlBk2B,EAAwB,CAE1B,MAAMiE,EAAUV,EAAGW,YAAYtB,GAAkB,YAE3CuB,EADaF,EAAQG,YAAYxB,IACT58B,IAAIE,KAAKy9B,WACvCQ,EAAWH,UAAY,KACrB,GAAyB,MAArBG,EAAWr6B,OAEb,OADAy5B,EAAGc,QACIv3B,EAAO,IAAI9E,MACd,gCAAAC,OAAgC/B,KAAKy9B,UAAS,wBAGlD92B,EAAQs3B,EAAWr6B,OAAOk2B,iBAG9BmE,EAAWG,QAAUlT,IACnBmS,EAAGc,QACIv3B,EAAOq3B,EAAW/S,QAE3B6S,EAAQM,WAAa,IAAMhB,EAAGc,O,KACzB,CAEL,MAAMG,EACFrE,GAA6BH,GAE3ByE,EAASlB,EAAGW,YAAYrB,GAAiB,aAC/C,IAAI6B,EAAYD,EAAOL,YAAYvB,IACnC,MAAM8B,EACFD,EAAUE,IAAI,CAACjB,UAAWz9B,KAAKy9B,UAAWa,uBAC9C,IAAIP,EACJU,EAAeX,UAAY,KAEzBC,EAAUV,EAAGW,YAAYtB,GAAkB,aAC3C,MACMiC,EADaZ,EAAQG,YAAYxB,IACJgC,IAAI,CACrCjB,UAAWz9B,KAAKy9B,UAChB3D,iBACAwE,uBAEFK,EAAgBb,UAAY,IAAMn3B,EAAQ,CAAC23B,uBAC3CK,EAAgBP,QAAUlT,IAGxBsT,EAAYD,EAAOL,YAAYvB,IAC/B,MAAMiC,EAAoBJ,EAAUn+B,OAAOL,KAAKy9B,WAChDmB,EAAkBd,UAAY,KAC5BT,EAAGc,QACIv3B,EAAO+3B,EAAgBzT,QAEhC0T,EAAkBR,QAAUlT,IAC1BmS,EAAGc,QACIv3B,EAAO+3B,EAAgBzT,UAIpCuT,EAAeL,QAAUlT,IACvBmS,EAAGc,QACIv3B,EAAO63B,EAAevT,QAE/BqT,EAAOF,WAAa,KACH,MAAXN,EACFV,EAAGc,QAEHJ,EAAQM,WAAa,IAAMhB,EAAGc,Q,GAKtCf,EAAYgB,QAAUlT,GAAStkB,EAAOw2B,EAAYlS,QAEtD,EAzHgBsS,GAAAqB,WAAa,eA4HxB,MAAMC,GAA6B9C,IACxC,OAAK3vB,KAAMC,QAAQ,gBAGZ1H,MAAMC,QAAQm3B,IAAQA,EAAI+C,WAAWvB,GAAiBqB,aA2B9BpB,EA1BHzB,EAAI50B,MAAMo2B,GAAiBqB,WAAW18B,QA2B3D,IAAIq7B,GAAiBC,IA9BnB,KA6BL,IAA2BA,GApBjClC,GAAiBI,mBAAmBmD,IACpCvD,GAAiBM,mBAAmBiD,IA6B9B,MAAOE,GAGXx/B,WAAAA,GACEQ,KAAK88B,UAAYF,IACnB,CAEA,gBAAMqC,GACJ,OAAO,IAAIv4B,QACP,CAACC,EAASC,KACR,MAAMw2B,EACFp9B,KAAK88B,UAAUc,KAAKnB,GA5OT,GA6OfW,EAAYS,gBAAkB,IAAMV,GAAcC,GAElDA,EAAYU,UAAY,KACtB,MAAMT,EAAKD,EAAYx5B,OACjBs7B,EAAK7B,EAAGW,YAAYrB,GAAiB,YAUrCwC,EATQD,EAAGhB,YAAYvB,IASYyC,SACzCD,EAAkBrB,UAAY,KAC5B,MAAMlR,EAA4C,CAAC,EACnD,IAAK,MAAMoB,KAAQmR,EAAkBv7B,OACnCgpB,EAAIoB,EAAKyP,WAAazP,EAAKsQ,mBAE7B33B,EAAQimB,IAEVuS,EAAkBf,QAAUlT,IAC1BmS,EAAGc,QACIv3B,EAAOu4B,EAAkBjU,QAElCgU,EAAGb,WAAa,IAAMhB,EAAGc,SAE3Bf,EAAYgB,QAAUlT,GAAStkB,EAAOw2B,EAAYlS,QAE1D,CAEA,iBAAMmU,CAAYvgB,GAlDpB,IAA0BlR,EAoDtB,OADAkR,GAnDsBlR,EAmDEkR,GAlDfigB,WAAWvB,GAAiBqB,YACnCjxB,EAAIxG,MAAMo2B,GAAiBqB,WAAW18B,QACtCyL,EAiDK,IAAIlH,QAA4B,CAACC,EAASC,KAC/C,MAAMw2B,EAAcp9B,KAAK88B,UAAUc,KAAKnB,GAhRrB,GAiRnBW,EAAYS,gBAAkB,IAAMV,GAAcC,GAElDA,EAAYU,UAAY,KACtB,MAAMT,EAAKD,EAAYx5B,OACjB26B,EAASlB,EAAGW,YAAYrB,GAAiB,aACzC6B,EAAYD,EAAOL,YAAYvB,IAE/B2C,EAAiBd,EAAU1+B,IAAIgf,GACrC,IAAIif,EACJuB,EAAexB,UAAY,KACzB,GAA6B,MAAzBwB,EAAe17B,OAEjB,OADAy5B,EAAGc,QACIv3B,EAAO,IAAI9E,MACd,gCAAAC,OAAgC+c,EAAI,wBAEnC,CAEL,MAAM8f,EAAoBJ,EAAUn+B,OAAOye,GACrCygB,EAAkBA,KAEtBxB,EAAUV,EAAGW,YAAYtB,GAAkB,aAC3C,MACM8C,EADazB,EAAQG,YAAYxB,IACDr8B,OAAOye,GAC7C0gB,EAAmB1B,UAAY,IAC3Bn3B,EAAQ24B,EAAe17B,OAAO06B,oBAClCkB,EAAmBpB,QAAUlT,GACzBtkB,EAAO04B,EAAepU,QAI5B0T,EAAkBd,UAAYyB,EAC9BX,EAAkBR,QAAUlT,IAC1BqU,IACAlC,EAAGc,QACIv3B,EAAO04B,EAAepU,O,GAInCoU,EAAelB,QAAUlT,IACvBmS,EAAGc,QACIv3B,EAAO04B,EAAepU,QAG/BqT,EAAOF,WAAa,KACH,MAAXN,EACFV,EAAGc,QAEHJ,EAAQM,WAAa,IAAMhB,EAAGc,UAIpCf,EAAYgB,QAAUlT,GAAStkB,EAAOw2B,EAAYlS,QAEtD,ECvUF,MAAMuU,GAAiB,IACjBC,GAAc,sBACdC,GAAc,OACdC,GAAwB,iBACxBC,GAAsB,eACtBC,GAAqB,cACrBC,GAAwB,iBAsD9B,SAASC,GAAalhB,GACpB,MAAO,CACL2L,KAAM,CAACiV,GAAa5gB,EAAM6gB,IAAanxB,KAAKixB,IAC5CQ,SAAU,CAACP,GAAa5gB,EAAM8gB,IAAuBpxB,KAAKixB,IAC1D7F,YAAa,CAAC8F,GAAa5gB,EAAM+gB,IAAqBrxB,KAAKixB,IAC3D5F,WAAY,CAAC6F,GAAa5gB,EAAMghB,IAAoBtxB,KAAKixB,IACzDS,cACI,CAACR,GAAa5gB,EAAMihB,IAAuBvxB,KAAKixB,IAExD,CAEA,SAASU,GAAY7W,GACnB,IAAK,MAAM1b,KAAOR,OAAO/L,OAAOioB,GAC9Bza,OAAOuxB,aAAaC,WAAWzyB,EAEnC,CASA,SAAS0yB,GAAoB1yB,GAC3B,MAAMirB,EAAQjrB,EAAIF,MAAM+xB,IACxB,GAAI5G,EAAM12B,OAAS,EACjB,MAAM,IAAIL,MAAM,uBAADC,OAAwB6L,IAEzC,OAAOirB,EAAMzxB,MAAM,EAAGyxB,EAAM12B,OAAS,GAAGqM,KAAKixB,GAC/C,CAaM,MAAOc,GAOX/gC,WAAAA,CAAYi+B,GACV,IAAKpxB,KAAMC,QAAQ,eAAmC,qBAAXuC,QACR,qBAAxBA,OAAOuxB,aAKhB,MAAM,IAAIt+B,MACN,2DAIN,GAFA9B,KAAKwgC,GAAK3xB,OAAOuxB,aAEA,MAAb3C,IAAsBA,EACxB,MAAM,IAAI37B,MACN,sEAEN9B,KAAKy9B,UAAYA,EACjBz9B,KAAKspB,KAAO0W,GAAahgC,KAAKy9B,UAChC,CAWA,UAAMtL,CAAK2H,GACT,GAAIA,EAAeb,yBAAyBiB,YAC1C,MAAM,IAAIp4B,MACN,4FAEC,CACL,MAAMm+B,EAAWnI,KAAKC,UAAU+B,EAAeb,eACzCW,EAAc9B,KAAKC,UAAU+B,EAAeF,aAE5C0E,EACFrE,GAA6BH,GAEjC,IACE95B,KAAKwgC,GAAGC,QAAQzgC,KAAKspB,KAAKmB,KAAMqN,KAAKC,UAAUuG,IAC/Ct+B,KAAKwgC,GAAGC,QAAQzgC,KAAKspB,KAAK2W,SAAUA,GACpCjgC,KAAKwgC,GAAGC,QAAQzgC,KAAKspB,KAAKsQ,YAAaA,GACvC55B,KAAKwgC,GAAGC,QACJzgC,KAAKspB,KAAKuQ,WHqHhB,SAAoChW,GACxC,GAAIqU,GACF,OAAOC,OAAO3b,KAAKqH,GAAQjD,SAAS,UAEtC,MAAM8f,EAAM,IAAIr4B,WAAWwb,GAC3B,IAAIpc,EAAI,GACR,IAAK,IAAInE,EAAI,EAAGwe,EAAI4e,EAAIv+B,OAAQmB,EAAIwe,EAAGxe,IACrCmE,GAAK6B,OAAOq3B,aAAaD,EAAIp9B,IAE/B,OAAOg1B,KAAK7wB,EACd,CG9HYm5B,CAA0B9G,EAAeD,aAK7C,MAAMgH,EAAoC,CACxC3H,OAAQY,EAAeZ,OACvBC,YAAaW,EAAeX,YAC5BC,YAAaU,EAAeV,YAC5BE,UAAuC,MAA5BQ,EAAeR,UACtBQ,EAAeR,eACf/0B,EACJg1B,oBAA2D,MAAtCO,EAAeP,oBAChCO,EAAeP,yBACfh1B,EACJi1B,iBAAqD,MAAnCM,EAAeN,iBAC7BM,EAAeN,sBACfj1B,EACJk1B,eAAiD,MAAjCK,EAAeL,eAC3BK,EAAeL,oBACfl1B,GAIN,OAFAvE,KAAKwgC,GAAGC,QAAQzgC,KAAKspB,KAAK4W,cAAepI,KAAKC,UAAU8I,IAEjD,CAACvC,qB,CACR,MAAOjU,GAIP,MAFA8V,GAAYngC,KAAKspB,MAEX,IAAIxnB,MACN,yBAAAC,OAAyB/B,KAAKy9B,UAAS,0FAC0B,sBAAA17B,OAC3Cu8B,EAAmBhE,mBAAkB,MAAI,oBAAAv4B,OAC3Cu8B,EAAmB/D,iBAAgB,MAAI,mBAAAx4B,OACxCu8B,EAAmB9D,gBAAe,K,EAG/D,CAUA,UAAMmD,GACJ,MAAMlT,EACFqN,KAAKgJ,MAAM9gC,KAAKwgC,GAAGO,QAAQ/gC,KAAKspB,KAAKmB,OACzC,GAAY,MAARA,EACF,MAAM,IAAI3oB,MAAM,kDAADC,OACuC/B,KAAKy9B,UAAS,MAGtE,GAA+B,SAA3BhT,EAAK4P,kBACP,MAAM,IAAIv4B,MACN,6EAIN,MAAM8qB,EAAsB,CAAC,EAGvBqT,EAAWnI,KAAKgJ,MAAM9gC,KAAKwgC,GAAGO,QAAQ/gC,KAAKspB,KAAK2W,WACtD,GAAgB,MAAZA,EACF,MAAM,IAAIn+B,MACN,4CAAAC,OAA4C/B,KAAKy9B,UAAS,qBAGhE7Q,EAAIqM,cAAgBgH,EAGpB,MAAMrG,EAAc9B,KAAKgJ,MAAM9gC,KAAKwgC,GAAGO,QAAQ/gC,KAAKspB,KAAKsQ,cACzD,GAAmB,MAAfA,EACF,MAAM,IAAI93B,MACN,gDAAAC,OAAgD/B,KAAKy9B,UAAS,sBAGpE7Q,EAAIgN,YAAcA,EAGlB,MAAMoH,EAAiBhhC,KAAKwgC,GAAGO,QAAQ/gC,KAAKspB,KAAK4W,eACjD,GAAsB,MAAlBc,EAAwB,CAC1B,MAAMH,EAAW/I,KAAKgJ,MAAME,GAC5BpU,EAAIsM,OAAS2H,EAAS3H,OACtBtM,EAAIuM,YAAc0H,EAAS1H,YAC3BvM,EAAIwM,YAAcyH,EAASzH,YACD,MAAtByH,EAASvH,YACX1M,EAAI0M,UAAYuH,EAASvH,WAES,MAAhCuH,EAAStH,sBACX3M,EAAI2M,oBAAsBsH,EAAStH,qBAEJ,MAA7BsH,EAASrH,mBACX5M,EAAI4M,iBAAmBqH,EAASrH,kBAEH,MAA3BqH,EAASpH,iBACX7M,EAAI6M,eAAiBoH,EAASpH,e,CAKlC,MAAMwH,EAAmBjhC,KAAKwgC,GAAGO,QAAQ/gC,KAAKspB,KAAKuQ,YACnD,GAAwB,MAApBoH,EACF,MAAM,IAAIn/B,MACN,2DAAAC,OACI/B,KAAKy9B,UAAS,mBAIxB,OAFA7Q,EAAIiN,WHyBF,SAAoCrB,GACxC,GAAIN,GAAe,CACjB,MAAMwI,EAAMvI,OAAO3b,KAAKgc,EAAK,UAC7B,OAAOkI,EAAI7c,OAAOzc,MAAMs5B,EAAIQ,WAAYR,EAAIQ,WAAaR,EAAIjJ,W,CAE/D,MAAMhwB,EAAI4wB,KAAKG,GACT3U,EAAS,IAAIxb,WAAWZ,EAAEtF,QAChC,IAAK,IAAImB,EAAI,EAAGA,EAAImE,EAAEtF,SAAUmB,EAC9BugB,EAAO1jB,IAAI,CAACsH,EAAE05B,WAAW79B,IAAKA,GAEhC,OAAOugB,EAAOA,MAChB,CGpCqBud,CAA0BH,GAEpCrU,CACT,EAjKgB2T,GAAA1B,WAAa,kBAoKxB,MAAMwC,GAAgCrF,IAC3C,OAAK3vB,KAAMC,QAAQ,gBAGZ1H,MAAMC,QAAQm3B,IAAQA,EAAI+C,WAAWwB,GAAoB1B,aAmC9BpB,EAjC1BzB,EAAI50B,MAAMm5B,GAAoB1B,WAAW18B,QAkC1C,IAAIo+B,GAAoB9C,IAtCtB,KAqCL,IAA8BA,GA3BpClC,GAAiBI,mBAAmB0F,IACpC9F,GAAiBM,mBAAmBwF,IA8B9B,MAAOC,GAGX9hC,WAAAA,GACEuE,EACIsI,KAAMC,QAAQ,cACd,IAAM,4CACVvI,EACsB,qBAAX8K,QAC4B,qBAAxBA,OAAOuxB,aAClB,IAAM,2DACVpgC,KAAKwgC,GAAK3xB,OAAOuxB,YACnB,CAEA,gBAAMnB,GACJ,MAAMrS,EAA4C,CAAC,EAC7C2U,EAAS7B,GAAcD,GACvB+B,EAAS/B,GAAiBE,GAChC,IAAK,IAAIr8B,EAAI,EAAGA,EAAItD,KAAKwgC,GAAGr+B,SAAUmB,EAAG,CACvC,MAAMsK,EAAM5N,KAAKwgC,GAAG5yB,IAAItK,GACxB,GAAIsK,EAAImxB,WAAWwC,IAAW3zB,EAAIwnB,SAASoM,GAAS,CAElD5U,EADkB0T,GAAoB1yB,IACrBkqB,KAAKgJ,MAAM9gC,KAAKwgC,GAAGO,QAAQnzB,G,EAGhD,OAAOgf,CACT,CAEA,iBAAMyS,CAAYvgB,GA3PpB,IAA0BlR,EA6PtB,MAAM0b,EAAO0W,GADblhB,GA5PsBlR,EA4PEkR,GA3PfigB,WAAWwB,GAAoB1B,YACtCjxB,EAAIxG,MAAMm5B,GAAoB1B,WAAW18B,QACzCyL,GA2PF,GAAkC,MAA9B5N,KAAKwgC,GAAGO,QAAQzX,EAAKmB,MACvB,MAAM,IAAI3oB,MAAM,8BAADC,OAA+B+c,EAAI,MAEpD,MAAM2L,EAAOqN,KAAKgJ,MAAM9gC,KAAKwgC,GAAGO,QAAQzX,EAAKmB,OAE7C,OADA0V,GAAY7W,GACLmB,CACT,ECxVF,MAAMgX,GAAoB,MAEpB,MAAOC,GAMXliC,WAAAA,GACEQ,KAAK2hC,SAAW,CAAC,CACnB,CAEQ,kBAAOjG,GAIb,OAH0C,MAAtCgG,GAA0B5c,WAC5B4c,GAA0B5c,SAAW,IAAI4c,IAEpCA,GAA0B5c,QACnC,CAQA,sBAAO8c,CAAgBC,EAAgBC,GACrC/9B,EAAiB,MAAV89B,EAAgB,IAAM,yCACzBA,EAAOzM,SAASqM,MAClBI,EAASA,EAAOz6B,MAAM,EAAGy6B,EAAOnN,QAAQ+M,MAE1C19B,EAAO89B,EAAO1/B,OAAS,EAAG,IAAM,uCAChC,MAAMomB,EAAWmZ,GAA0BhG,cAC3C33B,EACiC,MAA7BwkB,EAASoZ,SAASE,GAClB,IAAM,2DAAN9/B,OACI8/B,EAAM,OACdtZ,EAASoZ,SAASE,GAAUC,CAC9B,CAEA,iBAAOC,CAAWF,GAChB,MAAMC,EAAUJ,GAA0BhG,cAAciG,SAASE,GACjE,GAAe,MAAXC,EACF,MAAM,IAAIhgC,MAAM,yCAADC,OAA0C8/B,EAAM,MAEjE,OAAOC,CACT,CAEA,iBAAOE,GACL,OAAO50B,OAAOkc,KAAKoY,GAA0BhG,cAAciG,SAC7D,EAWF,SAASM,GAASjG,GAChB,IAAwC,IAApCA,EAAItH,QAAQ+M,IACd,MAAM,IAAI3/B,MACN,6EACyB,GAAAC,OACtB2/B,GAA0BM,aAAaxzB,KAAK,OAErD,MAAO,CACLqzB,OAAQ7F,EAAItuB,MAAM+zB,IAAmB,GACrC3iB,KAAMkd,EAAItuB,MAAM+zB,IAAmB,GAEvC,CAEArL,eAAe8L,GACXC,EAAmBC,GACC,IAApBC,EAAY/9B,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,IAAAA,UAAA,GACdP,EACIo+B,IAAcC,EACd,IAAM,wCAANrgC,OAA8CogC,EAAS,MAE3D,MAAMG,EAAe/G,GAAiBW,gBAAgBiG,GACtDp+B,EACIu+B,EAAangC,OAAS,EACtB,IAAM,kEAANJ,OACIogC,EAAS,MACjBp+B,EACIu+B,EAAangC,OAAS,EACtB,IAAM,yCAAAJ,OAAyCugC,EAAangC,OAAM,sCAAAJ,OAC9BogC,EAAS,MACjD,MAAMI,EAAcD,EAAa,GAE3BE,EAAejH,GAAiBQ,gBAAgBqG,GACtDr+B,EACIy+B,EAAargC,OAAS,EACtB,IAAM,0EAAAJ,OACKqgC,EAAO,MACtBr+B,EACIy+B,EAAargC,OAAS,EACtB,IAAM,yCAAAJ,OAAyCugC,EAAangC,OAAM,2CAAAJ,OACzBqgC,EAAO,MACpD,MAAMK,EAAcD,EAAa,GAE3BE,EAAeT,GAASE,GAAWN,OACnCc,EAAaV,GAASE,GAAWrjB,KACjC8jB,EAAaF,IAAiBT,GAASE,GAAWN,OAElD/H,QAAuByI,EAAY5E,OAKrC0E,GAAgBO,SACZlB,GAA0BK,WAAWW,GACtCrD,YAAYsD,GAGnB,MAAME,QAAmBJ,EAAYtQ,KAAK2H,GAU1C,OALIuI,IAAiBO,SACblB,GAA0BK,WAAWW,GACtCrD,YAAYsD,GAGZE,EAAWvE,kBACpB,CAqCAlI,eAAe6I,KACb,MAAM6D,EAAUpB,GAA0BM,aACpCpV,EAA2C,CAAC,EAClD,IAAK,MAAMiV,KAAUiB,EAAS,CAC5B,MAAMC,QACIrB,GAA0BK,WAAWF,GAAQ5C,aACvD,IAAK,MAAMngB,KAAQikB,EAAW,CAE5BnW,EADYiV,EAASJ,GAAoB3iB,GAC9BikB,EAAUjkB,E,EAGzB,OAAO8N,CACT,CAmCAwJ,eAAeiJ,GAAYrD,GACzB,MAAMgH,EAAgBf,GAASjG,GAE/B,OADgB0F,GAA0BK,WAAWiB,EAAcnB,QACpDxC,YAAY2D,EAAclkB,KAC3C,CAiDAsX,eAAe6M,GACXd,EAAmBC,GAErB,OAAOF,GAAmBC,EAAWC,GADhB,EAEvB,CAgDAhM,eAAe8M,GACXf,EAAmBC,GAErB,OAAOF,GAAmBC,EAAWC,GADhB,EAEvB,CCvUM,MAAOe,GAAb3jC,WAAAA,GAMU,KAAA4jC,YAAc,mBACd,KAAAC,aAA2B,GAC3B,KAAAC,oBAAsB,EACtB,KAAAC,kBAAmB,CAwD7B,CAtDElnB,KAAAA,CAAMyC,EAAc7P,GAClB,OAAOoN,MAAMyC,EAAM7P,EACrB,CAEA4P,GAAAA,GACE,OAAO2kB,YAAY3kB,KACrB,CAEAI,MAAAA,CAAOwkB,EAAczkB,GACnB,GAAiB,UAAbA,GAAqC,SAAbA,EAC1B,MAAM,IAAIld,MAAM,kDAADC,OACuCid,IAKxD,OAHwB,MAApBhf,KAAK0jC,cACP1jC,KAAK0jC,YAAc,IAAIC,aAElB3jC,KAAK0jC,YAAYzkB,OAAOwkB,EACjC,CACAtkB,MAAAA,CAAOhW,EAAmB6V,GACxB,OAAO,IAAI4kB,YAAY5kB,GAAUG,OAAOhW,EAC1C,CAMA06B,gBAAAA,CAAiBC,EAAuBC,GACjCl1B,QAAWxC,KAAMC,QAAQ,yBAK9BtM,KAAKqjC,aAAat+B,KAAK++B,GACvBr9B,WAAW,KACToI,OAAOm1B,YACH,CAAC31B,KAAMrO,KAAKojC,YAAahhC,MAAOpC,KAAKqjC,aAAalhC,OAAS,GAAI,MAClE4hC,GAEE/jC,KAAKujC,mBACRvjC,KAAKujC,kBAAmB,EACxB10B,OAAOo1B,iBAAiB,UAAYC,IAClC,GAAIA,EAAMC,SAAWt1B,QAAUq1B,EAAMvkC,KAAK0O,OAASrO,KAAKojC,YAAa,CACnEc,EAAME,mBAENN,EADoB9jC,KAAKqjC,aAAaa,EAAMvkC,KAAKyC,UAEjDpC,KAAKsjC,sBACDtjC,KAAKsjC,sBAAwBtjC,KAAKqjC,aAAalhC,SACjDnC,KAAKqjC,aAAe,GACpBrjC,KAAKsjC,oBAAsB,E,IAG9B,KAvBH78B,WAAWq9B,EAAaC,EAyB5B,EAGF,GAAI13B,KAAMvM,IAAI,cAAe,CAC3BuM,KAAMH,YAAY,UAAW,IAAIi3B,IAGjC,IACEzB,GAA0BE,gBACtBrB,GAAoB1B,WAAY,IAAIyC,G,CACxC,MAAOjX,I,CAIT,IACEqX,GAA0BE,gBACtBpE,GAAiBqB,WAAY,IAAIG,G,CACrC,MAAO3U,I,ECvFJ,MAAMga,GAEEC,IAAMC,EAAQ,KAI7B,IAAIC,GAaE,MAAOC,GAKXjlC,WAAAA,GAEEQ,KAAK6f,KAAO0kB,EAAQ,KAGpBvkC,KAAK0jC,YAAc,IAAI1jC,KAAK6f,KAAK8jB,WACnC,CAEAtnB,KAAAA,CAAMyC,EAAcC,GAClB,OAA0B,MAAtB1S,KAAMT,OAAOyQ,MACRhQ,KAAMT,OAAOyQ,MAAMyC,EAAMC,IAGf,MAAfylB,KACFA,GAAcH,MAETG,GAAY1lB,EAAMC,GAC3B,CAEAF,GAAAA,GACE,MAAMje,EAAOkO,QAAQ41B,SACrB,OAAiB,IAAV9jC,EAAK,GAAYA,EAAK,GAAK,GACpC,CAEAqe,MAAAA,CAAOwkB,EAAczkB,GACnB,GAAiB,UAAbA,GAAqC,SAAbA,EAC1B,MAAM,IAAIld,MAAM,sDAADC,OAC2Cid,IAE5D,OAAOhf,KAAK0jC,YAAYzkB,OAAOwkB,EACjC,CACAtkB,MAAAA,CAAOhW,EAAmB6V,GACxB,OAAqB,IAAjB7V,EAAMhH,OACD,GAEF,IAAInC,KAAK6f,KAAK+jB,YAAY5kB,GAAUG,OAAOhW,EACpD,ECjCI,SAAU0a,GACZviB,GACuB,IADHC,EAAA+C,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAW,UAC/BjD,EAAuBiD,UAAAnC,OAAA,EAAAmC,UAAA,QAAAC,EAGzB,OAFAhD,EAAQA,GAAS,UACjBse,GAAwCve,GACjC,IAAIyhB,GAAmBzhB,EAAOC,EAAOF,EAC9C,CD8BIgL,KAAMvM,IAAI,aAAeuM,KAAMvM,IAAI,eACrCuM,KAAMH,YAAY,OAAQ,IAAIu4B,IE1BzB,MAAMlgB,GAAO2Q,GAAG,CAACyP,MAnBxB,SAAiC/hC,EAAiBrB,GAChD,MAAMqjC,EAAKrQ,GAAgB3xB,EAAG,IAAK,QAGnC,IAAKid,GAAkBte,GACrB,MAAM,IAAIO,MAAM,mCAADC,OAAoCR,IAErD,GAAc,WAAVA,GAAmC,WAAbqjC,EAAGrjC,OACf,WAAVA,GAAmC,WAAbqjC,EAAGrjC,MAC3B,MAAM,IAAIO,MAAM,yCAGlB,MAAM2d,EAAqB,CAAC7c,EAAGgiC,GACzB/Y,EAAmB,CAACtqB,SAE1B,OAAOgqB,GAAOC,UACV1a,GAAM2O,EAAgCoM,EAC5C,ICPO,MAAMvH,GAAQ4Q,GAAG,CAAC2P,OATzB,SAAkCjiC,GAChC,MACM6c,EAAyB,CAAC7c,EADrB2xB,GAAgB3xB,EAAG,IAAK,QAAS,sBAK5C,OAAO2oB,GAAOC,UAAU7X,GAAU8L,EACpC,ICfM,SAAU4E,GAAwBzhB,GAAqB,IAAfse,EAAO5c,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,IAAAA,UAAA,GACnDiI,QAAQ8N,IAAIzX,EAAEge,SAASM,GACzB,CCbAuR,KxBgNEnP,GwBlM2B,CAC3BO,OAAM,GACNU,KAAI,GACJD,MAAK,GACLD,MAAKA,ICNP,SAASygB,GAASjkC,GAChB,OAAO,IAAI6F,QAAQC,GAAWF,WAAWE,IAAU8E,KAAK5K,EAC1D,CAEM,MAAOkkC,GAQXvlC,WAAAA,CAAYwlC,GACV,IAAK34B,KAAMC,QAAQ,cAGjB,MAAM,IAAIxK,MACN,uFAIFkjC,EAAejG,WAAWgG,GAAiBlG,cAC7CmG,EAAiBA,EAAe59B,MAAM29B,GAAiBlG,WAAW18B,SAE9C,MAAlB6iC,GAAoD,IAA1BA,EAAe7iC,SAC3C6iC,EA7B2B,SAgC7BhlC,KAAKilC,kBAAoBD,EA/BO,QAgChChlC,KAAKklC,mBACDF,EAhCmC,cAiCzC,CAEA,UAAM7S,CAAK2H,GACT,GAA0B,qBAAdnG,SACV,MAAM,IAAI7xB,MACN,2FAGN,MAAMqjC,EAAat2B,OAAOu2B,IAAIC,gBAAgB,IAAIjN,KAC9C,CAAC0B,EAAeD,YAAa,CAAC7T,KAAM,8BAExC,GAAI8T,EAAeb,yBAAyBiB,YAC1C,MAAM,IAAIp4B,MACN,yFAEC,CACL,MAIM63B,EACFb,GAA8BgB,EALa,CAAC,CAC9CwL,MAAO,CAAC,KAAOtlC,KAAKklC,oBACpBvK,QAASb,EAAeF,eAKpB2L,EAAe12B,OAAOu2B,IAAIC,gBAC5B,IAAIjN,KAAK,CAACN,KAAKC,UAAU4B,IAAa,CAAC3T,KAAM,sBAI3Cwf,EAAqC,MAAxBxlC,KAAKylC,gBACpB9R,SAAS+R,cAAc,KACvB1lC,KAAKylC,gBAQT,GAPAD,EAAWG,SAAW3lC,KAAKilC,kBAC3BO,EAAWI,KAAOL,QAIZT,GAAM,IAAMU,EAAWK,cAAc,IAAIC,WAAW,WAEzB,MAA7BhM,EAAeD,WAAoB,CACrC,MAAMkM,EAA4C,MAAzB/lC,KAAK+lC,iBAC1BpS,SAAS+R,cAAc,KACvB1lC,KAAK+lC,iBACTA,EAAiBJ,SAAW3lC,KAAKklC,mBACjCa,EAAiBH,KAAOT,QAClBL,GACF,IAAMiB,EAAiBF,cAAc,IAAIC,WAAW,U,CAG1D,MAAO,CAACxH,mBAAoBrE,GAA6BH,G,CAE7D,EAvEgBiL,GAAAlG,WAAa,eA0E/B,MAAMmH,GAIJxmC,WAAAA,CAAYymC,GACV,GAAa,MAATA,GAAiBA,EAAM9jC,OAAS,EAClC,MAAM,IAAIL,MACN,2EAAAC,OACgBkkC,IAEtBjmC,KAAKkmC,SAAWD,EAAM,GACtBjmC,KAAKmmC,aAAeF,EAAM7+B,MAAM,EAClC,CAEA,UAAMu2B,GACJ,OAAO,IAAIj3B,QAAQ,CAACC,EAASC,KAC3B,MAAMw/B,EAAa,IAAIC,WACvBD,EAAWE,OAAUpC,IAEnB,MAAMvK,EAAY7B,KAAKgJ,MAAOoD,EAAMqC,OAAe3iC,QAE7Cq1B,EAAgBU,EAAUV,cAChC,GAAqB,MAAjBA,EAGF,YAFAryB,EAAO,IAAI9E,MAAM,4CAADC,OACZ/B,KAAKkmC,SAAS73B,QAKpB,GAAuB,MADCsrB,EAAUN,gBAIhC,YAFAzyB,EAAO,IAAI9E,MAAM,6CAADC,OACZ/B,KAAKkmC,SAAS73B,QAIpB,GAAiC,IAA7BrO,KAAKmmC,aAAahkC,OAEpB,YADAwE,EAAQ,CAACsyB,kBAIX,MAAMuN,EAAwBzM,GAC1BJ,EAAYN,GAAoBr5B,KAAKg6B,YAAYX,IACrD1yB,EAAQ6/B,IAGVJ,EAAWhI,QAAUlT,GAAStkB,EAC1B,yEAAA7E,OACc/B,KAAKkmC,SAAS73B,KAAI,qCAAmC,wCAEvE+3B,EAAWK,WAAWzmC,KAAKkmC,WAE/B,CAEQlM,WAAAA,CAAYX,GAGlB,MAAMO,EAAsC,GACtC0L,EAAkB,GACxB,IAAK,MAAM5K,KAASrB,EAClBO,EAAY70B,QAAQ21B,EAAMC,SAC1B2K,EAAMvgC,QAAQ21B,EAAM4K,OAGtB,MAAMoB,EACF1mC,KAAK2mC,4BAA4BtN,GAE/BuN,EACFtB,EAAM99B,IAAIsX,GAAQ9e,KAAK6mC,gBAAgB/nB,EAAM4nB,EAAW5nB,KAE5D,OAAOpY,QAAQ+Z,IAAImmB,GAAUn7B,KACzBitB,GAAW,CAACkB,EAAanB,GAAwBC,IACvD,CAEQmO,eAAAA,CAAgB/nB,EAAcgoB,GACpC,OAAO,IAAIpgC,QAAQ,CAACC,EAASC,KAC3B,MAAMmgC,EAAmB,IAAIV,WAC7BU,EAAiBT,OAAUpC,IAEzB,MAAMrK,EAAcqK,EAAMqC,OAAe3iC,OACzC+C,EAAQkzB,IAEVkN,EAAiB3I,QAAUlT,GACvBtkB,EAAO,6CAAD7E,OAA8C+c,EAAI,OAC5DioB,EAAiBC,kBAAkBF,IAEvC,CAKQH,2BAAAA,CAA4B3N,GAElC,MAAMiO,EAAsB,GACtBC,EAAYlnC,KAAKmmC,aAAa3+B,IAAIs/B,GAAQnO,GAASmO,EAAKz4B,OACxDq4B,EAAqC,CAAC,EAC5C,IAAK,MAAMpQ,KAAS0C,EAClB1C,EAAMgP,MAAMl8B,QAAQ0V,IAClB,MAAMqoB,EAAexO,GAAS7Z,GAC9B,IAAyC,IAArCmoB,EAAUvS,QAAQyS,GACpB,MAAM,IAAIrlC,MACN,0DAAAC,OACIolC,EAAY,MAGtB,GADAF,EAAUliC,KAAKoiC,IAC0B,IAArCD,EAAUxS,QAAQyS,GACpB,MAAM,IAAIrlC,MAAM,8BAADC,OACmBolC,EAAY,uBAE9CT,EAAW5nB,GAAQ9e,KAAKmmC,aAAae,EAAUxS,QAAQyS,MAK7D,GAAIF,EAAU9kC,SAAWnC,KAAKmmC,aAAahkC,OACzC,MAAM,IAAIL,MACN,2DAAAC,OACIklC,EAAU9kC,OAAM,8CAA4C,IAAAJ,OAC5D/B,KAAKmmC,aAAahkC,OAAM,OAElC,OAAOukC,CACT,EAmGI,SAAUU,GAAanB,GAC3B,OAAO,IAAID,GAAaC,EAC1B,CCrTM,SAAUoB,GACZT,EAAmCU,EACnCC,EAAwBC,IAkB1B,SAAuBZ,GACrB7iC,EACgB,MAAZ6iC,GAAoBhiC,MAAMC,QAAQ+hC,IAAaA,EAASzkC,OAAS,EACjE,IAAM,sCACZ,CArBAslC,CAAcb,GAuBd,SAAuBW,EAAuBC,GAC5CzjC,EACIwjC,GAAiB,GAAKA,GAAiB,EACvC,IAAM,uEAAAxlC,OACmBwlC,IAC7BxjC,EACIyjC,GAAe,GAAKA,GAAe,EACnC,IAAM,qEAAAzlC,OACiBylC,IAC3BzjC,EACIyjC,GAAeD,EACf,IAAM,4EAAAxlC,OACmBwlC,EAAa,qBAAmB,GAAAxlC,OAClDylC,GACb,CAlCAE,CAFAH,EAAiC,MAAjBA,EAAwB,EAAIA,EAC5CC,EAA6B,MAAfA,EAAsB,EAAIA,GAExC,IAAIG,EAAkB,EAmCtB,OAAOjhC,QAAQ+Z,IAAImmB,EAASp/B,IAjCHogC,IACvBA,EAAQn8B,KAAKrL,IACX,MAAMynC,EAAWN,KACXI,EAAkBf,EAASzkC,QAAUqlC,EAAcD,GAGzD,OADAD,EAAWO,GACJznC,IAEFwnC,IA0BX,CCpCOxR,eAAe0R,GAClBC,EAAqB5L,GACJ,MAAfA,IACFA,EAAc,CAAC,GAGjB,MAAM6L,EAAqC,MAAzB7L,EAAY6L,UAAoB37B,KAAMD,SAASiQ,MACf8f,EAAY6L,UAGxDC,EAAWF,EAAUvgC,IACvB0gC,GACIF,EAAUE,EAAU/L,EAAYgM,YAAa,CAACC,UAAU,KAW1DC,GANsC,MAA1BlM,EAAYmL,iBACpB5gC,QAAQ+Z,IAAIwnB,SACZZ,GACFY,EAAU9L,EAAYmL,WANH,EACF,KAQQ9/B,IAAI8gC,GAAYA,EAASC,eAU1D,OAL0C,MAA1BpM,EAAYmL,iBAClB5gC,QAAQ+Z,IAAI4nB,SACZhB,GACFgB,EAAgBlM,EAAYmL,WANR,GACF,EAQ5B,CAWOlR,eAAe4D,GAClBhB,GAEyB,IAFQwP,EAAclkC,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,GAClDmkC,EAAsBnkC,UAAAnC,OAAA,EAAAmC,UAAA,QAAAC,EACtB4jC,EAAyB7jC,UAAAnC,OAAA,EAAAmC,UAAA,QAAAC,EAW3B,OAFoBmkC,GAFEC,GAClBb,GAAyBa,EAAW,CAACR,gBAGlCnO,CAAYhB,EAAUwP,EAAgBC,EAC/C,CA0BM,SAAUC,GACZE,GAGF,OAAOxS,eACI4C,GACmD,IADlBwP,EAAclkC,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,GAClDmkC,EAAsBnkC,UAAAnC,OAAA,EAAAmC,UAAA,QAAAC,EAG/B,MAAMskC,EAAyB7P,EAASxxB,IAAI,KAAM,GAC5CshC,EAKF,CAAC,EACCC,EACa,MAAfN,EAAsBA,EAAYjhC,IAAI,KAAM,GAAS,GACnDwhC,EAAmC,GAwCzC,GAvCAhQ,EAAS5vB,QAAQ,CAAC6/B,EAAqBC,KACrC,IAAIC,EAAc,EAClBF,EAAoBtO,QAAQvxB,QAAQggC,IAClC,MAAMC,EAAY,iBAAkBD,EAChCA,EAAalS,aAAa31B,MAC1B6nC,EAAa7nC,MAEX+nC,EAAepT,GAAqBmT,GACtCxpB,GAAmBupB,EAAa9nC,OAE9BioC,EAA8BA,KAClCV,EAAuBK,IAAc,EACE,MAAnCJ,EAAoBI,KACtBJ,EAAoBI,GAAc,IAGpCJ,EAAoBI,GAAYnkC,KAAK,CACnCykC,cAAeJ,EACfD,cACAM,UAAWH,KAII,MAAfb,EACFA,EAAYr/B,QAAQ,CAACsgC,EAAYC,KAC3BD,IAAeN,EAAa/6B,OAC9Bk7B,IACAR,EAAaY,IAAe,KAIhCJ,IAGFP,EAAuBjkC,KAAKqkC,EAAa/6B,MACzC86B,GAAeG,OAIdP,EAAarhC,MAAMkiC,GAASA,GAAQ,CACvC,MAAMC,EAAkBpB,EAAYha,OAAO,CAACC,EAAGprB,KAAOylC,EAAazlC,IACnE,MAAM,IAAIxB,MACN,qDAAAC,OACG8nC,EAAgBr7B,KAAK,MAAK,QAAM,yCACK,GAAAzM,OACrCinC,EAAuBx6B,KAAK,MAAK,K,CAK1C,MAAMs7B,EACFjB,EAAuBr+B,OAAO,CAACu/B,EAAaC,EAAa1mC,KACnD0mC,GACFD,EAAYhlC,KAAKzB,GAEZymC,GACN,IAEDpB,EAAsB,GAC5BmB,EAAoB1gC,QAAQ9F,IAC1B01B,EAAS11B,GAAGgiC,MAAMl8B,QAAQ6gC,IACxB,MAAMC,EAAW1B,GACXA,EAAepT,SAAS,KAAa,GAAN,KAAY6U,EACjDtB,EAAU5jC,KAAKmlC,OAGnB,MAAMxR,QAAgBkQ,EAAqBD,GAErCwB,EAAmC,CAAC,EAC1C,IAAIC,EAAoB,EAkCxB,OAjCAN,EAAoB1gC,QAAQ9F,IAC1B,MAAM+mC,EAAarR,EAAS11B,GAAGgiC,MAAMnjC,OAErC,IAAImoC,EAAa,EACjB,IAAK,IAAIhnC,EAAI,EAAGA,EAAI+mC,EAAY/mC,IAC9BgnC,GAAc5R,EAAQ0R,EAAoB9mC,GAAGm0B,WAI/C,MAAM8S,EAAc,IAAIrQ,YAAYoQ,GAC9BE,EAAkB,IAAIniC,WAAWkiC,GACvC,IAAIE,EAAoB,EACxB,IAAK,IAAInnC,EAAI,EAAGA,EAAI+mC,EAAY/mC,IAAK,CACnC,MAAMugB,EAAS,IAAIxb,WAAWqwB,EAAQ0R,EAAoB9mC,IAC1DknC,EAAgBrqC,IAAI0jB,EAAQ4mB,GAC5BA,GAAqB5mB,EAAO4T,U,CAGPqR,EAAoBxlC,GAC5B8F,QAAQggC,IACrB,MAGMsB,EACF1T,GAJeuT,EAAYnjC,MAC3BgiC,EAAaD,YACbC,EAAaD,YAAcC,EAAaK,WAEd,CAACL,EAAaI,gBAC5C,IAAK,MAAMn7B,KAAQq8B,EACjBP,EAAiB97B,GAAQq8B,EAAgBr8B,KAI7C+7B,GAAqBC,IAGhBF,CACT,CACF,CFKA5O,GAAiBI,mBAXgCK,GAC1C3vB,KAAMC,QAAQ,gBAGZ1H,MAAMC,QAAQm3B,IAAQA,EAAI+C,WAAWgG,GAAiBlG,YAgDzD,WAAmD,IAAxBmG,EAAc1gC,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,QAChD,OAAO,IAAIygC,GAAiBC,EAC9B,CAjDa2F,CAAiB3O,EAAI50B,MAAM29B,GAAiBlG,WAAW18B,SAHzD,MGjNL,MAAOyoC,GAcXprC,WAAAA,CAAYsf,EAAcqd,GAgCxB,GAvCO,KAAA0O,eAAiB,OAQL,MAAf1O,IACFA,EAAc,CAAC,GAEjBn8B,KAAK8qC,iBAAmB3O,EAAY2O,iBACpC9qC,KAAKsnC,WAAanL,EAAYmL,WAC9BtnC,KAAK+qC,mBAAqB5O,EAAY4O,mBAET,MAAzB5O,EAAY6L,WACdjkC,EACqC,oBAA1Bo4B,EAAY6L,UACnB,IAAM,+HAGVhoC,KAAKqc,MAAQ8f,EAAY6L,WAEzBhoC,KAAKqc,MAAQhQ,KAAMD,SAASiQ,MAG9BtY,EACY,MAAR+a,GAAgBA,EAAK3c,OAAS,EAC9B,IAAM,2DAGNyC,MAAMC,QAAQia,IAChB/a,EACoB,IAAhB+a,EAAK3c,OACL,IAAM,+CAA8C,qBAAAJ,OAC3B+c,EAAK3c,OAAM,OAE1CnC,KAAK8e,KAAOA,EAEmB,MAA3Bqd,EAAYgM,aACoB,MAAhChM,EAAYgM,YAAY6C,KAC1B,MAAM,IAAIlpC,MACN,sEAEN9B,KAAKmoC,YAAchM,EAAYgM,aAAe,CAAC,CACjD,CAEA,UAAMhW,CAAK2H,GACT,GAAIA,EAAeb,yBAAyBiB,YAC1C,MAAM,IAAIp4B,MACN,2FAIN,MAAMmN,EAAO7B,OAAOC,OAAO,CAAC49B,OAAQjrC,KAAK6qC,gBAAiB7qC,KAAKmoC,aAC/Dl5B,EAAK+7B,KAAO,IAAIE,SAEhB,MAIMC,EACFrS,GAA8BgB,EALa,CAAC,CAC9CwL,MAAO,CAAC,uBACR3K,QAASb,EAAeF,eAK1B3qB,EAAK+7B,KAAKI,OACN,aACA,IAAIhT,KACA,CAACN,KAAKC,UAAUoT,IAChB,CAACnlB,KA5EK,qBA6EV,cAE6B,MAA7B8T,EAAeD,YACjB5qB,EAAK+7B,KAAKI,OACN,oBACA,IAAIhT,KAAK,CAAC0B,EAAeD,YAAa,CAAC7T,KAnFlB,6BAoFrB,qBAGN,MAAMsiB,QAAiBtoC,KAAKqc,MAAMrc,KAAK8e,KAAM7P,GAE7C,GAAIq5B,EAAS+C,GACX,MAAO,CACL/M,mBAAoBrE,GAA6BH,GACjDwR,UAAW,CAAChD,IAGd,MAAM,IAAIxmC,MACN,mEAAAC,OACGumC,EAASiD,OAAM,KAE1B,CAUA,UAAM5N,GACJ,MAAM6N,QAA2BxrC,KAAKqc,MAAMrc,KAAK8e,KAAM9e,KAAKmoC,aAE5D,IAAKqD,EAAmBH,GACtB,MAAM,IAAIvpC,MACN,cAAAC,OAAc/B,KAAK8e,KAAI,gCAAA/c,OACpBypC,EAAmBD,OAAM,uCAAqC,wCAGvE,IAAI5R,EACJ,IACEA,QAAkB6R,EAAmBC,M,CACrC,MAAO3tB,GACP,IAAIyM,EAAU,+CAAHxoB,OAAkD/B,KAAK8e,KAAI,KActE,MAXI9e,KAAK8e,KAAKsW,SAAS,OACrB7K,GAAW,+UAOXA,GAAW,uEAGP,IAAIzoB,MAAMyoB,E,CAIlB,MAAM0O,EAAgBU,EAAUV,cAC1BI,EAAkBM,EAAUN,gBAClC,GAAqB,MAAjBJ,GAA4C,MAAnBI,EAC3B,MAAM,IAAIv3B,MACN,2BAAAC,OAA2B/B,KAAK8e,KAAI,iEAI1C,OAAOib,GACHJ,EAAYN,GAAoBr5B,KAAKg6B,YAAYX,GACvD,CAEQ,iBAAMW,CAAYX,GAExB,MAAMqS,EAAa9mC,MAAMC,QAAQ7E,KAAK8e,MAAQ9e,KAAK8e,KAAK,GAAK9e,KAAK8e,MAC3DyiB,EAAQC,GAyCb,SAAmBxF,GACvB,MAAM2P,EAAY3P,EAAI4P,YAAY,KAC5BC,EAAkB7P,EAAI4P,YAAY,KAClCrK,EAASvF,EAAI3G,UAAU,EAAGsW,GAC1BnK,EACFqK,EAAkBF,EAAY3P,EAAI3G,UAAUwW,GAAmB,GACnE,MAAO,CAACtK,EAAS,IAAKC,EACxB,CAhD6BsK,CAASJ,GAC5BK,EAAa/rC,KAAK8qC,kBAAoBvJ,EAEtC3H,EAAca,GAAepB,GAE7B0O,EAAsB,GACtBiE,EAAsC,GAC5C,IAAK,MAAMC,KAAgB5S,EACzB,IAAK,MAAMva,KAAQmtB,EAAa3G,MACC,MAA3BtlC,KAAK+qC,mBACPiB,EAAYjnC,KAAK/E,KAAK+qC,mBAAmBjsB,IAEzCipB,EAAUhjC,KAAKgnC,EAAajtB,EAAO0iB,GAKrCxhC,KAAK+qC,oBACPhD,EAAUhjC,cAAc2B,QAAQ+Z,IAAIurB,IAQtC,MAAO,CAACpS,EAAanB,SALCqP,GAAyBC,EAAW,CACxDI,YAAanoC,KAAKmoC,YAClBH,UAAWhoC,KAAKqc,MAChBirB,WAAYtnC,KAAKsnC,cAGrB,EAuBI,SAAU4E,GAAalQ,GAC3B,OAAkD,MAA3CA,EAAImQ,MAAMvB,GAAYwB,iBAC/B,CApMkBxB,GAAAwB,iBAAmB,eAsM9B,MAAMC,GACTA,CAACrQ,EAAaG,KACZ,GAAqB,qBAAV9f,QACS,MAAf8f,GAAgD,MAAzBA,EAAY6L,WAItC,OAAO,KACF,CACL,IAAIsE,GAAS,EAMb,GAJEA,EADE1nC,MAAMC,QAAQm3B,GACPA,EAAIt0B,MAAM6kC,GAAWL,GAAaK,IAElCL,GAAalQ,GAEpBsQ,EACF,OAAOE,GAAKxQ,EAAKG,E,CAGrB,OAAO,MA2EP,SAAUqQ,GAAK1tB,EAAcqd,GACjC,OAAO,IAAIyO,GAAY9rB,EAAMqd,EAC/B,CAOM,SAAUsQ,GACZ3tB,EAAcqd,GAChB,OAAOqQ,GAAK1tB,EAAMqd,EACpB,CArFAZ,GAAiBI,mBAAmB0Q,IACpC9Q,GAAiBM,mBAAmBwQ,IC/OpC,MAAMK,GACJltC,WAAAA,CAA6Bs6B,GAAA,KAAAA,eAAAA,CAAkC,CAE/D6D,IAAAA,GACE,OAAO39B,KAAK85B,cACd,EAGF,MAAM6S,GACJntC,WAAAA,CACmBijC,GAAA,KAAAA,YAAAA,CAAgD,CAEnEtQ,IAAAA,CAAK2H,GACH,OAAO95B,KAAKyiC,YAAY3I,EAC1B,EAGF,MAAM8S,GAIJptC,WAAAA,CAAY+8B,GACNA,EAAQoB,OACV39B,KAAK29B,KAAO,IAAMj3B,QAAQC,QAAQ41B,EAAQoB,SAExCpB,EAAQpK,OACVnyB,KAAKmyB,KAAQ2H,GACXpzB,QAAQC,QAAQ41B,EAAQpK,KAAK2H,IAEnC,EAwBI,SAAU+S,GACZ/S,EAAmCF,EACnCC,EAA0BJ,GAG5B,OAAO,IAAImT,GAAiBE,MADfxoC,WAEf,CAuBM,SAAUwoC,GACZhT,EAAmCF,EACnCC,EAA0BJ,GAC5B,GAAyB,IAArBn1B,UAAUnC,OAAc,CAI1B,OAFwD,MAAnD23B,EAAkCb,eACe,MAAjDa,EAAkCF,YAE9B,IAAI8S,GAAkB5S,IAI7BvtB,QAAQC,KACJ,yNAIG,IAAIkgC,GAAkB,CAACzT,cAAea,I,CAU/C,OALAvtB,QAAQC,KACJ,yNAIG,IAAIkgC,GAAkB,CAC3BzT,cAAea,EACfF,cACAC,aACAJ,kBAGN,CAiBM,SAAUsT,GACZtK,GAEF,OAAO,IAAIkK,GAAiBlK,EAC9B,CAiBM,SAAUuK,GACZvK,GACF,OAAO,IAAIkK,GAA6BlK,EAC1C,CC3HO,MAAMwK,GAAS/X,GAAG,CAACgY,QAd1B,SACI1pC,EAAsBC,GACJ,IAD0B0pC,EAAU7oC,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,IAAAA,UAAA,GACtD8oC,EAAU9oC,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,IAAAA,UAAA,GACR+oC,EAAK9Y,GAAgB/wB,EAAG,IAAK,UAC7B8pC,EAAK/Y,GAAgB9wB,EAAG,IAAK,WAChC4pC,EAAIC,GAAMrnB,GAAeonB,EAAIC,GAE9B,MAAM7tB,EAA4B,CAACjc,EAAG6pC,EAAI5pC,EAAG6pC,GACvCzhB,EAA0B,CAACshB,aAAYC,cAE7C,OAAO7hB,GAAOC,UACV/a,GAAagP,EAAgCoM,EACnD,ICYO,MAAM0hB,GAASrY,GAAG,CAACsY,QAhB1B,SACIxZ,EAA4ByZ,GACH,IADkBC,EAAOppC,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,EAAGqpC,EAAQrpC,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,EACnE/C,EAAA+C,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAkB,QACpB,GAAImpC,EAAQ,EACV,MAAM,IAAI3rC,MAAM,iDAADC,OAAkD0rC,IAEnE,MAEMhuB,EAAuB,CAACuU,QAFbO,GAAgBP,EAAS,UAAW,SAAU,UAGzDnI,EAAqB,CAACtqB,QAAOksC,QAAOC,UAASC,YAEnD,OAAOpiB,GAAOC,UACVrV,GAAQsJ,EACRoM,EACN,ICjCM,SAAU+hB,KACdvhC,KAAMlM,IAAI,QAAQ,EACpB,CAgBM,SAAU0tC,KACdxhC,KAAMlM,IAAI,SAAS,EACrB,CAGM,SAAU2tC,KACdzhC,KAAMlM,IAAI,gCAAgC,GAC1CoM,QAAQC,KAAK,yDACf,CAGM,SAAUuhC,GAAgB9pC,GAC1BoI,KAAMC,QAAQ,iCAChBC,QAAQC,KACJvI,gFAGR,CAQM,SAAU+qB,KACdzD,GAAOyD,kBACT,CAOM,SAAUgf,KACd,OAAOziB,EACT,CAuBM,SAAU9pB,KACd,OAAO8pB,GAAO9pB,QAChB,CAiCM,SAAU2tB,GAAQvuB,GAEtB,OAAO0qB,GAAO6D,QAAQvuB,EACxB,CA0CM,SAAU+pB,GACZC,EAA6BC,GAC/B,OAAOS,GAAOX,KAAKC,EAAUC,EAC/B,CAaM,SAAUlpB,GAAQ+kB,GACNJ,GAAsBI,GAC9Bvd,QAAQgd,GAAUA,EAAOxkB,UACnC,CAkCM,SAAU2rB,GAAuB3pB,GACrC,OAAO2nB,GAAOgC,KAAK3pB,EACrB,CA2BM,SAAUhD,GAAKC,GACnB,OAAO0qB,GAAO3qB,KAAKC,EACrB,CAiBM,SAAUqoB,GAAWzO,GACzB,OAAO8Q,GAAOrC,WAAWzO,EAC3B,CASM,SAAUkO,KACd,OAAO4C,GAAO5C,OAChB,CAQM,SAAUslB,KACd,OAAO1iB,GAAO9Q,WAChB,CAOM,SAAU+P,GAAcnc,GAC5Bkd,GAAOf,cAAcnc,EACvB,CAMM,SAAUkb,GAAYlb,GAC1B,OAAOkd,GAAOhC,YAAYlb,EAC5B,CAOM,SAAUmb,GAAmBnb,GAEjC,OAAOkd,GAAO/B,mBAAmBnb,EACnC,CAiBM,SAAUqb,GACZrb,EAAcob,GACF,IAAZE,EAAQrlB,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,EACb,OAAOinB,GAAO7B,gBAAgBrb,EAAMob,EAASE,EAC/C,CAUM,SAAUlqB,KACd,OAAO8rB,GAAO9rB,OAChB,CAQM,SAAUyM,GAAYC,EAAsBC,GAChDC,KAAMH,YAAYC,EAAcC,EAClC,ChClJEmX,GgCzKsBwqB,GCvBjB,MAAMpY,GAAOT,GAAG,CAACgZ,MAPxB,SAAiCptB,GAC/B,MAEMrB,EAAqB,CAACqB,MAFbyT,GAAgBzT,EAAO,QAAS,SAG/C,OAAOyK,GAAOC,UAAU3X,GAAM4L,EAChC,ICEO,MAAM0uB,GAAMjZ,GAAG,CAACkZ,KANvB,SAAgCxrC,GAC9B,MAEM6c,EAAoB,CAAC7c,EAFhB2xB,GAAgB3xB,EAAG,IAAK,QAGnC,OAAO2oB,GAAOC,UAAU3V,GAAK4J,EAC/B,ICGO,MAAMiW,GAAOR,GAAG,CAACmZ,MAPxB,SAAiCvtB,GAC/B,MAEMrB,EAAqB,CAACqB,MAFbyT,GAAgBzT,EAAO,QAAS,SAG/C,OAAOyK,GAAOC,UAAU3U,GAAM4I,EAChC,ICqDO,MAAM6uB,GAAYpZ,GAAG,CAACqZ,WA9C7B,SACI3rC,EAAiB4rC,EAAiBC,GACpC,MAAM7J,EAAKrQ,GAAgB3xB,EAAG,IAAK,aAgBnC,GAdY,MAAR4rC,IACFA,EAAO5J,EAAGtjC,MAAMkG,IAAI,CAACC,EAAGnE,IAAMA,GAAGorC,WAEnC7uB,EACI+kB,EAAGr9B,OAASinC,EAAKrsC,OACjB,IAAM,qCAAAJ,OAAqC6iC,EAAGr9B,KAAI,kCAAAxF,OACjBysC,EAAI,MACzCA,EAAKplC,QAAQ9B,IACXuY,EACIvY,GAAQ,GAAKA,EAAOs9B,EAAGr9B,KACvB,IAAM,+CAAAxF,OAA+C6iC,EAAGr9B,KAAO,GAAC,YAAAxF,OAChDysC,MAGlB5J,EAAGr9B,MAAQ,EACb,OAAOq9B,EAAGtgB,QAGZ,MAAM7E,EAA0B,CAAC7c,EAAGgiC,GAC9B/Y,EAAwB,CAAC2iB,QAE/B,MAAiB,cAAb5J,EAAGrjC,MACEqpB,GAAK,KACV,IAAIgL,EAAQF,GAAKkP,GACb/O,EAAQF,GAAKiP,GAUjB,OATAhP,EAAQrK,GAAOC,UACX/R,GAAW,CAAC7W,EAAGgzB,GACf/J,GACJgK,EAAQtK,GAAOC,UACX/R,GAAW,CAAC7W,EAAGizB,GACfhK,GACA4iB,IACF5Y,EAAQsY,GAAItY,IAEPL,GAAQI,EAAOC,KAInBtK,GAAOC,UACV/R,GAAWgG,EAAgCoM,EACjD,ICDO,MAAM8iB,GAAkBzZ,GAAG,CAAC0Z,iBAtC7B,SACFC,EAA6BC,EAC7BC,GACF,MAAMC,EAAUza,GAAgBsa,EAAQ,SAAU,mBAC5CI,EACF1a,GAAgBua,EAAa,cAAe,mBAEhDjvB,EACkB,MAAdkvB,GAAsBA,EAAa,GAAKjrC,OAAOqH,UAAU4jC,GACzD,IAAM,kEAAAhtC,OACSgtC,IACnBlvB,EACqB,IAAjBmvB,EAAQznC,KACR,IAAM,gDAANxF,OAAsDitC,EAAQznC,OAClEsY,EAC0B,IAAtBovB,EAAa1nC,KACb,IAAM,wDAAAxF,OACSktC,EAAa1nC,OAChCsY,EACImvB,EAAQ1tC,MAAM,KAAO2tC,EAAa3tC,MAAM,GACxC,IAAM,0CAAAS,OACCitC,EAAQ1tC,MAAM,GAAE,SAAAS,OAAQktC,EAAa3tC,MAAM,GAAE,MAAI,mEAE5Due,EACIkvB,EAAa,GAAKjrC,OAAOqH,UAAU4jC,GACnC,IAAM,+DAAAhtC,OACCgtC,IAIX,MAAMG,EAAe3B,GAAOhpB,GAAKyqB,EAAS,SAAUD,GAC9CI,EACF5B,GAAOhpB,GAAK0qB,EAAc,SAAUF,GAClCK,EAA0Bd,GAAUY,GACpCjc,EAAoBga,GAAOmC,EAAeD,GAChD,OAAO5qB,GAAK0O,EAAS,QACvB,ICnEM,SAAUoc,GACZC,EAAmBC,GACrB,MAAMC,EAASF,EAAQntC,OACjBstC,EAAiB,GACvB,IAAK,IAAInsC,EAAI,EAAGA,EAAIksC,EAAQlsC,IAAK,CAC/B,MAAMosC,EAAMF,EAAS,EAAIlsC,EACnBE,EAAI8rC,EAAQI,IAAQ,GAChBH,EAASA,EAASptC,OAAS,EAAImB,IAAM,GACvC,GAAW,IAANE,GACXisC,EAAKE,QAAQD,E,CAGjB,OAAOD,CACT,CAMM,SAAUG,GACZN,EAAmBC,GACrB,MAAM3rC,EAAmB,GACzB,IAAK,IAAIN,EAAI,EAAGA,EAAIisC,EAASptC,OAAQmB,IAAK,CACxC,MAAMusC,EAAQP,EAAQA,EAAQntC,OAASmB,EAAI,GACrCwsC,EAAUP,EAASptC,OAASmB,EAAI,EAChCysC,EAASR,EAASO,IACX,MAATD,GAA4B,IAAVA,GAAeE,EAAS,IAC5CnsC,EAAO+rC,QAAQG,E,CAGnB,OAAOlsC,CACT,CAEM,SAAUosC,GACZ7rC,EAAkBC,GACpB,MAAMR,EAAmB,GACnBke,EAAIzf,KAAKQ,IAAIsB,EAAOhC,OAAQiC,EAAOjC,QAEzC,IAAK,IAAImB,EAAI,EAAGA,EAAIwe,EAAGxe,IAAK,CAC1B,IAAIE,EAAIW,EAAOA,EAAOhC,OAASmB,EAAI,GAC1B,MAALE,IACFA,EAAI,GAEN,IAAIC,EAAIW,EAAOA,EAAOjC,OAASmB,EAAI,GAInC,GAHS,MAALG,IACFA,EAAI,GAEI,IAAND,EACFI,EAAO+rC,QAAQlsC,QACV,GAAU,IAANA,EACTG,EAAO+rC,QAAQnsC,OACV,IAAIA,IAAMC,EAAG,CAClB,MAAMwsC,EAAS,2DAAAluC,OACRoC,EAAM,SAAApC,OAAQqC,EAAM,KAC3B,MAAMtC,MAAMmuC,E,CAEZrsC,EAAO+rC,QAAQnsC,E,EAGnB,OAAOI,CACT,CCvCM,SAAUssC,GACZ7uC,EAAsBC,EACtBC,GAEF,GADAkD,EAAcpD,GACD,MAATC,GAAkC,IAAjBA,EAAMa,OACzB,MAAM,IAAIL,MAAM,mDAElB,MAAM6yB,EAAgBd,GAAWxyB,EAAQE,GACzC,GAA6B,IAAzBozB,EAAcxyB,QAAyC,IAAzBwyB,EAAcxyB,OAC9C,MAAM,IAAIL,MACN,oEAEN,GAA6B,IAAzB6yB,EAAcxyB,QAAyB,MAATb,EAChC,MAAM,IAAIQ,MACN,2EAGN,OAAOuhB,GAAWhiB,EAAQC,EAAOqzB,EAAepzB,EAClD,CCnCA,IAAI4uC,GAkCJ,SAASC,GACLC,GAEe,IAAfC,EAAWhsC,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,EAEhB,GAAIgsC,EAAc,EAChB,MAAM,IAAIxuC,MACN,kEAEN,GAAc,MAAVuuC,EACF,MAAM,IAAIvuC,MAAM,4DAElB,IAAIyuC,GAAc,EACdC,GAAc,EACdC,GAAU,EACVC,GAAU,EACVC,GAAe,EACfC,GAAgB,EACpB,GAAKP,EAAqB1wC,gBAAgB0I,WACxCkoC,GAAc,OACT,GACoB,qBAAfM,WAA8BR,aAAkBQ,UAC1DL,GAAc,OACT,GAC2B,qBAAtBM,kBACRT,aAAkBS,iBACpBL,GAAU,OACL,GAC2B,qBAAtBM,kBACRV,aAAkBU,iBACpBL,GAAU,OAEL,GAAkC,MAA7BL,EAAeW,WACzBL,GAAe,MACV,MACsB,qBAAjBM,aAAgCZ,aAAkBY,aAG5D,MAAM,IAAInvC,MACN,6OAG0D,WAAAC,OAC9CsuC,EAAc7wC,YAAY6O,OAP1CuiC,GAAgB,C,CAYlB,GAAc,MADCp2B,GAAUR,GAAYuR,GAAO9Q,aACxB,CAClB,MAAMgF,EAA2B,CAAC4wB,UAC5BxkB,EAAyB,CAACykB,eAChC,OAAO/kB,GAAOC,UACVxR,GAAYyF,EACZoM,E,CAGN,MAAOlmB,EAAOurC,GAAUT,EACpB,CACGJ,EAA4Bc,WAC5Bd,EAA4Be,aAE/B,CAACf,EAAO1qC,MAAO0qC,EAAOa,QAC1B,IAAI1oC,EAgCAnH,EA9BJ,GAAIsvC,EACFnoC,EAEK6nC,EAAeW,WAAW,MAAMK,aAAa,EAAG,EAAG1rC,EAAOurC,GAAQvxC,UAClE,GAAI6wC,GAAeD,EACxB/nC,EAAQ6nC,EAAiC1wC,UACpC,GAAI+wC,GAAWD,GAAWG,EAAe,CAC9C,GAA2B,MAAvBT,GACF,GAAwB,qBAAbxc,SAA0B,CACnC,GAA+B,qBAApB2d,iBACsC,qBAAtCC,kCAIT,MAAM,IAAIzvC,MACN,wGAHJquC,GAAsB,IAAImB,gBAAgB,EAAG,GAAGN,WAAW,K,MAO7Db,GACIxc,SAAS+R,cAAc,UAAUsL,WAC7B,KAAM,CAACQ,oBAAoB,IAGvCrB,GAAoBsB,OAAO9rC,MAAQA,EACnCwqC,GAAoBsB,OAAOP,OAASA,EACpCf,GAAoBuB,UAChBrB,EAA4B,EAAG,EAAG1qC,EAAOurC,GAC7C1oC,EAAO2nC,GAAoBkB,aAAa,EAAG,EAAG1rC,EAAOurC,GAAQvxC,I,CAG/D,GAAoB,IAAhB2wC,EACFjvC,EAAS,IAAI+G,WAAWI,OACnB,CACL,MAAMmpC,EAAYhsC,EAAQurC,EAC1B7vC,EAAS,IAAI+G,WAAWupC,EAAYrB,GACpC,IAAK,IAAIhtC,EAAI,EAAGA,EAAIquC,EAAWruC,IAC7B,IAAK,IAAIsuC,EAAU,EAAGA,EAAUtB,IAAesB,EAC7CvwC,EAAOiC,EAAIgtC,EAAcsB,GAAWppC,EAAS,EAAJlF,EAAQsuC,E,CAKvD,OAAO1B,GAAS7uC,EAD2B,CAAC6vC,EAAQvrC,EAAO2qC,GACzB,QACpC,CAqBA,SAASuB,GAA2BxB,GAGlC,MAbyB,qBAAXxhC,QACe,qBAAjBoiC,aACRpiC,OAAOijC,eAAe,wBAWgBzB,aAAkBY,cAR9D,SAA0BZ,GAExB,OAAiB,MAAVA,GAAmC,IAAjBA,EAAO1qC,OAAiC,IAAlB0qC,EAAOa,MACxD,CAMMa,CAAiB1B,KArBvB,SAAqBA,GAGnB,OAAkB,MAAVA,GAAqBA,EAAqB1wC,gBAAgB0I,UACpE,CAiBmCkoC,CAAYF,EAC/C,CA4BOja,eAAe4b,GAClB3B,GAEe,IAAfC,EAAWhsC,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,EACZmb,EAC+B,KAInC,GAAIpT,KAAMC,QAAQ,wBACdulC,GAA2BxB,GAAS,CAGtC,IAAI4B,EAEJ,IAKEA,QAAqBC,kBACjB7B,EAA6B,CAAC8B,iBAAkB,Q,CACpD,MAAOr0B,GACPm0B,EAAc,I,CAWdxyB,EAFiB,MAAfwyB,GAAuBA,EAAYtsC,QAAU0qC,EAAO1qC,OACpDssC,EAAYf,SAAWb,EAAOa,OACvBe,EAEA5B,C,MAGX5wB,EAAS4wB,EAGX,OAAOD,GAAY3wB,EAAQ6wB,EAC7B,CAsBOla,eAAegc,GAClBC,EACAZ,GACF,IAAIa,EAAO/d,GAAgB8d,EAAK,MAAO,YACvC,KAAMA,aAAe7uB,IAAS,CAE5B,MAAM+uB,EAAoBD,EAC1BA,EAAO/tB,GAAKguB,EAAmB,SAC/BA,EAAkB3wC,S,CAEpB,GAAkB,IAAd0wC,EAAK/qC,MAA4B,IAAd+qC,EAAK/qC,KAC1B,MAAM,IAAIzF,MAAM,wDAADC,OAC6CuwC,EAAK/qC,KAAI,MAEvE,MAAO2pC,EAAQvrC,GAAS2sC,EAAKhxC,MAAM8F,MAAM,EAAG,GACtCqmC,EAAsB,IAAd6E,EAAK/qC,KAAa,EAAI+qC,EAAKhxC,MAAM,GAE/C,GAAImsC,EAAQ,GAAe,IAAVA,EACf,MAAM,IAAI3rC,MACN,6DAAAC,OACqB0rC,IAG3B,GAAmB,YAAf6E,EAAK/wC,OAAsC,UAAf+wC,EAAK/wC,MACnC,MAAM,IAAIO,MACN,kCAAAC,OAAkCuwC,EAAK/wC,MAAK,8CAIlD,MAAM5B,QAAa2yC,EAAK3yC,OAClB6yC,EAA4B,YAAfF,EAAK/wC,MAAsB,IAAM,EAC9C4H,EAAQ,IAAIH,kBAAkBrD,EAAQurC,EAAS,GAErD,IAAK,IAAI5tC,EAAI,EAAGA,EAAI4tC,EAASvrC,IAASrC,EAAG,CACvC,MAAMmvC,EAAO,CAAC,EAAG,EAAG,EAAG,KAEvB,IAAK,IAAIpoC,EAAI,EAAGA,EAAIojC,EAAOpjC,IAAK,CAC9B,MAAMjK,EAAQT,EAAK2D,EAAImqC,EAAQpjC,GAE/B,GAAmB,YAAfioC,EAAK/wC,OACP,GAAInB,EAAQ,GAAKA,EAAQ,EACvB,MAAM,IAAI0B,MACN,sFAAAC,OACiC3B,EAAK,WAEvC,GAAmB,UAAfkyC,EAAK/wC,QACVnB,EAAQ,GAAKA,EAAQ,KACvB,MAAM,IAAI0B,MACN,sFAAAC,OACmC3B,EAAK,MAIlC,IAAVqtC,GACFgF,EAAK,GAAKryC,EAAQoyC,EAClBC,EAAK,GAAKryC,EAAQoyC,EAClBC,EAAK,GAAKryC,EAAQoyC,GAElBC,EAAKpoC,GAAKjK,EAAQoyC,C,CAItB,MAAMvqC,EAAQ,EAAJ3E,EACV6F,EAAMlB,EAAI,GAAK5F,KAAKuc,MAAM6zB,EAAK,IAC/BtpC,EAAMlB,EAAI,GAAK5F,KAAKuc,MAAM6zB,EAAK,IAC/BtpC,EAAMlB,EAAI,GAAK5F,KAAKuc,MAAM6zB,EAAK,IAC/BtpC,EAAMlB,EAAI,GAAK5F,KAAKuc,MAAM6zB,EAAK,G,CAGjC,GAAc,MAAVhB,EAAgB,CAClBA,EAAO9rC,MAAQA,EACf8rC,EAAOP,OAASA,EAChB,MAAMwB,EAAMjB,EAAOT,WAAW,MACxB2B,EAAY,IAAI9B,UAAU1nC,EAAOxD,EAAOurC,GAC9CwB,EAAIE,aAAaD,EAAW,EAAG,E,CAKjC,OAHIL,IAASD,GACXC,EAAK1wC,UAEAuH,CACT,CAEO,MAAM0pC,GAAa3d,GAAG,CAACkb,iBC1VxB,SAAU0C,GAAmB1sB,EAAoB4N,GAErD,MAAM+e,EAAa3sB,EAAO9kB,MAAMa,OAC1B6wC,EAAchf,EAAQ1yB,MAAMa,OAClC,GAAI4wC,EAAa,EACf,MAAM,IAAIjxC,MACN,0DAAyD,qBAAAC,OACpCgxC,EAAU,MAErC,GAAIC,EAAc,EAChB,MAAM,IAAIlxC,MACN,4DAA2D,qBAAAC,OACtCixC,EAAW,MAEtC,GAAsB,UAAlBhf,EAAQzyB,MACV,MAAM,IAAIO,MACN,sDAAqD,sBAAAC,OAC/BiyB,EAAQzyB,MAAK,MAEzC,GAAIyyB,EAAQ1yB,MAAM0xC,EAAc,GAAKD,EACnC,MAAM,IAAIjxC,MACN,iEAAgE,GAAAC,OAC7DiyB,EAAQ1yB,MAAM0xC,EAAc,GAAE,SAAAjxC,OAAQgxC,IAG/C,GAAoC,IAAhC/tC,GAAcohB,EAAO9kB,OACvB,MAAM,IAAIQ,MACN,qDAAoD,iBAAAC,OACnCqkB,EAAO9kB,MAAK,MAGnC,MAAM2xC,EAAejf,EAAQ1yB,MACvB4xC,EAAYD,EAAaA,EAAa9wC,OAAS,GAIrD,IAAIgxC,EAAU,EACd,IAAK,IAAI7vC,EAAI,EAAGA,EAAI2vC,EAAa9wC,OAAS,IAAKmB,EAC7C6vC,GAAWF,EAAa3vC,GAG1B,MAAMyd,EAAaqF,EAAO9kB,MAEpB8xC,EAAcH,EAAa7rC,QACjCgsC,EAAYhjB,MAEZ,IAAIijB,EAAY,EAChB,IAAK,IAAI/vC,EAAI4vC,EAAW5vC,EAAIyvC,IAAczvC,EACxC+vC,GAAatyB,EAAWzd,GACxB8vC,EAAYruC,KAAKgc,EAAWzd,IAG9B,MAAM0G,EACF,IAAID,GAAeqc,EAAO9kB,OAAOkG,IAAImb,GAAUA,EAAS0wB,GACvD,GAAGjsC,MAAM,EAAG8rC,GAEjB,MAAO,CAACE,EAAaD,EAASE,EAAWrpC,EAC3C,CC1DM,SAAUspC,GACZhyC,EAAiB0yB,EAAiBuf,GACpC,MAAMC,EAAYxf,EAAQzsB,KAAO,EAAKysB,EAAQ1yB,MAAM0yB,EAAQzsB,KAAO,GAAK,EAClEksC,EAAYzf,EAAQzsB,KAAO,EAAKysB,EAAQzsB,KAAO,EAAI,EAEnDmsC,EAAa,wDAAuD,wCAAA3xC,OAC9BwxC,EAAQjyC,OAAO,oBAAAS,OACnCiyB,EAAQ1yB,MAAK,aAAAS,OAAYT,GAAO,eAAAS,OACrCyxC,EAAQ,oBAAAzxC,OAAmB0xC,EAAQ,KAEtD,GAAIF,EAAQhsC,KAAOksC,EACjB,MAAM,IAAI3xC,MAAM4xC,EAAa,kBAAH3xC,OAAqB0xC,EAAQ,OAEzD,GAAInyC,EAAMa,OAASqxC,GAAYD,EAAQhsC,KAAOksC,GAC5C,MAAM,IAAI3xC,MACN4xC,EAAU,0BAAA3xC,OACgByxC,GAAYD,EAAQhsC,KAAOksC,KAE3D,GAAIF,EAAQhsC,OAASksC,EAAWnyC,EAAMa,OAASqxC,EAC7C,MAAM,IAAI1xC,MACN4xC,EAAa,mBAAH3xC,OAAsB0xC,EAAWnyC,EAAMa,OAASqxC,IAEhE,IAAK,IAAInpC,EAAI,EAAGA,EAAIopC,IAAYppC,EAC9B,GAAIkpC,EAAQjyC,MAAM+I,KAAO2pB,EAAQ1yB,MAAM+I,GACrC,MAAM,IAAIvI,MACN4xC,EAAU,kBAAA3xC,OACQsI,EAAC,OAAAtI,OAAMwxC,EAAQjyC,MAAM+I,GAAE,uBAAAtI,OAAsBsI,EAAC,OAAAtI,OAC5DiyB,EAAQ1yB,MAAM+I,GAAE,OAG5B,IAAK,IAAIA,EAAI,EAAGA,EAAIkpC,EAAQhsC,KAAOksC,IAAYppC,EAC7C,GAAIkpC,EAAQjyC,MAAM+I,EAAIopC,KAAcnyC,EAAM+I,EAAImpC,GAC5C,MAAM,IAAI1xC,MACN4xC,EAAU,kBAAA3xC,OACQsI,EAAIopC,EAAQ,OAAA1xC,OAC1BwxC,EAAQjyC,MAAM+I,EAAIopC,GAAS,eAAA1xC,OAAcsI,EAAIopC,EAAQ,OAAA1xC,OACrDT,EAAM+I,EAAIopC,GAAS,KAGjC,CAgBM,SAAUE,GACZJ,EAAiBvf,EAAiB1yB,GACpC,GAAI0yB,EAAQzsB,KAAO,EACjB,MAAM,IAAIzF,MACN,6DAA4D,qBAAAC,OACvCiyB,EAAQzsB,KAAI,MAEvC,GAAIgsC,EAAQhsC,KAAO,EACjB,MAAM,IAAIzF,MACN,6DAA4D,qBAAAC,OACvCwxC,EAAQhsC,KAAI,MAEvC,GAAsB,UAAlBysB,EAAQzyB,MACV,MAAM,IAAIO,MAAM,0DAADC,OACXiyB,EAAQzyB,QAEd,GAAID,EAAMa,OAAS,EACjB,MAAM,IAAIL,MAAM,6DAADC,OACkDT,IAGnE,GAAqB,IAAjBA,EAAMa,OAAc,CACtB,GAAqB,IAAjB6xB,EAAQ/uB,KACV,MAAM,IAAInD,MAAM,sDAADC,OACXiyB,EAAQ1yB,QAEd,GAAqB,IAAjBiyC,EAAQtuC,KACV,MAAM,IAAInD,MAAM,sDAADC,OACXwxC,EAAQjyC,O,CAIhBgyC,GAAoBhyC,EAAO0yB,EAASuf,EACtC,CAWM,SAAUK,GACZL,EAAqBvf,EACrB1yB,GAEF,MAAM0xC,EAAchf,EAAQ1yB,MAAMa,OAC5B+wC,EAAaF,EAAc,EAAKhf,EAAQ1yB,MAAM0xC,EAAc,GAAK,EAKjEa,EAAUvyC,EAAMa,OAEtB,IAAIkxC,EAAY,EAChB,IAAK,IAAI/vC,EAAI4vC,EAAW5vC,EAAIuwC,IAAWvwC,EACrC+vC,GAAa/xC,EAAMgC,GAGrB,MAAMwwC,EAAgBZ,EAAY,EAAK,EAAIA,EAK3C,MAAO,CAACA,YAAWa,WAJA/uC,GAAcgvB,EAAQ1yB,OAASwyC,EAInBT,YAAWrpC,QAF1B,IAAID,GAAezI,EAAM8F,MAAM,EAAG8rC,IAAa,GAEZc,WADhChvC,GAAc1D,GAEnC,CChIA,MAAM2yC,IAAY,EACZC,IAAe,EA6Df,SAAUC,GACZrzB,EAAmBszB,EAAiBnvC,GACtC,MAAM+b,EAAYF,EAAMxf,MAAMa,OAC9B0d,EACImB,IAAcozB,EAAMjyC,OACpB,IAAM,iBAAAJ,OAAiBif,EAAS,uBAAAjf,OAAsBqyC,EAAK,0CAAAryC,OACvBif,EAAS,OACjDnB,EACImB,IAAc/b,EAAK9C,OACnB,IAAM,iBAAAJ,OAAiBif,EAAS,sBAAAjf,OAAqBkD,EAAI,0CAAAlD,OACrBif,EAAS,OAEjD,IAAK,IAAI1d,EAAI,EAAGA,EAAI0d,IAAa1d,EAC/Buc,EACIu0B,EAAM9wC,GAAK2B,EAAK3B,IAAMwd,EAAMxf,MAAMgC,GAClC,IAAM,iBAAAvB,OAAiBif,EAAS,aAAAjf,OAAYuB,EAAC,aAAAvB,OAAYuB,EAAC,UAAAvB,OAClDqyC,EAAM9wC,GAAK2B,EAAK3B,GAAE,iCAAAvB,OAAgCuB,EAAC,OAAAvB,OACjD+e,EAAMxf,MAAMgC,GAAE,KAEhC,CAGM,SAAU+wC,GAAWC,GACzB,MAAMvsC,EAAO,GACb,IAAIT,EAAO,EACX,KAAOgtC,EAAO,GACD,EAAPA,GACFvsC,EAAKhD,KAAKuC,GAEZgtC,GAAQ,EACRhtC,IAEF,OAAOS,CACT,CAGM,SAAUwsC,GACZH,EAAiBj2B,EAAenU,GAClC,MAAM/E,EAAO,GACb,IAAK,IAAIqC,EAAO,EAAGA,EAAO8sC,EAAMjyC,OAAQmF,IACtCrC,EAAKqC,GAAQjF,KAAKuD,MAAMuY,EAAI7W,GAAQ8sC,EAAM9sC,IAAS0C,EAAQ1C,IAE7D,OAAOrC,CACT,CAIM,SAAUuvC,GACZxqC,EAAmByqC,EAAgCC,EACnD3zB,GACF,MAAM4zB,EAAa,IAAI3qC,GACvB,IAAK,IAAI1G,EAAIqxC,EAAWxyC,OAAQmB,EAAIyd,EAAW5e,OAAQmB,IACrDqxC,EAAW5vC,KAAK,GAElB,IAAK,IAAIzB,EAAI,EAAGA,EAAIoxC,EAAepxC,IACvB,IAANA,EACFqxC,EAAWF,GAA0B,GAErCE,EAAWC,OACPH,EAAwB,EACxB,GACJE,EAAWvkB,OAGf,OAAOukB,CACT,CAEA,SAASE,GACLJ,EAAgCC,EAChCI,GACF,OAAIA,GAAkBL,EACbK,EAGFA,GAAkBJ,EAAgB,EAC3C,CAEA,SAASK,GAAcL,EAAuBD,GAC5C,MAAMO,EAAa,GACnB,IAAK,IAAI1xC,EAAI,EAAGA,EAAIoxC,EAAepxC,IACjC0xC,EAAWjwC,KAAK0vC,EAAyBnxC,GAE3C,OAAO0xC,CACT,CAGM,SAAUC,GACZl0B,EAAsBm0B,EAAwBC,EAC9Cf,EAAiBj2B,EAAenU,EAAmBorC,EACnDC,EACAC,GACF,MAAMt0B,EAAYD,EAAW5e,OAC7B,IAAIozC,EAAkB,IAAI3wC,MAAMoc,GAC5Bw0B,EAAgB,IAAI5wC,MAAMoc,GAC1By0B,EAAoB,IAAI7wC,MAAMoc,GAClC,GAAIk0B,EAAa/yC,QAAUgzC,EAAsB,EAAG,CAClD,MAAMO,EAAYR,EAAa,GAIzBR,EAAgBS,EAAsB,EAC5CI,EAAkBI,GACdP,EAAWM,EAAWhB,EAAeN,EAAOrzB,GAChDy0B,EAAgBI,GACZP,EAASK,EAAWhB,EAAev2B,EAAK4C,GAC5C00B,EACIjB,GAAsBxqC,EAAS0rC,EAAWhB,EAAe3zB,E,MAE7D,IAAK,IAAIzZ,EAAO,EAAGA,EAAO0Z,EAAW1Z,IACnCiuC,EAAgBjuC,GAAQuuC,GACpBT,EAAWhB,EAAOpqC,EAAS+W,EAAYzZ,EAAMguC,GACjDE,EAAcluC,GACVwuC,GAAYT,EAASl3B,EAAKnU,EAAS+W,EAAYzZ,EAAMguC,GACzDG,EAAkBnuC,GAAQyuC,GAAe/rC,EAAS1C,EAAMguC,GAI5D,MAAO,CACLlB,MAAOmB,EACPp3B,IAAKq3B,EACLxrC,QAASyrC,EAEb,CAIM,SAAUE,GACZP,EAAmBX,EAAgCC,EACnDsB,EAAyBj1B,GAC3B,MAAMk1B,EAAa,IAAIl1B,GACjBi0B,EAAaD,GAAcL,EAAeD,GAEhD,IAAK,IAAIntC,EAAO,EAAGA,EAAO2uC,EAAW9zC,OAAQmF,IAC3C,GAAI0tC,EAAWtgB,QAAQptB,IAAS,EAC9B2uC,EAAW3uC,GAAQ,MACd,CACL,MAAM4uC,EACFrB,GAAgBJ,EAAwBC,EAAeptC,GAC3D,IAAI6uC,EAAgBH,EAAcE,GAC9Bd,EAAY,GAAKc,IACnBC,EAAgB,GAGlBF,EAAW3uC,GAAQ6uC,C,CAGvB,OAAOF,CACT,CAIM,SAAUL,GACZP,EAAiBZ,EAAgCC,EACjD0B,EAAuBr1B,GACzB,MAAMk1B,EAAa,IAAIl1B,GACjBi0B,EAAaD,GAAcL,EAAeD,GAEhD,IAAK,IAAIntC,EAAO,EAAGA,EAAO2uC,EAAW9zC,OAAQmF,IAC3C,GAAI0tC,EAAWtgB,QAAQptB,IAAS,EAC9B2uC,EAAW3uC,GAAQxD,OAAOuyC,qBACrB,CACL,MAAMH,EACFrB,GAAgBJ,EAAwBC,EAAeptC,GAC3D,IAAI6uC,EAAgBC,EAAYF,GAC5Bb,EAAU,GAAKa,IACjBC,EAAgBryC,OAAOuyC,kBAEzBJ,EAAW3uC,GAAQ6uC,C,CAIvB,IAAK,IAAI7yC,EAAI,EAAGA,EAAI2yC,EAAW9zC,OAAQmB,IAAK,CAE1C,MAAMgzC,EAAWv1B,EAAWzd,GACxB2yC,EAAW3yC,GAAK,IAClB2yC,EAAW3yC,IAAMgzC,GAEnBL,EAAW3yC,GAAKuc,EAAW,EAAGo2B,EAAW3yC,GAAIyd,EAAWzd,G,CAE1D,OAAO2yC,CACT,CAEM,SAAUF,GACZ/rC,EAAmB1C,EAAcguC,GACnC,IAAI3yB,EAAS3Y,EAAQ1C,GAKrB,OAJIguC,EAAgB,GAAKhuC,GAAmB,MAAVqb,KAChCA,EAAS,GAGJA,CACT,CAEM,SAAUkzB,GACZT,EAAmBmB,EAAwBvsC,EAC3C+W,EAAsBzZ,EAAcguC,GAEtC,IAAIxrC,EAAQysC,EAAajvC,GACzB,MAAMqb,EAAS3Y,EAAQ1C,IAAS,GAI5B8tC,EAAY,GAAK9tC,GAAQguC,EAAe,GAAKhuC,GAAiB,MAATwC,KAKrDA,EAJE6Y,EAAS,EAIH7e,OAAO0yC,iBAGP1yC,OAAOuyC,kBAKnB,MAAMC,EAAWv1B,EAAWzZ,GAQ5B,OAPIwC,EAAQ,IACVA,GAASwsC,GAIXxsC,EAAQ+V,EAAW,EAAG/V,EAAOwsC,EAAW,GAEjCxsC,CACT,CAEM,SAAUgsC,GACZT,EAAiBoB,EAAuBzsC,EACxC+W,EAAsBzZ,EAAcguC,GAEtC,IAAIoB,EAAOD,EAAYnvC,GACvB,MAAMqb,EAAS3Y,EAAQ1C,IAAS,GAI5B+tC,EAAW,GAAK/tC,GAASguC,EAAgB,GAAKhuC,GAAiB,MAARovC,KAIvDA,EAHE/zB,EAAS,EAGJ7e,OAAOuyC,iBAGPvyC,OAAO0yC,kBAKlB,MAAMF,EAAWv1B,EAAWzZ,GAgB5B,OAfIovC,EAAO,IACTA,GAAQJ,GAQRI,EAFE/zB,EAAS,EAEJ9C,EAAW,EAAG62B,EAAMJ,GAGpBz2B,GAAY,EAAG62B,EAAMJ,EAAW,GAGlCI,CACT,CAMM,SAAUC,GACZr1C,EAAiB8yC,EAAiBnvC,GAEpC,IAAI2xC,EAAkB3xC,EAAK9C,OAC3B,IAAK,IAAImB,EAAI,EAAGA,EAAI2B,EAAK9C,OAAQmB,IAC/B,GAAI2B,EAAK3B,GAAK,EAAG,CACfszC,EAAkBtzC,EAClB,K,CAIJ,IAAK,IAAIA,EAAIszC,EAAkB,EAAGtzC,EAAI2B,EAAK9C,OAAQmB,IACjD,GAAI8wC,EAAM9wC,GAAK,GAAK2B,EAAK3B,KAAOhC,EAAMgC,GACpC,OAAO,EAGX,OAAO,CACT,CAEM,SAAUuzC,GAAkBzC,EAAiBpqC,GACjD,IAAI8sC,EAAa1C,EAAMjyC,OAAS,EAAIiyC,EAAMA,EAAMjyC,OAAS,GAAK,EAC9D,IAAK,IAAImB,EAAI,EAAGA,EAAI8wC,EAAMjyC,OAAS,EAAGmB,IACpCwzC,GAAc1C,EAAM9wC,GAAK0G,EAAQ1G,GAEnC,OAAOwzC,CACT,CAEM,SAAUC,GACZn0C,EAAewxC,EAAwBnvC,GAEzC,IAAI+xC,EACJ,MAAMC,EAAQr0C,EAAEtB,MAAMa,OAYtB,IAAI+0C,EAqBJ,OA/BEF,EADmB,kBAAV5C,EACA,CAACA,KAAU,IAAIxvC,MAAMqyC,EAAQ,GAAG51B,KAAK,IACrC+yB,EAAMjyC,OAAS80C,EACf7C,EAAMryC,OAAO,IAAI6C,MAAMqyC,EAAQ7C,EAAMjyC,QAAQkf,KAAK,IAElD+yB,EAAMhtC,QAEjB4vC,EAAO5tC,QAAQiB,IACbwV,GACW,IAAPxV,EAAU,IAAM,uDAIpB6sC,EADU,MAARjyC,EACM,IAAIL,MAAMqyC,GAAO51B,MAAM,GACN,kBAATpc,EACR,CAACA,KAAS,IAAIL,MAAMqyC,EAAQ,GAAG51B,MAAM,IACpCpc,EAAK9C,OAAS80C,EACfhyC,EAAKlD,OAAO,IAAI6C,MAAMqyC,EAAQhyC,EAAK9C,QAAQkf,MAAM,IAEjDpc,EAEViyC,EAAQA,EAAM1vC,IAAI,CAAC6C,EAAG/G,IAChB+G,GAAK,EACAA,GAEPwV,GACW,IAAPxV,EACA,IAAM,wDAAAtI,OACCsI,EAAC,mCAAAtI,OAAkCuB,EAAC,MACxCV,EAAEtB,MAAMgC,GAAK0zC,EAAO1zC,KAGxB,CAAC0zC,EAAQE,EAClB,CAIM,SAAUC,GACZC,EAAkBhD,EAAiBj2B,EAAenU,EAClDorC,EAAmBC,EAAiBC,EACpC+B,EAAqBC,GACvB,IAAIC,EAaJ,GAZe,MAAXvtC,GACFutC,EAAiB,IAAI3yC,MAAMwvC,EAAMjyC,QACjCo1C,EAAel2B,KAAK,IAEpBk2B,EAAiBvtC,EAQC,MAAhBsrC,GAAgE,KAAvCA,EAAgBA,EAAe,GAC1D,MAAM,IAAIxzC,MAAM,8CAKlB,IAAI01C,GAAe,EAEnB,MAAMC,EAAqC,CACzChI,KAAM8H,EAAep1C,OACrBu1C,wBAAyB,EACzBtD,MAAOA,EAAMhtC,QACb+W,IAAKA,EAAI/W,QACT4C,QAASutC,EAAenwC,QACxBguC,YACAC,UACAC,eACA+B,cACAC,kBAGF,IAAK,IAAIh0C,EAAI,EAAGA,EAAIm0C,EAAWhI,KAAMnsC,IAC/Bk0C,GAA6C,KAA3B,GAAKl0C,EAAK+zC,IAC9BI,EAAWC,0BAER,GAAKp0C,EAAKgyC,IACbkC,GAAe,GAIdA,IACHC,EAAWnC,cAAiB,GAAKmC,EAAWhI,KAC5CgI,EAAWhI,QAYb,MAAMkI,EAAmC,CACvClI,KAAM2H,EAAOj1C,OACbizC,UAAW,EACXC,QAAS,EACTuC,YAAY,EACZC,UAAU,IAgJd,SACIC,EAAgCC,GAClCA,EAAM3C,UAAY,EAClB2C,EAAM1C,QAAU,EAChB0C,EAAMT,eAAiB,EAEvB,IAAI5B,EAAY,EAChBqC,EAAMH,WAA6B,MAAhBE,EAAO1D,MAC1B2D,EAAMF,SAAyB,MAAdC,EAAO35B,IAExB45B,EAAM3D,MAAQ,IAAIxvC,MAAMmzC,EAAMtI,MAC9BsI,EAAM55B,IAAM,IAAIvZ,MAAMmzC,EAAMtI,MAC5BsI,EAAM/tC,QAAU,IAAIpF,MAAMmzC,EAAMtI,MAChCsI,EAAMC,wBAA0B,GAChCD,EAAME,8BAAgC,GACtCF,EAAMG,8BAAgC,IAAItzC,MAAMmzC,EAAMtI,MAEtD,IAAK,IAAInsC,EAAI,EAAGA,EAAIw0C,EAAOrI,KAAMnsC,IAC/B,GAAK,GAAKA,EAAKw0C,EAAOxC,aAAc,CAIlC,MAAM6C,EAAY91C,KAAKM,IACnBo1C,EAAMtI,MAAQqI,EAAOrI,KAAOnsC,GAAK,EAAIw0C,EAAOJ,wBAC5CK,EAAMtI,MACV,KAAOiG,EAAYyC,EAAWzC,IAE5BqC,EAAM3D,MAAMsB,GAAa,EACzBqC,EAAM55B,IAAIu3B,GAAa,EACvBqC,EAAM/tC,QAAQ0rC,GAAa,EAC3BqC,EAAM3C,WAAc,GAAKM,EACzBqC,EAAM1C,SAAY,GAAKK,EACvBqC,EAAMC,wBAAwBjzC,KAAK2wC,GACnCqC,EAAME,8BAA8BlzC,MAAM,GAC1CgzC,EAAMG,8BAA8BxC,GAAapyC,C,MAE9C,GAAK,GAAKA,EAAKw0C,EAAOT,YAE3BU,EAAMC,wBAAwBjzC,KAAKkvC,IACnC8D,EAAME,8BAA8BlzC,MAAM,OACrC,CACL,GAAI2wC,IAAcqC,EAAM3D,MAAMjyC,OAC5B,MAAML,MACF,sCAAAC,OAAsC2zC,EAAS,wBAAA3zC,OACnCg2C,EAAMtI,KAAI,WAAA1tC,OAAUg2C,EAAM3D,MAAMjyC,OAAM,MAIpC,MAAhB21C,EAAO1D,QACT2D,EAAM3D,MAAMsB,GAAaoC,EAAO1D,MAAM9wC,IAEtB,MAAdw0C,EAAO35B,MACT45B,EAAM55B,IAAIu3B,GAAaoC,EAAO35B,IAAI7a,IAEpCy0C,EAAM/tC,QAAQ0rC,GAAaoC,EAAO9tC,QAAQ1G,GACtCw0C,EAAO1C,UAAa,GAAK9xC,IAC3By0C,EAAM3C,WAAc,GAAKM,GAEvBoC,EAAOzC,QAAW,GAAK/xC,IACzBy0C,EAAM1C,SAAY,GAAKK,GAKrBoC,EAAOR,eAAkB,GAAKh0C,GAChCy0C,EAAMC,wBAAwBjzC,KAAKmvC,IACnC6D,EAAME,8BAA8BlzC,MAAM,GAC1CgzC,EAAMT,gBAAmB,GAAK5B,IAE9BqC,EAAMC,wBAAwBjzC,KAAK2wC,GAEnCqC,EAAME,8BAA8BlzC,KAAKzB,IAE3Cy0C,EAAMG,8BAA8BxC,GAAapyC,EACjDoyC,G,CAGN,CA1NE0C,CAAeX,EAAYE,GAI3B,IAAIU,GAAa,EACbC,GAAY,EACZC,GAAgB,EACpB,MAAMC,EAAkB,GAClBC,EAAa,GAEnB,IAAK,IAAIn1C,EAAI,EAAGA,EAAI8zC,EAAOj1C,SAAUmB,EAAG,CACtC,GAA6B,IAAzBq0C,EAAU3tC,QAAQ1G,GACpB,MAAMxB,MAAM,WAADC,OAAYuB,EAAC,uBAE1B,MAAMo1C,KAAaf,EAAUL,eAAkB,GAAKh0C,GAC9Cq1C,EAAOvB,EAAO9zC,GACpB,IAAc,IAAVq1C,EAAa,CACfH,EAAgBzzC,KAAK2zC,EAAU,GAAK,GACpC,Q,CAGF,MAAME,EACF,CAACjB,EAAUvC,UAAa,GAAK9xC,EAAIq0C,EAAUtC,QAAW,GAAK/xC,GACzDu1C,EAAa,CACjBlB,EAAU3tC,QAAQ1G,GAAK,EAAI,GAAK,EAChCq0C,EAAU3tC,QAAQ1G,GAAK,EAAIq1C,EAAOA,EAAO,GAG3C,GAAID,GAAWf,EAAU3tC,QAAQ1G,IAAM,EACrC,MAAMxB,MAAM,gDAGdy2C,EAAgBA,GAA2C,IAAzBZ,EAAU3tC,QAAQ1G,GAEpD,MAAMw1C,KACEnB,EAAUvC,UAAa,GAAK9xC,GAAQq0C,EAAUtC,QAAW,GAAK/xC,GAEtE,GAAIq0C,EAAUC,YAAcD,EAAUE,SAAU,CAC9C,GAAIa,EAAS,CAKX,MAAMK,EAAOpB,EAAUvD,MAAM9wC,GAAK,EAAIq1C,EAAOhB,EAAUvD,MAAM9wC,GACvBq0C,EAAUvD,MAAM9wC,GAGtD,GAFAq0C,EAAUvD,MAAM9wC,GAAKy1C,EACrBpB,EAAUx5B,IAAI7a,GAAKq0C,EAAUvD,MAAM9wC,GAAK,EACpCy1C,EAAO,GAAKA,GAAQJ,EACtB,MAAM72C,MAAM,eAADC,OAAgB41C,EAAUvD,MAAM9wC,GAAE,kBAAAvB,OACzCuB,EAAC,mB,MAGPq0C,EAAUvD,MAAM9wC,GAAK01C,GACjBrB,EAAUvD,MAAM9wC,GAAI,EAAGq0C,EAAU3tC,QAAQ1G,GAAIq1C,EAAMC,EACnDC,GACJlB,EAAUx5B,IAAI7a,GAAK01C,GACfrB,EAAUx5B,IAAI7a,GAAI,EAAGq0C,EAAU3tC,QAAQ1G,GAAIq1C,EAAMC,EAAOC,GAG9D,MAAMI,EAA8C,IAAzBtB,EAAU3tC,QAAQ1G,IAClB,IAAvBq0C,EAAUvD,MAAM9wC,IAAYq0C,EAAUx5B,IAAI7a,KAAOq1C,EACrDN,EAAaA,GAAcY,EAC3BX,EAAYA,IACA,IAANh1C,GAAoC,IAAzBq0C,EAAU3tC,QAAQ1G,IAAa21C,E,MAEhDZ,EACIA,GAAyC,IAAzBV,EAAU3tC,QAAQ1G,IAAaw1C,EACnDR,EAAYA,IACA,IAANh1C,GAAoC,IAAzBq0C,EAAU3tC,QAAQ1G,IAAaw1C,GAGlD,IAAII,EACAC,GAAgB,EAsBpB,GArBIxB,EAAUC,YAAcD,EAAUE,UACpCqB,EAAiBvB,EAAUx5B,IAAI7a,GAAKq0C,EAAUvD,MAAM9wC,GACpD61C,GAAgB,GACPT,GAGTQ,EAAiB,EACjBC,GAAgB,GACPL,GAILH,GAAQ,IAERO,EADEvB,EAAU3tC,QAAQ1G,GAAK,GACPq1C,EAEDA,EAEnBQ,GAAgB,GAGhBA,EAAe,CACjB,IAAIC,EAKFA,EAFqB,IAAnBF,GACEA,EAAiB,IAAQvB,EAAU3tC,QAAQ1G,GAAK,EAC5C,EAEAjB,KAAKg3C,MAAMH,EAAiBvB,EAAU3tC,QAAQ1G,KACjD41C,EAAiBvB,EAAU3tC,QAAQ1G,KAAO,EAAI,EAAI,GAEzDk1C,EAAgBzzC,KAAKq0C,E,MAErBZ,EAAgBzzC,MAAM,E,CAS1B,IAAK,IAAIu0C,EAAW,EAAGA,EAAW3B,EAAUK,wBAAwB71C,SAC7Dm3C,EAAU,CACf,MAAMC,EAAc5B,EAAUK,wBAAwBsB,GAClDC,GAAe,EACjBd,EAAW1zC,KAAKyzC,EAAgBe,IACvBA,IAAgBtF,IACzBwE,EAAW1zC,KAAK,E,CAOpB,MAAO,CACLy0C,iBAJuBf,EAAWhqB,OAChC,CAACihB,EAAKpsC,IAAMq0C,EAAUK,wBAAwB10C,KAAO2wC,IAIvDwE,aACAJ,aACAC,YACAC,gBACAnE,MAAOuD,EAAUvD,MACjBj2B,IAAKw5B,EAAUx5B,IACfnU,QAAS2tC,EAAU3tC,QAEvB,CAiFA,SAASgvC,GACLp2C,EAAW8H,EAAW+uC,EAAiBd,EAAcC,EACrDC,GACF,GAAID,EAAMluC,GACR,OAAO+uC,EAAU,EAAIZ,EAAWnuC,GAAKmuC,EAAYnuC,EAAI,EAAK,GACrD,CACL,MAAMquC,EAAOn2C,EAAI,EAAI+1C,EAAO/1C,EAAIA,EAChC,OAAOm2C,EAAOF,EAAW,GAAKA,EAAW,GACXE,EAAOF,EAAW,GAAKA,EAAW,GAAKE,C,CAEzE,CCjpBM,MAAgBW,GAYpBC,YAAAA,GACE,OAAQ35C,KAAKR,YACRo6C,SACP,CAgBA,iBAAOC,CACHC,EAAiC7+B,GACnC,OAAO,IAAI6+B,EAAI7+B,EACjB,EAUI,MAAO8+B,GAOXv6C,WAAAA,GACEQ,KAAKg6C,aAAe,CAAC,CACvB,CAKA,aAAOC,GAIL,OAHiC,MAA7BF,GAAiBj1B,WACnBi1B,GAAiBj1B,SAAW,IAAIi1B,IAE3BA,GAAiBj1B,QAC1B,CAKA,eAAOo1B,CAAiCJ,GACtCC,GAAiBE,SAASD,aAAaF,EAAIF,WACvC,CAACE,EAAKA,EAAID,WAChB,EA2BI,SAAUM,GACZL,GACF/1C,EACqB,MAAjB+1C,EAAIF,UACJ,IAAM,+EAEV71C,EAC6B,kBAAlB+1C,EAAIF,UACX,IAAM,6DACKE,EAAIF,WACnB71C,EACI+1C,EAAIF,UAAUz3C,OAAS,EACvB,IAAM,qFAGV43C,GAAiBG,SAASJ,EAC5B,CC1JA,MAAMM,GAAuB,KAChBC,GAAuB,GAE9B,SAAUC,GACZC,EACAC,EAAoD74C,GAItD,OAHe,MAAXA,IACFA,EAAU84C,MAELC,GACHH,EAAQC,EAAU,CAACh3C,EAAGC,IAAMk3C,GAASn3C,EAAaC,EAAa9B,GACrE,CAEM,SAAU84C,KACd,OAA2C,KAApClvB,GAAO9rB,QAAQiC,iBAA0B04C,GACAC,EAClD,CAEA,SAASK,GACLH,EAAoBC,EACpBI,GACF,IAAIC,GAAiB,EAOrB,IANI/1C,GAAay1C,IAAWz1C,GAAa01C,MACvCK,GAAiB,GAEf/1C,GAAay1C,IAAWz1C,GAAa01C,KACvCK,GAAiB,GAEfA,EAAgB,CAClB,MAAMC,EAAQP,EAAO/6C,YAAY6O,KAC3B0sC,EAAQP,EAASh7C,YAAY6O,KAEnC,GAAIysC,IAAUC,EACZ,MAAM,IAAIj5C,MACN,yCAAAC,OAAyC+4C,EAAK,mBAAA/4C,OACjCg5C,G,CAIrB,GAAIn2C,MAAMC,QAAQ01C,IAAW31C,MAAMC,QAAQ21C,GAAW,CACpD,MAAMQ,EAAcnnB,GAAW0mB,GACzBU,EAAgBpnB,GAAW2mB,GACjC,IAAKh2C,GAAYw2C,EAAaC,GAC5B,MAAM,IAAIn5C,MACN,6CAAAC,OACYi5C,EAAW,kBAAAj5C,OAAiBk5C,EAAa,K,CAI7D,MAAMC,EACFp2C,GAAay1C,GAAUA,EAAS71C,GAAQ61C,GACtCY,EAAer2C,GAAa01C,GAC9BA,EACA91C,GAAQ81C,GAEZ,GAAIU,EAAW/4C,SAAWg5C,EAAah5C,OACrC,MAAM,IAAIL,MACN,yCAAAC,OAAyCm5C,EAAW/4C,OAAM,qBAAAJ,OAC7Co5C,EAAah5C,OAAM,OAAK,aAAAJ,OACxBm5C,EAAU,OAAK,aAAAn5C,OACfo5C,EAAY,MAE/B,IAAK,IAAI73C,EAAI,EAAGA,EAAI63C,EAAah5C,SAAUmB,EAAG,CAC5C,MAAME,EAAI03C,EAAW53C,GACfwa,EAAIq9B,EAAa73C,GAEvB,IAAKs3C,EAAUp3C,EAAGsa,GAChB,MAAM,IAAIhc,MACN,yBAAAC,OAAyBuB,EAAC,QAAAvB,OAAOyB,EAAC,eAAAzB,OAAcuB,EAAC,QAAAvB,OAAO+b,EAAC,oBAAA/b,OAC5Cm5C,EAAU,OAAK,aAAAn5C,OACfo5C,EAAY,K,CAGX,qBAAXC,QACTA,SAASC,SAEb,CAOM,SAAUC,GAAoBxwB,EAAuB/P,GACzD+P,IAAKrf,KAAK,IAAMsP,EAAKwgC,OAAQ,IAAMxgC,KACb,qBAAXqgC,QACTA,SAASC,SAEb,CAEM,SAAUG,GAAkBjB,EAAoBC,GACpD,MAAM/0C,EAA0B,kBAAb+0C,GAA6C,kBAAbA,GACvB,mBAAbA,EACX,CAACA,GACDA,EACJ,OAAInxC,GAASkxC,IAAWlxC,GAAUkxC,EAAoB,KAClDlxC,GAASmxC,IAAanxC,GAAUmxC,EAAsB,IAEjDE,GAAsBH,EAAQ90C,EAAK,CAACjC,EAAGC,IAAMD,GAAKC,GAEpDi3C,GACHH,EAAQC,EAAU,CAACh3C,EAAGC,IAAMk3C,GAASn3C,EAAaC,EAAa,GACrE,CAEM,SAAUg4C,GAAmBj4C,EAAWsa,EAAWnc,GAIvD,GAHe,MAAXA,IACFA,EAAU84C,OAEPE,GAASn3C,EAAGsa,EAAGnc,GAClB,MAAM,IAAIG,MAAM,8BAADC,OAA+ByB,EAAC,mBAAAzB,OAAkB+b,IAE7C,qBAAXs9B,QACTA,SAASC,SAEb,CAEA,SAASV,GAASn3C,EAAWsa,EAAWnc,GACtC,OAAKgH,SAASnF,KAAOmF,SAASmV,MAG1BpV,MAAMlF,IAAMkF,MAAMoV,IAAMzb,KAAKq5C,IAAIl4C,EAAIsa,GAAKnc,EAIhD,CAEM,SAAUg6C,GACZpB,EAA6BqB,EAAaC,GAC5C,IAAK,IAAIv4C,EAAI,EAAGA,EAAIi3C,EAAOp4C,OAAQmB,IACjC,GAAIi3C,EAAOj3C,GAAKs4C,GAAOrB,EAAOj3C,GAAKu4C,EACjC,MAAM,IAAI/5C,MAAM,sBAADC,OACWw4C,EAAOj3C,GAAE,UAAAvB,OAAS65C,EAAG,YAAA75C,OAAW85C,GAGhE,CAEM,SAAUC,GACZvB,EAAqBC,GAGvB,MAAMuB,EAAc,IAAI5zC,aAAaoyC,GAC/ByB,EAAgB,IAAI7zC,aAAaqyC,GACvC,GAAIuB,EAAY55C,SAAW65C,EAAc75C,OACvC,MAAM,IAAIL,MACN,wCAAuC,GAAAC,OACpCi6C,EAAc75C,OAAM,iBAAAJ,OAAgBg6C,EAAY55C,SAGzD,IAAK,IAAImB,EAAI,EAAGA,EAAI04C,EAAc75C,OAAQmB,IACxC,GAAIy4C,EAAYz4C,KAAO04C,EAAc14C,GACnC,MAAM,IAAIxB,MACN,iCAAAC,OAAiCuB,EAAC,cAAAvB,OAC/Bi6C,EAAc14C,GAAE,aAAAvB,OAAYg6C,EAAYz4C,GAAE,YAGvD,CAGM,SAAU24C,GAAcz4C,GAE5B,IAAK,IAAIF,EAAI,EAAGA,EAAKE,EAAgBrB,OAAQmB,IAAK,CAChD,MAAMP,EAAMS,EAAEF,GACVsB,MAAMC,QAAQ9B,GAChBk5C,GAAcl5C,GAEdS,EAAEF,GAAKib,GAAaxb,E,CAGxB,OAAOS,CACT,CAGM,SAAU04C,GAAmB/X,GAEjC,MAAMgY,EAAQxoB,SAAS+R,cAAc,SAarC,MAZI,gBAAiByW,IAElBA,EAAcC,aAAc,GAE/BD,EAAME,OAAQ,EACdF,EAAMG,MAAO,EACbH,EAAMI,MAAMC,SAAW,QACvBL,EAAMI,MAAMt5C,KAAO,MACnBk5C,EAAMI,MAAME,IAAM,MAElBN,EAAMO,QAAU,OAChBP,EAAMQ,YAAYxY,GACX,IAAIz9B,QAAQC,IACjBw1C,EAAMlY,iBAAiB,aAAcvV,GAAK/nB,EAAQw1C,IAClDA,EAAMxe,QAEV,CAEOvH,eAAewmB,GAAKT,SACnBA,EAAMS,OACR,8BAA+BT,SAC3B,IAAIz1C,QAAQC,IAEfw1C,EAAcU,0BAA0Bl2C,IAG/C,CC5NA,MAAMm2C,GAAU,SCwDT,MAAMv/B,GAAM2X,GAAG,CAAC6nB,KAVvB,SAAgCv5C,EAAsBC,GACpD,IAAI4pC,EAAK9Y,GAAgB/wB,EAAG,IAAK,OAC7B8pC,EAAK/Y,GAAgB9wB,EAAG,IAAK,QAChC4pC,EAAIC,GAAMrnB,GAAeonB,EAAIC,GAE9B,MAAM7tB,EAAoB,CAACjc,EAAG6pC,EAAI5pC,EAAG6pC,GAErC,OAAO/hB,GAAOC,UAAU9b,GAAK+P,EAC/B,ICOO,MAAMu9B,GAAW9nB,GAAG,CAAC+nB,UAX5B,SACIz5C,EAAsBC,GACxB,IAAI4pC,EAAK9Y,GAAgB/wB,EAAG,IAAK,YAC7B8pC,EAAK/Y,GAAgB9wB,EAAG,IAAK,aAChC4pC,EAAIC,GAAMrnB,GAAeonB,EAAIC,GAE9B,MAAM7tB,EAAyB,CAACjc,EAAG6pC,EAAI5pC,EAAG6pC,GAE1C,OAAO/hB,GAAOC,UAAUnY,GAAUoM,EACpC,ICMO,MAAMy9B,GAAMhoB,GAAG,CAACioB,KAhBvB,SAAgC35C,EAAsBC,GACpD,IAAI4pC,EAAK9Y,GAAgB/wB,EAAG,IAAK,OAC7B8pC,EAAK/Y,GAAgB9wB,EAAG,IAAK,OAGjC,IAFC4pC,EAAIC,GAAMrnB,GAAeonB,EAAIC,GAEb,UAAbD,EAAG9rC,OAAkC,UAAb+rC,EAAG/rC,MAC7B,OAAOy7C,GAAS3P,EAAIC,GAGtB,MAAM7tB,EAAwB,CAACjc,EAAG6pC,EAAI5pC,EAAG6pC,GAIzC,OAAO/hB,GAAOC,UAAUhZ,GAASiN,EAHnB,CAAC,EAIjB,ICLO,MAAMvC,GAAMgY,GAAG,CAACkoB,KATvB,SAAgC55C,EAAsBC,GACpD,IAAI4pC,EAAK9Y,GAAgB/wB,EAAG,IAAK,OAC7B8pC,EAAK/Y,GAAgB9wB,EAAG,IAAK,QAChC4pC,EAAIC,GAAMrnB,GAAeonB,EAAIC,GAE9B,MAAM7tB,EAAyB,CAACjc,EAAG6pC,EAAI5pC,EAAG6pC,GAE1C,OAAO/hB,GAAOC,UAAU5V,GAAU6J,EACpC,ICfO,MAAM5Z,GAAOqvB,GAAG,CAACmoB,MAPxB,SAAiCz6C,GAC/B,MAEM6c,EAAqB,CAAC7c,EAFjB2xB,GAAgB3xB,EAAG,IAAK,OAAQ,YAI3C,OAAO2oB,GAAOC,UAAUrT,GAAMsH,EAChC,ICHO,MAAM69B,GAASpoB,GAAG,CAACqoB,QAN1B,SAAmC36C,GACjC,MAAMgiC,EAAKrQ,GAAgB3xB,EAAG,IAAK,UAEnC,OAAO2oB,GAAOC,UAAU,SAAU,CAAC5oB,EAAGgiC,GADxB,CAAC,EAEjB,ICKO,MAAM4Y,GAAYtoB,GAAG,CAACuoB,WAL7B,SAAsC76C,GACpC,MACM6c,EAA0B,CAAC7c,EADtB2xB,GAAgB3xB,EAAG,IAAK,cAEnC,OAAO2oB,GAAOC,UAAU1R,GAAW2F,EACrC,ICeA,SAAS6S,GAAKzxB,GAIZ,OAFAgf,EACIA,GAAgBhf,GAAI,IAAM,8CACvB,CAAC+B,EAAsB+oB,KAE5B,MAAMiZ,EAAKrQ,GAAgB3xB,EAAG,IAAK,UAAW,qBACxC86C,EACK,MAAN/xB,EAAc4I,GAAgB5I,EAAI,KAAM,WAAa,KAC1D,OAAOJ,GAAOX,KAAK,KACjB,MAAM,MAACxqB,EAAK,MAAE2xB,GAASxG,GAAO+E,UAAU,IAAMzvB,EAAE+jC,GAAK,CAACA,GAAK8Y,GAQ3D,OAPW,MAAPA,GACF79B,EACIzf,EAAMkB,MAAOo8C,EAAIp8C,MACjB,kFAGNq8C,GAAW5rB,GACJA,EAAM,KAGnB,CA+BA,SAASA,GAAMlxB,GAIb,OAFAgf,EACIA,GAAgBhf,GAAI,IAAM,+CACvB,CAAC+8C,EAAgCjyB,KACtC9L,EACIjb,MAAMC,QAAQ+4C,GACd,IAAM,oFAGV,MAAMC,EACFjpB,GAAqBgpB,EAAM,OAAQ,WAAY,qBAC7CF,EACK,MAAN/xB,EAAc4I,GAAgB5I,EAAI,KAAM,YAAc,KAC3D,OAAOJ,GAAOX,KAAK,KACjB,MAAM,MAACxqB,EAAK,MAAE2xB,GAASxG,GAAO+E,UAAU,IAAMzvB,KAAKg9C,GAAQA,EAAOH,GAQlE,OAPW,MAAPA,GACF79B,EACIzf,EAAMkB,MAAOo8C,EAAIp8C,MACjB,iGAGNq8C,GAAW5rB,GACJA,IAGb,CA2BA,SAAS+rB,GAAiDj9C,GAQxD,OAHAgf,EACIA,GAAgBhf,GAChB,IAAM,sDACH,CAAC+B,EAAM+oB,KACZ9L,EACIjd,aAAa4gB,GACb,IAAM,uDACV3D,EACU,MAAN8L,GAAcA,aAAcnI,GAC5B,IAAM,4DACV,MAAM,MAACuO,EAAK,MAAE3xB,GAASmrB,GAAO+E,UAAU,IAAMzvB,EAAE+B,GAAI,CAACA,GAAI+oB,GAEzD,OADAgyB,GAAW5rB,GACJ,CAACO,KAAMP,EAAM,GAAS3xB,SAEjC,CAiCA,SAAS29C,GAAgCl9C,GAQvC,OAHAgf,EACIA,GAAgBhf,GAChB,IAAM,uDACH,CAAC+8C,EAAgBjyB,KACtB9L,EACIjb,MAAMC,QAAQ+4C,IAASA,EAAKl2C,MAAMmtB,GAAOA,aAAerR,IACxD,IAAM,sEAEV3D,EACU,MAAN8L,GAAcA,aAAcnI,GAC5B,IAAM,gEACV,MAAM2H,EAAMI,GAAO+E,UAAU,IAAMzvB,KAAK+8C,GAAOA,EAAMjyB,GAQrD,OAPU,MAANA,GACF9L,EACIsL,EAAI/qB,MAAMkB,MAAOqqB,EAAGrqB,MACpB,yGAGNq8C,GAAWxyB,EAAI4G,OACR5G,EAEX,CAgCA,SAAS6yB,GAAcn9C,EAAiBo9C,GAEtCp+B,EACIA,GAAgBhf,GAChB,IAAM,uDACVgf,EACe,MAAXo+B,GACIr5C,MAAMC,QAAQo5C,IAAYA,EAAQv2C,MAAMuV,GAAKA,aAAa8H,IAC9D,IACI,iFAGR,MAAMm5B,EAA8B,MAAXD,EACzB,IAAKC,EAAkB,CAErBD,EAAU,GACV,IAAK,MAAMhvB,KAAW1D,GAAOpE,oBAC3B82B,EAAQl5C,KAAKwmB,GAAOpE,oBAAoB8H,G,CAI5C,MAAMkvB,EACFD,EAAmBD,EAAQxvB,OAAOjK,IAAaA,EAASC,WAAa,KAGnE25B,EAAmBH,EAAQ97C,OACjC87C,EAAUA,EAAQxvB,OAAOjK,GAAYA,EAASC,WAC9C5E,EACIo+B,EAAQ97C,OAAS,EACjB,IAAM,mGAAAJ,OAC+Bq8C,EAAgB,kBAAgB,cAGzE,MACM,MAACh+C,EAAK,MAAE2xB,GAASxG,GAAO+E,UAAUzvB,EAAGo9C,EAAS,MAD3B,GAGzBp+B,EACIkS,EAAMzL,KAAKvI,GAAU,MAALA,GAChB,IAAM,gMAGV8B,EACmB,IAAfzf,EAAMmH,KACN,IAAM,oFAAAxF,OACiB3B,EAAMmH,KAAI,YAErC,MAAM82C,EAA6B,CAAC,EAWpC,OAVAJ,EAAQ70C,QAAQ,CAAC6T,EAAG3Z,KACF,MAAZyuB,EAAMzuB,KACR+6C,EAAWphC,EAAE5O,MAAQ0jB,EAAMzuB,MAGF,MAAzB66C,GAGFA,EAAsB/0C,QAAQ6T,GAAKohC,EAAWphC,EAAE5O,MAAQ,MAEnD,CAACjO,QAAO2xB,MAAOssB,EACxB,CA0CA,SAASrsB,GAA6BnxB,GAEpC,OAAO0qB,GAAOyG,WAAWnxB,EAC3B,CAEA,SAAS88C,GAAW5rB,GAElB,GADyBA,EAAMtD,OAAO1Q,GAAU,MAALA,GAAW5b,OAC/B,EACrB,MAAM,IAAIL,MAAM,2IAIpB,CC5VM,SAAUw8C,GACZl+C,EAAyCmB,GAC3C,IAAMuD,GAAa1E,IAAoB,WAAVmB,GAAuBqD,MAAMC,QAAQzE,KACpD,cAAVmB,EACF,MAAM,IAAIO,MACN,kFAGN,GAAc,WAAVP,GAAsBuD,GAAa1E,MACjCA,aAAiBiI,YACrB,MAAM,IAAIvG,MACN,6EAKN,OAAOuhB,GAAWjjB,EAFM,GACQ,GACemB,EACjD,CCbM,MAAgBg9C,WAAkB7E,GAiBtC8E,QAAAA,CAAS39C,GAAyD,IAAxC49C,EAAUn6C,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,IAAAA,UAAA,GAAU25C,EAAoB35C,UAAAnC,OAAA,EAAAmC,UAAA,QAAAC,EAEhE,MAAM,MAACnE,EAAK,MAAE2xB,GAAS/xB,KAAK0+C,iBAAiB79C,EAAGo9C,GAEhD,GAAe,MAAXA,EAAiB,CACnB,MAAMU,EACFV,EAAQz2C,IAAIyV,IAAK,CAAE5O,KAAM4O,EAAE5O,KAAM+X,OAAQ2L,EAAM9U,EAAE5O,SACrDrO,KAAK4+C,eAAeD,E,MAEpB3+C,KAAK4+C,eAAe7sB,GAMtB,OAFAnwB,GAAQmwB,GAEJ0sB,EACKr+C,GAEPA,EAAMwB,UACC,KAEX,CAKA,cAAIi9C,GAIF,OAHwB,MAApB7+C,KAAK8+C,cACP9+C,KAAK8+C,YAAc,GAEd9+C,KAAK8+C,WACd,CAEUC,mBAAAA,GACR/+C,KAAK8+C,YAAc9+C,KAAK6+C,WAAa,CACvC,CAeAH,gBAAAA,CAAiB79C,EAAiBo9C,GAEhC,OAAOD,GAAcn9C,EAAGo9C,EAC1B,CAeAr8C,OAAAA,GAC0B,MAApB5B,KAAK8+C,aACPl9C,GAAQ5B,KAAK8+C,YAEjB,CAEA,oBAAME,GAIJ,OAHwB,MAApBh/C,KAAK8+C,cACP9+C,KAAK8+C,YAAc,GAEd,CACLzwC,KAAM,OAEN+X,OAAQk4B,GAAOt+C,KAAK8+C,YAAa,SAErC,CAEA,gBAAMG,GACJ,MAAM,IAAIn9C,MAAM,0DAClB,CAEA,gBAAMo9C,CAAWC,GACf,MAAM,IAAIr9C,MACN,+DAAAC,OACG/B,KAAK25C,gBACd,CASU,uBAAMyF,CAAkBD,GAGhC,OADAn/C,KAAK8+C,mBAAqBK,EAAa,GAAG/4B,OAAOzmB,QAAQ,GAClDw/C,EAAa/3C,MAAM,EAC5B,EAGFgG,OAAOuX,eAAe45B,GAAW35B,OAAOC,YAAa,CACnDzkB,MAAQ0kB,GACsB,MAArBA,EAAS05B,UAAiD,MAA7B15B,EAAS45B,kBACd,MAA3B55B,EAAS85B,iBC3IX,MAAOS,WAA0Bd,GAMrC/+C,WAAAA,CACc8/C,EAAgCC,GACV,IAAtB59C,EAAA2C,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAkB,KAC9B4gB,QAFY,KAAAo6B,aAAAA,EAAgC,KAAAC,IAAAA,EAChC,KAAA59C,QAAAA,EALN,KAAA69C,iBAAwC,GACxC,KAAAC,mBAA0C,GAOjC,MAAX99C,IACF3B,KAAK2B,QAAU4pB,GAAO9rB,QAAQkC,UAElC,CAEAi9C,cAAAA,CAAec,IACS96C,MAAMC,QAAQ66C,GAChCA,EAAkBl4C,IAAIwmB,GAAQA,EAAK3f,MACnCjB,OAAOkc,KAAKo2B,IAEFt2C,QAAQ,CAACiF,EAAM/K,KAC3B,MAAMlD,EAAQmrB,GAAOpE,oBAAoB9Y,GACnCoW,GAAY,EACc,MAA5BzkB,KAAKw/C,iBAAiBl8C,KACxBtD,KAAKw/C,iBAAiBl8C,GAAK,CACzBq8C,aAAc,GAAF59C,OAAKsM,EAAI,eACrBmW,SAAUoG,GAAK,IAAM4yB,GAAUp9C,GAAOokB,SAASC,MAGjB,MAA9BzkB,KAAKy/C,mBAAmBn8C,KAC1BtD,KAAKy/C,mBAAmBn8C,GAAK,CAC3Bq8C,aAAc,GAAF59C,OAAKsM,EAAI,cACrBmW,SAAUoG,GAAK,IAAM4yB,GAAUp9C,GAAOokB,SAASC,MAInD,MAAMkL,EAAW/qB,MAAMC,QAAQ66C,GAC3BA,EAAkBp8C,GAAG8iB,OACrBs5B,EAAkBrxC,GACtB,GAAgB,MAAZshB,EACF,OAGF,MAAMiwB,EAAkB5/C,KAAKw/C,iBAAiBl8C,GAAGkhB,SAC3Cq7B,EAAoB7/C,KAAKy/C,mBAAmBn8C,GAAGkhB,SAErDoG,GAAK,KACH,MAAMk1B,EACFviC,GAAIL,GAAI0iC,EAAiB5/C,KAAKu/C,KAC1BriC,GAAIogC,GAAO3tB,GAAW,EAAI3vB,KAAKu/C,MAEjChM,EACFr2B,GAAIggC,GAAIr3C,GAAK0X,GAAIsiC,EAAmB7/C,KAAK2B,UACjCkE,GAAK0X,GAAIqiC,EAAiB5/C,KAAK2B,WACnCguB,GAEFowB,EACFxiC,GAAIL,GAAI2iC,EAAmB7/C,KAAKu/C,KAC5BriC,GAAIogC,GAAO/J,GAAU,EAAIvzC,KAAKu/C,MAEtCK,EAAgBvyC,OAAOyyC,GACvBD,EAAkBxyC,OAAO0yC,GAEzB,MAAM56B,EAAW5H,GAAIL,GAAIq2B,GAAUvzC,KAAKs/C,cAAel/C,GACvDA,EAAMiN,OAAO8X,OAGjBnlB,KAAK++C,qBACP,CAEAn9C,OAAAA,GACiC,MAA3B5B,KAAKy/C,qBACP79C,GAAQ5B,KAAKw/C,iBAAiBh4C,IAAIyV,GAAKA,EAAEuH,WACzC5iB,GAAQ5B,KAAKy/C,mBAAmBj4C,IAAIyV,GAAKA,EAAEuH,WAE/C,CAEA,gBAAMy6B,GAEJ,MAAMe,EACF,IAAIhgD,KAAKw/C,oBAAqBx/C,KAAKy/C,oBACvC,MAAO,OAAOz/C,KAAKg/C,kBAAkBj9C,OACjCi+C,EAAUx4C,IAAIyV,IAAK,CAAE5O,KAAM4O,EAAE0iC,aAAcv5B,OAAQnJ,EAAEuH,YAC3D,CAEA,gBAAM06B,CAAWC,GAEf,MAAMc,GADNd,QAAqBn/C,KAAKo/C,kBAAkBD,IACTh9C,OAAS,EACtCsiB,GAAY,EAClBzkB,KAAKw/C,iBACDL,EAAa/3C,MAAM,EAAG64C,GAAez4C,IAAIyV,IAAK,CACH0iC,aAAc1iC,EAAE5O,KAChBmW,SAAUvH,EAAEmJ,OAAO5B,SACfC,MAEnDzkB,KAAKy/C,mBACDN,EAAa/3C,MAAM64C,EAA+B,EAAhBA,GAC7Bz4C,IAAIyV,IAAK,CACH0iC,aAAc1iC,EAAE5O,KAChBmW,SAAUvH,EAAEmJ,OAAO5B,SAASC,KAE7C,CAEAy7B,SAAAA,GACE,MAAO,CACL,aAAgBlgD,KAAKs/C,aACrB,IAAOt/C,KAAKu/C,IACZ,QAAWv/C,KAAK2B,QAEpB,CAGA,iBAAOk4C,CACHC,EAAiC7+B,GACnC,OAAO,IAAI6+B,EAAI7+B,EAAqB,aAAGA,EAAY,IAAGA,EAAgB,QACxE,EC9GF,SAASoG,GACL/f,EAAoBlB,EAAsBmB,GAC5C,MAAMsqB,EAAmB,CAACvqB,QAAOlB,QAAOmB,SAExC,OAAOgqB,GAAOC,UAAUtY,GAAM,CAAC,EAAG2Y,EACpC,CDTSwzB,GAAAzF,UAAY,WAoHrBO,GAAckF,IEtHR,MAAOc,WAAyB5B,GAMpC/+C,WAAAA,CACc8/C,GAA2D,IAA7Bc,EAAA97C,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAA0B,GACpE4gB,QADY,KAAAo6B,aAAAA,EAA8B,KAAAc,wBAAAA,EAHpC,KAAAZ,iBAAwC,EAKhD,CAEAZ,cAAAA,CAAec,IACS96C,MAAMC,QAAQ66C,GAChCA,EAAkBl4C,IAAIwmB,GAAQA,EAAK3f,MACnCjB,OAAOkc,KAAKo2B,IAEFt2C,QAAQ,CAACiF,EAAM/K,KAC3B,MAAMlD,EAAQmrB,GAAOpE,oBAAoB9Y,GACzC,GAAgC,MAA5BrO,KAAKw/C,iBAAiBl8C,GAAY,CACpC,MAAMmhB,GAAY,EAClBzkB,KAAKw/C,iBAAiBl8C,GAAK,CACzBq8C,aAAc,GAAF59C,OAAKsM,EAAI,gBACrBmW,SAAUoG,GACN,IAAMvJ,GAAKjhB,EAAMkB,MAAOtB,KAAKogD,yBAClB57B,SAASC,I,CAI5B,MAAMkL,EAAW/qB,MAAMC,QAAQ66C,GAC3BA,EAAkBp8C,GAAG8iB,OACrBs5B,EAAkBrxC,GACtB,GAAgB,MAAZshB,EACF,OAGF,MAAMiwB,EAAkB5/C,KAAKw/C,iBAAiBl8C,GAAGkhB,SAEjDoG,GAAK,KACH,MAAMk1B,EAAqBviC,GAAIqiC,EAAiBtC,GAAO3tB,IACvDiwB,EAAgBvyC,OAAOyyC,GAEvB,MAAM36B,EAAW5H,GACbL,GAAIggC,GAAIvtB,EACA9pB,GAAK0X,GAAIuiC,EAAoBv0B,GAAO9rB,QAAQkC,cAC/C3B,KAAKs/C,cACVl/C,GACJA,EAAMiN,OAAO8X,OAGjBnlB,KAAK++C,qBACP,CAEAn9C,OAAAA,GAC+B,MAAzB5B,KAAKw/C,kBACP59C,GAAQ5B,KAAKw/C,iBAAiBh4C,IAAIyV,GAAKA,EAAEuH,UAE7C,CAEA,gBAAMy6B,GAEJ,MAAO,OAAOj/C,KAAKg/C,kBAAkBj9C,OAAO/B,KAAKw/C,iBAAiBh4C,IAC9DyV,IAAK,CAAE5O,KAAM4O,EAAE0iC,aAAcv5B,OAAQnJ,EAAEuH,YAC7C,CAEA,gBAAM06B,CAAWC,GACfA,QAAqBn/C,KAAKo/C,kBAAkBD,GAE5Cn/C,KAAKw/C,iBAAmBL,EAAa33C,IACjCyV,IAAK,CAAE0iC,aAAc1iC,EAAE5O,KAAMmW,SAAUvH,EAAEmJ,OAAO5B,SAFlC,SAGpB,CAEA07B,SAAAA,GACE,MAAO,CACL,aAAgBlgD,KAAKs/C,aACrB,wBAA2Bt/C,KAAKogD,wBAEpC,CAGA,iBAAOvG,CACHC,EAAiC7+B,GACnC,OAAO,IAAI6+B,EAAI7+B,EAAqB,aAAGA,EAAgC,wBACzE,EAhFOklC,GAAAvG,UAAY,UAkFrBO,GAAcgG,IClDP,MAAME,GAAMnrB,GAAG,CAACorB,KAXvB,SACI7hC,EAAyBhZ,GAC3B,IAAI86C,EAAQhsB,GAAgB9V,EAAM,OAAQ,OACtC+hC,EAAOjsB,GAAgB9uB,EAAK,MAAO,QACtC86C,EAAOC,GAAQv6B,GAAes6B,EAAOC,GAEtC,MAAM/gC,EAAoB,CAACjc,EAAG+8C,EAAO98C,EAAG+8C,GAExC,OAAOj1B,GAAOC,UAAUjV,GAAKkJ,EAC/B,ICJO,MAAMghC,GAAMvrB,GAAG,CAACwrB,KAVvB,SAAgCl9C,EAAsBC,GACpD,IAAI4pC,EAAK9Y,GAAgB/wB,EAAG,IAAK,OAC7B8pC,EAAK/Y,GAAgB9wB,EAAG,IAAK,QAChC4pC,EAAIC,GAAMrnB,GAAeonB,EAAIC,GAE9B,MAAM7tB,EAAoB,CAACjc,EAAG6pC,EAAI5pC,EAAG6pC,GAErC,OAAO/hB,GAAOC,UAAUrS,GAAKsG,EAC/B,ICvBM,MAAOkhC,WAAsBpC,GASjC/+C,WAAAA,CACc8/C,EAAgCsB,EAChCC,GAA+C,IAAtBl/C,EAAA2C,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAkB,KACvD4gB,QAFY,KAAAo6B,aAAAA,EAAgC,KAAAsB,MAAAA,EAChC,KAAAC,MAAAA,EAAyB,KAAAl/C,QAAAA,EAL/B,KAAAm/C,uBAA8C,GAC9C,KAAAC,wBAA+C,GAMrDn2B,GAAK,KAEH5qB,KAAKghD,SAAW1C,GAAOsC,GAAOp8B,WAC9BxkB,KAAKihD,SAAW3C,GAAOuC,GAAOr8B,aAGjB,MAAX7iB,IACF3B,KAAK2B,QAAU4pB,GAAO9rB,QAAQkC,UAElC,CAEAi9C,cAAAA,CAAec,GACb,MAAMwB,EAAWt8C,MAAMC,QAAQ66C,GAC3BA,EAAkBl4C,IAAIyV,GAAKA,EAAE5O,MAC7BjB,OAAOkc,KAAKo2B,GAChB90B,GAAK,KACH,MAAMu2B,EAAmBV,GAAI,EAAGzgD,KAAKghD,UAC/BI,EAAmBX,GAAI,EAAGzgD,KAAKihD,UAErCC,EAAS93C,QAAQ,CAACiF,EAAM/K,KACtB,MAAMlD,EAAQmrB,GAAOpE,oBAAoB9Y,GACnCoW,GAAY,EACoB,MAAlCzkB,KAAK8gD,uBAAuBx9C,KAC9BtD,KAAK8gD,uBAAuBx9C,GAAK,CAC/Bq8C,aAAc,GAAF59C,OAAKsM,EAAI,MACrBmW,SAAUoG,GAAK,IAAM4yB,GAAUp9C,GAAOokB,SAASC,MAGZ,MAAnCzkB,KAAK+gD,wBAAwBz9C,KAC/BtD,KAAK+gD,wBAAwBz9C,GAAK,CAChCq8C,aAAc,GAAF59C,OAAKsM,EAAI,MACrBmW,SAAUoG,GAAK,IAAM4yB,GAAUp9C,GAAOokB,SAASC,MAInD,MAAMkL,EAAW/qB,MAAMC,QAAQ66C,GAC3BA,EAAkBp8C,GAAG8iB,OACrBs5B,EAAkBrxC,GACtB,GAAgB,MAAZshB,EACF,OAGF,MAAM0xB,EAAcrhD,KAAK8gD,uBAAuBx9C,GAAGkhB,SAC7C88B,EAAethD,KAAK+gD,wBAAwBz9C,GAAGkhB,SAE/C+8B,EACFhkC,GAAIL,GAAImkC,EAAarhD,KAAK4gD,OAAQ1jC,GAAIyS,EAAU,EAAI3vB,KAAK4gD,QACvDY,EACFjkC,GAAIL,GAAIokC,EAActhD,KAAK6gD,OACvB3jC,GAAIogC,GAAO3tB,GAAW,EAAI3vB,KAAK6gD,QAEjCY,EAA2BvE,GAAIqE,EAAgBJ,GAC/CO,EACFxE,GAAIsE,EAAiBJ,GAEzBC,EAAYh0C,OAAOk0C,GACnBD,EAAaj0C,OAAOm0C,GAEpB,MAAMr8B,EACF5H,GAAIL,GAAIggC,GAAIuE,EACAlkC,GAAI1X,GAAK67C,GAA4B1hD,KAAK2B,WAC7C3B,KAAKs/C,cACVl/C,GACRA,EAAMiN,OAAO8X,KAGfnlB,KAAKghD,SAAS3zC,OAAO6P,GAAIld,KAAKghD,SAAUhhD,KAAK4gD,QAC7C5gD,KAAKihD,SAAS5zC,OAAO6P,GAAIld,KAAKihD,SAAUjhD,KAAK6gD,UAE/C7gD,KAAK++C,qBACP,CAEAn9C,OAAAA,GACE5B,KAAKghD,SAASp/C,UACd5B,KAAKihD,SAASr/C,UAEqB,MAA/B5B,KAAK8gD,wBACPl/C,GAAQ5B,KAAK8gD,uBAAuBt5C,IAAIyV,GAAKA,EAAEuH,WAEb,MAAhCxkB,KAAK+gD,yBACPn/C,GAAQ5B,KAAK+gD,wBAAwBv5C,IAAIyV,GAAKA,EAAEuH,UAEpD,CAEA,gBAAMy6B,GAEJ,MAAMe,EACF,IAAIhgD,KAAK8gD,0BAA2B9gD,KAAK+gD,yBAC7C,MAAO,OAAO/gD,KAAKg/C,kBAAkBj9C,OACjCi+C,EAAUx4C,IAAIyV,IAAK,CAAE5O,KAAM4O,EAAE0iC,aAAcv5B,OAAQnJ,EAAEuH,YAC3D,CAEA,gBAAM06B,CAAWC,GACfA,QAAqBn/C,KAAKo/C,kBAAkBD,GAC5Cv0B,GAAK,KACH5qB,KAAKghD,SAAS3zC,OAAOgzC,GAAIrgD,KAAK4gD,MAAO5gD,KAAK8+C,YAAc,IACxD9+C,KAAKihD,SAAS5zC,OAAOgzC,GAAIrgD,KAAK6gD,MAAO7gD,KAAK8+C,YAAc,MAG1D,MAAMmB,EAAgBd,EAAah9C,OAAS,EACtCsiB,GAAY,EAClBzkB,KAAK8gD,uBACD3B,EAAa/3C,MAAM,EAAG64C,GAAez4C,IAAIyV,IAAK,CACH0iC,aAAc1iC,EAAE5O,KAChBmW,SAAUvH,EAAEmJ,OAAO5B,SACfC,MAEnDzkB,KAAK+gD,wBACD5B,EAAa/3C,MAAM64C,EAA+B,EAAhBA,GAC7Bz4C,IAAIyV,IAAK,CACH0iC,aAAc1iC,EAAE5O,KAChBmW,SAAUvH,EAAEmJ,OAAO5B,SAASC,KAE7C,CAEAy7B,SAAAA,GACE,MAAO,CACL,aAAgBlgD,KAAKs/C,aACrB,MAASt/C,KAAK4gD,MACd,MAAS5gD,KAAK6gD,MACd,QAAW7gD,KAAK2B,QAEpB,CAGA,iBAAOk4C,CACHC,EAAiC7+B,GACnC,OAAO,IAAI6+B,EACP7+B,EAAqB,aAAGA,EAAc,MAAGA,EAAc,MACvDA,EAAgB,QACtB,EA7IO0lC,GAAA/G,UAAY,OA+IrBO,GAAcwG,ICjIP,MAAMjF,GAAMxmB,GAAG,CAACysB,KAZvB,SAAgC/+C,GAC9B,MAAMgiC,EAAKrQ,GAAgB3xB,EAAG,IAAK,OAEnC,GAAiB,cAAbgiC,EAAGrjC,MAAuB,CAC5B,MAAMke,EAA2B,CAAC7c,EAAGgiC,GACrC,OAAOrZ,GAAOC,UAAUta,GAAYuO,E,CAC/B,CACL,MAAMA,EAAoB,CAAC7c,EAAGgiC,GAC9B,OAAOrZ,GAAOC,UAAUjc,GAAKkQ,E,CAEjC,ICyBO,MAAMmiC,GAAU1sB,GAAG,CAAC2sB,SAjB3B,SACIr+C,EAAsBC,GACxB,IAAI4pC,EAAK9Y,GAAgB/wB,EAAG,IAAK,WAC7B8pC,EAAK/Y,GAAgB9wB,EAAG,IAAK,YAChC4pC,EAAIC,GAAMrnB,GAAeonB,EAAIC,GAEb,SAAbD,EAAG9rC,QACL8rC,EAAK9oB,GAAK8oB,EAAI,SACdC,EAAK/oB,GAAK+oB,EAAI,UAEhB0C,GAA2B3C,EAAG/rC,MAAOgsC,EAAGhsC,OAExC,MAAMme,EAAwB,CAACjc,EAAG6pC,EAAI5pC,EAAG6pC,GAEzC,OAAO/hB,GAAOC,UAAUxW,GAASyK,EACnC,ICtCM,MAAOqiC,WAAwBvD,GASnC/+C,WAAAA,CACc8/C,EAAgCsB,EAChCC,GACW,IADcl/C,EAAA2C,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAkB,KAC3Cy9C,EAAAz9C,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAQ,EACpB4gB,QAHY,KAAAo6B,aAAAA,EAAgC,KAAAsB,MAAAA,EAChC,KAAAC,MAAAA,EAAyB,KAAAl/C,QAAAA,EACzB,KAAAogD,MAAAA,EANN,KAAAjB,uBAA8C,GAC9C,KAAAkB,2BAAkD,GAQxDp3B,GAAK,KACH5qB,KAAKiiD,UAAY3D,GAAO,GAAG95B,WAC3BxkB,KAAKghD,SAAW1C,GAAOsC,GAAOp8B,aAGjB,MAAX7iB,IACF3B,KAAK2B,QAAU4pB,GAAO9rB,QAAQkC,UAElC,CAEAi9C,cAAAA,CAAec,GACb,MAAMwC,EAAgBt9C,MAAMC,QAAQ66C,GAChCA,EAAkBl4C,IAAIwmB,GAAQA,EAAK3f,MACnCjB,OAAOkc,KAAKo2B,GAEhB90B,GAAK,KACH,MAAMu2B,EAAmBV,GAAI,EAAGzgD,KAAKghD,UAC/BmB,EACFjF,IAAKl9C,KAAKs/C,aAAc/hC,GAAIL,GAAIld,KAAKiiD,UAAWjiD,KAAK+hD,OAAQ,IAEjEG,EAAc94C,QAAQ,CAACiF,EAAM/K,KAC3B,MAAMlD,EAAQmrB,GAAOpE,oBAAoB9Y,GACnCoW,GAAY,EACoB,MAAlCzkB,KAAK8gD,uBAAuBx9C,KAC9BtD,KAAK8gD,uBAAuBx9C,GAAK,CAC/Bq8C,aAAc,GAAF59C,OAAKsM,EAAI,MACrBmW,SAAUg5B,GAAUp9C,GAAOokB,SAASC,KAGE,MAAtCzkB,KAAKgiD,2BAA2B1+C,KAClCtD,KAAKgiD,2BAA2B1+C,GAAK,CACnCq8C,aAAc,GAAF59C,OAAKsM,EAAI,MACrBmW,SAAUg5B,GAAUp9C,GAAOokB,SAASC,KAIxC,MAAMkL,EAAW/qB,MAAMC,QAAQ66C,GAC3BA,EAAkBp8C,GAAG8iB,OACrBs5B,EAAkBrxC,GACtB,GAAgB,MAAZshB,EACF,OAGF,MAAM0xB,EAAcrhD,KAAK8gD,uBAAuBx9C,GAAGkhB,SAC7C49B,EAAkBpiD,KAAKgiD,2BAA2B1+C,GAAGkhB,SAErD+8B,EACFhkC,GAAIL,GAAImkC,EAAarhD,KAAK4gD,OAAQ1jC,GAAIyS,EAAU,EAAI3vB,KAAK4gD,QAEvDyB,EAAMnlC,GAAIklC,EAAiBpiD,KAAK6gD,OAChCyB,EAAM5G,GAAI/rB,GAEV4yB,EAAqBX,GAAQS,EAAKC,GAExCjB,EAAYh0C,OAAOk0C,GACnBa,EAAgB/0C,OAAOk1C,GAEvB,MAAMp9B,EACF5H,GAAIL,GAAIggC,GAAIiF,EAAIhB,GACRjE,GAAIqE,EAAgBhkC,GAAIglC,EAAoBviD,KAAK2B,WACrDvB,GAERA,EAAMiN,OAAO8X,KAGfnlB,KAAKiiD,UAAU50C,OAAOkQ,GAAIvd,KAAKiiD,UAAW,IAC1CjiD,KAAKghD,SAAS3zC,OAAO6P,GAAIld,KAAKghD,SAAUhhD,KAAK4gD,UAE/C5gD,KAAK++C,qBACP,CAEAn9C,OAAAA,GACE5B,KAAKghD,SAASp/C,UACd5B,KAAKiiD,UAAUrgD,UAEoB,MAA/B5B,KAAK8gD,wBACPl/C,GAAQ5B,KAAK8gD,uBAAuBt5C,IAAIyV,GAAKA,EAAEuH,WAEV,MAAnCxkB,KAAKgiD,4BACPpgD,GAAQ5B,KAAKgiD,2BAA2Bx6C,IAAIyV,GAAKA,EAAEuH,UAEvD,CAEA,gBAAMy6B,GACJ,MAAM,IAAIn9C,MAAM,kDAClB,CAEA,gBAAMo9C,CAAWC,GACf,MAAM,IAAIr9C,MAAM,kDAClB,CAEAo+C,SAAAA,GACE,MAAO,CACL,aAAgBlgD,KAAKs/C,aACrB,MAASt/C,KAAK4gD,MACd,MAAS5gD,KAAK6gD,MACd,QAAW7gD,KAAK2B,QAChB,MAAS3B,KAAK+hD,MAElB,CAGA,iBAAOlI,CACHC,EAAiC7+B,GACnC,OAAO,IAAI6+B,EACP7+B,EAAqB,aAAGA,EAAc,MAAGA,EAAc,MACvDA,EAAgB,QAAGA,EAAc,MACvC,EAxHO6mC,GAAAlI,UAAY,SA0HrBO,GAAc2H,IChIR,MAAOU,WAAqBjE,GAKhC/+C,WAAAA,CAAsB8/C,GACpBp6B,QADoB,KAAAo6B,aAAAA,EAEpBt/C,KAAKyiD,gBAAgBnD,EACvB,CAEAV,cAAAA,CAAec,IACI96C,MAAMC,QAAQ66C,GAC3BA,EAAkBl4C,IAAIyV,GAAKA,EAAE5O,MAC7BjB,OAAOkc,KAAKo2B,IACPt2C,QAAQ,CAACiF,EAAM/K,KACtB,MAAMqsB,EAAW/qB,MAAMC,QAAQ66C,GAC3BA,EAAkBp8C,GAAG8iB,OACrBs5B,EAAkBrxC,GACtB,GAAgB,MAAZshB,EACF,OAEF,MAAMvvB,EAAQmrB,GAAOpE,oBAAoB9Y,GACzCuc,GAAK,KACH,MAAMzF,EAAW5H,GAAIL,GAAIld,KAAK0K,EAAGilB,GAAWvvB,GAC5CA,EAAMiN,OAAO8X,OAGjBnlB,KAAK++C,qBACP,CAKA0D,eAAAA,CAAgBnD,GACdt/C,KAAKs/C,aAAeA,EACN,MAAVt/C,KAAK0K,GACP1K,KAAK0K,EAAE9I,UAET5B,KAAK0K,EAAI6iB,GAAK+wB,IAAQgB,GACxB,CAEA19C,OAAAA,GACE5B,KAAK0K,EAAE9I,SACT,CAEA,gBAAMq9C,GACJ,MAAO,OAAOj/C,KAAKg/C,iBACrB,CAEA,gBAAME,CAAWC,GAEf,GAA4B,KAD5BA,QAAqBn/C,KAAKo/C,kBAAkBD,IAC3Bh9C,OACf,MAAM,IAAIL,MAAM,gDAEpB,CAEAo+C,SAAAA,GACE,MAAO,CAAC,aAAgBlgD,KAAKs/C,aAC/B,CAGA,iBAAOzF,CACHC,EAAiC7+B,GACnC,OAAO,IAAI6+B,EAAI7+B,EAAqB,aACtC,EA9DOunC,GAAA5I,UAAY,MAgErBO,GAAcqI,IChER,MAAOE,WAA0BF,GAMrChjD,WAAAA,CACc8/C,EAA8BqD,GACb,IAAnBC,EAAAt+C,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,IAAAA,UAAA,GACV4gB,MAAMo6B,GAFM,KAAAA,aAAAA,EAA8B,KAAAqD,SAAAA,EAChC,KAAAC,YAAAA,EAJJ,KAAAC,cAAqC,GAM3C7iD,KAAK86B,EAAIwjB,GAAOt+C,KAAK2iD,SACvB,CAEA/D,cAAAA,CAAec,IACS96C,MAAMC,QAAQ66C,GAChCA,EAAkBl4C,IAAIwmB,GAAQA,EAAK3f,MACnCjB,OAAOkc,KAAKo2B,IAEFt2C,QAAQ,CAACiF,EAAM/K,KAC3B,MAAMlD,EAAQmrB,GAAOpE,oBAAoB9Y,GACzC,GAA6B,MAAzBrO,KAAK6iD,cAAcv/C,GAAY,CACjC,MAAMmhB,GAAY,EAClBzkB,KAAK6iD,cAAcv/C,GAAK,CACtBq8C,aAAc,GAAF59C,OAAKsM,EAAI,aACrBmW,SAAUoG,GAAK,IAAM4yB,GAAUp9C,GAAOokB,SAASC,I,CAInD,MAAMq+B,EAAe9iD,KAAK6iD,cAAcv/C,GAAGkhB,SACrCmL,EAAW/qB,MAAMC,QAAQ66C,GAC3BA,EAAkBp8C,GAAG8iB,OACrBs5B,EAAkBrxC,GACN,MAAZshB,GAIJ/E,GAAK,KACH,IAAIzF,EACJ,MAAM49B,EAAkBxlC,GAAIL,GAAIld,KAAK86B,EAAGgoB,GAAenzB,GAErDxK,EADEnlB,KAAK4iD,YACIrlC,GACPL,GAAIld,KAAK0K,EAAG6S,GAAIoS,EAAUzS,GAAI6lC,EAAiB/iD,KAAK86B,KAAM16B,GAEnDmd,GAAIL,GAAIld,KAAK0K,EAAGq4C,GAAkB3iD,GAE/C0iD,EAAaz1C,OAAO01C,GACpB3iD,EAAMiN,OAAO8X,OAGjBnlB,KAAK++C,qBACP,CAEAn9C,OAAAA,GACE5B,KAAK86B,EAAEl5B,UACmB,MAAtB5B,KAAK6iD,eACPjhD,GAAQ5B,KAAK6iD,cAAcr7C,IAAIyV,GAAKA,EAAEuH,UAE1C,CAOAw+B,WAAAA,CAAYL,GACV3iD,KAAK2iD,SAAWA,CAClB,CAEA,gBAAM1D,GAEJ,MAAO,OAAOj/C,KAAKg/C,kBAAkBj9C,OAAO/B,KAAK6iD,cAAcr7C,IAC3DyV,IAAK,CAAE5O,KAAM4O,EAAE0iC,aAAcv5B,OAAQnJ,EAAEuH,YAC7C,CAEA,gBAAM06B,CAAWC,GACfA,QAAqBn/C,KAAKo/C,kBAAkBD,GAE5Cn/C,KAAK6iD,cAAgB1D,EAAa33C,IAC9ByV,IAAK,CAAE0iC,aAAc1iC,EAAE5O,KAAMmW,SAAUvH,EAAEmJ,OAAO5B,SAFlC,SAGpB,CAEA07B,SAAAA,GACE,MAAO,CACL,aAAgBlgD,KAAKs/C,aACrB,SAAYt/C,KAAK2iD,SACjB,YAAe3iD,KAAK4iD,YAExB,CAGA,iBAAO/I,CACHC,EAAiC7+B,GACnC,OAAO,IAAI6+B,EACP7+B,EAAqB,aAAGA,EAAiB,SAAGA,EAAoB,YACtE,EA5FOynC,GAAA9I,UAAY,WA8FrBO,GAAcuI,IC/FR,MAAOO,WAAyB1E,GASpC/+C,WAAAA,CACc8/C,GAEM,IAF0ByC,EAAAz9C,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAQ,GACxCq+C,EAAAr+C,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAW,EAAe3C,EAAA2C,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAkB,KACtD4+C,EAAQ5+C,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,IAAAA,UAAA,GAQV,GAPA4gB,QAHY,KAAAo6B,aAAAA,EAAgC,KAAAyC,MAAAA,EAChC,KAAAY,SAAAA,EAA0B,KAAAhhD,QAAAA,EANhC,KAAAwhD,uBAA8C,GAC9C,KAAAC,mBAA0C,GAC1C,KAAAC,qBAA4C,GAQlDrjD,KAAKkjD,SAAWA,EAED,MAAXvhD,IACF3B,KAAK2B,QAAU4pB,GAAO9rB,QAAQkC,WAEZ,MAAhB29C,EACF,MAAM,IAAIx9C,MAAM,qDAEpB,CAEA88C,cAAAA,CAAec,IACS96C,MAAMC,QAAQ66C,GAChCA,EAAkBl4C,IAAIwmB,GAAQA,EAAK3f,MACnCjB,OAAOkc,KAAKo2B,IAEFt2C,QAAQ,CAACiF,EAAM/K,KAC3B,MAAMlD,EAAQmrB,GAAOpE,oBAAoB9Y,GACnCoW,GAAY,EACoB,MAAlCzkB,KAAKmjD,uBAAuB7/C,KAC9BtD,KAAKmjD,uBAAuB7/C,GAAK,CAC/Bq8C,aAAc,GAAF59C,OAAKsM,EAAI,QACrBmW,SAAUoG,GAAK,IAAM4yB,GAAUp9C,GAAOokB,SAASC,MAGjB,MAA9BzkB,KAAKojD,mBAAmB9/C,KAC1BtD,KAAKojD,mBAAmB9/C,GAAK,CAC3Bq8C,aAAc,GAAF59C,OAAKsM,EAAI,aACrBmW,SAAUoG,GAAK,IAAM4yB,GAAUp9C,GAAOokB,SAASC,MAGf,MAAhCzkB,KAAKqjD,qBAAqB//C,IAActD,KAAKkjD,WAC/CljD,KAAKqjD,qBAAqB//C,GAAK,CAC7Bq8C,aAAc,GAAF59C,OAAKsM,EAAI,OACrBmW,SAAUoG,GAAK,IAAM4yB,GAAUp9C,GAAOokB,SAASC,MAInD,MAAMkL,EAAW/qB,MAAMC,QAAQ66C,GAC3BA,EAAkBp8C,GAAG8iB,OACrBs5B,EAAkBrxC,GACtB,GAAgB,MAAZshB,EACF,OAGF,MAAM2zB,EAAwBtjD,KAAKmjD,uBAAuB7/C,GAAGkhB,SACvD4+B,EAAqBpjD,KAAKojD,mBAAmB9/C,GAAGkhB,SACtDoG,GAAK,KACH,MAAM24B,EACFhmC,GAAIL,GAAIomC,EAAuBtjD,KAAK+hD,OAChC7kC,GAAIogC,GAAO3tB,GAAW,EAAI3vB,KAAK+hD,QAEvC,GAAI/hD,KAAKkjD,SAAU,CACjB,MAAMM,EAAsBxjD,KAAKqjD,qBAAqB//C,GAAGkhB,SAEnDi/B,EACFlmC,GAAIL,GAAIsmC,EAAqBxjD,KAAK+hD,OAC9B7kC,GAAIyS,EAAU,EAAI3vB,KAAK+hD,QAEzB2B,EACFxG,GAAIhgC,GAAIyS,EAAU3vB,KAAKs/C,cACnBz5C,GACI46C,GAAI8C,EACAhmC,GAAI+/B,GAAOmG,GAAyBzjD,KAAK2B,YACnDgiD,EACFpmC,GAAIL,GAAIkmC,EAAoBpjD,KAAK2iD,UAAWe,GAEhDJ,EAAsBj2C,OAAOk2C,GAC7BC,EAAoBn2C,OAAOo2C,GAC3BL,EAAmB/1C,OAAOs2C,GAE1B,MAAMx+B,EAAWs7B,GAAIrgD,EAAOujD,GAC5BvjD,EAAMiN,OAAO8X,E,KACR,CAEL,MAAMo+B,EACFhmC,GAAIL,GAAIomC,EAAuBtjD,KAAK+hD,OAChC7kC,GAAIogC,GAAO3tB,GAAW,EAAI3vB,KAAK+hD,QAEjC4B,EACFpmC,GAAIL,GAAIkmC,EAAoBpjD,KAAK2iD,UAC7BzF,GAAIhgC,GAAIyS,EAAU3vB,KAAKs/C,cACnBz5C,GAAK0X,GAAIgmC,EAA0BvjD,KAAK2B,YAEpD2hD,EAAsBj2C,OAAOk2C,GAC7BH,EAAmB/1C,OAAOs2C,GAE1B,MAAMx+B,EAAWs7B,GAAIrgD,EAAOujD,GAC5BvjD,EAAMiN,OAAO8X,E,MAInBnlB,KAAK++C,qBACP,CAEAn9C,OAAAA,GACqC,MAA/B5B,KAAKmjD,wBACPvhD,GAAQ5B,KAAKmjD,uBAAuB37C,IAAIyV,GAAKA,EAAEuH,WAEhB,MAA7BxkB,KAAKqjD,sBAAgCrjD,KAAKkjD,UAC5CthD,GAAQ5B,KAAKqjD,qBAAqB77C,IAAIyV,GAAKA,EAAEuH,WAEhB,MAA3BxkB,KAAKojD,oBACPxhD,GAAQ5B,KAAKojD,mBAAmB57C,IAAIyV,GAAKA,EAAEuH,UAE/C,CAEA,gBAAMy6B,GAEJ,MAAMe,EACF,IAAIhgD,KAAKmjD,0BAA2BnjD,KAAKojD,oBAI7C,OAHIpjD,KAAKkjD,UACPlD,EAAUj7C,QAAQ/E,KAAKqjD,sBAElB,OAAOrjD,KAAKg/C,kBAAkBj9C,OACjCi+C,EAAUx4C,IAAIyV,IAAK,CAAE5O,KAAM4O,EAAE0iC,aAAcv5B,OAAQnJ,EAAEuH,YAC3D,CAEA,gBAAM06B,CAAWC,GACfA,QAAqBn/C,KAAKo/C,kBAAkBD,GAC5C,MAAMc,EACFjgD,KAAKkjD,SAAW/D,EAAah9C,OAAS,EAAIg9C,EAAah9C,OAAS,EAC9DsiB,GAAY,EAClBzkB,KAAKmjD,uBACDhE,EAAa/3C,MAAM,EAAG64C,GAAez4C,IAAIyV,IAAK,CACH0iC,aAAc1iC,EAAE5O,KAChBmW,SAAUvH,EAAEmJ,OAAO5B,SACfC,MAEnDzkB,KAAKojD,mBACDjE,EAAa/3C,MAAM64C,EAA+B,EAAhBA,GAC7Bz4C,IAAIyV,IAAK,CACH0iC,aAAc1iC,EAAE5O,KAChBmW,SAAUvH,EAAEmJ,OAAO5B,SAASC,MAEvCzkB,KAAKkjD,WACPljD,KAAKqjD,qBACDlE,EAAa/3C,MAAsB,EAAhB64C,EAAmC,EAAhBA,GACjCz4C,IAAIyV,IAAK,CACH0iC,aAAc1iC,EAAE5O,KAChBmW,SAAUvH,EAAEmJ,OAAO5B,SAASC,MAG/C,CAEAy7B,SAAAA,GACE,MAAO,CACL,aAAgBlgD,KAAKs/C,aACrB,MAASt/C,KAAK+hD,MACd,SAAY/hD,KAAK2iD,SACjB,QAAW3iD,KAAK2B,QAChB,SAAY3B,KAAKkjD,SAErB,CAGA,iBAAOrJ,CACHC,EAAiC7+B,GACnC,OAAO,IAAI6+B,EACP7+B,EAAqB,aAAGA,EAAc,MAAGA,EAAiB,SAC1DA,EAAgB,QAAGA,EAAiB,SAC1C,EA7KOgoC,GAAArJ,UAAY,UA+KrBO,GAAc8I,ICxLR,MAAOW,GAsCX,UAAOC,CAAIvE,GACT,OAAO,IAAIkD,GAAalD,EAC1B,CAiBA,eAAOqD,CAASrD,EAAsBqD,GAEpC,OAAO,IAAID,GAAkBpD,EAAcqD,EAFsBr+C,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,IAAAA,UAAA,GAGnE,CAsBA,cAAOw/C,CACHxE,GAEF,OAAO,IAAI2D,GACP3D,EAHyBh7C,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,GAAYA,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,EAAKA,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAkB,KAC5DA,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,IAAAA,UAAA,GAGZ,CAcA,WAAOy/C,GAGL,OAAO,IAAIpD,GAFGr8C,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,KAAYA,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,GAAUA,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,KAC3CA,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAkB,KAEtB,CAcA,eAAO0/C,GAEL,OAAO,IAAI3E,GAFe/6C,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,KAASA,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,IAAKA,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAkB,KAGlE,CAeA,aAAO2/C,GAGL,OAAO,IAAInC,GAFGx9C,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,KAAYA,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,GAAUA,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,KAAOA,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAkB,KAC/DA,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,EAEZ,CAkBA,cAAO4/C,CAAQ5E,GAEb,OAAO,IAAIa,GAAiBb,EAF8Bh7C,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,GAG/D,ECjJK,MAAM6/C,GAAOjvB,GAAG,CAACkvB,MANxB,SAAiCxhD,GAC/B,MACM6c,EAAqB,CAAC7c,EADjB2xB,GAAgB3xB,EAAG,IAAK,SAGnC,OAAO2oB,GAAOC,UAAUhc,GAAMiQ,EAChC,ICIO,MAAM4kC,GAAQnvB,GAAG,CAACovB,OANzB,SAAkC1hD,GAChC,MACM6c,EAAsB,CAAC7c,EADlB2xB,GAAgB3xB,EAAG,IAAK,UAGnC,OAAO2oB,GAAOC,UAAU/b,GAAOgQ,EACjC,IC2BO,MAAM8kC,GAAOrvB,GAAG,CAACsvB,MAhCxB,SAAiCl3B,GAC/BzN,EACIjb,MAAMC,QAAQyoB,GACd,IAAM,8DACVzN,EACIyN,EAAQnrB,QAAU,EAClB,IAAM,0DAAAJ,OACCurB,EAAQnrB,SAEnB,MAAMsiD,EACFn3B,EAAQ9lB,IAAI,CAAC2G,EAAG7K,IAAMixB,GAAgBpmB,EAAG,UAAFpM,OAAYuB,GAAK,SAEtDohD,EAAcD,EAAS,GAC7BA,EAASr7C,QAAQ+E,IACf,GAAIA,EAAE5M,QAAUmjD,EAAYnjD,MAC1B,MAAM,IAAIO,MACN,8DAIR2iD,EAASr7C,QAAQ+E,IACf,IAAK0R,GAAiB1R,EAAE7M,MAAOojD,EAAYpjD,OACzC,MAAM,IAAIQ,MACN,8DAIR,MAAM2d,EAAqBglC,EAE3B,OAAOl5B,GAAOC,UAAU7b,GAAM8P,EAChC,ICFO,MAAMgB,GAAMyU,GAAG,CAACyvB,KAXvB,SACI/hD,GAAoE,IAA9C0E,EAAAhD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAwB,KAAMsgD,EAAQtgD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,IAAAA,UAAA,GAC9D,MAEMmb,EAAoB,CAAC7c,EAFhB2xB,GAAgB3xB,EAAG,IAAK,MAAO,SAGpCipB,EAAkB,CAACvkB,OAAMs9C,YAE/B,OAAOr5B,GAAOC,UACV5b,GAAK6P,EAAgCoM,EAC3C,ICGO,MAAMg5B,GAAM3vB,GAAG,CAAC4vB,KAZvB,SACIliD,GAAoE,IAA9C0E,EAAAhD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAwB,KAAMsgD,EAAQtgD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,IAAAA,UAAA,GAC9D,MAEMmb,EAAoB,CAAC7c,EAFhB2xB,GAAgB3xB,EAAG,IAAK,MAAO,SAGpCipB,EAAkB,CAACvkB,OAAMs9C,YAE/B,OAAOr5B,GAAOC,UACV3b,GAAK4P,EAAgCoM,EAC3C,ICJO,MAAMk5B,GAAS7vB,GAAG,CAAC8vB,QAV1B,SAAmCpiD,GAA8B,IAAR0E,EAAIhD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,EAC9D,MAEMmb,EAAuB,CAAC7c,EAFnB2xB,GAAgB3xB,EAAG,IAAK,WAG7BipB,EAAqB,CAACvkB,QAE5B,OAAOikB,GAAOC,UACV1b,GAAQ2P,EAAgCoM,EAC9C,ICEO,MAAMo5B,GAAS/vB,GAAG,CAACgwB,QAV1B,SAAmCtiD,GAA8B,IAAR0E,EAAIhD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,EAC9D,MAEMmb,EAAuB,CAAC7c,EAFnB2xB,GAAgB3xB,EAAG,IAAK,WAG7BipB,EAAqB,CAACvkB,QAE5B,OAAOikB,GAAOC,UACVzb,GAAQ0P,EAAgCoM,EAC9C,IChBO,MAAMs5B,GAAOjwB,GAAG,CAACkwB,MANxB,SAAiCxiD,GAC/B,MACM6c,EAAqB,CAAC7c,EADjB2xB,GAAgB3xB,EAAG,IAAK,SAGnC,OAAO2oB,GAAOC,UAAUxb,GAAMyP,EAChC,ICIO,MAAM4lC,GAAQnwB,GAAG,CAACowB,OAPzB,SAAkC1iD,GAChC,MAEM6c,EAAsB,CAAC7c,EAFlB2xB,GAAgB3xB,EAAG,IAAK,UAInC,OAAO2oB,GAAOC,UAAUvb,GAAOwP,EACjC,ICAO,MAAM8lC,GAAOrwB,GAAG,CAACswB,MAPxB,SAAiC5iD,GAC/B,MAEM6c,EAAqB,CAAC7c,EAFjB2xB,GAAgB3xB,EAAG,IAAK,SAInC,OAAO2oB,GAAOC,UAAUtb,GAAMuP,EAChC,ICUO,MAAMgmC,GAAQvwB,GAAG,CAACwwB,OAXzB,SACIliD,EAAsBC,GACxB,IAAI4pC,EAAK9Y,GAAgB/wB,EAAG,IAAK,SAC7B8pC,EAAK/Y,GAAgB9wB,EAAG,IAAK,UAChC4pC,EAAIC,GAAMrnB,GAAeonB,EAAIC,GAE9B,MAAM7tB,EAAsB,CAACjc,EAAG6pC,EAAI5pC,EAAG6pC,GAEvC,OAAO/hB,GAAOC,UAAUpb,GAAOqP,EACjC,ICNO,MAAMkmC,GAAQzwB,GAAG,CAAC0wB,OAPzB,SAAkChjD,GAChC,MAEM6c,EAAsB,CAAC7c,EAFlB2xB,GAAgB3xB,EAAG,IAAK,UAInC,OAAO2oB,GAAOC,UAAUrb,GAAOsP,EACjC,ICsDM,SAAUomC,GACZ9kC,EACA+kC,EAAuC97C,EACvC+X,GACkC,IADNgkC,EAAAzhD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAqB,OACjD0hD,EAAkC1hD,UAAAnC,OAAA,EAAAmC,UAAA,QAAAC,EAUpC,OAAO0hD,GACHllC,EAJA,IAAI+kC,EAFc/kC,EAAW,IAMH/W,EAASg8C,EAAWjkC,EAC9C,KAAyB,KAJTmkC,GAAwBH,GAK9C,CAEM,SAAUI,GACZ7W,EACA8W,EAAqCp8C,EACrCg8C,EACAjkC,EACAskC,GAC2D,IAA3DN,EAAAzhD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAA6C,eAC/C,MAAOgiD,EAAcC,GAAeC,GAAgBJ,GAEpD,IAAIN,EACJ,GAAmB,iBAAfC,EACFD,EAAc,CAACQ,EAAcC,EAAajX,EAAQ,GAAIA,EAAQ,QACzD,IAAmB,kBAAfyW,EAGT,MAAM,IAAIjkD,MAAM,sBAADC,OAAuBgkD,IAFtCD,EAAc,CAACQ,EAAcC,EAAajX,EAAQ,GAAIA,EAAQ,G,CAKhE,OAAO2W,GACH3W,EAASwW,EAAa97C,EAASg8C,EAAWjkC,EAAKskC,GAAc,EAC7DN,EACN,CAKM,SAAUU,GACZnX,EACA8W,EACAp8C,EACAg8C,EAA4CjkC,EAC5CskC,GACqC,IAArCN,EAAAzhD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAA8B,QAChC,MAAOoiD,EAAaJ,EAAcC,GAAeI,GAAiBP,GAElE,IAAIN,EACAc,EACJ,GAAmB,UAAfb,EACFa,EAAc,eACdd,EACI,CAACY,EAAaJ,EAAcC,EAAajX,EAAQ,GAAIA,EAAQ,QAC5D,IAAmB,UAAfyW,EAKT,MAAM,IAAIjkD,MAAM,sBAADC,OAAuBgkD,IAJtCa,EAAc,gBACdd,EACI,CAACY,EAAaJ,EAAcC,EAAajX,EAAQ,GAAIA,EAAQ,G,CAKnE,OAAOuX,GACHvX,EAASwW,EAAa97C,EAASg8C,EAAWjkC,GAAK,EAAO6kC,EACtDP,EACN,CAMM,SAAUJ,GACZ3W,EACAwW,EACA97C,EAAkCg8C,EAClCjkC,EACAskC,GAC2D,IADpBS,EAASxiD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,IAAAA,UAAA,GAChDyhD,EAAAzhD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAA6C,gBAC1CyiD,EAAWC,EAAUC,EAASC,GAAc,EAAE,GAAI,GAAI,GAAI,GAC/D,GAAmB,iBAAfnB,GACDgB,EAAWC,EAAUC,EAASC,GAAc5X,MACxC,IAAmB,kBAAfyW,EAGT,MAAM,IAAIjkD,MAAM,sBAADC,OAAuBgkD,KAFrCgB,EAAWG,EAAYF,EAAUC,GAAW3X,C,CAK/C,MAAOgX,EAAcC,EAAY,CAAGY,GAAkBrB,GAC/CsB,EAAcC,GAAeb,GAAgBx8C,IAC7Cs9C,EAAgBC,GAAiBf,GAAgBR,GAElDwB,EACFC,GAAuBnB,EAAcgB,GACnCI,EACFD,GAAuBlB,EAAagB,IAClC,QAACI,EAAO,UAAEC,EAAS,SAAEC,GAqO7B,SACI9lC,EAA4CilC,EAC5CC,EAAiBG,EAAsBC,EACvCf,EAAsBC,EACtBF,EACAN,GAEF,IAAI4B,EACAC,EACAC,EAEJ,GAAmB,kBAAR9lC,EAAkB,CAE3B4lC,EAAU,CAAClL,IAAK16B,EAAK+lC,OAAQ/lC,EAAK9e,KAAM8e,EAAK7e,MAAO6e,EAAKiE,KADhC,IAARjE,EAAa,QAAU,UAExC,MAAMwtB,EA9FV,SACID,EAA2ByY,EAAmBplC,EAC9CqlC,EAAkB3B,GACL,MAAX2B,IACFA,EAAUC,GAAkB3Y,EAASyY,EAAWplC,IAElD,MAAMulC,EAAY5Y,EAAQ,GACpB6Y,EAAY7Y,EAAQ,GAEpB8Y,EACFxpC,IAAOspC,EAAYH,EAAY,EAAIC,GAAWrlC,EAAS,EAAG0jC,GACxDgC,EACFzpC,IAAOupC,EAAYJ,EAAY,EAAIC,GAAWrlC,EAAS,EAAG0jC,GAE9D,MAAO,CAAC+B,EAAYC,EACtB,CA+EqBC,CACb,CAACtB,EAAUC,GAAUX,EAAcc,EAAcrlC,EAAKskC,GAC1DuB,EAAYrY,EAAS,GACrBsY,EAAWtY,EAAS,E,MACf,GAAY,SAARxtB,EAAgB,CACzB6lC,EAAYvlD,KAAKuD,KAAKohD,EAAWI,GACjCS,EAAWxlD,KAAKuD,KAAKqhD,EAAUI,GAC/B,MAAMkB,EACFlmD,KAAKQ,IAAI,GAAI+kD,EAAY,GAAKR,EAAed,EAAeU,GAC1DwB,EACFnmD,KAAKQ,IAAI,GAAIglD,EAAW,GAAKR,EAAcd,EAAcU,GACvDxK,EAAMp6C,KAAKkJ,MAAMg9C,EAAiB,GAClCT,EAASS,EAAiB9L,EAC1Bx5C,EAAOZ,KAAKkJ,MAAMi9C,EAAgB,GAExCb,EAAU,CAAClL,MAAKqL,SAAQ7kD,OAAMC,MADhBslD,EAAgBvlD,EACO+iB,KAAM,O,MACtC,GAAY,UAARjE,EACT4lC,EAAU,CAAClL,IAAK,EAAGqL,OAAQ,EAAG7kD,KAAM,EAAGC,MAAO,EAAG8iB,KAAM,SACvD4hC,EAAYvlD,KAAKuD,MAAMohD,EAAWV,EAAe,GAAKc,GACtDS,EAAWxlD,KAAKuD,MAAMqhD,EAAUV,EAAc,GAAKc,OAC9C,IAAmB,kBAARtlC,EAehB,MAAMjgB,MAAM,8BAADC,OAA+BggB,IAfR,CAClC,MAAM06B,EAAqB,iBAAfsJ,EAAgChkC,EAAI,GAAG,GAAKA,EAAI,GAAG,GACzD+lC,EAAwB,iBAAf/B,EAAgChkC,EAAI,GAAG,GAAKA,EAAI,GAAG,GAC5D9e,EAAsB,iBAAf8iD,EAAgChkC,EAAI,GAAG,GAAKA,EAAI,GAAG,GAC1D7e,EAAuB,iBAAf6iD,EAAgChkC,EAAI,GAAG,GAAKA,EAAI,GAAG,GAIjE4lC,EAAU,CAAClL,MAAKqL,SAAQ7kD,OAAMC,QAAO8iB,KAHZ,IAARy2B,GAAwB,IAAXqL,GAAyB,IAAT7kD,GAAwB,IAAVC,EACxD,QACA,YAEJ0kD,EAAYhpC,IACPooC,EAAWV,EAAe7J,EAAMqL,GAAUV,EAAe,EAC1Df,GACJwB,EAAWjpC,IACNqoC,EAAUV,EAActjD,EAAOC,GAASmkD,EAAc,EAAGhB,E,EAIhE,MAAO,CAACsB,UAASC,YAAWC,WAC9B,CAzRyCY,CACnC1mC,EAAKilC,EAAUC,EAASG,EAAcC,EAAaG,EACnDE,EAAsBrB,EAAcN,GAElC2C,EAAc5B,EAAYK,EAAiBD,EAAaC,EAE9D,IAAI5X,EAOJ,MANmB,kBAAfwW,EACFxW,EAAW,CAACwX,EAAW2B,EAAad,EAAWC,GACvB,iBAAf9B,IACTxW,EAAW,CAACwX,EAAWa,EAAWC,EAAUa,IAGvC,CACL3B,YACAhB,aACAiB,WACAC,UACAC,aACAU,YACAC,WACAa,cACAf,UACAP,eACAC,cACAf,eACAC,cACAiB,wBACAE,uBACAJ,iBACAC,gBACAjY,UACAC,WACAuW,cAEJ,CAwCM,SAAUe,GACZvX,EACAwW,EACA97C,EACAg8C,EAA4CjkC,GAGP,IAFrC+kC,EAASxiD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,IAAAA,UAAA,GACTyhD,EAAAzhD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAA6C,eAC7C+hD,EAAqC/hD,UAAAnC,OAAA,EAAAmC,UAAA,QAAAC,GAClCwiD,EAAW4B,EAAS3B,EAAUC,EAASC,GACxC,EAAE,GAAI,GAAI,GAAI,GAAI,GACtB,GAAmB,iBAAfnB,GACDgB,EAAW4B,EAAS3B,EAAUC,EAASC,GAAc5X,MACjD,IAAmB,kBAAfyW,EAGT,MAAM,IAAIjkD,MAAM,sBAADC,OAAuBgkD,KAFrCgB,EAAWG,EAAYyB,EAAS3B,EAAUC,GAAW3X,C,CAKxD,MAAOoX,EAAaJ,EAAcC,EAAY,CAAGY,GAC7CrB,GACG8C,EAAaxB,EAAcC,GAAeV,GAAiB38C,IAC3D6+C,EAAevB,EAAgBC,GAClCZ,GAAiBX,GAEf8C,EACFrB,GAAuBf,EAAamC,GAClCrB,EACFC,GAAuBnB,EAAcgB,GACnCI,EACFD,GAAuBlB,EAAagB,IAClC,QAACI,EAAO,SAAEoB,EAAQ,UAAEnB,EAAS,SAAEC,GAkLvC,SACI9lC,EAA4B4mC,EAAiB3B,EAC7CC,EAAiB2B,EAAqBxB,EACtCC,EAAqBX,EAAqBJ,EAC1CC,EAAqBF,GAMvB,IAAIsB,EACAoB,EACAnB,EACAC,EAEJ,GAAmB,kBAAR9lC,EAAkB,CAE3B4lC,EAAU,CACRlL,IAAK16B,EACL+lC,OAAQ/lC,EACR9e,KAAM8e,EACN7e,MAAO6e,EACPinC,MAAOjnC,EACPknC,KAAMlnC,EACNiE,KARuB,IAARjE,EAAa,QAAU,UAUxC,MAAMwtB,EA/IV,SACID,EAA2CyY,EAC3CW,EAAqB/lC,EAAgBqlC,EACrC3B,GACa,MAAX2B,IACFA,EAAUC,GAAkB3Y,EAASyY,EAAWplC,IAElD,MAAMumC,EAAa5Z,EAAQ,GACrB4Y,EAAY5Y,EAAQ,GACpB6Y,EAAY7Y,EAAQ,GAEpB6Z,EACFvqC,IAAOsqC,EAAanB,EAAY,EAAIC,GAAWrlC,EAAS,EAAG0jC,GACzD+B,EACFxpC,IAAOspC,EAAYH,EAAY,EAAIC,GAAWrlC,EAAS,EAAG0jC,GACxDgC,EACFzpC,IAAOupC,EAAYJ,EAAY,EAAIC,GAAWrlC,EAAS,EAAG0jC,GAE9D,MAAO,CAAC8C,EAAcf,EAAYC,EAAYK,EAChD,CA4HqBU,CACb,CAACT,EAAS3B,EAAUC,EAAS,GAAIP,EAAa,EAAGkC,EAAa7mC,EAC9DskC,GACJ0C,EAAWxZ,EAAS,GACpBqY,EAAYrY,EAAS,GACrBsY,EAAWtY,EAAS,E,MACf,GAAY,SAARxtB,EAAgB,CACzBgnC,EAAW1mD,KAAKuD,KAAK+iD,EAAUC,GAC/BhB,EAAYvlD,KAAKuD,KAAKohD,EAAWI,GACjCS,EAAWxlD,KAAKuD,KAAKqhD,EAAUI,GAC/B,MAAMgC,GAAiBN,EAAW,GAAKH,EAAclC,EAAciC,EAC7DJ,GACDX,EAAY,GAAKR,EAAed,EAAeU,EAC9CwB,GAAiBX,EAAW,GAAKR,EAAcd,EAAcU,EAC7D+B,EAAQ3mD,KAAKkJ,MAAM89C,EAAgB,GACnCJ,EAAOI,EAAgBL,EACvBvM,EAAMp6C,KAAKkJ,MAAMg9C,EAAiB,GAClCT,EAASS,EAAiB9L,EAC1Bx5C,EAAOZ,KAAKkJ,MAAMi9C,EAAgB,GAGxCb,EAAU,CAAClL,MAAKqL,SAAQ7kD,OAAMC,MAFhBslD,EAAgBvlD,EAEO+lD,QAAOC,OAAMjjC,KAAM,O,KACnD,IAAY,UAARjE,EAcT,MAAMjgB,MAAM,8BAADC,OAA+BggB,IAb1C4lC,EAAU,CACRlL,IAAK,EACLqL,OAAQ,EACR7kD,KAAM,EACNC,MAAO,EACP8lD,MAAO,EACPC,KAAM,EACNjjC,KAAM,SAER+iC,EAAW1mD,KAAKuD,MAAM+iD,EAAUjC,EAAc,GAAKkC,GACnDhB,EAAYvlD,KAAKuD,MAAMohD,EAAWV,EAAe,GAAKc,GACtDS,EAAWxlD,KAAKuD,MAAMqhD,EAAUV,EAAc,GAAKc,E,CAIrD,MAAO,CAACM,UAASoB,WAAUnB,YAAWC,WACxC,CAnPmDyB,CAC7CvnC,EAAK4mC,EAAS3B,EAAUC,EAAS2B,EAAaxB,EAAcC,EAC5DyB,EAAsBtB,EAAuBE,EAC7CrB,GAEEqC,EAAc5B,EAAYK,EAAiBD,EAAaC,EAE9D,IAAI5X,EAOJ,MANmB,kBAAfwW,EACFxW,EAAW,CAACwX,EAAW2B,EAAaK,EAAUnB,EAAWC,GACjC,iBAAf9B,IACTxW,EAAW,CAACwX,EAAWgC,EAAUnB,EAAWC,EAAUa,IAGjD,CACL3B,YACAhB,aACA4C,UACA3B,WACAC,UACAC,aACA6B,WACAnB,YACAC,WACAa,cACAf,UACAiB,cACAxB,eACAC,cACAX,cACAJ,eACAC,cACAuC,uBACAtB,wBACAE,uBACAmB,gBACAvB,iBACAC,gBACAjY,UACAC,WACAuW,cAEJ,CAwCM,SAAUmC,GACZlnC,EACAgnC,EAAmBplC,GACrB,MAAM4mC,EAAqB9B,GAAuBM,EADLzjD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,GAEhD,OAAOjC,KAAKkJ,OACPwV,EAAW,IAAM4B,EAAS,GAAKA,EAAS4mC,GAAsB,EACrE,CAEA,SAAS/C,GAAgBgD,GACvB,MAAqB,kBAAVA,EACF,CAACA,EAAOA,EAAOA,GAEH,IAAjBA,EAAMrnD,OACD,CAACqnD,EAAM,GAAIA,EAAM,GAAI,GAEvBA,CACT,CAEA,SAAS7C,GAAiB6C,GAExB,MAAwB,kBAAVA,EAAqB,CAACA,EAAOA,EAAOA,GAASA,CAC7D,CAaA,SAAS/B,GAAuBrB,EAAoBqD,GAClD,OAAIA,GAAY,EACPrD,EAGFA,GAAcA,EAAa,IAAMqD,EAAW,EACrD,CAiIA,SAAS7qC,GAAMxe,EAAeimD,GAC5B,IAAKA,EACH,OAAOhkD,KAAKg3C,MAAMj5C,GAEpB,OAAQimD,GACN,IAAK,QAEH,OAAOhkD,KAAKuc,MAAMxe,GACpB,IAAK,OAEH,OAAOiC,KAAKuD,KAAKxF,GACnB,IAAK,QACH,OAAOiC,KAAKkJ,MAAMnL,GACpB,QACE,MAAM,IAAI0B,MAAM,wBAADC,OAAyBskD,IAE9C,CAEM,SAAUqD,GAAkBF,GAChC,MAAOG,EAAMC,EAAMC,GAAQrD,GAAgBgD,GAC3C,OAAgB,IAATG,GAAuB,IAATC,GAAuB,IAATC,CACrC,CAEM,SAAUC,GACZ9/C,EAA0Bg8C,GAC5B,OAAO0D,GAAkB1/C,IAAY0/C,GAAkB1D,EACzD,CASM,SAAUE,GAAwBH,GAEtC,GAAmB,SAAfA,EACF,MAAO,eACF,GAAmB,SAAfA,EACT,MAAO,gBAEP,MAAM,IAAIjkD,MAAM,sBAADC,OAAuBgkD,GAE1C,CAiBM,SAAUgE,GACZC,EAAgBjoC,EAChBkoC,GACF,GAAuB,MAAnBA,EAAyB,CAC3B,GAAmB,kBAARloC,EACT,MAAMjgB,MACF,YAAAC,OAAYioD,EAAM,2DAAAjoD,OACCkoD,EAAe,iBAAAloD,OAAgBggB,EAAG,MACpD,GAAmB,kBAARA,EAChBlC,EACEA,GAAWkC,GACT,IAAM,YAAAhgB,OAAYioD,EAAM,2DAAAjoD,OACDkoD,EAAe,iBAAAloD,OAAgBggB,EAAG,UACxD,IAAmB,kBAARA,EAShB,MAAMjgB,MAAM,YAADC,OAAaioD,EAAM,iCAAAjoD,OAAgCggB,IAR7DA,EAAwB3Y,QAAQytB,IAAMA,EAAEztB,QAAQ6T,IAC/C4C,EACEA,GAAW5C,GACT,IAAM,YAAAlb,OAAYioD,EAAM,2DAAAjoD,OACDkoD,EAAe,iBAAAloD,OAAgBkb,EAAC,S,EAOnE,CCpkBO,MAAMitC,GAAUh1B,GAAG,CAACi1B,SAT3B,SACIvnD,EAAsBtB,GACxB,MAEMme,EAAwB,CAAC7c,EAFpB2xB,GAAgB3xB,EAAG,IAAK,UAAW,sBAGxCipB,EAAsB,CAACvqB,SAC7B,OAAOiqB,GAAOC,UACVxU,GAASyI,EAAgCoM,EAC/C,IC+BO,MAAMu+B,GAAUl1B,GAAG,CAACm1B,SAzC3B,SACIznD,EAAiBwjD,EACjBp8C,EACA+X,EACAkoC,GACF,MAAMrlB,EAAKrQ,GAAgB3xB,EAAG,IAAK,UAAW,WAG9Cid,EACIyqC,GAAyCtgD,EAH3B,GAId,IAAM,4DAA2D,eAAAjI,OAC9CiI,EAAO,oBAAAjI,OALZ,EAKwC,MAE1D,IAAIwoD,EAAM3lB,EACN4lB,GAAe,EACH,IAAZ5lB,EAAGr9B,OACLijD,GAAe,EACfD,EAAML,GAAQtlB,EAAI,CAAC,EAAGA,EAAGtjC,MAAM,GAAIsjC,EAAGtjC,MAAM,GAAIsjC,EAAGtjC,MAAM,MAG3Due,EACiB,IAAb0qC,EAAIhjD,KACJ,IAAM,mDAANxF,OAAyDwoD,EAAIhjD,KAAI,MACrE+iD,GAAoC,UAAWvoC,EAAKkoC,GACpD,MAAMxqC,EAAwB,CAAC7c,EAAG2nD,GAC5B1+B,EAAsB,CAACu6B,aAAYp8C,UAAS+X,MAAKkoC,mBAGvD,IAAI9+B,EAAMI,GAAOC,UACHnb,GAASoP,EACToM,GAId,OAFAV,EAAM5G,GAAK4G,EAAKyZ,EAAGrjC,OAEfipD,EACKN,GAAQ/+B,EAAK,CAACA,EAAI7pB,MAAM,GAAI6pB,EAAI7pB,MAAM,GAAI6pB,EAAI7pB,MAAM,KAGtD6pB,CACT,ICmBO,MAAMs/B,GAAYv1B,GAAG,CAACw1B,WA1C7B,SACI9nD,EAAiBwjD,EACjBp8C,EAA0C+X,EAC1CkoC,GACqC,IAArClE,EAAAzhD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAA8B,QAChC,MAAMsgC,EAAKrQ,GAAgB3xB,EAAG,IAAK,YAAa,WAEhD,IAAI+nD,EAAM/lB,EACNgmB,GAAe,EACH,IAAZhmB,EAAGr9B,OACLqjD,GAAe,EACfD,EAAMT,GAAQtlB,EAAI,CAAC,EAAGA,EAAGtjC,MAAM,GAAIsjC,EAAGtjC,MAAM,GAAIsjC,EAAGtjC,MAAM,GAAIsjC,EAAGtjC,MAAM,MAGxEue,EACiB,IAAb8qC,EAAIpjD,KACJ,IAAM,qDAANxF,OAA2D4oD,EAAIpjD,KAAI,MACvEsY,EACmB,UAAfkmC,EACA,IAAM,mFAAAhkD,OACuBgkD,IACjCgE,GAA0B,YAAahoC,EAAKkoC,GAC5C,MAAMxqC,EAA0B,CAAC7c,EAAG+nD,GAC9B9+B,EACe,CAACu6B,aAAYp8C,UAAS+X,MAAKkoC,kBAAiBlE,cAGjE,IAAI56B,EAAMI,GAAOC,UACHjb,GAAWkP,EACXoM,GAId,OAFAV,EAAM5G,GAAK4G,EAAKw/B,EAAIppD,OAEhBqpD,EACKV,GACI/+B,EAAK,CAACA,EAAI7pB,MAAM,GAAI6pB,EAAI7pB,MAAM,GAAI6pB,EAAI7pB,MAAM,GAAI6pB,EAAI7pB,MAAM,KAIhE6pB,CACT,ICbO,MAAMppB,GAASmzB,GAAG,CAAC21B,QA1B1B,SAAmCv9B,GAAsC,IAARhmB,EAAIhD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,EACtEP,EAAOupB,EAAQnrB,QAAU,EAAG,IAAM,sCAElC,MAAMsiD,EACF7vB,GAAqBtH,EAAS,UAAW,SAAU,qBAWvD,GAT0B,cAAtBm3B,EAAS,GAAGljD,OACdkjD,EAASr7C,QAAQgd,IACf,GAAqB,cAAjBA,EAAO7kB,MACT,MAAM,IAAIO,MAAM,4EAADC,OACAqkB,EAAO7kB,MAAK,SAKT,IAApBkjD,EAAStiD,OACX,OAAOmiB,GAAMmgC,EAAS,IAGxB,MAAMhlC,EAAuBglC,EACvBqG,EAAoB,CAACxjD,QAE3B,OAAOikB,GAAOC,UACVra,GAAQsO,EAAgCqrC,EAC9C,IC/CO,MAAMC,GAAU71B,GAAG,CAAC81B,SAP3B,SAAoCpoD,GAClC,MAEM6c,EAAwB,CAAC7c,EAFpB2xB,GAAgB3xB,EAAG,IAAK,UAAW,YAI9C,OAAO2oB,GAAOC,UAAUvT,GAASwH,EACnC,ICgCO,MAAMrY,GAAQ8tB,GAAG,CAAC+1B,OAfzB,SACIroD,EAAiBwxC,EAAwBnvC,GAC3C,MAAM2/B,EAAKrQ,GAAgB3xB,EAAG,IAAK,QAAS,qBAE5C,GAAgB,IAAZgiC,EAAGr9B,KACL,MAAM,IAAIzF,MAAM,kCAGlB,MAAM2d,EAAsB,CAAC7c,EAAGgiC,GAC1B/Y,EAAoB,CAACuoB,QAAOnvC,QAElC,OAAOsmB,GAAOC,UACV3T,GAAO4H,EAAgCoM,EAC7C,IC7BO,MAAMvmB,GAAO4vB,GAAG,CAACg2B,MAPxB,SAAiCtoD,GAC/B,MAEM6c,EAAqB,CAAC7c,EAFjB2xB,GAAgB3xB,EAAG,IAAK,OAAQ,YAI3C,OAAO2oB,GAAOC,UAAUnS,GAAMoG,EAChC,ICmCO,MAAM0rC,GAAgBj2B,GAAG,CAACk2B,eAjCjC,SACIC,EAA+BC,EAC/BC,EAA+B5rD,EAC/B+K,EAAwBsT,GAC1B,MAAMwtC,EACFj3B,GAAgB82B,EAAY,aAAc,iBACxCI,EACFl3B,GAAgB+2B,EAAY,aAAc,iBACxCI,EAAYn3B,GAAgBg3B,EAAU,WAAY,iBAClDI,EAAQp3B,GAAgB50B,EAAM,OAAQ,iBACtCisD,EAAKr3B,GAAgB7pB,EAAG,IAAK,iBAC7BmhD,EAAKt3B,GAAgBvW,EAAG,IAAK,iBAE7B8tC,EAAW/pD,GAAO,CAAC4pD,EAAOE,GAAK,GAC/BE,EAAW9e,GAAO6e,EAAUL,GAC5BtgC,EAAgB5N,GAAIwuC,EAAUL,GAG9B3E,EAAY57B,EAAI7pB,MAAM,GACtB0qD,EAAY7gC,EAAI7pB,MAAM,GAAK,EAC3B+xC,EAA8B,CAAC0T,EAAWiF,GAC1C1oD,EAAI8D,GAAM+jB,EAAK,CAAC,EAAG,GAAIkoB,GACvBprC,EAAIb,GAAM+jB,EAAK,CAAC,EAAG6gC,GAAY3Y,GAC/BxyC,EAAIuG,GAAM+jB,EAAK,CAAC,EAAe,EAAZ6gC,GAAgB3Y,GACnC5hB,EAAIrqB,GAAM+jB,EAAK,CAAC,EAAe,EAAZ6gC,GAAgB3Y,GAEnC4Y,EACF1uC,GAAIL,GAAI6tC,GAAQznD,GAAIgC,GAAK2C,IACrBiV,GAAI0uC,EAAIb,GAAQxtC,GAAIiuC,EAAa3qD,MAEzC,MAAO,CAACorD,EADe/uC,GAAI5X,GAAK2mD,GAAOlB,GAAQt5B,IAEjD,IC6BO,MAAMy6B,GAAiBh3B,GAAG,CAACi3B,gBA9BlC,SACIvpD,EAAiBwpD,EAAsBC,GACzC,MAAMznB,EAAKrQ,GAAgB3xB,EAAG,IAAK,kBAC7B0pD,EAAOF,EAAW5hD,OAAO,CAAChH,EAAGC,IAAMD,EAAIC,GAE7Coc,EACI+kB,EAAGr9B,MAAQ,EAAI6kD,EAAWjqD,OAC1B,IAAM,iBAANJ,OAAuB6iC,EAAGr9B,KAAI,4CAAAxF,OAC1BqqD,EAAWjqD,SAEnB0d,EACIwsC,EAAMlqD,SAAWiqD,EAAWjqD,OAC5B,IAAM,mBAANJ,OACIsqD,EAAMlqD,OAAM,+CAAAJ,OACZqqD,EAAWjqD,SAEnB0d,EACI+kB,EAAGtjC,MAAM,GAAKgrD,IAAS,EACvB,IAAM,yBAAAvqD,OACI6iC,EAAGtjC,MAAM,GAAE,0EAAAS,OACaqqD,EAAW59C,KAAK,OAAM,SAAAzM,OAAQuqD,IAEpE,MAAM7sC,EAA+B,CAAC7c,EAAGgiC,GACnC/Y,EAA6B,CAACugC,aAAYC,SAEhD,OAAO9gC,GAAOC,UACV9a,GAAgB+O,EAChBoM,EACN,ICMO,MAAM0gC,GAAYr3B,GAAG,CAACs3B,WAtD7B,SACI5pD,EAAyB6pD,EACzBC,EACAxiD,EACAqtB,EACAo1B,GACqB,MAAnBA,IACFA,EAAkB,MAEpB,MAAM/nB,EAAKrQ,GAAgB3xB,EAAG,IAAK,aAC7BgqD,EAAQr4B,GAAgBk4B,EAAM,OAAQ,aACtCI,EAAYt4B,GAAgBm4B,EAAU,WAAY,aACxD,IAAII,EAIAC,EAHS,MAATx1B,IACFu1B,EAASv4B,GAAgBgD,EAAO,QAAS,cAG7B,MAAVrtB,IACF6iD,EAAUx4B,GAAgBrqB,EAAQ,SAAU,cAG9C2V,EACI+sC,EAAMrlD,OAASslD,EAAUtlD,KACzB,IAAM,gFAEVsY,EACe,MAAXktC,GAAmBH,EAAMrlD,OAASwlD,EAAQxlD,KAC1C,IAAM,8EAEVsY,EACc,MAAVitC,GAAkBF,EAAMrlD,OAASulD,EAAOvlD,KACxC,IAAM,6EAGV,MAEMkY,EAA+B,CACnC7c,ECzEE,SAAgCA,GACpC,IAAI2nD,EAWJ,OATEA,EADa,IAAX3nD,EAAE2E,MAAyB,IAAX3E,EAAE2E,KACd2iD,GAAQtnD,EAAG,CAAC,EAAG,EAAG,EAAGA,EAAEqC,OACT,IAAXrC,EAAE2E,KACL2iD,GAAQtnD,EAAG,CAAC,EAAG,EAAGA,EAAEtB,MAAM,GAAIsB,EAAEtB,MAAM,KACxB,IAAXsB,EAAE2E,KACL2iD,GAAQtnD,EAAG,CAAC,EAAGA,EAAEtB,MAAM,GAAIsB,EAAEtB,MAAM,GAAIsB,EAAEtB,MAAM,KAE/CsB,EAGD2nD,CACT,CDyDwByC,CAAMpoB,GAI1BrN,MAAOu1B,EACP5iD,OAAQ6iD,EACRN,KAAMG,EACNF,SAAUG,GAGNhhC,EAA6B,CAAC8gC,mBAG9BxhC,EAAMI,GAAOC,UACHlY,GAAgBmM,EAChBoM,GAEhB,OAAOq+B,GAAQ/+B,EAAKyZ,EAAGtjC,MACzB,IE7BO,MAAM2rD,GAAc/3B,GAAG,CAACg4B,aA5C/B,SACItqD,EAAwB6pD,EACxBC,EACAxiD,EAAuCqtB,EACvCo1B,GACF,MAAM/nB,EAAKrQ,GAAgB3xB,EAAG,IAAK,aAC7BgqD,EAAQr4B,GAAgBk4B,EAAM,OAAQ,aACtCI,EAAYt4B,GAAgBm4B,EAAU,WAAY,aACxD,IAAII,EAIAC,EA6BJ,OAhCa,MAATx1B,IACFu1B,EAASv4B,GAAgBgD,EAAO,QAAS,cAG7B,MAAVrtB,IACF6iD,EAAUx4B,GAAgBrqB,EAAQ,SAAU,cAE9C2V,EACgB,IAAZ+kB,EAAGr9B,KACH,IAAM,0DAAAxF,OACC6iC,EAAGr9B,KAAI,MAClBsY,EACmB,IAAf+sC,EAAMrlD,MAA6B,IAAfqlD,EAAMrlD,KAC1B,IAAM,uEAAAxF,OACU6qD,EAAMrlD,KAAI,MAC9BsY,EACuB,IAAnBgtC,EAAUtlD,MAAiC,IAAnBslD,EAAUtlD,KAClC,IAAM,2EAAAxF,OACc8qD,EAAUtlD,KAAI,MACxB,MAAVulD,GACFjtC,EACoB,IAAhBitC,EAAOvlD,MAA8B,IAAhBulD,EAAOvlD,KAC5B,IAAM,wEAAAxF,OACc+qD,EAAOvlD,KAAI,MAEtB,MAAXwlD,GACFltC,EACqB,IAAjBktC,EAAQxlD,MAA+B,IAAjBwlD,EAAQxlD,KAC9B,IAAM,yEAAAxF,OACcgrD,EAAQxlD,KAAI,MAG/BglD,GAAU3nB,EAAIgoB,EAAOC,EAAWE,EAASD,EAAQH,EAC1D,ICEO,MAAMQ,GAAcj4B,GAAG,CAACk4B,aA5C/B,SACIxqD,EAAwB6pD,EACxBC,EACAxiD,EAAuCqtB,EACvCo1B,GACF,MAAM/nB,EAAKrQ,GAAgB3xB,EAAG,IAAK,aAC7BgqD,EAAQr4B,GAAgBk4B,EAAM,OAAQ,aACtCI,EAAYt4B,GAAgBm4B,EAAU,WAAY,aACxD,IAAII,EAIAC,EA6BJ,OAhCa,MAATx1B,IACFu1B,EAASv4B,GAAgBgD,EAAO,QAAS,cAG7B,MAAVrtB,IACF6iD,EAAUx4B,GAAgBrqB,EAAQ,SAAU,cAE9C2V,EACgB,IAAZ+kB,EAAGr9B,KACH,IAAM,0DAAAxF,OACC6iC,EAAGr9B,KAAI,MAClBsY,EACmB,IAAf+sC,EAAMrlD,MAA6B,IAAfqlD,EAAMrlD,KAC1B,IAAM,uEAAAxF,OACU6qD,EAAMrlD,KAAI,MAC9BsY,EACuB,IAAnBgtC,EAAUtlD,MAAiC,IAAnBslD,EAAUtlD,KAClC,IAAM,2EAAAxF,OACc8qD,EAAUtlD,KAAI,MACxB,MAAVulD,GACFjtC,EACoB,IAAhBitC,EAAOvlD,MAA8B,IAAhBulD,EAAOvlD,KAC5B,IAAM,wEAAAxF,OACc+qD,EAAOvlD,KAAI,MAEtB,MAAXwlD,GACFltC,EACqB,IAAjBktC,EAAQxlD,MAA+B,IAAjBwlD,EAAQxlD,KAC9B,IAAM,yEAAAxF,OACcgrD,EAAQxlD,KAAI,MAG/BglD,GAAU3nB,EAAIgoB,EAAOC,EAAWE,EAASD,EAAQH,EAC1D,ICCO,MAAMU,GAAcn4B,GAAG,CAACo4B,aA3C/B,SACI1qD,EAAwB6pD,EACxBC,EACAxiD,EAAuCqtB,EACvCo1B,GACF,MAAM/nB,EAAKrQ,GAAgB3xB,EAAG,IAAK,aAC7BgqD,EAAQr4B,GAAgBk4B,EAAM,OAAQ,aACtCI,EAAYt4B,GAAgBm4B,EAAU,WAAY,aACxD,IAAII,EAIAC,EA4BJ,OA/Ba,MAATx1B,IACFu1B,EAASv4B,GAAgBgD,EAAO,QAAS,cAG7B,MAAVrtB,IACF6iD,EAAUx4B,GAAgBrqB,EAAQ,SAAU,cAE9C2V,EACgB,IAAZ+kB,EAAGr9B,KACH,IAAM,0DAAAxF,OACC6iC,EAAGr9B,KAAI,MAClBsY,EACmB,IAAf+sC,EAAMrlD,MAA6B,IAAfqlD,EAAMrlD,KAC1B,IAAM,uEAAAxF,OACU6qD,EAAMrlD,KAAI,MAC9BsY,EACuB,IAAnBgtC,EAAUtlD,MAAiC,IAAnBslD,EAAUtlD,KAClC,IAAM,2EAAAxF,OACc8qD,EAAUtlD,KAAI,MACxB,MAAVulD,GACFjtC,EACoB,IAAhBitC,EAAOvlD,MAA8B,IAAhBulD,EAAOvlD,KAC5B,IAAM,wEAAAxF,OACc+qD,EAAOvlD,KAAI,MAEtB,MAAXwlD,GACFltC,EACqB,IAAjBktC,EAAQxlD,MAA+B,IAAjBwlD,EAAQxlD,KAC9B,IAAM,yEAAAxF,OACcgrD,EAAQxlD,KAAI,MAE/BglD,GAAU3nB,EAAIgoB,EAAOC,EAAWE,EAASD,EAAQH,EAC1D,ICRO,MAAMY,GAAWr4B,GAAG,CAACs4B,UAvB5B,SACI5qD,EAAiB+3B,EAAuB11B,GAC1C,MAAM2/B,EAAKrQ,GAAgB3xB,EAAG,IAAK,YAC7B6qD,EAAWl5B,GAAgBoG,EAAS,UAAW,YAErD9a,EACiB,UAAb+kB,EAAGrjC,MACH,IAAM,4DAAAQ,OAC8B6iC,EAAGrjC,QAC3Cse,EAAY5a,GAAQ,EAAG,IAAM,sCAANlD,OAA4CkD,EAAI,MACvE4a,EACI4tC,EAASxoD,OAAS2/B,EAAG3/B,MAA0B,IAAlBwoD,EAASxoD,KACtC,IAAM,mGAAAlD,OACgC6iC,EAAGtjC,MAAK,qBAAmB,GAAAS,OAC1D0rD,EAASnsD,MAAK,MAEzB,MAAMme,EAAyB,CAAC7c,EAAGgiC,EAAIjK,QAAS8yB,GAC1C5hC,EAAuB,CAAC5mB,QAE9B,OAAOsmB,GAAOC,UACV7a,GAAU8O,EAAgCoM,EAChD,ICLO,MAAM6hC,GAAgBx4B,GAAG,CAAEy4B,eArBlC,SACEC,EAAyBC,GACzB,MAAMC,EAAcv5B,GAAgBq5B,EAAI,KAAM,gBAAiB,SACzDG,EAAcx5B,GAAgBs5B,EAAI,KAAM,gBAAiB,SAE/D,GAAyB,IAArBC,EAAYvmD,KACd,MAAM,IAAIzF,MACR,2DAA0D,YAAAC,OAC9C+rD,EAAYvmD,OAG5B,GAAyB,IAArBwmD,EAAYxmD,KACd,MAAM,IAAIzF,MACR,4DAA2D,YAAAC,OAC/CgsD,EAAYxmD,OAG5B,MAAMkY,EAA8B,CAAEmuC,GAAIE,EAAaD,GAAIE,GAC3D,OAAOxiC,GAAOC,UAAU3a,GAAe4O,EACzC,IC6BO,MAAMuuC,GAAc94B,GAAG,CAAC+4B,aA7C/B,SACIrrD,EAAsBtB,GACxB,IAAIwf,EAAQyT,GAAgB3xB,EAAG,cAAe,KAC9C,MAAMw0C,EAASt2B,EAAMxf,MAErB,GAAIA,EAAMglB,KAAKjc,KAAOA,EAAI,IAAMA,EAAI,IAAM,GACxC,MAAM,IAAIvI,MAAM,2CAADC,OAA4CT,EAAK,OAGlE,GAAIA,EAAMa,OAAS2e,EAAMvZ,KACvB,MAAM,IAAIzF,MAAM,+BAADC,OAAgCT,EAAMa,OAAM,kBAAAJ,OACvD+e,EAAMvZ,KAAI,MAGhB,GAAIjG,EAAMa,OAAS2e,EAAMvZ,KAAM,CAC7B,MAAMJ,EAAW2Z,EAAMxf,MAAM8F,QAC7B,KAAOD,EAAShF,OAASb,EAAMa,QAC7BgF,EAASwoC,QAAQ,GAEnB7uB,EAAQopC,GAAQppC,EAAO3Z,E,CAGzB,MAAM4Z,EAAaD,EAAMxf,MACnB4sD,EAAiBtpD,MAAM4X,KAAKlb,GAClC,IAAK,IAAIgC,EAAIhC,EAAMa,OAAS,EAAGmB,GAAK,EAAGA,IACrC,GAAIyd,EAAWzd,KAAOhC,EAAMgC,GAC1B4qD,EAAK5qD,GAAK,OACL,GAAuB,IAAnBwd,EAAMxf,MAAMgC,GACrB,MAAM,IAAIxB,MAAM,mBAADC,OACQq1C,EAAM,8BAAAr1C,OAA6BT,EAAK,OAKnE,GAAoB,IAFP4sD,EAAK1mD,IAAI,CAACzB,EAAGzC,IAAMyC,EAAI,EAAIzC,GAAK,GAAGmrB,OAAOnrB,GAAKA,GAAK,GAExDnB,OACP,OAAOmiB,GAAMxD,GAIf,MAAMrB,EAAqB,CAAC7c,EAAGke,GACzB+K,EAAmB,CAACqiC,QAC1B,OAAO3iC,GAAOC,UACVlS,GAAMmG,EAAgCoM,EAC5C,IC1CO,MAAMjmB,GAAOsvB,GAAG,CAACi5B,MANxB,SAAiCvrD,GAC/B,MAEM6c,EAAqB,CAAC7c,EAFjB2xB,GAAgB3xB,EAAG,IAAK,OAAQ,YAG3C,OAAO2oB,GAAOC,UAAUza,GAAM0O,EAChC,ICkBO,MAAM2uC,GAAcl5B,GAAG,CAACm5B,aAnB/B,SACIzrD,EAAiB0rD,EAAsBC,GACzC,MAAM3pB,EAAKrQ,GAAgB3xB,EAAG,IAAK,eAMnC,GALAid,EACKyuC,GAAgBC,EACjB,IAAM,uBAAAxsD,OAAuBusD,EAAY,4CAAAvsD,OACPwsD,EAAY,OAE9CD,IAAiBC,EACnB,OAAOltC,GAAKujB,EAAGtjC,MAAOgtD,EAAc1pB,EAAGrjC,OAGzC,MAAMke,EAA4B,CAAC7c,EAAGgiC,GAChC/Y,EAA0B,CAACyiC,eAAcC,gBAE/C,OAAOhjC,GAAOC,UACVxa,GAAayO,EAAgCoM,EACnD,ICtBO,MAAM2iC,GAAWt5B,GAAG,CAACu5B,UAJ5B,SAAmBnhC,GACjB,OAAOvrB,GAAOurB,EAAS,EACzB,ICmBO,MAAMohC,GAAWx5B,GAAG,CAACy5B,UAL5B,SACIrhC,EAAqChmB,GACvC,OAAOvF,GAAOurB,EAAShmB,EACzB,ICMO,MAAMsnD,GAAW15B,GAAG,CAAC25B,UAL5B,SACIvhC,EAAqChmB,GACvC,OAAOvF,GAAOurB,EAAShmB,EACzB,ICrBO,MAAMwnD,GAAW55B,GAAG,CAAC65B,UAL5B,SACIzhC,EAAqChmB,GACvC,OAAOvF,GAAOurB,EAAShmB,EACzB,IC+EO,MAAM0nD,GAAS95B,GAAG,CAAC+5B,QAnD1B,SACIrsD,EAAiB6rB,EACjBzkB,EACA+X,GAGwC,IAFxCgkC,EAAAzhD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAA4B,OAC5B0hD,EAAA1hD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAqC,CAAC,EAAG,GACzC2lD,EAAwC3lD,UAAAnC,OAAA,EAAAmC,UAAA,QAAAC,EAC1C,MAAMqgC,EAAKrQ,GAAgB3xB,EAAG,IAAK,SAAU,WACvCssD,EAAU36B,GAAgB9F,EAAQ,SAAU,SAAU,WAE5D,IAAI87B,EAAM3lB,EACN4lB,GAAe,EAEH,IAAZ5lB,EAAGr9B,OACLijD,GAAe,EACfD,EAAML,GAAQtlB,EAAI,CAAC,EAAGA,EAAGtjC,MAAM,GAAIsjC,EAAGtjC,MAAM,GAAIsjC,EAAGtjC,MAAM,MAG3Due,EACiB,IAAb0qC,EAAIhjD,KACJ,IAAM,uDAANxF,OAA6DwoD,EAAIhjD,KAAI,MACzEsY,EACqB,IAAjBqvC,EAAQ3nD,KACR,IAAM,2DAAAxF,OACCmtD,EAAQ3nD,KAAI,MACvB+iD,GAAoC,SAAUvoC,EAAKkoC,GACnD,MAAMtB,EAAyB,SAAf5C,EAAwBwE,EAAIjpD,MAAM,GAAKipD,EAAIjpD,MAAM,GACjEue,EACI8oC,IAAYuG,EAAQ5tD,MAAM,GAC1B,IAAM,oCAAAS,OAAoC4mD,EAAO,2CAAA5mD,OACnBmtD,EAAQ5tD,MAAM,GAAE,MAClDue,EACIyqC,GAAyCtgD,EAASg8C,GAClD,IAAM,2DAA0D,eAAAjkD,OAC7CiI,EAAO,oBAAAjI,OAAmBikD,EAAS,MAE1D,MAAMvmC,EAAuB,CAAC7c,EAAG2nD,EAAK97B,OAAQygC,GACxCrjC,EACY,CAAC7hB,UAAS+X,MAAKgkC,aAAYC,YAAWiE,mBAGlD9+B,EAAMI,GAAOC,UACHpa,GAAQqO,EACRoM,GAEhB,OAAI2+B,EACKN,GAAQ/+B,EAAK,CAACA,EAAI7pB,MAAM,GAAI6pB,EAAI7pB,MAAM,GAAI6pB,EAAI7pB,MAAM,KAEtD6pB,CACT,ICDO,MAAMgkC,GAASj6B,GAAG,CAACk6B,QAvD1B,SACIxsD,EAAiB6rB,EAA6B9L,EAC9CZ,GAEwC,IADxCgkC,EAAAzhD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAA0B,MAAOmlD,EAAQnlD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,EAC5C2lD,EAAwC3lD,UAAAnC,OAAA,EAAAmC,UAAA,QAAAC,EAC1C,MAAMqgC,EAAKrQ,GAAgB3xB,EAAG,IAAK,UAC7BssD,EAAU36B,GAAgB9F,EAAQ,SAAU,UAElD,IAAI4gC,EAAMzqB,EACN0qB,GAAe,EACH,IAAZ1qB,EAAGr9B,OACL+nD,GAAe,EACfD,EAAMnF,GAAQtlB,EAAI,CAAC,EAAGA,EAAGtjC,MAAM,GAAIsjC,EAAGtjC,MAAM,MAG9Cue,EACiB,IAAbwvC,EAAI9nD,KACJ,IAAM,uDAANxF,OAA6DstD,EAAI9nD,KAAI,MACzEsY,EACqB,IAAjBqvC,EAAQ3nD,KACR,IAAM,2DAAAxF,OACCmtD,EAAQ3nD,KAAI,MACvB+iD,GAAoC,SAAUvoC,EAAKkoC,GACnDpqC,EACIwvC,EAAI/tD,MAAM,KAAO4tD,EAAQ5tD,MAAM,GAC/B,IAAM,oCAAAS,OAAoCstD,EAAI/tD,MAAM,GAAE,2CAAAS,OACxBmtD,EAAQ5tD,MAAM,GAAE,MAClDue,EACIyqC,GAAyC3nC,EAAQ8mC,GACjD,IAAM,yDAAwD,cAAA1nD,OAC5C4gB,EAAM,mBAAA5gB,OAAkB0nD,EAAQ,MACtD5pC,EACmB,QAAfkmC,EACA,IAAM,sCAANhkD,OACIgkD,EAAU,0CAElB,MAAMwJ,EAAWrF,GACbgF,EAAS,CAAC,EAAGA,EAAQ5tD,MAAM,GAAI4tD,EAAQ5tD,MAAM,GAAI4tD,EAAQ5tD,MAAM,KAC7DkuD,EAAUtF,GAAQmF,EAAK,CAACA,EAAI/tD,MAAM,GAAI,EAAG+tD,EAAI/tD,MAAM,GAAI+tD,EAAI/tD,MAAM,KAMjE6pB,EAAM6jC,GACPQ,EAAuBD,EANM,CAAC,EAAG5sC,GAMsBZ,EAHnC,OAFW,CAAC,EAAG0nC,GAMPQ,GAEjC,OACSC,GAAQ/+B,EADbmkC,EACkB,CAACnkC,EAAI7pB,MAAM,GAAI6pB,EAAI7pB,MAAM,IAG3B,CAAC6pB,EAAI7pB,MAAM,GAAI6pB,EAAI7pB,MAAM,GAAI6pB,EAAI7pB,MAAM,IAC7D,ICGO,MAAMmuD,GAAsBv6B,GAAG,CAACw6B,qBA3DvC,SACItY,EAAmEzrB,EACnE8C,EAAkBzkB,EAClB+X,GAEwC,IADxCgkC,EAAAzhD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAA4B,OAC5B2lD,EAAwC3lD,UAAAnC,OAAA,EAAAmC,UAAA,QAAAC,EAC1Csb,EACIu3B,EAAOj1C,SAAWwpB,EAAGpkB,KACrB,IAAM,yBAAAxF,OACEq1C,EAAOj1C,OAAM,sBAAAJ,OAAqB4pB,EAAGpkB,KAAI,iBAErD,IAAIooD,EAAWvY,EACXwY,EAAOjkC,EACP6+B,GAAe,EACH,IAAZ7+B,EAAGpkB,OACLijD,GAAe,EACfoF,EAAO1F,GAAQv+B,EAAI,CAAC,EAAGA,EAAGrqB,MAAM,GAAIqqB,EAAGrqB,MAAM,GAAIqqB,EAAGrqB,MAAM,KAC1DquD,EAAW,CAAC,EAAGvY,EAAO,GAAIA,EAAO,GAAIA,EAAO,KAG9Cv3B,EACwB,IAApB8vC,EAASxtD,OACT,IACI,wEAAAJ,OACG4tD,EAASxtD,OAAM,MAC1B0d,EACkB,IAAd+vC,EAAKroD,KACL,IAAM,+DAAAxF,OACM6tD,EAAKroD,OACrBsY,EACoB,IAAhB4O,EAAOlnB,KACP,IAAM,mEAAAxF,OACM0sB,EAAOlnB,OACvB,MAAMohD,EAAyB,SAAf5C,EAAwB4J,EAAS,GAAKA,EAAS,GACzD5G,EAA0B,SAAfhD,EAAwB6J,EAAKtuD,MAAM,GAAKsuD,EAAKtuD,MAAM,GACpEue,EACI8oC,IAAYl6B,EAAOntB,MAAM,GACzB,IAAM,4CAAAS,OAA4C4mD,EAAO,2CAAA5mD,OACrB0sB,EAAOntB,MAAM,GAAE,MACvDue,EACIkpC,IAAat6B,EAAOntB,MAAM,GAC1B,IAAM,6CAAAS,OAA6CgnD,EAAQ,4CAAAhnD,OACtB0sB,EAAOntB,MAAM,GAAE,MACxDgpD,GAAoC,iBAAkBvoC,EAAKkoC,GAC3D,MAAMxqC,EAAoC,CAACkM,GAAIikC,EAAMnhC,UAC/C5C,EACF,CAAC7hB,UAAS+X,MAAKgkC,aAAYkE,kBAAiBlpC,WAAY4uC,GAGtDxkC,EAAMI,GAAOC,UACHla,GAAqBmO,EACrBoM,GAEhB,OAAI2+B,EACKN,GAAQ/+B,EAAK,CAACA,EAAI7pB,MAAM,GAAI6pB,EAAI7pB,MAAM,GAAI6pB,EAAI7pB,MAAM,KAEtD6pB,CACT,ICnDO,MAAM0kC,GAAkB36B,GAAG,CAAC46B,iBAbnC,SACIltD,EAAiB6rB,EACjBshC,EACA/lD,EACA+X,EACAkoC,GACF,MAAMrlB,EAAKrQ,GAAgB3xB,EAAG,IAAK,mBAC7BssD,EAAU36B,GAAgB9F,EAAQ,SAAU,mBAElD,OAAOghC,GACHM,EAAanrB,EAAIsqB,EAASllD,EAAS+X,EAAK,OAAQkoC,EACtD,IC0DO,MAAM+F,GAAS96B,GAAG,CAAC+6B,QApD1B,SACIrtD,EAAiB6rB,EACjBzkB,EAA0C+X,GAEY,IADtDgkC,EAAAzhD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAA8B,QAC9B0hD,EAAA1hD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAA6C,CAAC,EAAG,EAAG,GACtD,MAAMsgC,EAAKrQ,GAAgB3xB,EAAG,IAAK,UAC7BssD,EAAU36B,GAAgB9F,EAAQ,SAAU,UAElD,IAAIk8B,EAAM/lB,EACNgmB,GAAe,EAEH,IAAZhmB,EAAGr9B,OACLqjD,GAAe,EACfD,EAAMT,GAAQtlB,EAAI,CAAC,EAAGA,EAAGtjC,MAAM,GAAIsjC,EAAGtjC,MAAM,GAAIsjC,EAAGtjC,MAAM,GAAIsjC,EAAGtjC,MAAM,MAExEue,EACiB,IAAb8qC,EAAIpjD,KACJ,IAAM,uDAANxF,OAA6D4oD,EAAIpjD,KAAI,MACzEsY,EACqB,IAAjBqvC,EAAQ3nD,KACR,IAAM,2DAAAxF,OACCmtD,EAAQ3nD,KAAI,MACvBsY,EACI8qC,EAAIrpD,MAAM,KAAO4tD,EAAQ5tD,MAAM,GAC/B,IAAM,oCAAAS,OAAoC4oD,EAAIrpD,MAAM,GAAE,2CAAAS,OACxBmtD,EAAQ5tD,MAAM,GAAE,MAClDue,EACIiqC,GAA+B9/C,EAASg8C,GACxC,IAAM,2DAA0D,eAAAjkD,OAC7CiI,EAAO,oBAAAjI,OAAmBikD,EAAS,MAC1DnmC,EACmB,UAAfkmC,EACA,IAAM,sCAANhkD,OACIgkD,EAAU,4CAElB,MAAMtmC,EAAuB,CAAC7c,EAAG+nD,EAAKl8B,OAAQygC,GAExCrjC,EAAqB,CAAC7hB,UAAS+X,MAAKgkC,aAAYC,aAGhD76B,EAAMI,GAAOC,UACHja,GAAQkO,EACRoM,GAEhB,OAAI++B,EACKV,GACI/+B,EAAK,CAACA,EAAI7pB,MAAM,GAAI6pB,EAAI7pB,MAAM,GAAI6pB,EAAI7pB,MAAM,GAAI6pB,EAAI7pB,MAAM,KAGhE6pB,CACT,ICLO,MAAM+kC,GAAsBh7B,GAAG,CAACi7B,qBA9DvC,SACI/Y,EAGAzrB,EAAO8C,EAAkBzkB,EACzB+X,GACFlC,EACIu3B,EAAOj1C,SAAWwpB,EAAGpkB,KACrB,IAAM,yBAAAxF,OACEq1C,EAAOj1C,OAAM,sBAAAJ,OAAqB4pB,EAAGpkB,KAAI,iBAErD,IAAI6oD,EAAWhZ,EACXiZ,EAAO1kC,EACPi/B,GAAe,EACH,IAAZj/B,EAAGpkB,OACLqjD,GAAe,EACfyF,EAAOnG,GAAQv+B,EAAI,CAAC,EAAGA,EAAGrqB,MAAM,GAAIqqB,EAAGrqB,MAAM,GAAIqqB,EAAGrqB,MAAM,GAAIqqB,EAAGrqB,MAAM,KACvE8uD,EAAW,CAAC,EAAGhZ,EAAO,GAAIA,EAAO,GAAIA,EAAO,GAAIA,EAAO,KAGzD,MAAMuR,EAAUyH,EAAS,GACnBrH,EAAWsH,EAAK/uD,MAAM,GAC5Bue,EACwB,IAApBuwC,EAASjuD,OACT,IACI,wEAAAJ,OACGquD,EAASjuD,OAAM,MAC1B0d,EACkB,IAAdwwC,EAAK9oD,KACL,IAAM,+DAAAxF,OACMsuD,EAAK9oD,OACrBsY,EACoB,IAAhB4O,EAAOlnB,KACP,IAAM,mEAAAxF,OACM0sB,EAAOlnB,OACvBsY,EACI8oC,IAAYl6B,EAAOntB,MAAM,GACzB,IAAM,4CAAAS,OAA4C4mD,EAAO,2CAAA5mD,OACrB0sB,EAAOntB,MAAM,GAAE,MACvDue,EACIkpC,IAAat6B,EAAOntB,MAAM,GAC1B,IAAM,6CAAAS,OAA6CgnD,EAAQ,4CAAAhnD,OACtB0sB,EAAOntB,MAAM,GAAE,MAExD,MAAMme,EAAsC,CAACkM,GAAI0kC,EAAM5hC,UAEjD5C,EAC2B,CAAC9J,MAAK/X,UAAS+W,WAAYqvC,GAGtDjlC,EAAMI,GAAOC,UACH/Z,GAAuBgO,EACvBoM,GAEhB,OAAI++B,EACKV,GACI/+B,EAAK,CAACA,EAAI7pB,MAAM,GAAI6pB,EAAI7pB,MAAM,GAAI6pB,EAAI7pB,MAAM,GAAI6pB,EAAI7pB,MAAM,KAGhE6pB,CACT,IClDO,MAAMmlC,GAAkBp7B,GAAG,CAACq7B,iBAZnC,SACI3tD,EAAiB6rB,EACjBshC,EAGA/lD,EAA0C+X,GAC5C,MAAM6iB,EAAKrQ,GAAgB3xB,EAAG,IAAK,mBAC7BssD,EAAU36B,GAAgB9F,EAAQ,SAAU,mBAElD,OAAOyhC,GAAoBH,EAAanrB,EAAIsqB,EAASllD,EAAS+X,EAChE,ICPO,MAAMyuC,GAAMt7B,GAAG,CAACu7B,KAPvB,SAAgC7tD,GAC9B,MAEM6c,EAAoB,CAAC7c,EAFhB2xB,GAAgB3xB,EAAG,IAAK,MAAO,YAI1C,OAAO2oB,GAAOC,UAAU9Z,GAAK+N,EAC/B,ICAO,MAAMixC,GAAOx7B,GAAG,CAACy7B,MANxB,SAAiC/tD,GAC/B,MACM6c,EAAqB,CAAC7c,EADjB2xB,GAAgB3xB,EAAG,IAAK,OAAQ,YAG3C,OAAO2oB,GAAOC,UAAU7Z,GAAM8N,EAChC,ICyBO,MAAMmxC,GAAU17B,GAAG,CAAE27B,SAlB5B,SACEjuD,GAGe,IAFf0E,EAAIhD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,EACPwsD,EAASxsD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,IAAAA,UAAA,GACToqC,EAAOpqC,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,IAAAA,UAAA,GAEP,MAEMmb,EAAwB,CAAE7c,EAFrB2xB,GAAgB3xB,EAAG,IAAK,YAG7BipB,EAAsB,CAAEvkB,OAAMwpD,YAAWpiB,WAE/C,OAAOnjB,GAAOC,UACZ5Z,GACA6N,EACAoM,EAEJ,ICLO,MAAMklC,GAAS77B,GAAG,CAAC87B,QAX1B,SACIpuD,GAAkE,IAA5C0E,EAAIhD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,EAAGwsD,EAASxsD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,IAAAA,UAAA,GAAUoqC,EAAOpqC,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,IAAAA,UAAA,GAC5D,MAEMmb,EAAuB,CAAC7c,EAFnB2xB,GAAgB3xB,EAAG,IAAK,WAG7BipB,EAAqB,CAACvkB,OAAMwpD,YAAWpiB,WAE7C,OAAOnjB,GAAOC,UACV3Z,GAAQ4N,EAAgCoM,EAC9C,ICkBO,MAAMolC,GAAgB/7B,GAAG,CAACg8B,eA9BjC,SACItuD,EAAiB+3B,EAAuB11B,GACpB,IAApBksD,EAAY7sD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,IAAAA,UAAA,GACd,MAAMsgC,EAAKrQ,GAAgB3xB,EAAG,IAAK,iBAC7B6qD,EAAWl5B,GAAgBoG,EAAS,UAAW,iBAErD9a,EACiB,UAAb+kB,EAAGrjC,MACH,IAAM,iEAAAQ,OAC8B6iC,EAAGrjC,QAC3Cse,EACI+kB,EAAGr9B,MAAQ,EACX,IAAM,yEAAAxF,OACM6iC,EAAGr9B,KAAI,MACvBsY,EAAY5a,GAAQ,EAAG,IAAM,sCAANlD,OAA4CkD,EAAI,MACvE4a,EACI4tC,EAASxoD,OAAS2/B,EAAG3/B,MAA0B,IAAlBwoD,EAASxoD,KACtC,IACI,kGAAAlD,OAC8B6iC,EAAGtjC,MAAK,qBAAmB,GAAAS,OACtD0rD,EAASnsD,MAAK,MAEzB,MAAMme,EAA8B,CAAC7c,EAAGgiC,EAAIjK,QAAS8yB,GAC/C5hC,EAA4B,CAAC5mB,OAAMksD,gBAEzC,OAAO5lC,GAAOC,UACVzZ,GAAe0N,EACfoM,EACN,IC6BO,MAAMulC,GAAel8B,GAAG,CAACm8B,cAvChC,SACIzuD,EAA0B0uD,GACQ,IAAlCvL,EAAAzhD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAA4B,OAC9B,MAAMsgC,EAAKrQ,GAAgB3xB,EAAG,IAAK,eAAgB,WAE7C2uD,EAA8B,SAAfxL,EAAyBnhB,EAAGtjC,MAAM,GAAKsjC,EAAGtjC,MAAM,GAC/DkwD,EAA6B,SAAfzL,EAAyBnhB,EAAGtjC,MAAM,GAAKsjC,EAAGtjC,MAAM,GAC9D4nD,EAA6B,SAAfnD,EAAyBnhB,EAAGtjC,MAAM,GAAKsjC,EAAGtjC,MAAM,GAEpEue,EACIyxC,EAAY,EACZ,IAAM,sDAANvvD,OAA4DuvD,IAEhEzxC,EACI0xC,EAAcD,GAAa,EAC3B,IAAM,oEAANvvD,OACAwvD,EAAW,SAAAxvD,OAAQuvD,EAAS,6CAAAvvD,OAC5B6iC,EAAGtjC,QAEPue,EACI2xC,EAAaF,GAAa,EAC1B,IAAM,oEAANvvD,OACAyvD,EAAU,SAAAzvD,OAAQuvD,EAAS,gDAAAvvD,OACvB6iC,EAAGtjC,QAEXue,EACKqpC,GAAcoI,EAAYA,KAAe,EAC1C,IAAM,8CAANvvD,OACIuvD,EAAYA,EAAS,YAAAvvD,OACrBmnD,EAAU,uCAAAnnD,OAAsC6iC,EAAGtjC,QAE3D,MAAMme,EAA6B,CAAC7c,EAAGgiC,GACjC/Y,EAA2B,CAACylC,YAAWvL,cAE7C,OAAOx6B,GAAOC,UACVxZ,GAAcyN,EACdoM,EACN,ICmBO,MAAM4lC,GAAkBv8B,GAAG,CAACw8B,iBA/CnC,SACI9uD,EAAiB6rB,EACjBzkB,EACA+X,GAGwC,IAFxCgkC,EAAAzhD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAA4B,OAC5B0hD,EAAA1hD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAqC,CAAC,EAAG,GACzC2lD,EAAwC3lD,UAAAnC,OAAA,EAAAmC,UAAA,QAAAC,EAC1C,MAAMqgC,EAAKrQ,GAAgB3xB,EAAG,IAAK,kBAAmB,WAChDssD,EACF36B,GAAgB9F,EAAQ,SAAU,kBAAmB,WAEzD,IAAI87B,EAAM3lB,EACN4lB,GAAe,EACH,IAAZ5lB,EAAGr9B,OACLijD,GAAe,EACfD,EAAML,GAAQtlB,EAAI,CAAC,EAAGA,EAAGtjC,MAAM,GAAIsjC,EAAGtjC,MAAM,GAAIsjC,EAAGtjC,MAAM,MAE3Due,EACiB,IAAb0qC,EAAIhjD,KACJ,IAAM,mEAAAxF,OACMwoD,EAAIhjD,KAAI,MACxBsY,EACqB,IAAjBqvC,EAAQ3nD,KACR,IAAM,oEAAAxF,OACCmtD,EAAQ3nD,KAAI,MACvB,MAAM2/C,EAA4B,SAAfnB,EAAwBwE,EAAIjpD,MAAM,GAAKipD,EAAIjpD,MAAM,GACpEue,EACIqnC,IAAegI,EAAQ5tD,MAAM,GAC7B,IAAM,0DAAAS,OACEmlD,EAAU,6CAA2C,UAAAnlD,OAC/CmtD,EAAQ5tD,MAAM,GAAE,MAClCgpD,GAAoC,kBAAmBvoC,EAAKkoC,GAC5D,MAAMxqC,EAAsC,CAAC7c,EAAG2nD,EAAK97B,OAAQygC,GACvDrjC,EACF,CAAC7hB,UAAS+X,MAAKgkC,aAAYC,YAAWiE,mBAGpC9+B,EAAMI,GAAOC,UACHvZ,GAAuBwN,EACvBoM,GAEhB,OAAI2+B,EACKN,GAAQ/+B,EAAK,CAACA,EAAI7pB,MAAM,GAAI6pB,EAAI7pB,MAAM,GAAI6pB,EAAI7pB,MAAM,KAEtD6pB,CACT,IC/DO,MAAMwmC,GAAOz8B,GAAG,CAAC08B,MARxB,SAAehvD,GACb,MAEM6c,EAAqB,CAAC7c,EAFjB2xB,GAAgB3xB,EAAG,IAAK,SAInC,OAAO2oB,GAAOC,UAAUpZ,GAAMqN,EAChC,ICkDO,MAAMoyC,GAAa38B,GAAG,CAAC48B,YA5C9B,SACIlvD,EAAiB6rB,EACjBzkB,EAAkC+X,GAEP,IAD3BikC,EAAA1hD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAqC,CAAC,EAAG,GACzCyhD,EAAAzhD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAqB,OACvB,MAAMsgC,EAAKrQ,GAAgB3xB,EAAG,IAAK,cAC7BssD,EAAU36B,GAAgB9F,EAAQ,SAAU,cAElD5O,EACgB,IAAZ+kB,EAAGr9B,MAA0B,IAAZq9B,EAAGr9B,KACpB,IAAM,mEAAAxF,OACC6iC,EAAGr9B,KAAI,MAClBsY,EACqB,IAAjBqvC,EAAQ3nD,KACR,IAAM,+DAAAxF,OACCmtD,EAAQ3nD,KAAI,MACvBsY,EACmB,SAAfkmC,EACA,IAAM,mFAAAhkD,OACuBgkD,IAEjC,IAAIwE,EAAM3lB,EACN4lB,GAAe,EAEH,IAAZ5lB,EAAGr9B,OACLgjD,EAAML,GAAQtlB,EAAI,CAAC,EAAGA,EAAGtjC,MAAM,GAAIsjC,EAAGtjC,MAAM,GAAIsjC,EAAGtjC,MAAM,KACzDkpD,GAAe,GAGjB,MAAM/qC,EAA2B,CAAC7c,EAAG2nD,EAAK97B,OAAQygC,GAC5CrjC,EAAyB,CAAC7hB,UAAS+X,MAAKikC,aAGxC76B,EAAMI,GAAOC,UACHnZ,GAAYoN,EACZoM,GAEhB,OAAI2+B,EACKN,GAAQ/+B,EAAK,CAACA,EAAI7pB,MAAM,GAAI6pB,EAAI7pB,MAAM,GAAI6pB,EAAI7pB,MAAM,KAGtD6pB,CACT,IC/CO,MAAM4mC,GAAQ78B,GAAG,CAAC88B,OAbzB,SACIxuD,EAAsBC,GACxB,IAAI4pC,EAAK9Y,GAAgB/wB,EAAG,IAAK,QAAS,qBACtC8pC,EAAK/Y,GAAgB9wB,EAAG,IAAK,QAAS,sBACzC4pC,EAAIC,GAAMrnB,GAAeonB,EAAIC,GAE9B0C,GAA2B3C,EAAG/rC,MAAOgsC,EAAGhsC,OAExC,MAAMme,EAAsB,CAACjc,EAAG6pC,EAAI5pC,EAAG6pC,GAEvC,OAAO/hB,GAAOC,UAAU3Y,GAAO4M,EACjC,ICoBO,MAAMwyC,GAAQ/8B,GAAG,CAACg9B,OAtBzB,SACIC,EAA8B3uD,EAAiBC,GACjD,MAAM4pC,EAAK9Y,GAAgB/wB,EAAG,IAAK,SAC7B8pC,EAAK/Y,GAAgB9wB,EAAG,IAAK,SAC7B2uD,EAAa79B,GAAgB49B,EAAW,YAAa,QAAS,QAI9DE,EAAiBriB,GACnBA,GAA2BoiB,EAAW9wD,MAAO+rC,EAAG/rC,OAAQgsC,EAAGhsC,OAKzDme,EAAuB,CAC3B0yC,UAL4BnE,GAAYoE,EAAYC,GAMpDlkD,EALoB6/C,GAAY3gB,EAAIglB,GAMpCv0C,EALoBkwC,GAAY1gB,EAAI+kB,IAOtC,OAAO9mC,GAAOC,UAAU7T,GAAQ8H,EAClC,ICAO,MAAM6yC,GAAWp9B,GAAG,CAACq9B,UAb5B,SACI/uD,EAAsBC,GAExB,IAAI4pC,EAAK9Y,GAAgB/wB,EAAG,IAAK,OAC7B8pC,EAAK/Y,GAAgB9wB,EAAG,IAAK,QAChC4pC,EAAIC,GAAMrnB,GAAeonB,EAAIC,GAE9B,MAAMklB,EAAYtV,GAAI7P,EAAIC,GACpBmlB,EAAQjV,GAAUgV,GAClBE,EAAcX,GAAMzkB,EAAImlB,GAC9B,OAAOR,GAAMS,EAAaD,EAAOD,EACnC,ICYO,MAAMG,GAAMz9B,GAAG,CAAC09B,KAtCvB,SAAcC,EAAuBC,GACnC,MAAMC,EAAMx+B,GAAgBs+B,EAAI,KAAM,OAChCG,EAAMz+B,GAAgBu+B,EAAI,KAAM,OAEtCjzC,GACkB,IAAbkzC,EAAIxrD,MAA2B,IAAbwrD,EAAIxrD,QAA6B,IAAbyrD,EAAIzrD,MAA2B,IAAbyrD,EAAIzrD,MAC7D,IAAM,kEAAAxF,OACCgxD,EAAIxrD,KAAI,SAAAxF,OAAQixD,EAAIzrD,KAAI,MAEnC,MAAM0rD,EAAwB,IAAbF,EAAIxrD,KAAawrD,EAAI9tD,KAAO8tD,EAAIzxD,MAAM,GACjD4xD,EAAwB,IAAbF,EAAIzrD,KAAayrD,EAAI/tD,KAAO+tD,EAAI1xD,MAAM,GAOvD,GALAue,EACIozC,IAAYC,EACZ,IAAM,mEAAAnxD,OACCkxD,EAAO,SAAAlxD,OAAQmxD,EAAO,MAEhB,IAAbH,EAAIxrD,MAA2B,IAAbyrD,EAAIzrD,KAAY,CACpC,MAAM4rD,EAAOjJ,GAAQ6I,EAAK,CAAC,GAAI,IACzBK,EAAOlJ,GAAQ8I,EAAK,EAAE,EAAG,IACzBK,EAAOpmB,GAAOkmB,EAAMC,GAC1B,OAAOlJ,GAAQmJ,EAAM,G,CAChB,GAAiB,IAAbN,EAAIxrD,MAA2B,IAAbyrD,EAAIzrD,KAAY,CAC3C,MAAM4rD,EAAOjJ,GAAQ6I,EAAK,CAAC,GAAI,IACzBK,EAAOlJ,GAAQ8I,EAAK,CAACA,EAAI1xD,MAAM,GAAI0xD,EAAI1xD,MAAM,KAC7C+xD,EAAOpmB,GAAOkmB,EAAMC,GAC1B,OAAOlJ,GAAQmJ,EAAM,CAACA,EAAKpuD,M,CACtB,GAAiB,IAAb8tD,EAAIxrD,MAA2B,IAAbyrD,EAAIzrD,KAAY,CAC3C,MAAM6rD,EAAOlJ,GAAQ8I,EAAK,EAAE,EAAG,IACzBK,EAAOpmB,GAAO8lB,EAAKK,GACzB,OAAOlJ,GAAQmJ,EAAM,CAACA,EAAKpuD,M,CACtB,CACL,MAAMmuD,EAAOlJ,GAAQ8I,EAAK,CAACA,EAAI1xD,MAAM,GAAI0xD,EAAI1xD,MAAM,KAEnD,OADa2rC,GAAO8lB,EAAKK,E,CAG7B,IC+BO,MAAME,GAASp+B,GAAG,CAACq+B,QARpB,SAAkBC,GAAsC,QAAAtlD,EAAA5J,UAAAnC,OAAjBmrB,EAAiB,IAAA1oB,MAAAsJ,EAAA,EAAAA,EAAA,KAAAE,EAAA,EAAAA,EAAAF,EAAAE,IAAjBkf,EAAiBlf,EAAA,GAAA9J,UAAA8J,GAC5D,MAAMq2C,EACFn3B,EAAQ9lB,IAAI,CAAC2G,EAAG7K,IAAMixB,GAAgBpmB,EAAG,UAAFpM,OAAYuB,GAAK,WACtDuoB,EAAqB,CAAC2nC,YAC5B,OAAOjoC,GAAOC,UACV/Y,GAAQgyC,EAAkC54B,EAChD,IC9DO,MAAM4nC,GAAMv+B,GAAG,CAACw+B,KARvB,SAAgC9wD,GAC9B,MAEM6c,EAAoB,CAAC7c,EAFhB2xB,GAAgB3xB,EAAG,IAAK,MAAO,YAI1C,OAAO2oB,GAAOC,UAAU9Y,GAAK+M,EAC/B,ICUO,MAAMk0C,GAAMz+B,GAAG,CAAC0+B,KAbvB,SAAgChxD,GAC9B,IAAIgiC,EAAKrQ,GAAgB3xB,EAAG,IAAK,OACjCid,EACiB,UAAb+kB,EAAGrjC,OAAkC,YAAbqjC,EAAGrjC,MAC3B,IAAM,6CAEO,UAAbqjC,EAAGrjC,QACLqjC,EAAKrgB,GAAKqgB,EAAI,YAGhB,MAAMnlB,EAAoB,CAAC7c,EAAGgiC,GAC9B,OAAOrZ,GAAOC,UAAU5Y,GAAK6M,EAC/B,IC9BM,SAAUo0C,GAAqB9rD,EAAgBR,GACnD,IAAK,IAAIjE,EAAI,EAAGA,EAAIyE,EAAK5F,SAAUmB,EACjC,GAAIyE,EAAKA,EAAK5F,OAASmB,EAAI,KAAOiE,EAAO,EAAIjE,EAC3C,OAAO,EAGX,OAAO,CACT,CAEM,SAAUwwD,GACZC,EAAqBC,EAAqBjsD,GAC5C,MAAMR,EAAOwsD,EAAU5xD,OAAS6xD,EAAU7xD,OACpC+gB,EAAM,GACZ,IAAI+wC,EAAS,EACTC,EAAY,EACd,IAAK,IAAIxkB,EAAM,EAAGA,EAAMnoC,EAAMmoC,KACH,IAAvB3nC,EAAK2sB,QAAQgb,GACfxsB,EAAIne,KAAKgvD,EAAUE,MAEnB/wC,EAAIne,KAAKivD,EAAUE,MAGvB,OAAOhxC,CACT,CAEM,SAAUixC,GACZC,EAAkBrsD,GACpB,MAAMwnC,EAAW,GACXhoC,EAAO6sD,EAAOjyD,OACpB,IAAK,IAAIutC,EAAM,EAAGA,EAAMnoC,EAAMmoC,KACD,IAAvB3nC,EAAK2sB,QAAQgb,IACfH,EAASxqC,KAAKqvD,EAAO1kB,IAIzB,MAAO,CAACH,EADYxnC,EAAKP,IAAIkoC,GAAO0kB,EAAO1kB,IAE7C,CAEM,SAAU2kB,GACZ/yD,EAAiByG,GAEnB,OAAO+rD,GAAiBxyD,EADDyG,EAAKP,IAAI5E,GAAK,GACUmF,EACjD,CAEM,SAAUusD,GACZrwD,EAAa8D,EAAgBR,GAC/BsY,EACIg0C,GAAqB9rD,EAAMR,GAC3B,IAAM,GAAAxF,OAAGkC,EAAG,wDAAAlC,OACIgG,EAAI,cAAAhG,OAAawF,EAAI,WAC3C,CAOM,SAAUgtD,GAAmBxsD,EAAgBR,GAEjD,GAAIssD,GAAqB9rD,EAAMR,GAC7B,OAAO,KAET,MAAM3D,EAAmB,GACzB,IAAK,IAAIN,EAAI,EAAGA,EAAIiE,IAAQjE,GACD,IAArByE,EAAK2sB,QAAQpxB,IACfM,EAAOmB,KAAKzB,GAIhB,OADAyE,EAAKqB,QAAQ9B,GAAQ1D,EAAOmB,KAAKuC,IAC1B1D,CACT,CAGM,SAAU4wD,GAAuBzsD,GACrC,OAAOA,EAAKP,IAAI,CAACF,EAAMhE,IAAM,CAACA,EAAGgE,IAC5BU,KAAK,CAACxE,EAAGC,IAAMD,EAAE,GAAKC,EAAE,IACxB+D,IAAI5E,GAAKA,EAAE,GAClB,CAEM,SAAU6xD,GAAiBC,EAAiBntD,GAChD,MAAM4jB,EAAgB,GACtB,IAAK,IAAI7nB,EAAIiE,EAAOmtD,EAASpxD,EAAIiE,IAAQjE,EACvC6nB,EAAIpmB,KAAKzB,GAEX,OAAO6nB,CACT,CCzCO,MAAMtoB,GAAMqyB,GAAG,CAACy/B,KAXvB,SACI/xD,GAAoE,IAA9C0E,EAAAhD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAwB,KAAMsgD,EAAQtgD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,IAAAA,UAAA,GAC9D,MAEMmb,EAAoB,CAAC7c,EAFhB2xB,GAAgB3xB,EAAG,IAAK,QAG7BipB,EAAkB,CAAC+oC,iBAAkBttD,EAAMs9C,YAEjD,OAAOr5B,GAAOC,UACVzW,GAAK0K,EAAgCoM,EAC3C,ICGO,MAAMlpB,GAAMuyB,GAAG,CAAC2/B,KAbvB,SACIjyD,GAAoE,IAA9C0E,EAAAhD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAwB,KAAMsgD,EAAQtgD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,IAAAA,UAAA,GAC9D,MAEMmb,EAAoB,CAAC7c,EAFhB2xB,GAAgB3xB,EAAG,IAAK,QAG7BipB,EAAkB,CAACvkB,OAAMs9C,YAG/B,OAAOr5B,GAAOC,UACHjW,GAAKkK,EACLoM,EACb,ICKO,MAAMzoB,GAAM8xB,GAAG,CAAC4/B,KAdvB,SACIlyD,GAAoE,IAA9C0E,EAAAhD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAwB,KAAMsgD,EAAQtgD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,IAAAA,UAAA,GAC1DsgC,EAAKrQ,GAAgB3xB,EAAG,IAAK,OAChB,SAAbgiC,EAAGrjC,QACLqjC,EAAKrgB,GAAKqgB,EAAI,UAGhB,MAAMnlB,EAAoB,CAAC7c,EAAGgiC,GACxB/Y,EAAkB,CAACvkB,OAAMs9C,YAE/B,OAAOr5B,GAAOC,UACVpT,GAAKqH,EAAgCoM,EAC3C,ICiBA,SAASkpC,GACLnyD,EAAWi0B,GAA8C,IAA5BvvB,EAAAhD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAwB,KACvD,GAAe,IAAX1B,EAAE2E,KACJ,OAAOm0C,GAAI94C,GAIb,GAAe,IAAXA,EAAE2E,MAAuB,OAATD,EAClB,OAAOytD,GAAS7K,GAAQtnD,EAAG,EAAE,IAAKi0B,EAAGvvB,GAIvC,GAAe,IAAX1E,EAAE2E,MAA8B,kBAATD,GACvB1C,MAAMC,QAAQyC,IAAyB,IAAhBA,EAAKnF,OAAc,CAC5C,GAAU,IAAN00B,EACF,OAAOzzB,GAAIs4C,GAAI94C,GAAI0E,GAErB,GAAIuvB,IAAMtxB,IACR,OAAO1C,GAAI64C,GAAI94C,GAAI0E,GAErB,GAAIuvB,KAAOtxB,IACT,OAAO5C,GAAI+4C,GAAI94C,GAAI0E,GAErB,GAAU,cAANuvB,GAA2B,IAANA,EAEvB,OAAOhxB,GAAKzC,GAAIi9C,GAAI3E,GAAI94C,GAAI07C,GAAO,EAAG,UAAWh3C,IAGnD,MAAM,IAAIxF,MAAM,qCAADC,OAAsC80B,G,CAIvD,GAAIjyB,MAAMC,QAAQyC,IAAyB,IAAhBA,EAAKnF,OAAc,CAC5C,GAAU,IAAN00B,EACF,OAAOh0B,GAAIO,GAAIs4C,GAAI94C,GAAI0E,EAAK,IAAKA,EAAK,GAAK,GAE7C,GAAIuvB,IAAMtxB,IACR,OAAO1C,GAAIO,GAAIs4C,GAAI94C,GAAI0E,EAAK,IAAKA,EAAK,IAExC,GAAIuvB,KAAOtxB,IACT,OAAO5C,GAAIS,GAAIs4C,GAAI94C,GAAI0E,EAAK,IAAKA,EAAK,IAExC,GAAU,QAANuvB,GAAqB,cAANA,EAEjB,OAAOhxB,GAAKzC,GAAIk6C,GAAO16C,GAAI0E,IAG7B,MAAM,IAAIxF,MAAM,qCAADC,OAAsC80B,G,CAGvD,MAAM,IAAI/0B,MAAM,gCAADC,OAAiCuF,GAClD,CAEO,MAAM0tD,GAAO9/B,GAAG,CAAC+/B,MAnExB,SACIryD,GAC8C,IADxBsyD,EAAA5wD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAgC,YACtDgD,EAAAhD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAwB,KAAMsgD,EAAQtgD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,IAAAA,UAAA,GAGxC,MAAM0wD,EAAOD,GAFbnyD,EAAI2xB,GAAgB3xB,EAAG,IAAK,QAEHsyD,EAAK5tD,GAC9B,IAAI6tD,EAAgBH,EAAK1zD,MACzB,GAAIsjD,EAAU,CACZ,MAAM78C,EAAOV,GAAeC,EAAM1E,EAAEtB,OACpC6zD,EAAgBC,GAA+BJ,EAAK1zD,MAAOyG,E,CAE7D,OAAOmiD,GAAQ8K,EAAMG,EACvB,IChCO,MAAME,GAAgBngC,GAAG,CAACogC,eANjC,SACI1yD,GAEF,OAAOoyD,GAAKpyD,EAAG,YAFS0B,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAwB,KACtCA,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,IAAAA,UAAA,GAEZ,ICNO,MAAMmB,GAAMyvB,GAAG,CAACqgC,KANvB,SAAgC3yD,GAC9B,MAEM6c,EAAoB,CAAC7c,EAFhB2xB,GAAgB3xB,EAAG,IAAK,QAGnC,OAAO2oB,GAAOC,UAAU1Y,GAAK2M,EAC/B,ICaO,MAAM+1C,GAAatgC,GAAG,CAACugC,YAZ9B,SAAuC7yD,GAA8B,IAAR0E,EAAIhD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,EAClE,MAAMsgC,EAAKrQ,GAAgB3xB,EAAG,IAAK,aAAc,qBAEjDid,EAAYvY,GAAQs9B,EAAGr9B,KAAM,IAAM,sCAEnC,MAAMkY,EAA2B,CAACqB,MAAO8jB,GACnC/Y,EAAyB,CAAC6jB,IAAKpoC,GAErC,OAAOikB,GAAOC,UACVzY,GAAY0M,EAAgCoM,EAClD,ICTO,MAAM6pC,GAAQxgC,GAAG,CAACygC,OANzB,SAAkC/yD,GAChC,MAEM6c,EAAsB,CAAC7c,EAFlB2xB,GAAgB3xB,EAAG,IAAK,UAGnC,OAAO2oB,GAAOC,UAAUxY,GAAOyM,EACjC,ICwBO,MAAMm2C,GAAO1gC,GAAG,CAAC2gC,MAfxB,SAAiCjzD,EAAiBsrD,GAChD,MAAMtpB,EAAKrQ,GAAgB3xB,EAAG,IAAK,OAAQ,qBAC3Cid,EACI+kB,EAAGr9B,OAAS2mD,EAAK/rD,OACjB,IAAM,qCAAAJ,OAAqC6iC,EAAGr9B,KAAI,kCAAAxF,OACjBmsD,EAAI,MAEzC,MAAMzuC,EAAqB,CAAC7c,EAAGgiC,GACzB/Y,EAAmB,CAACqiC,QAE1B,OAAO3iC,GAAOC,UACVlS,GAAMmG,EACNoM,EACN,ICeO,MAAMiqC,GAAM5gC,GAAG,CAAC6gC,KAzCvB,SACIC,EAAiBC,EACjBC,GAMgB,MAAdD,IACFA,EAAaD,GAEf,MAAMG,EAAOtyC,GAAO,CAACmyC,EAASC,GAJ5B3xD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAkB,WAKdyB,EAAIiwD,GAAWC,EAAaD,EAAUC,EAC5C,IAAK,IAAI3yD,EAAI,EAAGA,EAAIyC,IAAKzC,EACvB6yD,EAAKh2D,IAAI,EAAGmD,EAAGA,GAEjB,MAAMspB,EAAgBs9B,GAAQiM,EAAKhzC,WAAY,CAAC6yC,EAASC,IACzD,GAAkB,MAAdC,EACF,OAAOtpC,EAEP,GAA0B,IAAtBspC,EAAW/zD,OACb,OAAOyzD,GAAKJ,GAAW5oC,EAAK,GAAI,CAACspC,EAAW,GAAI,EAAG,IAC9C,GAA0B,IAAtBA,EAAW/zD,OAEpB,OAAOyzD,GACIJ,GAAWA,GAAW5oC,EAAK,GAAI,GAC/B,CAACspC,EAAW,GAAIA,EAAW,GAAI,EAAG,IACxC,GAA0B,IAAtBA,EAAW/zD,OAEpB,OAAOyzD,GAAKJ,GAAWA,GAAWA,GAAW5oC,EAAK,GAAI,GAAI,GAAI,CACrDspC,EAAW,GAAIA,EAAW,GAAIA,EAAW,GAAI,EAAG,IAGzD,MAAM,IAAIp0D,MACN,2CACA,6BAAAC,OAC8Bm0D,EAAmB/zD,OAAM,MAGjE,ICpCO,MAAMoJ,GAAQ2pB,GAAG,CAACkhC,OANzB,SAAkCxzD,GAChC,MAEM6c,EAAsB,CAAC7c,EAFlB2xB,GAAgB3xB,EAAG,IAAK,QAAS,YAG5C,OAAO2oB,GAAOC,UAAUpY,GAAOqM,EACjC,ICuBO,MAAM42C,GAASnhC,GAAG,CAACohC,QAZ1B,SACI1zD,EAAiBoxB,GAAmD,IAAvB1sB,EAAIhD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,EAAGiyD,EAASjyD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,EACrE,MAGMmb,EAAyB,CAAC7c,EAHrB2xB,GAAgB3xB,EAAG,IAAK,UAGIoxB,QAFtBO,GAAgBP,EAAS,UAAW,SAAU,UAGzDnI,EAAuB,CAACvkB,OAAMivD,aAEpC,OAAOhrC,GAAOC,UACVjY,GAAUkM,EAAgCoM,EAChD,ICRO,MAAM2qC,GAAUthC,GAAG,CAACuhC,SAb3B,SACIjzD,EAAsBC,GACxB,IAAI4pC,EAAK9Y,GAAgB/wB,EAAG,IAAK,UAAW,qBACxC8pC,EAAK/Y,GAAgB9wB,EAAG,IAAK,UAAW,sBAC3C4pC,EAAIC,GAAMrnB,GAAeonB,EAAIC,GAE9B0C,GAA2B3C,EAAG/rC,MAAOgsC,EAAGhsC,OAExC,MAAMme,EAAwB,CAACjc,EAAG6pC,EAAI5pC,EAAG6pC,GAEzC,OAAO/hB,GAAOC,UAAU/X,GAASgM,EACnC,ICEO,MAAMi3C,GAAexhC,GAAG,CAACyhC,cAbhC,SACInzD,EAAsBC,GACxB,IAAI4pC,EAAK9Y,GAAgB/wB,EAAG,IAAK,eAAgB,qBAC7C8pC,EAAK/Y,GAAgB9wB,EAAG,IAAK,eAAgB,sBAChD4pC,EAAIC,GAAMrnB,GAAeonB,EAAIC,GAE9B0C,GAA2B3C,EAAG/rC,MAAOgsC,EAAGhsC,OAExC,MAAMme,EAA6B,CAACjc,EAAG6pC,EAAI5pC,EAAG6pC,GAE9C,OAAO/hB,GAAOC,UAAU9X,GAAc+L,EACxC,ICRO,MAAM9W,GAAWusB,GAAG,CAAC0hC,UAP5B,SAAqCh0D,GACnC,MAEM6c,EAAyB,CAAC7c,EAFrB2xB,GAAgB3xB,EAAG,IAAK,aAInC,OAAO2oB,GAAOC,UAAU1X,GAAU2L,EACpC,ICCO,MAAMo3C,GAAQ3hC,GAAG,CAAC4hC,OAPzB,SAAkCl0D,GAChC,MAEM6c,EAAsB,CAAC7c,EAFlB2xB,GAAgB3xB,EAAG,IAAK,UAInC,OAAO2oB,GAAOC,UAAUzX,GAAO0L,EACjC,ICAO,MAAM/W,GAAQwsB,GAAG,CAAC6hC,OANzB,SAAkCn0D,GAChC,MACM6c,EAAsB,CAAC7c,EADlB2xB,GAAgB3xB,EAAG,IAAK,UAGnC,OAAO2oB,GAAOC,UAAUxX,GAAOyL,EACjC,ICWO,MAAMu3C,GAAY9hC,GAAG,CAAC+hC,WAV7B,SAAsCr0D,GAA4B,IAAXs0D,EAAK5yD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,GAC7D,MAEMmb,EAA0B,CAAC7c,EAFtB2xB,GAAgB3xB,EAAG,IAAK,cAG7BipB,EAAwB,CAACqrC,SAE/B,OAAO3rC,GAAOC,UACVvX,GAAWwL,EAAgCoM,EACjD,ICEO,MAAMsrC,GAAOjiC,GAAG,CAACkiC,MAbxB,SACI5zD,EAAsBC,GACxB,IAAI4pC,EAAK9Y,GAAgB/wB,EAAG,IAAK,OAAQ,qBACrC8pC,EAAK/Y,GAAgB9wB,EAAG,IAAK,OAAQ,sBACxC4pC,EAAIC,GAAMrnB,GAAeonB,EAAIC,GAE9B0C,GAA2B3C,EAAG/rC,MAAOgsC,EAAGhsC,OAExC,MAAMme,EAAqB,CAACjc,EAAG6pC,EAAI5pC,EAAG6pC,GAEtC,OAAO/hB,GAAOC,UAAUtX,GAAMuL,EAChC,ICGO,MAAM43C,GAAYniC,GAAG,CAACoiC,WAb7B,SACI9zD,EAAsBC,GACxB,IAAI4pC,EAAK9Y,GAAgB/wB,EAAG,IAAK,YAAa,qBAC1C8pC,EAAK/Y,GAAgB9wB,EAAG,IAAK,YAAa,sBAC7C4pC,EAAIC,GAAMrnB,GAAeonB,EAAIC,GAE9B0C,GAA2B3C,EAAG/rC,MAAOgsC,EAAGhsC,OAExC,MAAMme,EAA0B,CAACjc,EAAG6pC,EAAI5pC,EAAG6pC,GAE3C,OAAO/hB,GAAOC,UAAUrX,GAAWsL,EACrC,ICnBM,SAAU83C,GAASztD,EAAe4sC,EAAcjuC,GACpD,GAAIA,GAAO,EACT,MAAM,IAAI3G,MAAM,4CAGlB,MAAM+pB,EAAuB,CAAC/hB,QAAO4sC,OAAMjuC,OAC3C,OAAO8iB,GAAOC,UAAUpX,GAAU,CAAC,EAAGyX,EACxC,CCsCO,MAAM2rC,GAA6BtiC,GAAG,CAACuiC,4BAnC9C,SACI70D,GAAiE,IAAhD80D,EAAWpzD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,EAAGqzD,EAAIrzD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,EAAG4yD,EAAK5yD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,EAAGszD,EAAItzD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,GAChE,MAAMsgC,EAAKrQ,GAAgB3xB,EAAG,IAAK,8BACnCid,EACgB,IAAZ+kB,EAAGr9B,MAA0B,IAAZq9B,EAAGr9B,KACpB,IAAM,2FAANxF,OACgB6iC,EAAGr9B,KAAI,MAC3BsY,EACIA,GAAW63C,GACX,IAAM,8FAAA31D,OAC6B21D,EAAW,MAElD,IAAInN,EAAM3lB,EACN4lB,GAAe,EACH,IAAZ5lB,EAAGr9B,OACLijD,GAAe,EACfD,EAAML,GAAQtlB,EAAI,CAAC,EAAGA,EAAGtjC,MAAM,GAAIsjC,EAAGtjC,MAAM,GAAIsjC,EAAGtjC,MAAM,MAG3D,MAAMme,EAAoB,CAAC7c,EAAG2nD,GAExB1+B,EAAkB,CAAC6rC,cAAaC,OAAMT,QAAOU,QAG7CzsC,EAAMI,GAAOC,UACH3W,GAAK4K,EACLoM,GAEhB,OAAI2+B,EACKN,GAAQ/+B,EAAK,CAACA,EAAI7pB,MAAM,GAAI6pB,EAAI7pB,MAAM,GAAI6pB,EAAI7pB,MAAM,KAEpD6pB,CAEX,ICjCO,MAAM9Q,GAAM6a,GAAG,CAAC2iC,KANvB,SAAgCj1D,GAC9B,MAEM6c,EAAoB,CAAC7c,EAFhB2xB,GAAgB3xB,EAAG,IAAK,MAAO,YAG1C,OAAO2oB,GAAOC,UAAUnX,GAAKoL,EAC/B,ICEO,MAAMq4C,GAAQ5iC,GAAG,CAAC6iC,OANzB,SAAkCn1D,GAChC,MAEM6c,EAAsB,CAAC7c,EAFlB2xB,GAAgB3xB,EAAG,IAAK,UAGnC,OAAO2oB,GAAOC,UAAUlX,GAAOmL,EACjC,ICAO,MAAMu4C,GAAW9iC,GAAG,CAAC+iC,UAN5B,SAAqCr1D,GACnC,MAEM6c,EAAyB,CAAC7c,EAFrB2xB,GAAgB3xB,EAAG,IAAK,aAGnC,OAAO2oB,GAAOC,UAAUtT,GAAUuH,EACpC,ICmBO,MAAMy4C,GAAahjC,GAAG,CAACijC,YArB9B,SAAuCv1D,GACrC,MAAMgiC,EAAKrQ,GAAgB3xB,EAAG,IAAK,cAkBnC,OAbiBovB,GAAYpvB,IAUpB,CAACxC,MANM+tC,GAAI6pB,GAAS7pB,GAAIvrC,KAMhB8sB,SAJG/D,GACHzO,GAAIyO,EAAIo/B,GAAQ5c,GAAIvrC,OAM9Bw1D,CAASxzB,EAClB,IC4CO,MAAMyzB,GAAanjC,GAAG,CAACojC,YAnD9B,SAAuCC,GAA+B,IAATjxD,EAAIhD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,IAAI,EACnE,MAAMk0D,EAAUjkC,GAAgBgkC,EAAQ,SAAU,cAKlD,IAHc,IAAVjxD,IACFA,EAAOkxD,EAAQjxD,KAAO,GAEpBD,IAASkxD,EAAQjxD,KAAO,EAC1B,MAAMzF,MACF,gEAA+D,mBAAAC,OAC5Cy2D,EAAQjxD,KAAI,kBAAAxF,OAAiBuF,IAetD,MAAM8wD,EAAWpmC,GAAW,CAACumC,EAAgBpmC,KAC3C,MACMsmC,EAAO51D,GAAI01D,EAAQjxD,GAAM,GACzBoxD,EAAUjY,GAAI8X,EAAQE,GACtBr4D,EACFqgD,GAAIl8B,GAAKm0C,EAAS,WAAYr+C,GAAIjX,GAAIqC,GAAIizD,GAAUpxD,GAJvC,KAKjB6qB,EAAK,CAAC/xB,IAQN,MAAO,CAACA,QAAOsvB,SANEA,CAAC/D,EAAYY,KAC5B,MAAOnsB,GAASmsB,EAEVosC,EAAUlzD,GAAIrF,GACpB,OAAOqgD,GAAI90B,EAAIzO,GAAI9Z,GAAIuoB,EAAIrkB,GAFV,GAE2BqxD,QAKhD,OAAOP,EAASI,EAQlB,ICvBO,MAAMI,GAAY1jC,GAAG,CAAC2jC,WAnB7B,SACIj2D,GAAoE,IAA9C0E,EAAAhD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAwB,KAAMsgD,EAAQtgD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,IAAAA,UAAA,GAC9D,MAAMsgC,EAAKrQ,GAAgB3xB,EAAG,IAAK,aAE7BmF,EAAOV,GAAeC,EAAMs9B,EAAGtjC,OAC/Bm3D,EAAO51D,GAAI+hC,EAAI78B,GAAM,GACrBvE,EAAIi9C,GAAI7b,EAAI6zB,GACZh1D,EAAIgC,GAAIjC,GACRkH,EAAItH,GAAIK,EAAGsE,GACXsC,EAAIgQ,GAAI3P,GACRygB,EAAM5N,GAAI2sC,GAAQuO,EAAMpuD,EAAE/I,OAAQ+I,GAExC,GAAIu6C,EAAU,CACZ,MAAMz9C,EAAWktD,GAAqBlpC,EAAI7pB,MAAOyG,GACjD,OAAOmiD,GAAQ/+B,EAAKhkB,E,CAEtB,OAAOgkB,CACT,IC1BO,MAAM2tC,GAAa5jC,GAAG,CAAC6jC,YAX9B,SACIv1D,EAAsBC,GACxB,MAAM4pC,EAAK9Y,GAAgB/wB,EAAG,IAAK,aAAc,QAC3C8pC,EAAK/Y,GAAgB9wB,EAAG,IAAK,aAAc,QACjDusC,GAA2B3C,EAAG/rC,MAAOgsC,EAAGhsC,OAExC,MAAMme,EAA2B,CAACjc,EAAG6pC,EAAI5pC,EAAG6pC,GAE5C,OAAO/hB,GAAOC,UAAUjX,GAAYkL,EACtC,ICNO,MAAMu5C,GAAa9jC,GAAG,CAAC+jC,YAN9B,SAAuCr2D,GACrC,MACM6c,EAA2B,CAAC7c,EADvB2xB,GAAgB3xB,EAAG,IAAK,aAAc,SAEjD,OAAO2oB,GAAOC,UAAUhX,GAAYiL,EACtC,ICOO,MAAMy5C,GAAYhkC,GAAG,CAACikC,WAT7B,SACI31D,EAAsBC,GACxB,MAAM4pC,EAAK9Y,GAAgB/wB,EAAG,IAAK,YAAa,QAC1C8pC,EAAK/Y,GAAgB9wB,EAAG,IAAK,YAAa,QAChDusC,GAA2B3C,EAAG/rC,MAAOgsC,EAAGhsC,OAExC,MAAMme,EAA0B,CAACjc,EAAG6pC,EAAI5pC,EAAG6pC,GAC3C,OAAO/hB,GAAOC,UAAU/W,GAAWgL,EACrC,ICIO,MAAM25C,GAAalkC,GAAG,CAACmkC,YAV9B,SACI71D,EAAsBC,GACxB,MAAM4pC,EAAK9Y,GAAgB/wB,EAAG,IAAK,aAAc,QAC3C8pC,EAAK/Y,GAAgB9wB,EAAG,IAAK,aAAc,QAIjD,OAHAusC,GAA2B3C,EAAG/rC,MAAOgsC,EAAGhsC,OAGjCw3D,GAAWI,GAAU11D,EAAGC,GAAIu1D,GAAWF,GAAWt1D,EAAGC,IAC9D,ICxBM61D,GAAY,WAyFX,MAAMC,GAAerkC,GAAG,CAACskC,cApChC,SACIC,EAAmCp4D,GACN,IAA7Bq4D,EAAAp1D,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAuB,OACzB,MAAMq1D,EACFplC,GAAgBklC,EAAgB,iBAAkB,gBAChDG,EAAUrlC,GAAgBlzB,EAAQ,SAAU,gBAE5Cw4D,EAAeF,EAAgBr4D,MAAMq4D,EAAgBr4D,MAAMa,OAAS,GACpE23D,EAAaF,EAAQt4D,MAAMs4D,EAAQt4D,MAAMa,OAAS,GAClD43D,EAAoB7P,GAAQyP,EAAiB,EAAE,EAAGE,IAClDG,EAAY9P,GAAQ0P,EAAS,EAAE,EAAGE,IAExC,GAAIC,EAAkBxyD,KAAO,EAC3B,MAAM,IAAIzF,MAAM,wDAElB,GAAIi4D,EAAkBz4D,MAAM,KAAO04D,EAAU14D,MAAM,GACjD,MAAM,IAAIQ,MAAM,kEAGlB,GAAIkD,GAAcg1D,EAAU14D,QAAUg4D,GACpC,MAAM,IAAIx3D,MAAM,qCAADC,OAAsCu3D,KAEvD,GAAIS,EAAkBz4D,MAAM,IAAMg4D,GAChC,MAAM,IAAIx3D,MAAM,oCAADC,OACXu3D,GAAS,gCAAAv3D,OAA+Bg4D,EAAkBz4D,MAAM,KAGtE,MAAMme,EAA6B,CACjCg6C,eAAgBM,EAChB14D,OAAQ24D,GAEJnuC,EAA2B,CAAC6tC,QAElC,OAAOnuC,GAAOC,UAAU9T,GAAc+H,EAAcoM,EACtD,IC7CM,SAAUouC,GACZR,EAAmCp4D,GACrC,OAAOk4D,GAAaE,EAAgBp4D,EAAQ,OAC9C,CCqBO,MAAM64D,GAAUhlC,GAAG,CAACilC,SArC3B,SACIv3D,EAAiBwjD,EACjBp8C,EACA+X,EACAkoC,GACF,MAAMrlB,EAAKrQ,GAAgB3xB,EAAG,IAAK,WAGnC,IAAI2nD,EAAM3lB,EACN4lB,GAAe,EACH,IAAZ5lB,EAAGr9B,OACLijD,GAAe,EACfD,EAAML,GAAQtlB,EAAI,CAAC,EAAGA,EAAGtjC,MAAM,GAAIsjC,EAAGtjC,MAAM,GAAIsjC,EAAGtjC,MAAM,MAG3Due,EACiB,IAAb0qC,EAAIhjD,KACJ,IAAM,uDAANxF,OAA6DwoD,EAAIhjD,KAAI,MACzEsY,EACIyqC,GAAyCtgD,EAb3B,GAcd,IAAM,4DAA2D,eAAAjI,OAC9CiI,EAAO,oBAAAjI,OAfZ,EAewC,MAC1DuoD,GAAoC,UAAWvoC,EAAKkoC,GACpD,MAAMxqC,EAAwB,CAAC7c,EAAG2nD,GAC5B1+B,EAAsB,CAACu6B,aAAYp8C,UAAS+X,MAAKkoC,mBAGjD9+B,EAAMI,GAAOC,UACHvW,GAASwK,EACToM,GAEhB,OAAI2+B,EACKN,GAAQ/+B,EAAK,CAACA,EAAI7pB,MAAM,GAAI6pB,EAAI7pB,MAAM,GAAI6pB,EAAI7pB,MAAM,KAEtD6pB,CACT,ICeO,MAAMivC,GAAYllC,GAAG,CAACmlC,WAxC7B,SACIz3D,GAGqC,IAHpBwjD,EAAA9hD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAA8C,CAAC,EAAG,EAAG,GACtE0F,EAAwC1F,UAAAnC,OAAA,EAAAmC,UAAA,QAAAC,EAAEwd,EAA0Bzd,UAAAnC,OAAA,EAAAmC,UAAA,QAAAC,EACpE0lD,EAAwC3lD,UAAAnC,OAAA,EAAAmC,UAAA,QAAAC,EACxCwhD,EAAAzhD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAA8B,QAChC,MAAMsgC,EAAKrQ,GAAgB3xB,EAAG,IAAK,aAEnC,IAAI+nD,EAAM/lB,EACNgmB,GAAe,EACH,IAAZhmB,EAAGr9B,OACLqjD,GAAe,EACfD,EAAMT,GAAQtlB,EAAI,CAAC,EAAGA,EAAGtjC,MAAM,GAAIsjC,EAAGtjC,MAAM,GAAIsjC,EAAGtjC,MAAM,GAAIsjC,EAAGtjC,MAAM,MAGxEue,EACiB,IAAb8qC,EAAIpjD,KACJ,IAAM,qDAANxF,OAA2D4oD,EAAIpjD,KAAI,MACvEsY,EACmB,UAAfkmC,EACA,IAAM,mFAAAhkD,OACuBgkD,IACjCgE,GAA0B,YAAahoC,EAAKkoC,GAC5C,MAAMxqC,EAA0B,CAAC7c,EAAG+nD,GAC9B9+B,EACe,CAACu6B,aAAYp8C,UAAS+X,MAAKkoC,kBAAiBlE,cAG3D56B,EAAMI,GAAOC,UACHrW,GAAWsK,EACXoM,GAEhB,OAAI++B,EACKV,GACI/+B,EAAK,CAACA,EAAI7pB,MAAM,GAAI6pB,EAAI7pB,MAAM,GAAI6pB,EAAI7pB,MAAM,GAAI6pB,EAAI7pB,MAAM,KAIhE6pB,CACT,ICzBO,MAAMmvC,GAAoBplC,GAAG,CAACqlC,mBAlBrC,SACI33D,EAAiBwjD,EACjBp8C,EAAkC+X,GACP,IAA3By4C,EAAmBl2D,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,IAAAA,UAAA,GACrB,MAEMmb,EAAkC,CAAC7c,EAF9B2xB,GAAgB3xB,EAAG,IAAK,sBAG7BipB,EACuB,CAACu6B,aAAYp8C,UAAS+X,MAAKy4C,uBAGlD52D,EAAS2nB,GAAOC,UACHnW,GAAmBoK,EACnBoM,GAEnB,MAAO,CAACjoB,OAAQA,EAAO,GAAI62D,QAAS72D,EAAO,GAC7C,ICTO,MAAM6oD,GAAOv3B,GAAG,CAACwlC,MAXxB,SACI93D,GAAoE,IAA9C0E,EAAAhD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAwB,KAAMsgD,EAAQtgD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,IAAAA,UAAA,GAC9D,MAEMmb,EAAqB,CAAC7c,EAFjB2xB,GAAgB3xB,EAAG,IAAK,SAG7BipB,EAAmB,CAACvkB,OAAMs9C,YAEhC,OAAOr5B,GAAOC,UACVlW,GAAMmK,EAAgCoM,EAC5C,IC5BM,SAAU4mC,GACZnxD,GAA+C,IAA3BC,EAAA+C,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAkB,UACxC,GAAc,cAAV/C,EAAuB,CACzB,MAAMm0B,EAAO+8B,GAAMnxD,EAAO,WACpBq0B,EAAO88B,GAAMnxD,EAAO,WAC1B,OAAOk0B,GAAQE,EAAMC,E,CAEvB,MAAMt0B,EAASwJ,GAAoB7F,GAAc1D,GAAQC,GACzD,OAAOgqB,GAAOlI,WAAWhiB,EAAQC,EAAOC,EAC1C,CCRM,SAAUgwB,GACZjwB,GAA+C,IAA3BC,EAAA+C,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAkB,UACxC,GAAc,cAAV/C,EAAuB,CACzB,MAAMm0B,EAAOnE,GAAKjwB,EAAO,WACnBq0B,EAAO88B,GAAMnxD,EAAO,WAC1B,OAAOk0B,GAAQE,EAAMC,E,CAEvB,MAAMt0B,EAASuJ,GAAmB5F,GAAc1D,GAAQC,GACxD,OAAOgqB,GAAOlI,WAAWhiB,EAAQC,EAAOC,EAC1C,CCSM,SAAUo5D,GACZ/3D,EAAkBya,GAAwC,IAAtB,SAACu9C,EAAW,MAAKt2D,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,CAAC,EAC3D,GAAiB,OAAbs2D,GAAkC,OAAbA,EACvB,MAAM,IAAIC,UAAU,GAAD94D,OACZ64D,EAAQ,+CAEjB,QAAUr2D,IAAN3B,EACF,MAAO,GAET,IAAIgiC,EAAKrQ,GACL3xB,EAAG,IAAK,WAAYA,aAAa4gB,GAAS5gB,EAAErB,MAAQ,WAExD,QAAUgD,IAAN8Y,EACF,MAAO,CAACunB,GAEV,IAAIk2B,EAAKvmC,GACLlX,EAAG,IAAK,WAAYA,aAAamG,GAASnG,EAAE9b,MAAQ,WAExD,MAAM6b,EAAIpY,GAAc4/B,EAAGtjC,OACrB0c,EAAIhZ,GAAc81D,EAAGx5D,OAE3B,MAAiB,OAAbs5D,GACFh2B,EAAKslB,GAAQtlB,EAAI,CAAC,GAAI,IACtBk2B,EAAK5Q,GAAQ4Q,EAAI,EAAE,EAAG,IACf,CACL7tB,GAAO1b,GAAK,CAACvT,EAAG,GAAI4mB,EAAGrjC,OAAQqjC,GAC/BqI,GAAO6tB,EAAIvpC,GAAK,CAAC,EAAGnU,GAAI09C,EAAGv5D,WAI/BqjC,EAAKslB,GAAQtlB,EAAI,EAAE,EAAG,IACtBk2B,EAAK5Q,GAAQ4Q,EAAI,CAAC,GAAI,IACf,CACL7tB,GAAOrI,EAAIrT,GAAK,CAAC,EAAGvT,GAAI4mB,EAAGrjC,QAC3B0rC,GAAO1b,GAAK,CAACnU,EAAG,GAAI09C,EAAGv5D,OAAQu5D,IAEnC,CClBO,MAAMC,GAAU7lC,GAAG,CAAC8lC,SAlB3B,SACIx3D,EAAsBC,GACxB,IAAI4pC,EAAK9Y,GAAgB/wB,EAAG,IAAK,WAC7B8pC,EAAK/Y,GAAgB9wB,EAAG,IAAK,YAChC4pC,EAAIC,GAAMrnB,GAAeonB,EAAIC,GAEb,SAAbD,EAAG9rC,QACL8rC,EAAK9oB,GAAK8oB,EAAI,SACdC,EAAK/oB,GAAK+oB,EAAI,UAGhB0C,GAA2B3C,EAAG/rC,MAAOgsC,EAAGhsC,OAExC,MAAMme,EAAwB,CAACjc,EAAG6pC,EAAI5pC,EAAG6pC,GAEzC,OAAO/hB,GAAOC,UAAUhW,GAASiK,EACnC,ICkBO,MAAMw7C,GAAY/lC,GAAG,CAACgmC,WArC7B,SACIt4D,EAAiBu4D,EACjBC,GACFv7C,EACa,YAATu7C,GAA+B,cAATA,EACtB,IAAM,kEAAAr5D,OACKq5D,EAAI,MAEnB,MAAMx2B,EAAKrQ,GAAgB3xB,EAAG,IAAK,aACnC,GAAgB,IAAZgiC,EAAGr9B,KACL,MAAM,IAAIzF,MACN,kEAGN+d,EACIs7C,EAASh5D,SAAWyiC,EAAGr9B,KACvB,IAAM,wCAAAxF,OAAwC6iC,EAAGr9B,KAAI,aAAAxF,OAC1Co5D,EAASh5D,OAAM,MAC9B,MAAMk5D,EAAuB,YAATD,EAAqB,EAAI,EAC7C,IAAK,IAAI93D,EAAI,EAAGA,EAAIshC,EAAGr9B,KAAMjE,IAC3Buc,EAC2B,IAAvBs7C,EAAS73D,GAAGnB,OACZ,IAAM,yDACV0d,EACIs7C,EAAS73D,GAAG,IAAM,GAAK63D,EAAS73D,GAAG,IAAMshC,EAAGtjC,MAAMgC,GAAK+3D,GACnDF,EAAS73D,GAAG,IAAM,GAAK63D,EAAS73D,GAAG,IAAMshC,EAAGtjC,MAAMgC,GAAK+3D,EAC3D,IAAM,wBAAAt5D,OAAwBuB,EAAC,2CAAAvB,OACrB6iC,EAAGtjC,MAAMgC,GAAK+3D,EAAW,iCAA+B,SAAAt5D,OACrD6iC,EAAGtjC,QAGtB,MAAMuqB,EAAwB,CAACsvC,WAAUC,QACnC37C,EAA0B,CAAC7c,EAAGgiC,GACpC,OAAOrZ,GAAOC,UACV/V,GAAWgK,EAAgCoM,EACjD,ICvBO,MAAMyvC,GAAMpmC,GAAG,CAACqmC,KAVvB,SAAgC/3D,EAAsBC,GACpD,IAAI4pC,EAAK9Y,GAAgB/wB,EAAG,IAAK,OAC7B8pC,EAAK/Y,GAAgB9wB,EAAG,IAAK,QAChC4pC,EAAIC,GAAMrnB,GAAeonB,EAAIC,GAE9B,MAAM7tB,EAAoB,CAACjc,EAAG6pC,EAAI5pC,EAAG6pC,GAErC,OAAO/hB,GAAOC,UAAU9V,GAAK+J,EAC/B,ICHO,MAAM+7C,GAAUtmC,GAAG,CAACumC,SAhB3B,SACI74D,GACgB,IAAhBgiD,EAAQtgD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,IAAAA,UAAA,GAEV,MAAMyD,EAAOV,GAHW/C,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAwB,MAEhD1B,EAAI2xB,GAAgB3xB,EAAG,IAAK,YACQtB,OAC9Bo6D,EAAQjP,GAAK7pD,EAAGmF,EAAM68C,GAC5B,IAAIuQ,EAAgBuG,EAAMp6D,MACrBsjD,IACHuQ,EAAgBd,GAAqBqH,EAAMp6D,MAAOyG,IAEpD,MAAM4zD,EACFre,GAAOmD,GAAIl8B,GAAK3hB,EAAG,WAAYsnD,GAAQwR,EAAOvG,KAElD,MAAO,CAAC1I,KAAMiP,EAAOhP,SADJD,GAAKkP,EAAY5zD,EAAM68C,GAE1C,ICUO,MAAMgX,GAAe1mC,GAAG,CAAC2mC,cAxBhC,SACIC,EAA2Bn8D,EAC3B+K,EACAsT,GACF,MAAM2tC,EAAQp3B,GAAgB50B,EAAM,OAAQ,gBACtCisD,EAAKh3B,GAAqBlqB,EAAG,IAAK,gBAClCmhD,EAAKj3B,GAAqB5W,EAAG,IAAK,gBAExC,IAAI8C,EAAQ6qC,EACZ,MAAMoQ,EAAY,GAClB,IAAK,IAAIz4D,EAAI,EAAGA,EAAIw4D,EAAU35D,OAAQmB,IAAK,CACzC,MAAMwc,EAASg8C,EAAUx4D,GAAGwd,EAAO8qC,EAAGtoD,GAAIuoD,EAAGvoD,IAC7Cy4D,EAAUh3D,KAAK+a,EAAO,IACtBi8C,EAAUh3D,KAAK+a,EAAO,IACtBgB,EAAQhB,EAAO,E,CAEjB,MAAMmsC,EAAmB,GACnB+P,EAAmB,GACzB,IAAK,IAAI14D,EAAI,EAAGA,EAAIy4D,EAAU55D,OAAQmB,GAAK,EACzC2oD,EAAKlnD,KAAKg3D,EAAUz4D,IACpB04D,EAAKj3D,KAAKg3D,EAAUz4D,EAAI,IAE1B,MAAO,CAAC2oD,EAAM+P,EAChB,ICeO,MAAMC,GAAc/mC,GAAG,CAACgnC,aAlC/B,SACI3D,EAAsC4D,EAAoBz+C,GACxC,IAAlB0+C,EAAU93D,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,IAAAA,UAAA,GACZ,MAAMk0D,EAAUjkC,GAAgBgkC,EAAQ,SAAU,eAC5C8D,EAAc7D,EAAQvzD,KACtBq3D,EAAW9D,EAAQjxD,KACzB,GAAI80D,EAAc,EAChB,MAAM,IAAIv6D,MACN,kEAAAC,OACGs6D,EAAW,MAEpB,GAAIC,EAAW,EACb,MAAM,IAAIx6D,MAAM,gDAADC,OAAiDu6D,IAIlE5+C,EAAOA,GAAQrb,KAAKC,SAGpB,MAGMmd,EAA4B,CAAC84C,OAFlB,IAAb+D,EAAiBpS,GAAQsO,EAAS,CAAC,GAAI,IAAMA,GAG3C3sC,EAA0B,CAACswC,aAAYz+C,OAAM0+C,cAG7CjxC,EAAMI,GAAOC,UACH7V,GAAa8J,EACboM,GAGhB,OAAoB,IAAbywC,EAAiBpS,GAAQ/+B,EAAK,CAACA,EAAIlmB,OAAqBkmB,CACjE,IC1BO,MAAMoxC,GAAWrnC,GAAG,CAACsnC,UAb5B,SACIh5D,EAAsBC,GACxB,IAAI4pC,EAAK9Y,GAAgB/wB,EAAG,IAAK,WAAY,qBACzC8pC,EAAK/Y,GAAgB9wB,EAAG,IAAK,WAAY,sBAC5C4pC,EAAIC,GAAMrnB,GAAeonB,EAAIC,GAE9B0C,GAA2B3C,EAAG/rC,MAAOgsC,EAAGhsC,OAExC,MAAMme,EAAyB,CAACjc,EAAG6pC,EAAI5pC,EAAG6pC,GAE1C,OAAO/hB,GAAOC,UAAU1V,GAAU2J,EACpC,ICPO,MAAMg9C,GAAWvnC,GAAG,CAACwnC,UAP5B,SAAqC95D,GACnC,MAEM6c,EAAyB,CAAC7c,EAFrB2xB,GAAgB3xB,EAAG,IAAK,aAGnC,OAAO2oB,GAAOC,UAAUtV,GAAUuJ,EACpC,ICWO,MAAMk9C,GAAeznC,GAAG,CAAC0nC,cAfhC,SACIC,EAAyBC,GAC3B,MAAMC,EAAMxoC,GAAgBsoC,EAAI,KAAM,gBAChCG,EAAMzoC,GAAgBuoC,EAAI,KAAM,gBAEtCj9C,EACiB,IAAbk9C,EAAIx1D,MAA2B,IAAby1D,EAAIz1D,KACtB,IAAM,kEAAAxF,OACCg7D,EAAIx1D,KAAI,SAAAxF,OAAQi7D,EAAIz1D,KAAI,MAEnC,MAAM01D,EAAO/S,GAAQ6S,EAAK,EAAE,EAAG,IACzBG,EAAOhT,GAAQ8S,EAAK,CAAC,GAAI,IAC/B,OAAO/vB,GAAOgwB,EAAMC,EACtB,ICcO,MAAMn7C,GAAMmT,GAAG,CAACioC,KAdvB,SACIv6D,EAAiBu4D,GAAoD,IAAjBiC,EAAa94D,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,EACtE,MAAMsgC,EAAKrQ,GAAgB3xB,EAAG,IAAK,OACnC,GAAgB,IAAZgiC,EAAGr9B,KACL,MAAM,IAAIzF,MAAM,sDAGlB,MAAM+pB,EAAoB,CAACsvC,WAAUiC,iBAC/B39C,EAAsB,CAAC7c,EAAGgiC,GAChC,OAAOrZ,GAAOC,UACVnV,GAAOoJ,EACPoM,EACN,IC9BO,MAAMwxC,GAAQnoC,GAAG,CAACooC,OATzB,SACI16D,EAAwBu4D,GACP,IAAjBiC,EAAa94D,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,EAIlB,OAHAP,EACwB,IAApBo3D,EAASh5D,OACT,IAAM,oDACH4f,GAAInf,EAAG,CAACu4D,GAAWiC,EAC5B,ICGO,MAAMG,GAAQroC,GAAG,CAACsoC,OAVzB,SACI56D,EAAwBu4D,GACP,IAAjBiC,EAAa94D,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,EAKlB,OAJAP,EACwB,IAApBo3D,EAASh5D,QAAuC,IAAvBg5D,EAAS,GAAGh5D,QACV,IAAvBg5D,EAAS,GAAGh5D,OAChB,IAAM,yDACH4f,GAAInf,EAAGu4D,EAAUiC,EAC1B,ICGO,MAAMK,GAAQvoC,GAAG,CAACwoC,OAXzB,SACI96D,EACAu4D,GACiB,IAAjBiC,EAAa94D,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,EAKlB,OAJAP,EACwB,IAApBo3D,EAASh5D,QAAuC,IAAvBg5D,EAAS,GAAGh5D,QACV,IAAvBg5D,EAAS,GAAGh5D,QAAuC,IAAvBg5D,EAAS,GAAGh5D,OAC5C,IAAM,yDACH4f,GAAInf,EAAGu4D,EAAUiC,EAC1B,ICMO,MAAMO,GAAQzoC,GAAG,CAAC0oC,OAfzB,SACIh7D,EACAu4D,GAIiB,IAAjBiC,EAAa94D,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,EAMlB,OALAP,EACwB,IAApBo3D,EAASh5D,QAAuC,IAAvBg5D,EAAS,GAAGh5D,QACV,IAAvBg5D,EAAS,GAAGh5D,QAAuC,IAAvBg5D,EAAS,GAAGh5D,QACjB,IAAvBg5D,EAAS,GAAGh5D,OAChB,IAAM,yDACH4f,GAAInf,EAAGu4D,EAAUiC,EAC1B,IC4EO,MAAMS,GAAiB3oC,GAAG,CAAC4oC,gBAtClC,SACIl7D,EAAiBwpD,EAAsB+O,GACzC,MAAMv2B,EAAKrQ,GAAgB3xB,EAAG,IAAK,kBAEnCid,EACI+kB,EAAGr9B,MAAQ,EAAI6kD,EAAWjqD,OAC1B,IAAM,cAANJ,OAAoB6iC,EAAGr9B,KAAI,mCAAAxF,OACvBqqD,EAAWjqD,SAEnB0d,EACIs7C,EAASh5D,SAAWiqD,EAAWjqD,OAC/B,IAAM,qBAANJ,OACIo5D,EAASh5D,OAAM,mCAAAJ,OAAkCqqD,EAAWjqD,SAEpE0d,EACI+kB,EAAGtjC,MAAMkJ,OACL,CAAChH,EAAGC,EAAGH,IACDA,EAAI,GAAKA,GAAK8oD,EAAWjqD,OACpBqB,IACDC,EAAI03D,EAAS73D,EAAI,GAAG,GAAK63D,EAAS73D,EAAI,GAAG,IACtC8oD,EAAW9oD,EAAI,KACnB,EAEAE,GAET,GACJ,IAAM,4BAANzB,OAAkC6iC,EAAGtjC,MAAM8F,MAAM,GAAE,mBAAArF,OAC/Co5D,EAASv6C,WAAU,sCAAA7e,OACnBqqD,EAAWxrC,aAEnB,MAAMnB,EAA+B,CAAC7c,EAAGgiC,GACnC/Y,EAA6B,CAACugC,aAAY+O,YAEhD,OAAO5vC,GAAOC,UACVnT,GAAgBoH,EAChBoM,EACN,ICsDO,MAAMkyC,GAAO7oC,GAAG,CAAC8oC,MA5GxB,SACIl9C,EAAqBm9C,EACrBC,EACAn8C,EACAikC,EAAqCh8C,EACrCigD,GACe,MAAbjE,IACFA,EAAY,CAAC,EAAG,IAEH,MAAXh8C,IACFA,EAAU,GAEA,IAAR+X,IACFA,EAAM,SAGR,MAAM6iB,EAAKrQ,GAAgBzT,EAAO,IAAK,WACvC,IAAIypC,EAAM3lB,EACN4lB,GAAe,EAEH,IAAZ5lB,EAAGr9B,OACLijD,GAAe,EACfD,EAAML,GAAQtlB,EAAI,CAAC,EAAGA,EAAGtjC,MAAM,GAAIsjC,EAAGtjC,MAAM,GAAIsjC,EAAGtjC,MAAM,MAG3Due,EACIyqC,GAAyCtgD,EAASg8C,GAClD,IAAM,yDAAwD,eAAAjkD,OAC3CiI,EAAO,oBAAAjI,OAAmBikD,EAAS,MAE1D,MAAMmY,EAAW7T,GACbC,EAAIjpD,MAAO28D,EAAaj0D,EAASg8C,EAAWjkC,GAC1C0nC,EACF,CAAC0U,EAAS7W,eAAgB6W,EAAS5W,eAOvC,IAAI6W,EAEFA,EADU,SAARr8C,EAiDN,SACI+jC,EAA+B2D,GAGjC,MAAM4U,EAAqBvY,EAAYt+C,IAAI,CAACC,EAAGnE,IACtCmE,GAAKA,EAAI,IAAMgiD,EAASnmD,GAAK,IAEhCg7D,EAAgBD,EAAmB72D,IAAIC,GAAKA,EAAI,GAIhD82D,EAAgBD,EAAc92D,IAAIC,GAAKpF,KAAKkJ,MAAM9D,EAAI,IACtD+2D,EAAcF,EAAc92D,IAAI,CAACC,EAAGnE,IAAMmE,EAAI82D,EAAcj7D,IAClE,OAAOg7D,EAAc92D,IAAI,CAACknB,EAAGprB,IACpB,CAACi7D,EAAcj7D,GAAIk7D,EAAYl7D,IAE1C,CAhEkBm7D,CACV,CAACN,EAAS7X,aAAc6X,EAAS5X,aAAckD,GAErC,CAAC,CAAC,EAAG,GAAI,CAAC,EAAG,IAG7B,MAAMiV,EAAgC,IAAhBjV,EAAS,IAA4B,IAAhBA,EAAS,IAC7CkV,EAAiBC,GAyB1B,SACI79C,EAA8BqrC,EAC9BgS,GACF,MAAMS,EAAWT,EAAY52D,IAAI/D,GAAKA,EAAE,IAClCq7D,EAAaV,EAAY52D,IAAI/D,GAAKA,EAAE,IACpCs7D,EAAiBh+C,EAAWhf,OAAO88D,EAAUC,GAC7CE,EAAc5S,EAAW5kD,IAAI,CAAC/D,EAAGH,KAAOG,EAAIs7D,EAAez7D,GAAKG,GAAKA,GACrEw7D,EAASH,EAAWt3D,IAAI,CAACC,EAAGnE,IAAMmE,EAAIu3D,EAAY17D,IAClD63D,EAAW/O,EAAW5kD,IAAI,CAACknB,EAAGprB,IAAM,CAACu7D,EAASv7D,GAAI27D,EAAO37D,KACzD+oD,EAAQD,EAAW5kD,IAAI,CAACknB,EAAGprB,IAAM,CAAC,EAAG07D,EAAY17D,KACvD,MAAO,CAAC63D,EAAU9O,EACpB,CApC2C6S,CACrC,CAACf,EAASnX,SAAUmX,EAASlX,SAAUwC,EAAU2U,GAC/Ce,EAAeT,EAAgB38C,EAAM,QACrCq9C,EACFV,EAAgBnU,EAAMsT,GAAetT,EAAKd,EAAUkV,GAOlDthD,GAL4B,QAAhB6gD,EACd,IAAM9T,GAAQgV,EAAYnB,EAAaj0D,EAASm1D,EAClClV,GACd,IAAMiQ,GAAQkF,EAAYnB,EAAaj0D,EAASm1D,EAClClV,MAGZ9+B,EAAMuzC,EAAgBrhD,EAAI6uC,GAAe7uC,EAAGosC,EAAUmV,GAE5D,OAAIpU,EACKN,GAAQ/+B,EAAK,CAACA,EAAI7pB,MAAM,GAAI6pB,EAAI7pB,MAAM,GAAI6pB,EAAI7pB,MAAM,KAGtD6pB,CACT,IC7EO,MAAMk0C,GAAQnqC,GAAG,CAACoqC,OARzB,SAAkC18D,EAAiBs0D,GACjD,MAGMz3C,EAAsB,CAAC7c,EAHlB2xB,GAAgB3xB,EAAG,IAAK,SAGCs0D,MAFrB3iC,GAAgB2iC,EAAO,QAAS,UAG/C,OAAO3rC,GAAOC,UAAUhV,GAAOiJ,EACjC,IC0BO,MAAM6sC,GAAOp3B,GAAG,CAACqqC,MAhBxB,SACI38D,GAAoE,IAA9C0E,EAAAhD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAwB,KAAMsgD,EAAQtgD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,IAAAA,UAAA,GAC1DsgC,EAAKrQ,GAAgB3xB,EAAG,IAAK,QAEhB,SAAbgiC,EAAGrjC,QAELqjC,EAAKrgB,GAAKqgB,EAAI,UAGhB,MAAMnlB,EAAqB,CAAC7c,EAAGgiC,GACzB/Y,EAAmB,CAACvkB,OAAMs9C,YAEhC,OAAOr5B,GAAOC,UACV/U,GAAMgJ,EAAgCoM,EAC5C,ICEO,MAAM2zC,GAAetqC,GAAG,CAACuqC,cAxBhC,SACIC,EAA8BC,EAC9B3rC,EAA4B4rC,GAC9B,MAMMngD,EAA6B,CACjCigD,mBAP0BA,EAAmBl4D,IAC3C,CAAC2G,EAAG7K,IAAMixB,GAAgBpmB,EAAG,UAAFpM,OAAYuB,GAAK,eAAgB,UAO9Dq8D,kBALEprC,GAAgBorC,EAAmB,oBAAqB,gBAM1D3rC,QALeO,GAAgBP,EAAS,UAAW,eAAgB,UAO/DnI,EAA2B,CAAC+zC,oBAE5Bh8D,EACF2nB,GAAOC,UAAU9U,GAAc+I,EAAcoM,GACjD,MAAO,CACLg0C,mBAAoBj8D,EAAOwD,MAAM,EAAGxD,EAAOzB,OAAS,GACpD29D,kBAAmBl8D,EAAOA,EAAOzB,OAAS,GAE9C,IC6BO,MAAM49D,GAAuB7qC,GAAG,CAAC8qC,sBAxBxC,SACI1+D,EAA0BD,EAC1B4+D,EAAiCC,EACjCC,GACF,MAAMC,EACF7rC,GAAgBjzB,EAAO,QAAS,uBAAwB,SACtDs4D,EAAUrlC,GAAgBlzB,EAAQ,SAAU,wBAO5Coe,EAAqC,CACzCne,MAAO8+D,EACP/+D,OAAQu4D,EACRqG,aAToB1rC,GAClB0rC,EAAc,eAAgB,uBAAwBrG,EAAQr4D,OAShE2+D,oBAR2BA,EAAoB14D,IAC7C,CAAC2G,EAAG7K,IACAixB,GAAgBpmB,EAAG,UAAFpM,OAAYuB,GAAK,uBAAwB,WAQ5DuoB,EAAmC,CAACs0C,qBAE1C,OAAO50C,GAAOC,UAAU7U,GAAsB8I,EAAcoM,EAC9D,IC5CO,MAAMw0C,GAAOnrC,GAAG,CAACorC,MApBxB,SACIh/D,EAAoBi/D,EACpBh/D,GACF,MAAM0D,EAAOD,GAAc1D,GAC3B,IAAID,EAAS,KACb,GAAa,MAATE,GAA2B,YAAVA,EACnBF,EAAS,IAAI8G,aAAalD,QACrB,GAAc,UAAV1D,EACTF,EAAS,IAAI+G,WAAWnD,OACnB,IAAc,SAAV1D,EAGT,MAAM,IAAIO,MAAM,qBAADC,OAAsBR,IAFrCF,EAAS,IAAIgH,WAAWpD,E,CAI1B,IAAK,IAAI3B,EAAI,EAAGA,EAAI2B,EAAM3B,IACxBjC,EAAOiC,GAAKi9D,IAEd,OAAOh1C,GAAOlI,WAAWhiB,EAAQC,EAAOC,EAC1C,I,cCZM,MAAOi/D,GAUXhhE,WAAAA,CACIitD,EAAcgU,EAAsBl/D,EACpCm/D,EAAqBhjD,GACvB1d,KAAKysD,KAAOA,EACZzsD,KAAK2gE,OAASF,EACdzgE,KAAKuB,MAAQA,EACbvB,KAAK4gE,QAAUC,IACf7gE,KAAK0gE,UAAYA,EACb1gE,KAAK0gE,YACP1gE,KAAK8gE,MAAQ9gE,KAAKysD,KAAqB,EAAdzsD,KAAK2gE,OAC9B3gE,KAAK+gE,MAAQ/gE,KAAKysD,KAAqB,EAAdzsD,KAAK2gE,QAEhC,MAAMK,EAAYtjD,GAAcrb,KAAKC,SACrCtC,KAAKsC,OAAS2+D,GAAWC,KAAKF,EAAUpgD,WAC1C,CAGOugD,SAAAA,GACL,IAAKz4D,MAAM1I,KAAK4gE,SAAU,CACxB,MAAMxgE,EAAQJ,KAAK4gE,QAEnB,OADA5gE,KAAK4gE,QAAUC,IACRzgE,C,CAGT,IAAIghE,EAAiBC,EACjBC,GAAU,EACd,MAAQA,GAAS,CACf,IAAIzE,EAAYC,EAAYr1D,EAC5B,GACEo1D,EAAK,EAAI78D,KAAKsC,SAAW,EACzBw6D,EAAK,EAAI98D,KAAKsC,SAAW,EACzBmF,EAAIo1D,EAAKA,EAAKC,EAAKA,QACZr1D,GAAK,GAAW,IAANA,GAEnB,MAAMyV,EAAM7a,KAAKwD,MAAM,EAAMxD,KAAKgY,IAAI5S,GAAKA,GAC3C25D,EAAUphE,KAAKysD,KAAOzsD,KAAK2gE,OAAS9D,EAAK3/C,EACzCmkD,EAAUrhE,KAAKysD,KAAOzsD,KAAK2gE,OAAS7D,EAAK5/C,EAEpCld,KAAK0gE,YAAa1gE,KAAKuhE,iBAAiBH,KAC3CE,GAAU,E,CAOd,OAHKthE,KAAK0gE,YAAa1gE,KAAKuhE,iBAAiBF,KAC3CrhE,KAAK4gE,QAAU5gE,KAAKwhE,aAAaH,IAE5BrhE,KAAKwhE,aAAaJ,EAC3B,CAGQI,YAAAA,CAAaphE,GACnB,OAAkB,MAAdJ,KAAKuB,OAAgC,YAAfvB,KAAKuB,MACtBnB,EAEFiC,KAAKuc,MAAMxe,EACpB,CAGQmhE,gBAAAA,CAAiBnhE,GACvB,OAAOA,GAASJ,KAAK8gE,OAAS1gE,GAASJ,KAAK+gE,KAC9C,EAKI,MAAOU,GASXjiE,WAAAA,CACI03D,EAAeU,EAAcr2D,EAC7Bmc,GACF1d,KAAKk3D,MAAQA,EACbl3D,KAAK43D,KAAO,EAAIA,EAChB53D,KAAKuB,MAAQA,EAEb,MAAMy/D,EAAYtjD,GAAcrb,KAAKC,SACrCtC,KAAK0hE,MAAQT,GAAWC,KAAKF,EAAUpgD,YACvC5gB,KAAK2hE,MAAQ,IAAInB,GAAY,EAAG,EAAGj/D,GAAO,EAAOvB,KAAK0hE,SAGpD1hE,KAAKqK,EADH6sD,EAAQ,EACDA,EAAS,EAAI,EAEbA,EAAS,EAAI,EAExBl3D,KAAK0K,EAAI,EAAIrI,KAAKwD,KAAK,EAAI7F,KAAKqK,EAClC,CAGO82D,SAAAA,GACL,IAAIS,EAAYC,EAAYhF,EAAYj6D,EAAWoa,EAAWC,EAC9D,OAAa,CACX,GACEra,EAAI5C,KAAK2hE,MAAMR,YACflkD,EAAI,EAAKjd,KAAK0K,EAAI9H,QACXqa,GAAK,GAMd,GALAA,GAAKA,EAAIA,EACT2kD,EAAKh/D,EAAIA,EACTi/D,EAAK,EAAK,KAAQD,EAAKA,EACvB/E,EAAM,GAAM+E,EAAO5hE,KAAKqK,GAAK,EAAI4S,EAAI5a,KAAKgY,IAAI4C,IAC9CD,EAAIhd,KAAK0hE,QACL1kD,EAAI6kD,GAAMx/D,KAAKgY,IAAI2C,GAAK6/C,EAC1B,K,CAOJ,OAJA5/C,EAAK,EAAIjd,KAAK43D,KAAQ53D,KAAKqK,EAAI4S,EAC3Bjd,KAAKk3D,MAAQ,IACfj6C,GAAK5a,KAAKg+C,IAAIrgD,KAAK0hE,QAAS,EAAI1hE,KAAKk3D,QAEhCl3D,KAAKwhE,aAAavkD,EAC3B,CAEQukD,YAAAA,CAAaphE,GACnB,MAAmB,YAAfJ,KAAKuB,MACAnB,EAEFiC,KAAKuc,MAAMxe,EACpB,EAGI,MAAO0hE,GAMXtiE,WAAAA,GAEwB,IADpBmD,EAAG2B,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,EAAGzB,EAAGyB,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,EAAG/C,EAAiC+C,UAAAnC,OAAA,EAAAmC,UAAA,QAAAC,EACnDmZ,EAAoBpZ,UAAAnC,OAAA,EAAAmC,UAAA,QAAAC,EAWtB,GAQM,KAAAw9D,eAAiB,IACN,MAAd/hE,KAAKuB,OAAgC,YAAfvB,KAAKuB,MAnB9BvB,KAAK2C,IAAMA,EACX3C,KAAKgiE,MAAQn/D,EAAMF,EACnB3C,KAAKuB,MAAQA,EACD,MAARmc,IACFA,EAAOrb,KAAKC,UAEM,kBAATob,IACTA,EAAOA,EAAKkD,aAGT5gB,KAAK+hE,kBAAoB/hE,KAAKgiE,OAAS,EAC1C,MAAM,IAAIlgE,MAAM,0BAADC,OACeY,EAAG,OAAAZ,OAAMc,EAAG,iCAE5C7C,KAAKsC,OAAS2+D,GAAWC,KAAKxjD,EAChC,CAMQ8jD,YAAAA,CAAaphE,GACnB,OAAIJ,KAAK+hE,iBACA3hE,EAEFiC,KAAKuc,MAAMxe,EACpB,CAEA+gE,SAAAA,GACE,OAAOnhE,KAAKwhE,aAAaxhE,KAAK2C,IAAM3C,KAAKgiE,MAAQhiE,KAAKsC,SACxD,EC3JK,MAAM2/D,GAAc/sC,GAAG,CAACgtC,aApB/B,SACI5gE,EAAoB41D,GAC+B,IADhBU,EAAItzD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,EAC1C/C,EAAA+C,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAA2B,UAAWoZ,EAAapZ,UAAAnC,OAAA,EAAAmC,UAAA,QAAAC,EAOrD,GANY,MAARqzD,IACFA,EAAO,GAEI,MAATr2D,IACFA,EAAQ,WAEI,YAAVA,GAAiC,UAAVA,EACzB,MAAM,IAAIO,MAAM,yBAADC,OAA0BR,IAE3C,MAAM4gE,EAAS,IAAIV,GAAUvK,EAAOU,EAAMr2D,EAAOmc,GAC3CyN,EAAMtH,GAAOviB,EAAOC,GAC1B,IAAK,IAAI+B,EAAI,EAAGA,EAAI6nB,EAAI9pB,OAAOc,OAAQmB,IACrC6nB,EAAI9pB,OAAOiC,GAAK6+D,EAAOhB,YAEzB,OAAOh2C,EAAIhI,UACb,ICJO,MAAMi/C,GAAeltC,GAAG,CAACmtC,cAfhC,SACI/gE,GACa,IADOmrD,EAAInoD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,EAAGq8D,EAAMr8D,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,EAAG/C,EAAyB+C,UAAAnC,OAAA,EAAAmC,UAAA,QAAAC,EACnEmZ,EAAapZ,UAAAnC,OAAA,EAAAmC,UAAA,QAAAC,EACf,GAAa,MAAThD,GAAyC,SAAvBA,EACpB,MAAM,IAAIO,MAAM,yBAADC,OAA0BR,IAE3C,MAAM+gE,EACF,IAAI9B,GAAY/T,EAAMkU,EAAQp/D,GAAO,EAAuBmc,GAC1DyN,EAAMtH,GAAOviB,EAAOC,GAC1B,IAAK,IAAI+B,EAAI,EAAGA,EAAI6nB,EAAI9pB,OAAOc,OAAQmB,IACrC6nB,EAAI9pB,OAAOiC,GAAKg/D,EAAUnB,YAE5B,OAAOh2C,EAAIhI,UACb,ICNO,MAAMo/C,GAAuBrtC,GAAG,CAACstC,sBARxC,SACIlhE,EAAoBC,EAA2Bmc,GACjD,GAAa,MAATnc,GAAyC,SAAvBA,EACpB,MAAM,IAAIO,MAAM,yBAADC,OAA0BR,IAE3C,OAAO6gE,GAAa9gE,EAAO,EAAG,EAAGC,EAAOmc,EAC1C,ICWO,MAAM+kD,GAAgBvtC,GAAG,CAACwtC,eAXjC,SACIphE,GACoB,IADAqhE,EAAMr+D,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,EAAGs+D,EAAMt+D,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,EACzCoZ,EAAoBpZ,UAAAnC,OAAA,EAAAmC,UAAA,QAAAC,EACtB,MAAM4mB,EAAMtH,GAAOviB,EAF2BgD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAkB,WAG1DhC,EAAS,IAAIw/D,GAAca,EAAQC,EAAQ,KAAMllD,GACvD,IAAK,IAAIpa,EAAI,EAAGA,EAAI6nB,EAAI9pB,OAAOc,OAAQmB,IACrC6nB,EAAI9pB,OAAOiC,GAAKhB,EAAO6+D,YAEzB,OAAOh2C,EAAIhI,UACb,ICZM,SAAU6+C,GACZl4D,EAAe4sC,GACqB,IADPmsB,EAAIv+D,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,EACpC/C,EAAA+C,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAA2B,UAC7B,GAAa,IAATu+D,EACF,MAAM,IAAI/gE,MAAM,8BAGlB,MAAM+pB,EAAoB,CAAC/hB,QAAO4sC,OAAMmsB,OAAMthE,SAE9C,OAAOgqB,GAAOC,UAAU5U,GAAO,CAAC,EAAgBiV,EAClD,CCPO,MAAMi3C,GAAa5tC,GAAG,CAAC6tC,YAN9B,SAAuCngE,GACrC,MAEM6c,EAA2B,CAAC7c,EAFvB2xB,GAAgB3xB,EAAG,IAAK,eAGnC,OAAO2oB,GAAOC,UAAU1U,GAAY2I,EACtC,ICIO,MAAMujD,GAAO9tC,GAAG,CAAC+tC,MARxB,SAAiCrgE,GAC/B,MAEM6c,EAAqB,CAAC7c,EAFjB2xB,GAAgB3xB,EAAG,IAAK,SAInC,OAAO2oB,GAAOC,UAAUzU,GAAM0I,EAChC,ICEO,MAAMyjD,GAAQhuC,GAAG,CAACiuC,OARzB,SAAkCvgE,GAChC,MAEM6c,EAAsB,CAAC7c,EAFlB2xB,GAAgB3xB,EAAG,IAAK,UAInC,OAAO2oB,GAAOC,UAAUnU,GAAOoI,EACjC,ICwBO,MAAMivB,GAAUxZ,GAAG,CAACkuC,SAX3B,SACIxgE,EAAiB0E,GACnB,MAEMmY,EAAwB,CAAC7c,EAFpB2xB,GAAgB3xB,EAAG,IAAK,YAG7BipB,EAAsB,CAAC4jB,KAAMnoC,GAEnC,OAAOikB,GAAOC,UACVlU,GAASmI,EAAgCoM,EAC/C,IC9BO,MAAMw3C,GAAYnuC,GAAG,CAACouC,WAR7B,SAAoB1gE,GAClB,MAAMgiC,EAAKrQ,GAAgB3xB,EAAG,IAAK,WAInC,OAHAid,EACgB,IAAZ+kB,EAAGr9B,KACH,IAAM,qDAANxF,OAA2D6iC,EAAGr9B,KAAI,MAC/DmnC,GAAQ9J,EAAI,EACrB,ICIO,MAAM2+B,GAAYruC,GAAG,CAACsuC,WAR7B,SAAoB5gE,EAAwB0E,GAC1C,MAAMs9B,EAAKrQ,GAAgB3xB,EAAG,IAAK,WAInC,OAHAid,EACgB,IAAZ+kB,EAAGr9B,KACH,IAAM,qDAANxF,OAA2D6iC,EAAGr9B,KAAI,MAC/DmnC,GAAQ9J,EAAIt9B,EACrB,ICEO,MAAMm8D,GAAYvuC,GAAG,CAACwuC,WAR7B,SAAoB9gE,EAAwB0E,GAC1C,MAAMs9B,EAAKrQ,GAAgB3xB,EAAG,IAAK,WAInC,OAHAid,EACgB,IAAZ+kB,EAAGr9B,KACH,IAAM,qDAANxF,OAA2D6iC,EAAGr9B,KAAI,MAC/DmnC,GAAQ9J,EAAIt9B,EACrB,ICEO,MAAMq8D,GAAYzuC,GAAG,CAAC0uC,WAR7B,SAAoBhhE,EAAwB0E,GAC1C,MAAMs9B,EAAKrQ,GAAgB3xB,EAAG,IAAK,WAInC,OAHAid,EACgB,IAAZ+kB,EAAGr9B,KACH,IAAM,qDAANxF,OAA2D6iC,EAAGr9B,KAAI,MAC/DmnC,GAAQ9J,EAAIt9B,EACrB,ICSO,MAAMsX,GAAQsW,GAAG,CAAC2uC,OAPzB,SAAkCjhE,GAChC,MACM6c,EAAsB,CAAC7c,EADlB2xB,GAAgB3xB,EAAG,IAAK,UAGnC,OAAO2oB,GAAOC,UAAUjU,GAAOkI,EACjC,ICEO,MAAMqkD,GAAQ5uC,GAAG,CAAC6uC,OAPzB,SAAkCnhE,GAChC,MAEM6c,EAAsB,CAAC7c,EAFlB2xB,GAAgB3xB,EAAG,IAAK,QAAS,YAI5C,OAAO2oB,GAAOC,UAAUhU,GAAOiI,EACjC,ICGO,MAAMukD,GAAO9uC,GAAG,CAAC+uC,MARxB,SAAiCrhE,GAC/B,MAEM6c,EAAqB,CAAC7c,EAFjB2xB,GAAgB3xB,EAAG,IAAK,SAInC,OAAO2oB,GAAOC,UAAU5T,GAAM6H,EAChC,IC4FO,MAAMykD,GAAkBhvC,GAAG,CAACivC,iBAnEnC,SACIvhE,EAAiBwhE,EACjBC,EAAsCr6D,EACtC+X,GACkC,IADb0nC,EAAAnlD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAoC,CAAC,EAAG,GAC7DyhD,EAAAzhD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAA4B,OAC9B,MAAMsgC,EAAKrQ,GAAgB3xB,EAAG,IAAK,mBAC7B0hE,EACF/vC,GAAgB6vC,EAAiB,kBAAmB,mBAClDG,EACFhwC,GAAgB8vC,EAAiB,kBAAmB,mBAExD,IAAI9Z,EAAM3lB,EACN4lB,GAAe,EAMnB,GALgB,IAAZ5lB,EAAGr9B,OACLijD,GAAe,EACfD,EAAML,GAAQtlB,EAAI,CAAC,EAAGA,EAAGtjC,MAAM,GAAIsjC,EAAGtjC,MAAM,GAAIsjC,EAAGtjC,MAAM,MAGxC,SAAfykD,EACF,MAAM,IAAIjkD,MACN,sFAIN+d,EACiB,IAAb0qC,EAAIhjD,KACJ,IAAM,mEAAAxF,OACMwoD,EAAIhjD,KAAI,MACxBsY,EAC8B,IAA1BykD,EAAiB/8D,KACjB,IAAM,8EAAAxF,OACUuiE,EAAiB/8D,KAAI,MACzCsY,EAC8B,IAA1B0kD,EAAiBh9D,KACjB,IAAM,8EAAAxF,OACUuiE,EAAiB/8D,KAAI,MACzCsY,EACkC,IAA9B0kD,EAAiBjjE,MAAM,GACvB,IACI,4FAAAS,OACuBwiE,EAAiBjjE,MAAM,GAAE,MACxDue,EACkC,IAA9B0kD,EAAiBjjE,MAAM,GACvB,IAAM,4FAAAS,OAC2BwiE,EAAiBjjE,MAAM,GAAE,MAE9D,MAAM4lD,EAAaod,EAAiBhjE,MAAM,GACpCkjE,EAAoBF,EAAiBhjE,MAAM,GACjDue,EACI0kD,EAAiBjjE,MAAM,KAAO4lD,EAAasd,EAC3C,IACI,gFAAAziE,OACWmlD,EAAasd,EAAiB,MAAI,WAAAziE,OAClCwiE,EAAiBjjE,MAAM,GAAE,MAE5C,MAAMwlD,EAAY2K,GACdlH,EAAK+Z,EAAkBt6D,EAAS+X,EAAKgkC,EAAY0D,GAE/Ct+B,EACF6jC,GAAOlI,EAAWyd,EAFE,EAEiC,QAASxe,GAElE,OAAIyE,EACKN,GAAQ/+B,EAAK,CAACA,EAAI7pB,MAAM,GAAI6pB,EAAI7pB,MAAM,GAAI6pB,EAAI7pB,MAAM,KAEtD6pB,CACT,IChDO,MAAMs5C,GAtCbruC,eACIxzB,EAAsBya,GACxB,MAAMunB,EAAKrQ,GAAgB3xB,EAAG,IAAK,aAC7Bk4D,EAAKvmC,GAAgBlX,EAAG,IAAK,aAEnCwC,EACI+kB,EAAGrjC,QAAUu5D,EAAGv5D,MAChB,IAAM,kDAANQ,OACI6iC,EAAGrjC,MAAK,aAAAQ,OAAY+4D,EAAGv5D,MAAK,OAEpCse,EACgB,IAAZ+kB,EAAGr9B,KAAY,IAAM,qCAANxF,OAA2C6iC,EAAGtjC,MAAK,OAEtEue,EACgB,IAAZi7C,EAAGvzD,KAAY,IAAM,qCAANxF,OAA2C+4D,EAAGx5D,MAAK,OAEtE,MAAMojE,QAAc9/B,EAAGjlC,OACjBglE,QAAc7J,EAAGn7D,OACjBilE,EAAO,IAAIl+C,IAAIi+C,GAErB,IAAI3wB,EAAa,EACjB,IAAK,IAAI1wC,EAAI,EAAGA,EAAIohE,EAAMviE,OAAQmB,IAC3BshE,EAAK3kE,IAAIykE,EAAMphE,KAClB0wC,IAIJ,MAAMnwB,EAAS,IAAId,GAAa,CAACixB,GAAapP,EAAGrjC,OAC3CyyB,EAAU,IAAIjR,GAAa,CAACixB,GAAa,SAC/C,IAAK,IAAI1wC,EAAI,EAAGuzB,EAAI,EAAGvzB,EAAIohE,EAAMviE,OAAQmB,IAClCshE,EAAK3kE,IAAIykE,EAAMphE,MAClBugB,EAAOxiB,OAAOw1B,GAAK6tC,EAAMphE,GACzB0wB,EAAQ3yB,OAAOw1B,GAAKvzB,EACpBuzB,KAGJ,MAAO,CAAChT,EAAOV,WAAY6Q,EAAQ7Q,WACrC,EC5CO,MAAM0hD,GAAO3vC,GAAG,CAAC4vC,MALxB,SAAiCliE,GAC/B,MACM6c,EAAqB,CAAC7c,EADjB2xB,GAAgB3xB,EAAG,IAAK,SAEnC,OAAO2oB,GAAOC,UAAUxT,GAAMyH,EAChC,ICGO,MAAMslD,GAAM7vC,GAAG,CAAC8vC,KAPvB,SAAgCpiE,GAC9B,MAEM6c,EAAoB,CAAC7c,EAFhB2xB,GAAgB3xB,EAAG,IAAK,MAAO,YAI1C,OAAO2oB,GAAOC,UAAU1T,GAAK2H,EAC/B,ICAO,MAAMwlD,GAAO/vC,GAAG,CAACgwC,MANxB,SAAiCtiE,GAC/B,MACM6c,EAAqB,CAAC7c,EADjB2xB,GAAgB3xB,EAAG,IAAK,SAGnC,OAAO2oB,GAAOC,UAAUzT,GAAM0H,EAChC,ICLO,MAAM0lD,GAAUjwC,GAAG,CAACkwC,SAT3B,SACIxiE,EAAwBwxC,EAAenvC,GACzC,MAAM2/B,EAAKrQ,GAAgB3xB,EAAG,IAAK,WAKnC,OAJAid,EACgB,IAAZ+kB,EAAGr9B,KACH,uDAAAxF,OACuD6iC,EAAGr9B,KAAI,YAC3DH,GAAMw9B,EAAI,CAACwP,GAAQ,CAACnvC,GAC7B,ICEO,MAAMogE,GAAUnwC,GAAG,CAACowC,SAV3B,SACI1iE,EAAwBwxC,EACxBnvC,GACF,MAAM2/B,EAAKrQ,GAAgB3xB,EAAG,IAAK,WAKnC,OAJAid,EACgB,IAAZ+kB,EAAGr9B,KACH,uDAAAxF,OACuD6iC,EAAGr9B,KAAI,YAC3DH,GAAMw9B,EAAIwP,EAAOnvC,EAC1B,ICCO,MAAMsgE,GAAUrwC,GAAG,CAACswC,SAV3B,SACI5iE,EAAwBwxC,EACxBnvC,GACF,MAAM2/B,EAAKrQ,GAAgB3xB,EAAG,IAAK,WAKnC,OAJAid,EACgB,IAAZ+kB,EAAGr9B,KACH,uDAAAxF,OACuD6iC,EAAGr9B,KAAI,YAC3DH,GAAMw9B,EAAIwP,EAAOnvC,EAC1B,ICCO,MAAMwgE,GAAUvwC,GAAG,CAACwwC,SAV3B,SACI9iE,EAAwBwxC,EACxBnvC,GACF,MAAM2/B,EAAKrQ,GAAgB3xB,EAAG,IAAK,WAKnC,OAJAid,EACgB,IAAZ+kB,EAAGr9B,KACH,uDAAAxF,OACuD6iC,EAAGr9B,KAAI,YAC3DH,GAAMw9B,EAAIwP,EAAOnvC,EAC1B,IC6BO,MAAM0zD,GAAUzjC,GAAG,CAACywC,SAnB3B,SAAoCpN,GAA8B,IAAR7oB,EAAGprC,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,IAAI,EAC/D,MAAMk0D,EAAUjkC,GAAgBgkC,EAAQ,SAAU,UAAW,WAK7D,IAHa,IAAT7oB,IACFA,EAAM8oB,EAAQjxD,KAAO,GAEnBmoC,IAAQ8oB,EAAQjxD,KAAO,EACzB,MAAMzF,MACF,4DAA2D,mBAAAC,OACxCy2D,EAAQjxD,KAAI,iBAAAxF,OAAgB2tC,IAGrD,MAAMjwB,EAAwB,CAAC84C,OAAQC,GACjC3sC,EAAsB,CAAC6jB,OAE7B,OAAOnkB,GAAOC,UACVjT,GAASkH,EAAgCoM,EAC/C,ICbO,MAAM+5C,GAAM1wC,GAAG,CAAC2wC,KAXvB,SAAc/kD,GACZ/c,EACoB,cAAhB+c,EAAMvf,MACN,IAAM,gEAAAQ,OACS+e,EAAMvf,MAAK,MAE9B,MAAMke,EAAoB,CAACqB,SAE3B,OAAOyK,GAAOC,UAAUvY,GAAKwM,EAC/B,ICEO,MAAMqmD,GAAO5wC,GAAG,CAAC6wC,MAXxB,SAAejlD,GACb/c,EACoB,cAAhB+c,EAAMvf,MACN,IAAM,iEAAAQ,OACS+e,EAAMvf,MAAK,MAE9B,MAAMke,EAAqB,CAACqB,SAE5B,OAAOyK,GAAOC,UAAU5X,GAAM6L,EAChC,ICmCO,MAAMumD,GAAQ9wC,GAAG,CAAC+wC,OArCzB,SAAgBnlD,GACd,MAAMolD,EAAqBplD,EAAMxf,MAAMwf,EAAMxf,MAAMa,OAAS,GACtDgkE,EAAQrlD,EAAM7b,KAAOihE,EAC3B,IAAI97D,EACJ,GAAI87D,GAAsB,EAAG,CAC3B,MAAME,EAAelc,GAAQppC,EAAO,CAACqlD,EAAOD,IAC5C97D,EAAM07D,GAAKM,E,KACN,CAGL,MAAMrW,EAAc,CAACoW,EAAO,GAAKD,EAAqB,IAChDG,EAAYnc,GAAQx0B,GAAK5U,GAAQ,CAACqlD,EAAOD,IACzCI,EAAYpc,GAAQv0B,GAAK7U,GAAQ,CAACqlD,EAAOD,IAEzCK,EACF73B,GAAQtnC,GAAMi/D,EAAW,CAAC,EAAG,GAAI,CAACF,EAAOD,EAAqB,IAAK,GACjEM,EAA0BtpD,GAC5BwxB,GAAQtnC,GAAMk/D,EAAW,CAAC,EAAG,GAAI,CAACH,EAAOD,EAAqB,IAAK,GACnE5nB,IAAQ,IAEN56C,EAAI3B,GAAO,CAACskE,EAAWE,GAAgB,GACvCjjE,EAAIvB,GAAO,CAACukE,EAAWE,GAAgB,GACvCJ,EACFlc,GAAQ10B,GAAQ9xB,EAAGJ,GAAI,CAACysD,EAAY,GAAIA,EAAY,KACxD3lD,EAAM07D,GAAKM,E,CAIb,GAFAh8D,EAAMsrB,GAAKtrB,GAEQ,IAAf0W,EAAMvZ,MAAiC,IAAnBuZ,EAAMxf,MAAM,GAAU,CAC5C,MAAM6B,EAAOiH,EACP+7D,EAAQrlD,EAAMxf,MAAM,GAC1B8I,EAAM8/C,GAAQ9/C,EAAK,CAAC+7D,EAAO/7D,EAAI9I,MAAM,GAAK6kE,EAAO/7D,EAAI9I,MAAM,KAC3D6B,EAAKvB,S,CAEP,OAAOwI,CACT,ICVO,MAAMsD,GAAQwnB,GAAG,CAACuxC,OAZzB,SACI7jE,EAAsB8jE,GAA0C,IAARp/D,EAAIhD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,EACjE,MAEMmb,EAAuB,CAAC7c,EAFnB2xB,GAAgB3xB,EAAG,IAAK,UAG7BkoD,EAAoB,CAAC4b,kBAAiBp/D,QAE5C,OAAOikB,GAAOC,UACHlT,GAAQmH,EACRqrC,EACb,IC2BO,MAAM6b,GAAOzxC,GAAG,CAAC0xC,MAnDxB,SAAe9lD,EAAe+lD,GAC5B9iE,EACoB,YAAhB+c,EAAMvf,MACN,IAAM,mDAANQ,OAAyD+e,EAAMvf,QAEnE,IAAI2kE,EAAqBplD,EAAMxf,MAAMwf,EAAMxf,MAAMa,OAAS,GAC1D,MAAMgkE,EAAQrlD,EAAM7b,KAAOihE,EAE3B,IAAIY,EACJ,GAAiB,MAAbD,GAAqBA,EAAYX,EAAoB,CAEvD,MAAM9xB,EAAQtzB,EAAMxf,MAAMkG,IAAIyV,GAAK,GAC7BhY,EAAO6b,EAAMxf,MAAMkG,IAAIyV,GAAKA,GAClChY,EAAK6b,EAAMxf,MAAMa,OAAS,GAAK0kE,EAC/BC,EAAgB1/D,GAAM0Z,EAAOszB,EAAOnvC,GACpCihE,EAAqBW,C,MAChB,GAAiB,MAAbA,GAAqBA,EAAYX,EAAoB,CAE9D,MAAMa,EAAajmD,EAAMxf,MAAMkG,IAAIyV,GAAKA,GACxC8pD,EAAWjmD,EAAMxf,MAAMa,OAAS,GAAK0kE,EAAYX,EACjDY,EAAgB/kE,GAAO,CAAC+e,EAAO2xC,GAAMsU,IAAcjmD,EAAMxf,MAAMa,OAAS,GACxE+jE,EAAqBW,C,MAErBC,EAAgBhmD,EAIlB,MAAMkmD,EAAaxpB,GAAUspB,GACvBV,EACFlc,GAAQ10B,GAAQsxC,EAAeE,GAAa,CAACb,EAAOD,IAElD97D,EAAMw7D,GAAIQ,GAGVa,EAAO5kE,KAAKkJ,MAAM26D,EAAqB,GAAK,EAC5CgB,EAAaxxC,GAAKtrB,GAClB+8D,EAAaxxC,GAAKvrB,GAClBg9D,EAAuB15D,GACzBw5D,EAAY,CAACD,EAAMf,EAAqBe,GACxCC,EAAW5lE,MAAMa,OAAS,GACxBklE,EAAuB35D,GACzBy5D,EAAY,CAACF,EAAMf,EAAqBe,GACxCE,EAAW7lE,MAAMa,OAAS,GAExB4tD,EAAc+W,EAAcxlE,MAAM8F,QAGxC,OAFA2oD,EAAY+W,EAAcxlE,MAAMa,OAAS,GAAK8kE,EAEvC/c,GACH10B,GAAQ4xC,EAAqB,GAAIC,EAAqB,IAAKtX,EACjE,IC7BO,MAAMuX,GAAoBpyC,GAAG,CAACqyC,mBAfrC,SACI/jE,EAAsBC,GACxB,IAAI4pC,EAAK9Y,GAAgB/wB,EAAG,IAAK,qBAC7B8pC,EAAK/Y,GAAgB9wB,EAAG,IAAK,sBAChC4pC,EAAIC,GAAMrnB,GAAeonB,EAAIC,GAE9B0C,GAA2B3C,EAAG/rC,MAAOgsC,EAAGhsC,OAExC,MAAMme,EAAkC,CAACjc,EAAG6pC,EAAI5pC,EAAG6pC,GAGnD,OAAO/hB,GAAOC,UACV3S,GAAmB4G,EAHT,CAAC,EAIjB,ICpBO,MAAM+nD,GAAUtyC,GAAG,CAACuyC,SAL3B,SAAoC7kE,EAAsB0E,GACxD,MAAMs9B,EAAKrQ,GAAgB3xB,EAAG,IAAK,UAAW,qBAC9C,OAAOsnD,GAAQtlB,EAAIh9B,GAAag9B,EAAGtjC,MAAOgG,GAAMH,SAClD,ICoBO,MAAMmjB,GAAQ4K,GAAG,CAACwyC,OApBzB,SACIp6C,GAAsC,IAARhmB,EAAIhD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,EACvC,MAAMmgD,EACF7vB,GAAqBtH,EAAS,UAAW,QAAS,qBAEtDzN,EACI4kC,EAAStiD,QAAU,EAAG,IAAM,wCAE5BsiD,EAAStiD,OAAS,GACpB0d,EACIvY,GAAQm9C,EAAS,GAAGl9C,KAAM,IAAM,sCAGtC,MAAMkY,EAAqBglC,EACrB54B,EAAmB,CAACvkB,QAE1B,OAAOikB,GAAOC,UACVpV,GAAMqJ,EAAgCoM,EAC5C,ICZO,MAAMg3C,GAAO3tC,GAAG,CAACyyC,MATxB,SAAiC/kE,GAA4B,IAAXs0D,EAAK5yD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,EACxD,MAEMmb,EAAqB,CAAC7c,EAFjB2xB,GAAgB3xB,EAAG,IAAK,SAG7BipB,EAAmB,CAACqrC,SAE1B,OAAO3rC,GAAOC,UACVzR,GAAM0F,EAAgCoM,EAC5C,ICmCO,MAAM+7C,GAAe1yC,GAAG,CAAC2yC,cAvBhC,SACIjlE,EAAsBwxC,EAAiBj2B,EAAenU,GAEpC,IADlBorC,EAAS9wC,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,EAAG+wC,EAAO/wC,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,EAAGgxC,EAAYhxC,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,EAAG+yC,EAAW/yC,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,EAC5DgzC,EAAchzC,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,EACnB,MAEMmb,EAA6B,CAAC7c,EAFzB2xB,GAAgB3xB,EAAG,IAAK,eAAgB,sBAG7CipB,EAA2B,CAC/BuoB,QACAj2B,MACAnU,UACAorC,YACAC,UACAC,eACA+B,cACAC,kBAGF,OAAO/rB,GAAOC,UACVzS,GAAc0G,EACdoM,EACN,ICpCO,MAAMi8C,GAAM5yC,GAAG,CAAC6yC,KAPvB,SAAgCnlE,GAC9B,MAEM6c,EAAoB,CAAC7c,EAFhB2xB,GAAgB3xB,EAAG,IAAK,MAAO,YAI1C,OAAO2oB,GAAOC,UAAUpS,GAAKqG,EAC/B,ICJM,SAAUuoD,GAAS3mE,EAAsBE,GAC7CkD,EAAcpD,GACd,MAAMszB,EAAgBd,GAAWxyB,EAAQE,GACzC,GAA6B,IAAzBozB,EAAcxyB,OAChB,MAAM,IAAIL,MAAM,sDAGlB,OAAOuhB,GAAWhiB,EADM,KACSszB,EAAepzB,EAClD,CCDM,SAAU0mE,GACZ5mE,EAAsBC,EACtBC,GAEF,GADAkD,EAAcpD,GACD,MAATC,GAAkC,IAAjBA,EAAMa,OACzB,MAAM,IAAIL,MAAM,iDAElB,MAAM6yB,EAAgBd,GAAWxyB,EAAQE,GACzC,GAA6B,IAAzBozB,EAAcxyB,QAAyC,IAAzBwyB,EAAcxyB,OAC9C,MAAM,IAAIL,MACN,kEAEN,GAA6B,IAAzB6yB,EAAcxyB,QAAyB,MAATb,EAChC,MAAM,IAAIQ,MACN,gFAGN,OAAOuhB,GAAWhiB,EAAQC,EAAOqzB,EAAepzB,EAClD,CClBM,SAAU2mE,GACZ7mE,EAAsBC,EACtBC,GAEF,GADAkD,EAAcpD,GACD,MAATC,GAAkC,IAAjBA,EAAMa,OACzB,MAAM,IAAIL,MAAM,kDAElB,MAAM6yB,EAAgBd,GAAWxyB,EAAQE,GACzC,GAA6B,IAAzBozB,EAAcxyB,QAAyC,IAAzBwyB,EAAcxyB,OAC9C,MAAM,IAAIL,MACN,sEAEN,GAA6B,IAAzB6yB,EAAcxyB,QAAyB,MAATb,EAChC,MAAM,IAAIQ,MACN,2EAGN,OAAOuhB,GAAWhiB,EAAQC,EAAOqzB,EAAepzB,EAClD,CClBM,SAAU4mE,GACZ9mE,EAAsBC,EACtBC,GAEF,GADAkD,EAAcpD,GACD,MAATC,GAAkC,IAAjBA,EAAMa,OACzB,MAAM,IAAIL,MAAM,kDAElB,MAAM6yB,EAAgBd,GAAWxyB,EAAQE,GACzC,GAA6B,IAAzBozB,EAAcxyB,QAAyC,IAAzBwyB,EAAcxyB,OAC9C,MAAM,IAAIL,MACN,wEAGN,GAA6B,IAAzB6yB,EAAcxyB,QAAyB,MAATb,EAChC,MAAM,IAAIQ,MACN,2EAGN,OAAOuhB,GAAWhiB,EAAQC,EAAOqzB,EAAepzB,EAClD,CCnBM,SAAU6mE,GACZ/mE,EACAC,EACAC,GAEF,GADAkD,EAAcpD,GACD,MAATC,GAAkC,IAAjBA,EAAMa,OACzB,MAAM,IAAIL,MAAM,iDAElB,MAAM6yB,EAAgBd,GAAWxyB,EAAQE,GACzC,GAA6B,IAAzBozB,EAAcxyB,QAAyC,IAAzBwyB,EAAcxyB,OAC9C,MAAM,IAAIL,MACN,0EAGN,GAA6B,IAAzB6yB,EAAcxyB,QAAyB,MAATb,EAChC,MAAM,IAAIQ,MACN,2EAKN,OAAOuhB,GAAWhiB,EAFlBC,EAAQA,GACJqzB,EAC6BA,EAAepzB,EAClD,CCSO,MAAM8mE,GAAOnzC,GAAG,CAACozC,MA3BxB,SACI1lE,GAAqC,IAApBmkB,EAACziB,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,EAAGikE,IAAMjkE,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,KAAAA,UAAA,GAChC,MAAMsgC,EAAKrQ,GAAgB3xB,EAAG,IAAK,QACnC,GAAgB,IAAZgiC,EAAGr9B,KACL,MAAM,IAAIzF,MAAM,sDAElB,MAAM0mE,EAAU5jC,EAAGtjC,MAAMsjC,EAAGtjC,MAAMa,OAAS,GAE3C,GAAI4kB,EAAI,EACN,MAAM,IAAIjlB,MAAM,6CAADC,OAA8CglB,IAG/D,GAAIA,EAAIyhD,EACN,MAAM,IAAI1mE,MACN,uDAAAC,OAAuDymE,EAAO,iBAAAzmE,OACnDglB,IAGjB,MAAMtH,EAAqB,CAAC7c,EAAGgiC,GACzB/Y,EAAmB,CAAC9E,IAAGwhD,WAEtBlnE,EAAQ2yB,GAAWzI,GAAOC,UAC7BjS,GAAMkG,EAAgCoM,GAE1C,MAAO,CAACxqB,SAAQ2yB,UAClB,ICjBO,MAAMy0C,GAAkBvzC,GAAG,CAACwzC,iBAfnC,SACIpnE,GACa,IADOmrD,EAAInoD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,EAAGq8D,EAAMr8D,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,EAAG/C,EAAyB+C,UAAAnC,OAAA,EAAAmC,UAAA,QAAAC,EACnEmZ,EAAapZ,UAAAnC,OAAA,EAAAmC,UAAA,QAAAC,EACf,GAAa,MAAThD,GAAyC,SAAvBA,EACpB,MAAM,IAAIO,MAAM,qCAElB,MAAMwgE,EACF,IAAI9B,GAAY/T,EAAMkU,EAAQp/D,GAAO,EAAsBmc,GACzDyN,EAAMtH,GAAOviB,EAAOC,GAC1B,IAAK,IAAI+B,EAAI,EAAGA,EAAI6nB,EAAI9pB,OAAOc,OAAQmB,IACrC6nB,EAAI9pB,OAAOiC,GAAKg/D,EAAUnB,YAE5B,OAAOh2C,EAAIhI,UACb,ICiCO,MAAMwlD,GAASzzC,GAAG,CAAC0zC,QAb1B,SACIhmE,GAAyB,IAAR0E,EAAIhD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,EAC1B,MAAMsgC,EAAKrQ,GAAgB3xB,EAAG,IAAK,SAAU,qBAC7CmB,EAAO6gC,EAAGr9B,KAAO,EAAG,IAAM,wCAE1B,MAAMkY,EAAuB,CAAC7c,EAAGgiC,GAC3B/Y,EAAqB,CAACvkB,SACrBjG,EAAQ2yB,GAAWzI,GAAOC,UACH9R,GAAQ+F,EACRoM,GAC9B,MAAO,CAACxqB,SAAQ2yB,UAClB,IC3BO,MAAM60C,GAAqB3zC,GAAG,CAAC4zC,oBAftC,SACIlmE,EAAiBmmE,EAAiCC,GACpD,MAAMpkC,EAAKrQ,GAAgB3xB,EAAG,IAAK,sBAC7BqmE,EACF10C,GAAgBw0C,EAAY,aAAc,qBAAsB,SACpEhlE,EAAOsB,GAAM2jE,GAAc,IAAM,oCAEjC,MAAMvpD,EAAmC,CAAC7c,EAAGgiC,EAAImkC,WAAYE,GACvDp9C,EAAiC,CAACm9C,eAExC,OAAOz9C,GAAOC,UACV5R,GAAoB6F,EACpBoM,EACN,ICHO,MAAMq9C,GAAUh0C,GAAG,CAACi0C,SAd3B,SAAkBvmE,GAA8B,IAAR0E,EAAIhD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,EAC7C,MAAMsgC,EAAKrQ,GAAgB3xB,EAAG,IAAK,UAAW,qBAC9Cid,EACIvY,IAASs9B,EAAGtjC,MAAMa,QAAUmF,EAAOs9B,EAAGtjC,MAAMa,OAC5C,cAAAJ,OACcuF,EAAI,iBAAAvF,OAAgB6iC,EAAGtjC,MAAMa,OAAM,MAAAJ,OAAK6iC,EAAGtjC,MAAMa,OAAM,MAEzE,MAAMsd,EAAuB,CAACrf,MAAOwkC,GAC/B/Y,EAAqB,CAACvkB,QAE5B,OAAOikB,GAAOC,UACV7R,GAAQ8F,EAAgCoM,EAC9C,ICCM,SAAUu9C,GACZ3P,EAAmCp4D,GACrC,OAAOk4D,GAAaE,EAAgBp4D,EAAQ,QAC9C,CCrBM,SAAUmjB,GACZQ,GACgB,IADSP,IAASngB,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,KAAAA,UAAA,GAAS+J,EAAa/J,UAAAnC,OAAA,EAAAmC,UAAA,QAAAC,EACxDhD,EAAgB+C,UAAAnC,OAAA,EAAAmC,UAAA,QAAAC,EAClB,OAAOgnB,GAAO7G,aAAaM,EAAcP,EAAWpW,EAAM9M,EAE5D,CCnBM,SAAU8nE,GAAUC,EAAqBC,GAC7C,MAAMv1C,EAAU,GAChB,IAAK,IAAI1wB,EAAI,EAAGA,EAAIimE,EAASpnE,OAAQmB,IAC/BimE,EAASjmE,IACX0wB,EAAQjvB,KAAKzB,GAIjB,MAAMkmE,EAAW3lD,GAAOylD,EAAW,SAE7B18C,EAAM/I,GAAO,CAACmQ,EAAQ7xB,OAAQmnE,EAAUnnE,QAAS,SACvD,IAAK,IAAImB,EAAI,EAAGA,EAAI0wB,EAAQ7xB,OAAQmB,IAAK,CACvC,MAAM4f,EAAMsmD,EAASl+D,WAAW0oB,EAAQ1wB,IAClC4G,EAAS5G,EAAIgmE,EAAUnnE,OAC7ByqB,EAAIvrB,OAAOlB,IAAI+iB,EAAKhZ,E,CAEtB,OAAO0iB,EAAIzJ,UACb,CCYO,MAAMsmD,GAXbrzC,eAA2B+7B,GACzB,MAAMC,EACF79B,GAAgB49B,EAAW,YAAa,aAAc,QACpD3pD,QAAa4pD,EAAWzyD,OACxBwrB,EAAMk+C,GAAUjX,EAAW9wD,MAAOkH,GAIxC,OAHI2pD,IAAcC,GAChBA,EAAWxwD,UAENupB,CACT,ECuCO,MAAMu+C,GA5CbtzC,eACIhQ,EAA2BkuB,EAC3BhtC,GACF,MAAMqiE,EAAUp1C,GAAgBnO,EAAQ,SAAU,YAC5CwjD,EAAQr1C,GAAgB+f,EAAM,OAAQ,WAAY,QAElDu1B,EAAmB,MAARviE,EAAe,EAAIA,EAC9BwiE,EAAUF,EAAMriE,KAChBwiE,EAAcJ,EAAQroE,MAE5Bue,EAAYiqD,EAAU,EAAG,IAAM,yBAC/BjqD,EACIkqD,EAAY3iE,MAAMyiE,EAAUA,EAAWC,GAAUF,EAAMtoE,MAAK,qEAGhE,IAAI0oE,EAAc,EAClB,IAAK,IAAI1mE,EAAIumE,EAAUvmE,EAAIumE,EAAWC,EAASxmE,IAC7C0mE,GAAeD,EAAYzmE,GAE7B,MAAM2mE,EACFF,EAAY3iE,MAAM,EAAGyiE,GAChB9nE,OAAO,CAACioE,GAAcD,EAAY3iE,MAAMyiE,EAAWC,IACtDI,EAAiBhgB,GAAQyf,EAASM,GAClCE,EAAejgB,GAAQ0f,EAAO,EAAE,IAChCQ,QAA0BX,GAAWU,GACrCn2C,EAAUwzC,GAAQ4C,EAAmB,CAAC,IAEtCj/C,EAAMkrC,GAAO6T,EAAgBl2C,EAAS61C,GAc5C,OAXIzjD,IAAWujD,GACbA,EAAQ/nE,UAEN0yC,IAASs1B,GACXA,EAAMhoE,UAERoyB,EAAQpyB,UACRsoE,EAAetoE,UACfuoE,EAAavoE,UACbwoE,EAAkBxoE,UAEXupB,CACT,ECJO,MAAMk/C,GAAgBn1C,GAAG,CAACo1C,eAxBjC,SACIrtD,EAAiBra,EAAiBm/C,EAClC8gB,GAAuC,IAAjB0H,IAAUjmE,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,KAAAA,UAAA,GAClC,MAAMkmE,EAAKj2C,GAAgBtX,EAAG,IAAK,iBAC7B2nB,EAAKrQ,GAAgB3xB,EAAG,IAAK,iBAC7B6nE,EAASl2C,GAAgBwtB,EAAO,QAAS,iBAE/C77B,GAAiBskD,EAAI5lC,GACrB/kB,EACIA,GAAiB2qD,EAAGlpE,MAAOsjC,EAAGtjC,OAAQ,IAAM,6BAEhD,MAAMopE,EAAMpsB,GAAO,GACbqsB,EAAgBlqB,GAAIiqB,EAAKD,GAE/B,IAAIG,EAAS1tD,GAAIujC,GAAI7b,EAAI4lC,GAAKG,GAC9B,GAAIJ,EAAY,CACd1qD,EACY,MAARgjD,EAAc,IAAM,kDACxB,MAAMgI,EAAQt2C,GAAgBsuC,EAAM,OAAQ,iBAC5C+H,EAAS1tB,GAAI0tB,EAAQnqB,GAAIiqB,EAAKrqB,GAAIoqB,EAAQI,I,CAE5C,OAAOttD,GAAIitD,EAAII,EACjB,IClBO,MAAME,GAAY51C,GAAG,CAAC61C,WAhB7B,SACI/2C,EAA4Buf,EAC5BjyC,GACF,MAAM0pE,EAAWz2C,GAAgBP,EAAS,UAAW,YAAa,SAC5Di3C,EAAW12C,GAAgBgf,EAAS,UAAW,aACrD23B,GAA8BD,EAAUD,EAAU1pE,GAElD,MAAMme,EAA0B,CAACuU,QAASg3C,EAAUz3B,QAAS03B,GACvDp/C,EAAwB,CAACvqB,SAG/B,OAAOiqB,GAAOC,UACH/T,GAAWgI,EACXoM,EACb,IC+BO,MAAMs/C,GAAgBj2C,GAAG,CAACk2C,eA1BjC,SACIC,EAAkCC,EAClCvb,GAA6D,IAAnCkQ,EAAA37D,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAkC,EAC9D,MAAMinE,EACFh3C,GAAgB82C,EAAe,gBAAiB,gBAAiB,SAC/DG,EAAgBj3C,GAClB+2C,EAAc,eAAgB,gBAAiB,qBAC7CG,EAAgBl3C,GAClB0rC,EAAc,eAAgB,gBAAiBuL,EAAcjqE,QC3C7D,SACF8pE,EAAuBC,EAAsBvb,EAC7C2b,GACF,GAA4B,UAAxBL,EAAc9pE,MAChB,MAAM,IAAIO,MACN,2DAA0D,sBAAAC,OACpCspE,EAAc9pE,MAAK,MAE/C,GAAI8pE,EAAc9jE,KAAO,EACvB,MAAM,IAAIzF,MACN,uDAAsD,kBAAAC,OACpCspE,EAAc/pE,MAAK,MAG3C,MAAMqqE,EAAWN,EAAc9jE,KAAO,EAAI8jE,EAAc/pE,MAAM,GAAK,EAC7DsqE,EAAUP,EAAc9jE,KAAO,EAAI8jE,EAAc/pE,MAAM,GAAK,EAElE,GAAIyuD,EAAY5tD,SAAWypE,EACzB,MAAM,IAAI9pE,MACN,iDAAgD,IAAAC,OAC5CguD,EAAY5tD,OAAM,iBAAAJ,OAAgB6pE,EAAO,MAGnD,MAAMC,EAAYP,EAAarmE,KAC/B,GAA4B,IAAtBqmE,EAAa/jE,OACS,IAAtB+jE,EAAa/jE,MAAcskE,IAAcF,GAC7C,MAAM,IAAI7pE,MACN,oCAAmC,GAAAC,OAChCupE,EAAahqE,MAAK,uBAAAS,OAAsB4pE,EAAQ,MAGzD,GAAIL,EAAa/pE,QAAUmqE,EAAcnqE,MACvC,MAAM,IAAIO,MAAM,oDAEpB,CDWEgqE,CACIP,EAAgBC,EAAezb,EAAa0b,GAEhD,MAAMhsD,EAA8B,CAClC4rD,cAAeE,EACfD,aAAcE,EACdvL,aAAcwL,GAGV5/C,EAA4B,CAACkkC,eAEnC,OAAOxkC,GAAOC,UACV5S,GAAe6G,EACfoM,EACN,IEnBO,MAAMkgD,GAAW72C,GAAG,CAAC82C,UAT5B,SAAmBppE,EAAsBoxB,GACvC,MAAMg3C,EAAWz2C,GAAgBP,EAAS,UAAW,WAAY,SAG3DvU,EAAyB,CAACzR,OAFrBumB,GAAgB3xB,EAAG,IAAK,WAAY,qBAEHoxB,QAASg3C,GAErD,OAAOz/C,GAAOC,UAAUhY,GAAUiM,EACpC,ICSO,MAAMwsD,GAAU/2C,GAAG,CAACg3C,SA1B3B,SACItpE,EAAsBupE,EAAcC,EACpC1uD,GACF,MAAMknB,EAAKrQ,GAAgB3xB,EAAG,IAAK,WAUnC,GARAid,EACiB,YAAb+kB,EAAGrjC,MACH,IAAM,mFAAAQ,OACmB6iC,EAAGrjC,MAAK,qBACrCse,EACIssD,GAAQ,GAAKA,EAAO,EACpB,IAAM,qDAANpqE,OAA2DoqE,EAAI,MAEtD,IAATA,EACF,OAAOvpE,aAAa4gB,GAASohB,EAAGtgB,QAAUsgB,EAG5C,MAAMynC,ECzCF,SAAwBzpE,EAAWwpE,GACvC,GAAkB,MAAdA,EACF,OAAOxpE,EAAEtB,MAAM8F,QAEjB,GAAIyY,GAAiBjd,EAAEtB,MAAO8qE,GAC5B,OAAOA,EAET,GAAIxpE,EAAEtB,MAAMa,SAAWiqE,EAAWjqE,OAAQ,CACxC,MAAMmqE,EAAyB,GAC/B,IAAK,IAAIhpE,EAAI,EAAGA,EAAIV,EAAEtB,MAAMa,OAAQmB,IACb,MAAjB8oE,EAAW9oE,IAA4B,MAAdV,EAAEtB,MAAMgC,GACnCgpE,EAAavnE,KAAKnC,EAAEtB,MAAMgC,IAE1BgpE,EAAavnE,KAAKqnE,EAAW9oE,IAGjC,OAAOgpE,C,CAGT,OAAOF,CACT,CDqBsBG,CAAc3nC,EAAIwnC,GAChCI,EAAW,EAAIL,EACf35B,EAAa0K,GACf3xC,GAAMgS,GAAIklD,GAAc4J,EAAa,EAAG,EAAG,UAAW3uD,GAAO8uD,IAC7DA,GAEJ,OAAOtvD,GAAI0nB,EAAI4N,EACjB,IExDM,SAAUi6B,GAAoBrsE,GAElC,OAAOiC,KAAKkJ,MAAMlJ,KAAKg+C,IAAI,EAAGh+C,KAAKuD,KAAKvD,KAAKgY,IAAIja,GAASiC,KAAKgY,IAAI,KACrE,CAEM,SAAUqyD,GACZC,EAAsBnpE,EAAWC,GACnC,MAAMmpE,EAAO,EAAID,EAAe,EAC1BE,EAAY,IAAI1kE,aAAawkE,GACnC,IAAK,IAAIrpE,EAAI,EAAGA,EAAIqpE,IAAgBrpE,EAAG,CACrC,MAAMwpE,EAAU,EAAMzqE,KAAK0qE,GAAKzpE,GAAMqpE,EAAeC,EAAO,GAC5DC,EAAUvpE,GAAKE,EAAIC,EAAIpB,KAAKmuD,IAAIsc,E,CAElC,OAAO9E,GAAS6E,EAAW,UAC7B,CCoEO,MAAMG,GA9Db52C,eACI0Y,EAA2Bm+B,GAA4B,IAALlmD,EAACziB,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,EACxD,MAAM2qC,EAAe1a,GAAgBua,EAAa,cAAe,UAC3Do+B,EAAW34C,GAAgB04C,EAAS,UAAW,UAErDlpE,EACIkrC,EAAa1nC,KAAO,EACpB,IAAM,+DAA8D,WAAAxF,OACrDktC,EAAa1nC,OAChCxD,EACIkrC,EAAa1nC,KAAO,IAAM2lE,EAAS3lE,KACnC,IAAM,mFACuC,GAAAxF,OACtCktC,EAAa1nC,KAAI,sBAAAxF,OAAqBmrE,EAAS3lE,OAC1DrD,EACI+qC,EAAa3tC,MAAM8F,MAAM,EAAG6nC,EAAa3tC,MAAMa,OAAS,GACxD+qE,EAAS5rE,MACT,2FAEJ,MAAMknE,EAAUv5B,EAAa3tC,MAAM2tC,EAAa3tC,MAAMa,OAAS,GAC/D4B,EACIgjB,EAAI,GAAKA,GAAKyhD,EACd,IAAM,+EAAAzmE,OACYymE,EAAO,eAAAzmE,OAAcglB,IAE3C,MAAMomD,QAAwBl+B,EAAatvC,OACrCytE,QAAoBF,EAASvtE,QAI5BwmE,EAAOlhE,GAAQ,CAACkoE,EAAgBhrE,OAASqmE,EAASA,GACnD6E,EAAYnlE,GAAuB,OAAQi+D,GAEjD,IAAK,IAAI1iE,EAAI,EAAGA,EAAI0iE,EAAO1iE,IAAK,CAC9B,MAAMyG,EAASzG,EAAIwB,EACbuD,EAAO2kE,EAAgBG,SAASpjE,EAAQA,EAASjF,GACjDsoE,EAAmD,GACzD,IAAK,IAAIjqE,EAAI,EAAGA,EAAIkF,EAAKrG,OAAQmB,IAC/BiqE,EAAUxoE,KAAK,CAAC3E,MAAOoI,EAAKlF,GAAIlB,MAAOkB,IAEzCiqE,EAAUvlE,KAAK,CAACxE,EAAGC,IAAMA,EAAErD,MAAQoD,EAAEpD,OAErCitE,EAAU5pE,GAAK,EACf,IAAK,IAAIH,EAAI,EAAGA,EAAIyjB,EAAGzjB,IACrB,GAAIiqE,EAAUjqE,GAAGlB,QAAUgrE,EAAY3pE,GAAI,CACzC4pE,EAAU5pE,GAAK,EACf,K,EAaN,OARIqrC,IAAgBG,GAClBA,EAAartC,UAEXqrE,IAAYC,GACdA,EAAStrE,UAIJwkB,GAAOinD,EAAWH,EAAS5rE,MAAO,OAC3C,ECNO,MAAMksE,GAAuBt4C,GAAG,CAACu4C,sBA/CxC,SACI7qE,EAAM+oB,EAAOm6B,EACb97C,EACA+X,GAEwC,IADxCgkC,EAAAzhD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAA4B,OAC5B2lD,EAAwC3lD,UAAAnC,OAAA,EAAAmC,UAAA,QAAAC,EACtCgmD,EAAM3nD,EACK,IAAXA,EAAE2E,OACJgjD,EAAML,GAAQtnD,EAAG,CAAC,EAAGA,EAAEtB,MAAM,GAAIsB,EAAEtB,MAAM,GAAIsB,EAAEtB,MAAM,MAEvD,IAAIsuD,EAAOjkC,EACO,IAAdikC,EAAKroD,OACPqoD,EAAO1F,GAAQv+B,EAAI,CAAC,EAAGA,EAAGrqB,MAAM,GAAIqqB,EAAGrqB,MAAM,GAAIqqB,EAAGrqB,MAAM,MAE5Due,EACiB,IAAb0qC,EAAIhjD,KACJ,IAAM,oEAAAxF,OACCwoD,EAAIjpD,MAAK,MACpBue,EACkB,IAAd+vC,EAAKroD,KACL,IAAM,iEAAAxF,OACC6tD,EAAKtuD,MAAK,MACrBue,EAC2B,IAAvBimC,EAAY3jD,OACZ,IAAM,sEAAAJ,OACC+jD,EAAW,MACtB,MAAM6C,EAAyB,SAAf5C,EAAwBwE,EAAIjpD,MAAM,GAAKipD,EAAIjpD,MAAM,GAC3DynD,EAA0B,SAAfhD,EAAwB6J,EAAKtuD,MAAM,GAAKsuD,EAAKtuD,MAAM,GACpEue,EACI8oC,IAAY7C,EAAY,GACxB,IAAM,4CAAA/jD,OAA4C4mD,EAAO,2CAAA5mD,OACrB+jD,EAAY,GAAE,MACtDjmC,EACIkpC,IAAajD,EAAY,GACzB,IAAM,0CAAA/jD,OAA0CgnD,EAAQ,6CAAAhnD,OAClB+jD,EAAY,GAAE,OACxDwE,GAAoC,kBAAmBvoC,EAAKkoC,GAC5D,MAAMxqC,EAAqC,CAAC7c,EAAG2nD,EAAK5+B,GAAIikC,GAClD/jC,EACF,CAAC7hB,UAAS+X,MAAKgkC,aAAYkE,kBAAiBnE,eAGhD,OAAOv6B,GAAOC,UACHna,GAAsBoO,EACtBoM,EACb,IC3DM,SAAU6hD,GACZ/hD,EAAYtO,EAAWswD,GACzB,GAAkB,MAAdA,GAAqC,WAAfA,EACxB,OAAOhiD,EAET,GAAmB,SAAfgiD,EACF,OAAOzwD,GAAIyO,EAAIk3C,GAAKxlD,IAEtB,MAAM,IAAIvb,MAAM,gDAADC,OACqC4rE,EAAU,KAChE,CAGM,SAAUC,GACZjW,EAAckW,GAChB,IAAI1iD,EAAM0iD,EACV,MAAMC,EACFC,GAAgCpW,EAAKr2D,MAAOusE,EAAavsE,OAI7D,OAHIwsE,EAAW3rE,OAAS,IACtBgpB,EAAM/nB,GAAI+nB,EAAK2iD,IAEV5jB,GAAQ/+B,EAAKwsC,EAAKr2D,MAC3B,CAEM,SAAU0sE,GACZprE,EAAW+qE,EAAwBM,EACnCC,GACF,GAAmB,WAAfP,EACF,OAAO/qE,EACF,GAAmB,SAAf+qE,EACT,OAAO3K,GAAKpgE,GACP,GAAmB,QAAf+qE,EACT,OAAOla,GAAI7wD,GACN,GAAmB,UAAf+qE,EACT,OAAOzK,GAAMtgE,GACR,GAAmB,UAAf+qE,EACT,OAAOtO,GAAMz8D,EAAGqrE,GACX,GAAmB,cAAfN,EACT,OAAO3W,GAAUp0D,EAAGsrE,GACf,GAAmB,YAAfP,EACT,OAAO5iB,GAAQnoD,GAEjB,MAAM,IAAId,MAAM,4BAADC,OAA6B4rE,EAAU,KACxD,CAGO,MAAMQ,GAAaA,CAAC3mD,EAAuBmmD,MAC3BnmD,EAAgB,IACE,WAAfmmD,EC0PnB,MAAM3e,GAAS95B,GAAG,CAACk5C,aA5O1B,SAAqBC,GAwBpB,IAxBkD,EACjDzrE,EAAC,OACD6rB,EAAM,QACNzkB,EAAO,IACP+X,EAAG,WACHgkC,EAAa,OAAM,UACnBC,EAAY,CAAC,EAAG,GAAE,gBAClBiE,EAAe,KACf0N,EAAI,WACJgW,EAAa,SAAQ,uBACrBM,EAAsB,eACtBC,GAaDG,EAGC,GAFAV,EAAaA,GAAc,UAEgC,IAAvDQ,GAAW5iD,GAAO7C,MAAMlB,cAAemmD,GAAuB,CAGhE9tD,EACmB,SAAfkmC,EACA,IAAM,4CAAAhkD,OAA4CgkD,EAAU,SAAtD,0GAIV,IAAIniD,EAAS0qE,GACT1rE,EAAG6rB,EAAQzkB,EAAS+X,EAAKgkC,EAAYC,EAAWiE,GAKpD,OAJY,MAAR0N,IACF/zD,EAAS2Z,GAAI3Z,EAAQ+zD,IAGhBqW,GACIpqE,EAAQ+pE,EAAYM,EAAwBC,E,CAGzD,MAAMtpC,EAAKrQ,GAAgB3xB,EAAG,IAAK,SAAU,WACvCssD,EAAU36B,GAAgB9F,EAAQ,SAAU,SAAU,WAE5D,IAAI87B,EAAM3lB,EACN4lB,GAAe,EAEH,IAAZ5lB,EAAGr9B,OACLijD,GAAe,EACfD,EAAML,GAAQtlB,EAAI,CAAC,EAAGA,EAAGtjC,MAAM,GAAIsjC,EAAGtjC,MAAM,GAAIsjC,EAAGtjC,MAAM,MAE3Due,EACiB,IAAb0qC,EAAIhjD,KACJ,IAAM,gEAAAxF,OACCwoD,EAAIhjD,KAAI,MACnBsY,EACqB,IAAjBqvC,EAAQ3nD,KACR,IAAM,iEAAAxF,OACCmtD,EAAQ3nD,KAAI,MACvB+iD,GAAoC,eAAgBvoC,EAAKkoC,GACzD,MAAMskB,EAA+B,SAAfxoB,EAAwBwE,EAAIjpD,MAAM,GAAKipD,EAAIjpD,MAAM,GACvEue,EACIqvC,EAAQ5tD,MAAM,KAAOitE,EACrB,IAAM,oCAAAxsE,OAAoCwsE,EAAa,2CAAAxsE,OACzBmtD,EAAQ5tD,MAAM,GAAE,MAClDue,EACIyqC,GAAyCtgD,EAASg8C,GAClD,IAAM,2DAA0D,eAAAjkD,OAC7CiI,EAAO,oBAAAjI,OAAmBikD,EAAS,MAE1D,MAAMmY,EAAW7T,GACbC,EAAIjpD,MAAO4tD,EAAQ5tD,MAAO0I,EAASg8C,EAAWjkC,EAAKkoC,GAEvD,IAAIukB,EA6BAC,EACJ,GA7BY,MAAR9W,IACF6W,EAAQj6C,GAAgBojC,EAAM,OAAQ,iBACrC6W,GAASvoD,GAAeuoD,EAAO5pC,GAQb,SAAfmhB,EACFgoB,GAA0C5P,EAAS5uB,SAAUi/B,EAAMltE,QAEnEue,EACI2uD,EAAMltE,MAAMa,QAAU,EACtB,IAAM,sGACyC,QAAAJ,OACnCysE,EAAMltE,MAAMa,OAAM,MAElC0d,EAC2B,IAAvB2uD,EAAMltE,MAAMa,QAAgBqsE,EAAMltE,MAAM,KAAO68D,EAASzV,aACjC,IAAnB8lB,EAAMltE,MAAM,GAChB,IAAM,sCAAAS,OAAsCysE,EAAMltE,MAAK,8DACH,IAAAS,OAC5Co8D,EAASzV,YAAW,QAKN,MAA1BulB,EAAgC,CAGlC,MAAMS,EAAaT,EAAuB3sE,MAO1C,GANAue,EACI6uD,EAAWvsE,QAAU,GAA2B,IAAtBusE,EAAWvsE,OACrC,IAAM,sHACwD,QAAAJ,OAClD2sE,EAAWvsE,OAAM,MAEP,IAAtBusE,EAAWvsE,OAIb0d,EACsB,IAAlB6uD,EAAW,IAAYA,EAAW,KAAOvQ,EAASzV,YAClD,IAAM,uDAAA3mD,OACE2sE,EAAU,kDAAgD,aAAA3sE,OACjDo8D,EAASzV,YAAW,YACpC,GAA0B,IAAtBgmB,EAAWvsE,OAGpB,IACE4rE,GACIW,EAAYvQ,EAAS5uB,S,CACzB,MAAOzxB,GACP,MAAMmyB,EACF,oDAAAluC,OAAoD2sE,EAAU,+DACN,IAAA3sE,OACpDo8D,EAAS5uB,SAAQ,MACzB,MAAMztC,MAAMmuC,E,CAIhBw+B,EAA0Bl6C,GACtB05C,EAAwB,gBAAiB,e,CAG/C,MAAM37C,EAAOA,CAAC3G,EAAcY,KAC1B1M,EACmB,SAAfkmC,EACA,IAAM,wDAANhkD,OACIgkD,EAAU,2CAElB,MAAOmJ,EAAS3E,EAAKltC,EAAGmxD,GACpBjiD,EAEEshD,EAAeH,GAAqB/hD,EAAItO,EAAGswD,GAEjD9tD,EACIyqC,GAA4BtE,GAC5B,IAAM,oEAC8B,sDAAAjkD,OACsBikD,EAAS,MAEvE,MAIM2oB,EAAgB,CAHlBlf,GAAoBlF,EAAIjpD,MAAOusE,EAAc3e,EAASllD,EAAS+X,GAE/DyrD,GAAqBjjB,EAAKsjB,EAAc3e,EAAQ5tD,MAAO0I,EAAS+X,IAGpE,GAAa,MAATysD,EAAe,CACjB,MAAMI,EAAUhB,GAAqBY,EAAOX,GAC5Cc,EAAI5pE,KAAK6pE,E,CAEX,OAAOD,GAGHlvD,EAA4B,CAChC7c,EAAG2nD,EACH97B,OAAQygC,EACRyI,KAAM6W,EACNP,uBAAwBQ,GAGpB5iD,EAA0B,CAC9B7hB,UACA+X,MACAgkC,aACAC,YACAiE,kBACA0jB,aACAO,kBAKF,GAAY,MAARvW,EAAc,CAChB,MAAMS,EACFpmC,GAAW,CAACu4B,EAAe97B,EAAkB0D,KAC3C,IAAIhH,EAEAI,GAAOC,UACHrR,GAAasF,EACboM,GAUR,OARAsG,EAAK,CAAC1D,EAAQ87B,EAAKp/B,IAEfq/B,IAEFr/B,EAAM++B,GAAQ/+B,EAAK,CAACA,EAAI7pB,MAAM,GAAI6pB,EAAI7pB,MAAM,GAAI6pB,EAAI7pB,MAAM,MAIrD,CAAClB,MAAO+qB,EAAKuE,SAAU4C,KAEpC,OAAO8lC,EAAS7N,EAAK2E,E,CAChB,CACL,MAAM2f,EAAmB78C,GACrB,CAACu4B,EAAe97B,EAAkBkpC,EAAcxlC,KAC9C,IAAIhH,EAAyBI,GAAOC,UAChCrR,GAAasF,EACboM,GAUJ,OARAsG,EAAK,CAAC1D,EAAQ87B,EAAKp/B,EAAKwsC,IAEpBnN,IAEFr/B,EAAM++B,GAAQ/+B,EAAK,CAACA,EAAI7pB,MAAM,GAAI6pB,EAAI7pB,MAAM,GAAI6pB,EAAI7pB,MAAM,MAIrD,CAAClB,MAAO+qB,EAAKuE,SAAU4C,KAGpC,OAAOu8C,EAAiBtkB,EAAK2E,EAASsf,E,CAE1C,ICtRO,MAAMM,GACT55C,GAAG,CAAC65C,qCA3BR,SACInsE,EAAM+oB,EAAOm6B,EACb97C,EACA+X,GAEwC,IADxCikC,EAAA1hD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAqC,CAAC,EAAG,GACzC2lD,EAAwC3lD,UAAAnC,OAAA,EAAAmC,UAAA,QAAAC,EACtCgmD,EAAM3nD,EACK,IAAXA,EAAE2E,OACJgjD,EAAML,GAAQtnD,EAAG,CAAC,EAAGA,EAAEtB,MAAM,GAAIsB,EAAEtB,MAAM,GAAIsB,EAAEtB,MAAM,MAEvD,IAAIsuD,EAAOjkC,EACO,IAAdikC,EAAKroD,OACPqoD,EAAO1F,GAAQv+B,EAAI,CAAC,EAAGA,EAAGrqB,MAAM,GAAIqqB,EAAGrqB,MAAM,GAAIqqB,EAAGrqB,MAAM,MAG5D,MAAMme,EAAoD,CAAC7c,EAAG2nD,EAAK5+B,GAAIikC,GACjE/jC,EACF,CAAC7hB,UAAS+X,MAAKkoC,kBAAiBjE,YAAWF,eAG/C,OAAOv6B,GAAOC,UACHtZ,GACAuN,EAAgCoM,EAE7C,ICKO,MAAMmjD,GACT95C,GAAG,CAAC+5C,oCA9BR,SACI73B,EAA0CzrB,EAAO8C,EACjDzkB,EACA+X,GAEwC,IADxCikC,EAAA1hD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAqC,CAAC,EAAG,GACzC2lD,EAAwC3lD,UAAAnC,OAAA,EAAAmC,UAAA,QAAAC,EACtCqrD,EAAOjkC,EACP6+B,GAAe,EACH,IAAZ7+B,EAAGpkB,OACLijD,GAAe,EACfoF,EAAO1F,GAAQv+B,EAAI,CAAC,EAAGA,EAAGrqB,MAAM,GAAIqqB,EAAGrqB,MAAM,GAAIqqB,EAAGrqB,MAAM,MAG5D,MAAMme,EAAmD,CAACkM,GAAIikC,EAAMnhC,UAC9D5C,EACF,CAAC7hB,UAAS+X,MAAKkoC,kBAAiBjE,YAAWjlC,WAAYq2B,GAErDjsB,EAEFI,GAAOC,UACHrZ,GAAoCsN,EACpCoM,GAER,OAAI2+B,EACKN,GAAQ/+B,EAAK,CAACA,EAAI7pB,MAAM,GAAI6pB,EAAI7pB,MAAM,GAAI6pB,EAAI7pB,MAAM,KAEtD6pB,CACT,IC8MO,MAAMsmC,GAAkBv8B,GAAG,CAACg6C,sBA1KnC,SAA8Bb,GAwB7B,IAxB2D,EAC1DzrE,EAAC,OACD6rB,EAAM,QACNzkB,EAAO,IACP+X,EAAG,WACHgkC,EAAa,OAAM,UACnBC,EAAY,CAAC,EAAG,GAAE,gBAClBiE,EAAe,KACf0N,EAAI,WACJgW,EAAa,SAAQ,uBACrBM,EAAsB,eACtBC,GAaDG,EACC,IAA2D,IAAvDF,GAAW5iD,GAAO7C,MAAMlB,cAAemmD,GAAuB,CAChE,IAAI/pE,EAASurE,GACTvsE,EAAG6rB,EAAQzkB,EAAS+X,EAAKgkC,EAAYC,EAAWiE,GAKpD,OAJY,MAAR0N,IACF/zD,EAAS2Z,GAAI3Z,EAAQ+zD,IAGhBqW,GACIpqE,EAAQ+pE,EAAYM,EAAwBC,E,CAGzD,MAAMtpC,EAAKrQ,GAAgB3xB,EAAG,IAAK,kBAAmB,WAChDssD,EACF36B,GAAgB9F,EAAQ,SAAU,kBAAmB,WAEzD,IAAI87B,EAAM3lB,EACN4lB,GAAe,EACH,IAAZ5lB,EAAGr9B,OACLijD,GAAe,EACfD,EAAML,GAAQtlB,EAAI,CAAC,EAAGA,EAAGtjC,MAAM,GAAIsjC,EAAGtjC,MAAM,GAAIsjC,EAAGtjC,MAAM,MAE3Due,EACiB,IAAb0qC,EAAIhjD,KACJ,IAAM,yEAAAxF,OACMwoD,EAAIhjD,KAAI,MACxBsY,EACqB,IAAjBqvC,EAAQ3nD,KACR,IAAM,0EAAAxF,OACcmtD,EAAQ3nD,KAAI,MACpCsY,EACI0qC,EAAIjpD,MAAM,KAAO4tD,EAAQ5tD,MAAM,GAC/B,IAAM,gEAAAS,OACEwoD,EAAIjpD,MAAM,GAAE,6CAA2C,UAAAS,OACjDmtD,EAAQ5tD,MAAM,GAAE,MACjB,MAAb0kD,IACFA,EAAY,CAAC,EAAG,IAElBnmC,EACIyqC,GAAyCtgD,EAASg8C,GAClD,IACI,oEAAmE,qBAAAjkD,OAC9CiI,EAAO,oBAAAjI,OAAmBikD,EAAS,MAChEsE,GACI,wBAAyBvoC,EAAKkoC,GAClC,MAAMkU,EAAW7T,GACbC,EAAIjpD,MAAO4tD,EAAQ5tD,MAAO0I,EAASg8C,EAAWjkC,EAAKkoC,GACnD,GAEJ,IAAIukB,EAQAC,EAPQ,MAAR9W,IACF6W,EAAQj6C,GAAgBojC,EAAM,OAAQ,iBACrC6W,GAASvoD,GAAeuoD,EAAO5pC,GAEhCmpC,GAA0C5P,EAAS5uB,SAAUi/B,EAAMltE,QAIvC,MAA1B2sE,IACFQ,EAA0Bl6C,GACtB05C,EAAwB,gBAAiB,0BAG/C,MAAM37C,EAAOA,CAAC3G,EAAcY,KAC1B1M,EACIyqC,GAA4BtE,GAC5B,IAAM,kHACoD,IAAAjkD,OAClDikD,EAAS,MACrB,MAAOkJ,EAAS3E,EAAKltC,EAAGs6C,GAAQprC,EAE1BshD,EAAeH,GAAqB/hD,EAAItO,EAAGswD,GAE3CyB,EAAOJ,GACRzkB,EAAiBjpD,MAAOusE,EAAc3e,EAAqBllD,EAC5D+X,EAAKikC,EAAWiE,GACdolB,EAAYP,GACdvkB,EAAiBsjB,EAAe3e,EAAqB5tD,MAAO0I,EAC5D+X,EAAKikC,EAAWiE,GAEpB,GAAY,MAAR0N,EAAc,CAEhB,MAAO,CAACyX,EAAMC,EADEzB,GAAqBY,EAAOX,G,CAG9C,MAAO,CAACuB,EAAMC,IAGV5vD,EAAqC,CACzC7c,EAAG2nD,EACH97B,OAAQygC,EACRyI,KAAM6W,EACNP,uBAAwBQ,GAEpB5iD,EAAmC,CACvC7hB,UACA+X,MACAgkC,aACAC,YACAiE,kBACA0jB,aACAO,kBAKF,GAAY,MAARvW,EAAc,CAChB,MAAMS,EACFpmC,GAAW,CAACu4B,EAAe97B,EAAkB0D,KAE3C,IAAIhH,EAAyBI,GAAOC,UAChCpR,GAAsBqF,EACtBoM,GAUJ,OARAsG,EAAK,CAAC1D,EAAQ87B,EAAKp/B,IAEfq/B,IAEFr/B,EAAM++B,GAAQ/+B,EAAK,CAACA,EAAI7pB,MAAM,GAAI6pB,EAAI7pB,MAAM,GAAI6pB,EAAI7pB,MAAM,MAIrD,CAAClB,MAAO+qB,EAAKuE,SAAU4C,KAEpC,OAAO8lC,EAAS7N,EAAK2E,E,CAChB,CACL,MAAM2f,EAAmB78C,GACrB,CAACu4B,EAAe97B,EAAkBkpC,EAAcxlC,KAE9C,IAAIhH,EAAyBI,GAAOC,UAChCpR,GAAsBqF,EACtBoM,GAUJ,OARAsG,EAAK,CAAC1D,EAAQ87B,EAAKp/B,EAAKwsC,IAEpBnN,IAEFr/B,EAAM++B,GAAQ/+B,EAAK,CAACA,EAAI7pB,MAAM,GAAI6pB,EAAI7pB,MAAM,GAAI6pB,EAAI7pB,MAAM,MAIrD,CAAClB,MAAO+qB,EAAKuE,SAAU4C,KAGpC,OAAOu8C,EAAiBtkB,EAAK2E,EAASsf,E,CAE1C,IC9CS,MAAMvhC,GAAS/X,GAAG,CAACo6C,aA3J5B,SAAqBjB,GAkBpB,IAlBqB,EACpB7qE,EAAC,EACDC,EAAC,WACD0pC,GAAa,EAAK,WAClBC,GAAa,EAAK,KAClBuqB,EAAI,WACJgW,EAAa,SAAQ,uBACrBM,EAAsB,eACtBC,EAAiB,IAUlBG,EACG,IAA2D,IAAvDF,GAAW5iD,GAAO7C,MAAMlB,cAAemmD,GAAuB,CAChE,IAAI/pE,EAAS2rE,GAAc/rE,EAAGC,EAAG0pC,EAAYC,GAK7C,OAJY,MAARuqB,IACF/zD,EAAS2Z,GAAI3Z,EAAQ+zD,IAGhBqW,GACIpqE,EAAQ+pE,EAAYM,EAAwBC,E,CAGzD,IAAI7gC,EAAK9Y,GAAgB/wB,EAAG,IAAK,gBAC7B8pC,EAAK/Y,GAAgB9wB,EAAG,IAAK,iBAChC4pC,EAAIC,GAAMrnB,GAAeonB,EAAIC,GAE9B,MAAMkiC,EACFriC,EAAaE,EAAG/rC,MAAM+rC,EAAG9lC,KAAO,GAAK8lC,EAAG/rC,MAAM+rC,EAAG9lC,KAAO,GACtDkoE,EACFriC,EAAaE,EAAGhsC,MAAMgsC,EAAG/lC,KAAO,GAAK+lC,EAAGhsC,MAAMgsC,EAAG/lC,KAAO,GAEtDmoE,EACFviC,EAAaE,EAAG/rC,MAAM+rC,EAAG9lC,KAAO,GAAK8lC,EAAG/rC,MAAM+rC,EAAG9lC,KAAO,GACtDooE,EACFviC,EAAaE,EAAGhsC,MAAMgsC,EAAG/lC,KAAO,GAAK+lC,EAAGhsC,MAAMgsC,EAAG/lC,KAAO,GAEtDqoE,EAAaviC,EAAG/rC,MAAM8F,MAAM,GAAI,GAChCyoE,EAAaviC,EAAGhsC,MAAM8F,MAAM,GAAI,GAChC0oE,EAAYjwD,GAAmB+vD,GAC/BG,EAAYlwD,GAAmBgwD,GAErChwD,EACI2vD,IAAgBC,EAChB,IAAM,wCAAA1tE,OAAwCytE,EAAW,cAAAztE,OAClD0tE,EAAW,6BAAA1tE,OAA4BsrC,EAAG/rC,MAAK,SAAO,GAAAS,OACtDurC,EAAGhsC,MAAK,oBAAAS,OAAmBorC,GAAY,mBAAAprC,OACvBqrC,EAAU,iBAErC,MAEMmC,EAFoBw+B,GACtB1gC,EAAG/rC,MAAM8F,MAAM,GAAI,GAAIkmC,EAAGhsC,MAAM8F,MAAM,GAAI,IACXrF,OAAO,CAAC2tE,EAAaC,IAElDK,EACF9lB,GAAQ7c,EADUF,EACN,CAAC2iC,EAAWN,EAAaE,GACzB,CAACI,EAAWJ,EAAaF,IACnCS,EACF/lB,GAAQ5c,EADUF,EACN,CAAC2iC,EAAWJ,EAAaF,GACzB,CAACM,EAAWN,EAAaE,IAEzC,IAAInB,EAQAC,EAPQ,MAAR9W,IACF6W,EAAQj6C,GAAgBojC,EAAM,OAAQ,iBACrC6W,GAASvoD,GAAeuoD,EAAOnhC,GAEhC0gC,GAA0Cx+B,EAAUi/B,EAAMltE,QAI9B,MAA1B2sE,IACFQ,EAA0Bl6C,GACtB05C,EAAwB,gBAAiB,iBAG/C,MAAM37C,EAAOA,CAAC3G,EAAcY,KAC1B,MAAOyjD,EAAKC,EAAK5yD,EAAGmxD,GAASjiD,EAIvBshD,EACFH,GAAqBxjB,GAAQv+B,EAAItO,EAAE/b,OAAQ+b,EAAGswD,GAClD,IAAIuC,EACAC,EAgBJ,GAdKhjC,GAAeC,GAGRD,GAAcC,GACxB8iC,EAAOX,GAAc1B,EAAcoC,GAAK,GAAO,GAC/CE,EAAOZ,GAAc1B,EAAcmC,GAAK,GAAM,IACrC7iC,IAAeC,GACxB8iC,EAAOX,GAAcU,EAAKpC,GAAc,GAAO,GAC/CsC,EAAOZ,GAAcS,EAAKnC,GAAc,GAAO,KAE/CqC,EAAOX,GAAcU,EAAKpC,GAAc,GAAM,GAC9CsC,EAAOZ,GAAc1B,EAAcmC,GAAK,GAAM,KAV9CE,EAAOX,GAAc1B,EAAcoC,GAAK,GAAO,GAC/CE,EAAOZ,GAAcS,EAAKnC,GAAc,GAAM,IAYpC,MAARlW,EAAc,CAEhB,MAAO,CAACuY,EAAMC,EADEvC,GAAqBY,EAAOX,G,CAG5C,MAAO,CAACqC,EAAMC,IAIZ1wD,EAA6B,CACjCjc,EAAGwsE,EACHvsE,EAAGwsE,EACHtY,KAAM6W,EACNP,uBAAwBQ,GAEpB5iD,EACF,CAACshB,aAAYC,aAAYugC,aAAYO,kBAIzC,GAAY,MAARvW,EAAc,CAChB,MAAMS,EACFpmC,GAAW,CAACg+C,EAAeC,EAAe99C,KACxC,MAAMhH,EAEFI,GAAOC,UACHtR,GAAcuF,EACdoM,GAIR,OAFAsG,EAAK,CAAC69C,EAAKC,EAAK9kD,IAET,CAAC/qB,MAAO8pD,GAAQ/+B,EAAKokB,GAAW7f,SAAU4C,KAEvD,OAAO8lC,EAAS4X,EAAKC,E,CAChB,CACL,MAAMpB,EAAmB78C,GACrB,CAACg+C,EAAeC,EAAezB,EAAer8C,KAC5C,MAAMhH,EAEFI,GAAOC,UACHtR,GAAcuF,EACdoM,GAIR,OAFAsG,EAAK,CAAC69C,EAAKC,EAAK9kD,EAAKqjD,IAEd,CAACpuE,MAAO8pD,GAAQ/+B,EAAKokB,GAAW7f,SAAU4C,KAGvD,OAAOu8C,EAAiBmB,EAAKC,EAAKzB,E,CAEtC,IC9KK,MAAM4B,GAAgBl7C,GAAG,CAACm7C,eAHjC,SAAwB1D,GACtB,OAAOD,GAAaC,EAAc,IAAM,IAC1C,ICEO,MAAM2D,GAAap7C,GAAG,CAACq7C,YAJ9B,SAAqB5D,GACnB,OAAOD,GAAaC,EAAc,GAAK,GACzC,ICiCO,MAAM6D,GAAQt7C,GAAG,CAACu7C,OA3BzB,SACIC,EAAkBC,EAAqBC,GAC3B,IAD8C3R,EAAM36D,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,IAAAA,UAAA,GAChEusE,EAAQvsE,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,EACTwF,EAAQ,EACZ,MAAMgW,EAAmB,GACzB,KAAOhW,EAAQ6mE,GAAeD,EAAOzrE,MACnC6a,EAAO/a,KAAKqC,GAAMspE,EAAQ5mE,EAAO6mE,IACjC7mE,GAAS8mE,EAGX,GAAI3R,EACF,KAAOn1D,EAAQ4mE,EAAOzrE,MAAM,CAC1B,MAAM6rE,EAAUhnE,EAAQ6mE,EAAeD,EAAOzrE,KACxC8c,EAAMhgB,GAAO,CACjBqF,GAAMspE,EAAQ5mE,EAAO6mE,EAAcG,GAASzvD,GAAK,CAACyvD,GAASD,KAE7D/wD,EAAO/a,KAAKgd,GACZjY,GAAS8mE,C,CAIb,OAAsB,IAAlB9wD,EAAO3d,OACF8lE,GAAS,GAAI,CAAC,EAAG0I,IAGnBzmB,GAAQnoD,GAAO+d,GAAS,CAACA,EAAO3d,OAAQwuE,GACjD,ICdO,MAAMI,GAAO77C,GAAG,CAAC87C,MAXxB,SACIN,EAAkBC,EAAqBC,EACvC/J,GACmD,IAAnDoK,EAAA3sE,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAyCgsE,GAC1B,MAAbzJ,IACFA,EAAY4F,GAAoBkE,IAElC,MAAMO,EAAeV,GAAME,EAAQC,EAAaC,GAC1CO,EAAiBj0D,GAAIg0D,EAAcD,EAASN,IAClD,OAAOhK,GAAKwK,EAAgBtK,EAC9B,IC6CO,MAAMuK,GAAgBl8C,GAAG,CAACm8C,eA9CjC,SACI15C,EACA25C,EACAC,EACAC,GAEsB,IADtBvmC,EAAA3mC,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAA+B,WAC/BmtE,EAAkBntE,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,EAEvB,MAAMotE,EAASn9C,GAAgBoD,EAAO,QAAS,iBACzCg6C,EAASp9C,GAAgB+8C,EAAO,QAAS,gBAAiB,WAC1DM,EAAUr9C,GAAgBg9C,EAAQ,SAAU,gBAAiB,SAE7DM,EAAWF,EAAOrwE,MAAM,GAE9Bue,EACoB,IAAhB6xD,EAAOnqE,KACP,IAAM,gDAA+C,gBAAAxF,OACjC2vE,EAAOnqE,KAAI,MACnCsY,EACoB,IAAhB8xD,EAAOpqE,MAAkC,IAApBoqE,EAAOrwE,MAAM,GAClC,IAAM,oDAAAS,OAAoD8vE,EAAQ,yBAAA9vE,OAC7C4vE,EAAOrwE,MAAK,MACrCue,EACqB,IAAjB+xD,EAAQrqE,MAAcqqE,EAAQtwE,MAAM,KAAOuwE,EAC3C,IAAM,qDAAA9vE,OAAqD8vE,EAAQ,uBAAA9vE,OAC9C4vE,EAAOrwE,MAAK,MACrCue,EACwB,IAApB2xD,EAASrvE,OACT,IAAM,2EAAAJ,OACQyvE,EAASrvE,OAAM,MACjC0d,EACI2xD,EAAS,IAAM,GAAKA,EAAS,IAAM,EACnC,IAAM,2CAANzvE,OAAiDyvE,IACrD3xD,EACe,aAAXorB,GAAoC,YAAXA,EACzB,IAAM,+CAANlpC,OAAqDkpC,IAEzD,MAAMxrB,EACoB,CAACkY,MAAO+5C,EAAQJ,MAAOK,EAAQJ,OAAQK,GAC3D/lD,EAA4B,CAACof,SAAQwmC,qBAAoBD,YAI/D,OAHYjmD,GAAOC,UACf1Z,GAAe2N,EACfoM,EAEN,IChDO,MAAMimD,GAAgB58C,GAAG,CAAC68C,eAdjC,SAAwBp6C,GACtB,MAAM+5C,EAASn9C,GAAgBoD,EAAO,QAAS,gBAAiB,WAEhE9X,EACoB,IAAhB6xD,EAAOnqE,KACP,IAAM,gDAA+C,gBAAAxF,OACjC2vE,EAAOnqE,KAAI,MAEnC,MAAMkY,EAA8B,CAACkY,MAAO+5C,GAG5C,OADInmD,GAAOC,UAAUrY,GAAesM,EAAgC,CAAC,EAEvE,ICaO,MAAMuyD,GAAiB98C,GAAG,CAAC+8C,gBAzBlC,SACmCt6C,GACjC,MAAM+5C,EAASn9C,GAAgBoD,EAAO,QAAS,kBAEzCu6C,EAAcR,EAAOnqE,KAAO,EAC5B4qE,EAAWT,EAAOpwE,MAAM4wE,GAE9BryD,EACI6xD,EAAOnqE,MAAQ,EACf,IAAM,4DAA2D,gBAAAxF,OAC7C2vE,EAAOnqE,KAAI,MAEnCsY,EACiB,IAAbsyD,EACA,IAAM,gEAA+D,kCAAApwE,OAC/BowE,EAAQ,MAElD,MAAMjkB,EAAO,IAAItpD,MAAM8sE,EAAOnqE,MAK9B,OAHA2mD,EAAK7sC,KAAK,EAAG,EAAG6wD,GAChBhkB,EAAKgkB,GAAe,EAEbtc,GAAK8b,EAAQxjB,EACtB,ICOO,MAAMkkB,GAAmBl9C,GAAG,CAACm9C,kBAnBpC,SACI16C,EAA4B26C,GAES,IADrCC,EAAAjuE,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAA6C,EAC7CkuE,EAAAluE,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAkC,GACpC,MAAMotE,EAASn9C,GAAgBoD,EAAO,QAAS,mBAAoB,WAEnE9X,EACoB,IAAhB6xD,EAAOnqE,KACP,IAAM,mDAAkD,gBAAAxF,OACpC2vE,EAAOnqE,KAAI,MAEnC,MAAMkY,EAAiC,CAACkY,MAAO+5C,GACzC7lD,EAA+B,CAACymD,UAASC,YAAWC,UAI1D,OAHYjnD,GAAOC,UACfvR,GAAkBwF,EAClBoM,EAEN,ICzCA,SAAS4mD,GACLnB,EAAiBoB,EAAkBC,EACnCC,EAAsBC,EAAwBC,GAM5B,MAAhBF,IACFA,EAAe,IAEK,MAAlBC,IACFA,EAAiB/uE,OAAOivE,mBAEN,MAAhBD,IACFA,EAAe,GAGjB,MAAMjB,EAAWP,EAAMhwE,MAAM,GAqB7B,OApBAqxE,EAAgBtwE,KAAKM,IAAIgwE,EAAed,GAExChyD,EACI,GAAK+yD,GAAgBA,GAAgB,EACrC,IAAM,4CAAN7wE,OAAkD6wE,EAAY,MAClE/yD,EACmB,IAAfyxD,EAAM/pE,KACN,IAAM,+CAANxF,OAAqDuvE,EAAM/pE,KAAI,MACnEsY,EACuB,IAAnByxD,EAAMhwE,MAAM,GACZ,wDAAAS,OACwDuvE,EAAMhwE,MAAM,KACxEue,EAA4B,IAAhB6yD,EAAOnrE,KAAY,IAAM,8BACrCsY,EACI6yD,EAAOpxE,MAAM,KAAOuwE,EACpB,IAAM,sDAAA9vE,OAAsD8vE,EAAQ,iBAAA9vE,OACrD2wE,EAAOpxE,MAAM,KAChCue,EACI,GAAKizD,GAAgBA,GAAgB,EACrC,IAAM,4CAAN/wE,OAAkD+wE,EAAY,MAC3D,CAACH,gBAAeC,eAAcC,iBAAgBC,eACvD,CCGO,MAAME,GAAoB99C,GAAG,CAAC+9C,mBApBrC,SACI3B,EAA4BoB,EAC5BC,GACyC,IADlBC,EAAYtuE,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,GACtCuuE,EAAcvuE,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAGR,OAAOivE,kBAC1B,MAAMpB,EACFp9C,GAAgB+8C,EAAO,QAAS,oBAAqB,WACnD4B,EACF3+C,GAAgBm+C,EAAQ,SAAU,oBAAqB,WAErDjzD,EAASgzD,GACXd,EAAQuB,EAASP,EAAeC,EAAcC,GAClDF,EAAgBlzD,EAAOkzD,cACvBC,EAAenzD,EAAOmzD,aACtBC,EAAiBpzD,EAAOozD,eAExB,MAAMhnD,EAAQ,CAAC8mD,gBAAeC,eAAcC,kBAC5C,OAAOtnD,GAAOC,UACVzV,GAAqB,CAACu7D,MAAOK,EAAQe,OAAQQ,GAAUrnD,EAC7D,IC/BM,SAAUsnD,GACZ9vE,EAAU+vE,EAAYC,GACxB,MAAMjxE,EAoBF,SACFiB,EAAUkjC,EAAW8sC,GACvB,OAcF,SACIhwE,EAAUkjC,EAAW8sC,GACvB,IAAIpwE,EAAO,EACPC,EAAQG,EAAIlB,OACZmxE,EAAS,EACT1pC,GAAQ,EACZ,KAAO3mC,EAAOC,GAAO,CACnBowE,EAASrwE,GAASC,EAAQD,IAAU,GACpC,MAAMswE,EAAgBF,EAAW9sC,EAAQljC,EAAIiwE,IACzCC,EAAgB,EAClBtwE,EAAOqwE,EAAS,GAEhBpwE,EAAQowE,EAGR1pC,GAAS2pC,E,CAIb,OAAO3pC,EAAQ3mC,GAAQA,EAAO,CAChC,CAlCSuwE,CAAcnwE,EAAKkjC,EAAQ8sC,GAAcI,GAClD,CAvBgBC,CAAarwE,EAAK+vE,EAASC,GACnCM,EAAiBvxE,EAAQ,IAAMA,EAAQ,GAAKA,EAClDiB,EAAIuxC,OAAO++B,EAAgB,EAAGP,EAChC,CA6BA,SAASK,GAAqBjwE,EAAMC,GAClC,OAAOD,EAAIC,EAAI,EAAID,EAAIC,GAAK,EAAI,CAClC,CC/BM,SAAUmwE,GACZtC,EAAmBoB,EAAoBC,EACvCC,EAAsBC,GACxB,OAAOgB,GACHvC,EAAOoB,EAAQC,EAAeC,EAAcC,EAC5C,EACN,CAEM,SAAUiB,GACZxC,EAAmBoB,EAAoBC,EACvCC,EAAsBC,EACtBkB,GACF,OAAOF,GACHvC,EAAOoB,EAAQC,EAAeC,EAAcC,EAC5C,GAAsB,EACtBkB,GAA6C,EAEnD,CAEM,SAAUC,GACZ1C,EAAmBoB,EAAoBC,EACvCC,EAAsBC,EACtBC,GACF,OAAOe,GACHvC,EAAOoB,EAAQC,EAAeC,EAAcC,EAAgBC,GAC5D,EACN,CAEA,SAASe,GACLvC,EAAmBoB,EAAoBC,EACvCC,EAAsBC,EAAwBC,GAEpB,IAD1BmB,EAAkB3vE,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,IAAAA,UAAA,GAAUyvE,EAAkBzvE,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,IAAAA,UAAA,GAC9C4vE,EAAkB5vE,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,IAAAA,UAAA,GAGpB,MAAM6vE,EAAa,GAEnB,IAAK,IAAI7wE,EAAI,EAAGA,EAAIovE,EAAOvwE,OAAQmB,IAC7BovE,EAAOpvE,GAAKuvE,GACdsB,EAAWpvE,KAAK,CAACqvE,MAAO1B,EAAOpvE,GAAI+wE,SAAU/wE,EAAGgxE,mBAAoB,IAIxEH,EAAWnsE,KAAKusE,IAIhB,MAAMh9C,EAAQu7C,EAAe,GAAM,GAAMA,EAAgB,EAEnD0B,EAA4B,GAC5BC,EAA2B,GAEjC,KAAOD,EAAgBryE,OAASwwE,GAAiBwB,EAAWhyE,OAAS,GAAG,CACtE,MAAMuyE,EAAYP,EAAW/jD,OACtBgkD,MAAOO,EAAa,SAAEN,EAAQ,mBAAEC,GAAsBI,EAE7D,GAAIC,EAAgB9B,EAClB,MASF,IAAI+B,GAAkB,EACtB,IAAK,IAAI3sE,EAAIusE,EAAgBryE,OAAS,EAAG8F,GAAKqsE,IAAsBrsE,EAAG,CACrE,MAAM4sE,EAAMC,GAAsBxD,EAAO+C,EAAUG,EAAgBvsE,IAEnE,GAAI4sE,GAAOjC,EAAc,CACvBgC,GAAkB,EAClB,K,CAMF,GAHAF,EAAUN,MACNM,EAAUN,MAAQW,GAAenC,EAAcr7C,EAAOs9C,GAEtDH,EAAUN,OAASvB,EACrB,K,CAWJ6B,EAAUJ,mBAAqBE,EAAgBryE,OAE1CyyE,IAGCF,EAAUN,QAAUO,GACtBH,EAAgBzvE,KAAKsvE,GACrBI,EAAe1vE,KAAK2vE,EAAUN,QACrBM,EAAUN,MAAQvB,GAG3BM,GAAagB,EAAYO,EAAWH,I,CAM1C,MAAMS,EAAeR,EAAgBryE,OAC/B8yE,EAAatC,EAAgBqC,EAE/BjB,GAAsBkB,EAAa,IACrCT,EAAgBzvE,QAAQ,IAAIH,MAAMqwE,GAAY5zD,KAAK,IACnDozD,EAAe1vE,QAAQ,IAAIH,MAAMqwE,GAAY5zD,KAAK,KAGpD,MAAMzd,EAAkC,CAAC4wE,mBAUzC,OARIP,IACFrwE,EAAuB,eAAI6wE,GAGzBP,IACFtwE,EAAqB,aAAIoxE,GAGpBpxE,CACT,CAEA,SAASkxE,GAAsBxD,EAAmBhuE,EAAW2E,GAC3D,MAAMitE,EAAS5D,EAAMhE,SAAa,EAAJhqE,EAAW,EAAJA,EAAQ,GACvC6xE,EAAS7D,EAAMhE,SAAa,EAAJrlE,EAAW,EAAJA,EAAQ,GACvCmtE,EAAQ/yE,KAAKM,IAAIuyE,EAAO,GAAIA,EAAO,IACnCG,EAAQhzE,KAAKM,IAAIuyE,EAAO,GAAIA,EAAO,IACnCI,EAAQjzE,KAAKQ,IAAIqyE,EAAO,GAAIA,EAAO,IACnCK,EAAQlzE,KAAKQ,IAAIqyE,EAAO,GAAIA,EAAO,IACnCM,EAAQnzE,KAAKM,IAAIwyE,EAAO,GAAIA,EAAO,IACnCM,EAAQpzE,KAAKM,IAAIwyE,EAAO,GAAIA,EAAO,IACnCO,EAAQrzE,KAAKQ,IAAIsyE,EAAO,GAAIA,EAAO,IACnCQ,EAAQtzE,KAAKQ,IAAIsyE,EAAO,GAAIA,EAAO,IACnCS,GAASN,EAAQF,IAAUG,EAAQF,GACnCQ,GAASH,EAAQF,IAAUG,EAAQF,GACzC,GAAIG,GAAS,GAAKC,GAAS,EACzB,OAAO,EAET,MAAMC,EAAmBzzE,KAAKQ,IAAIuyE,EAAOI,GACnCO,EAAmB1zE,KAAKQ,IAAIwyE,EAAOI,GACnCO,EAAmB3zE,KAAKM,IAAI2yE,EAAOI,GACnCO,EAAmB5zE,KAAKM,IAAI4yE,EAAOI,GACnCO,EAAmB7zE,KAAKQ,IAAImzE,EAAmBF,EAAkB,GACnEzzE,KAAKQ,IAAIozE,EAAmBF,EAAkB,GAClD,OAAOG,GAAoBN,EAAQC,EAAQK,EAC7C,CAMA,SAASnB,GAAenC,EAAsBr7C,EAAes9C,GAC3D,MAAMsB,EAAS9zE,KAAKoD,IAAI8xB,EAAQs9C,EAAMA,GACtC,OAAOA,GAAOjC,EAAeuD,EAAS,CACxC,CAEA,SAAS5B,GAAoB6B,EAAeC,GAK1C,OAAQD,EAAGhC,MAAQiC,EAAGjC,OAChBgC,EAAGhC,QAAUiC,EAAGjC,OAAWiC,EAAGhC,SAAW+B,EAAG/B,QACpD,CChIO,MAAMiC,GAhCblgD,eACIk7C,EAA4BoB,EAC5BC,GACyC,IADlBC,EAAYtuE,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,GACtCuuE,EAAcvuE,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAGR,OAAOivE,kBAC1B,MAAMpB,EAASp9C,GAAgB+8C,EAAO,QAAS,0BACzC4B,EAAU3+C,GAAgBm+C,EAAQ,SAAU,0BAE5CjzD,EAASgzD,GACXd,EAAQuB,EAASP,EAAeC,EAAcC,GAClDF,EAAgBlzD,EAAOkzD,cACvBC,EAAenzD,EAAOmzD,aACtBC,EAAiBpzD,EAAOozD,eAExB,MAAM0D,QAAuB7vE,QAAQ+Z,IAAI,CAACkxD,EAAOhyE,OAAQuzE,EAAQvzE,SAC3D62E,EAAYD,EAAe,GAC3BE,EAAaF,EAAe,IAK5B,gBAAC/B,GAAmBZ,GACtB4C,EAAWC,EAAY9D,EAAeC,EAAcC,GAQxD,OAPIlB,IAAWL,GACbK,EAAO/vE,UAELsxE,IAAYR,GACdQ,EAAQtxE,UAGHomE,GAASwM,EAAiB,QACnC,ECWO,MAAMkC,GAA6BxhD,GAAG,CAACyhD,4BA5B9C,SACIrF,EAA4BoB,EAC5BC,GAEkB,IAFKC,EAAYtuE,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,GACtCuuE,EAAcvuE,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAGR,OAAOivE,kBACxBD,EAAYxuE,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,EACjB,MAAMqtE,EAASp9C,GAAgB+8C,EAAO,QAAS,qBACzC4B,EAAU3+C,GAAgBm+C,EAAQ,SAAU,qBAE5C1kE,EAASykE,GACXd,EAAQuB,EAASP,EAAeC,EAAcC,EAC9CC,GACJH,EAAgB3kE,EAAO2kE,cACvBC,EAAe5kE,EAAO4kE,aACtBC,EAAiB7kE,EAAO6kE,eACxBC,EAAe9kE,EAAO8kE,aAEtB,MAAMrzD,EAAoC,CAAC6xD,MAAOK,EAAQe,OAAQQ,GAC5DrnD,EACF,CAAC8mD,gBAAeC,eAAcC,iBAAgBC,gBAG5ClvE,EAAS2nB,GAAOC,UACHvV,GAAqBwJ,EACrBoM,GAEnB,MAAO,CAAC2oD,gBAAiB5wE,EAAO,GAAI6wE,eAAgB7wE,EAAO,GAC7D,ICUO,MAAMgzE,GAxCbxgD,eACIk7C,EAA4BoB,EAC5BC,GAEkB,IAFKC,EAAYtuE,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,GACtCuuE,EAAcvuE,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAGR,OAAOivE,kBACxBD,EAAYxuE,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,EACjB,MAAMqtE,EAASp9C,GAAgB+8C,EAAO,QAAS,0BACzC4B,EAAU3+C,GAAgBm+C,EAAQ,SAAU,0BAE5C1kE,EAASykE,GACXd,EAAQuB,EAASP,EAAeC,EAAcC,EAC9CC,GACJH,EAAgB3kE,EAAO2kE,cACvBC,EAAe5kE,EAAO4kE,aACtBC,EAAiB7kE,EAAO6kE,eACxBC,EAAe9kE,EAAO8kE,aAEtB,MAAMyD,QAAuB7vE,QAAQ+Z,IAAI,CAACkxD,EAAOhyE,OAAQuzE,EAAQvzE,SAC3D62E,EAAYD,EAAe,GAC3BE,EAAaF,EAAe,IAK5B,gBAAC/B,EAAe,eAAEC,GAAkBT,GACtCwC,EAAWC,EAAY9D,EAAeC,EAAcC,EACpDC,GASJ,OAPInB,IAAWL,GACbK,EAAO/vE,UAELsxE,IAAYR,GACdQ,EAAQtxE,UAGH,CACL4yE,gBAAiBxM,GAASwM,EAAiB,SAC3CC,eAAgBzM,GAASyM,GAE7B,ECTO,MAAMoC,GAA0B3hD,GAAG,CAAC4hD,yBA/B3C,SACIxF,EAA4BoB,EAC5BC,GAE0B,IAFHC,EAAYtuE,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,GACtCuuE,EAAcvuE,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAGR,OAAOivE,kBACxBgB,EAAkBzvE,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,IAAAA,UAAA,GACpB,MAAMqtE,EAASp9C,GAAgB+8C,EAAO,QAAS,qBACzC4B,EAAU3+C,GAAgBm+C,EAAQ,SAAU,qBAE5C1kE,EAASykE,GACXd,EAAQuB,EAASP,EAAeC,EAAcC,EAC9C,MAKEpzD,EAAoC,CAAC6xD,MAAOK,EAAQe,OAAQQ,GAC5DrnD,EAAkC,CACtC8mD,cANqB3kE,EAAO2kE,cAO5BC,aANoB5kE,EAAO4kE,aAO3BC,eANsB7kE,EAAO6kE,eAO7BkB,sBAIInwE,EAAS2nB,GAAOC,UACHxV,GAAqByJ,EACrBoM,GAEnB,MAAO,CAAC2oD,gBAAiB5wE,EAAO,GAAIoxE,aAAcpxE,EAAO,GAC3D,ICMO,MAAMmzE,GAtCb3gD,eACIk7C,EAA4BoB,EAC5BC,GAE0B,IAFHC,EAAYtuE,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,GACtCuuE,EAAcvuE,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAGR,OAAOivE,kBACxBgB,EAAkBzvE,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,IAAAA,UAAA,GACpB,MAAMqtE,EAASp9C,GAAgB+8C,EAAO,QAAS,0BACzC4B,EAAU3+C,GAAgBm+C,EAAQ,SAAU,0BAE5C1kE,EAASykE,GACXd,EAAQuB,EAASP,EAAeC,EAAcC,EAC9C,MACEmE,EAAiBhpE,EAAO2kE,cACxBsE,EAAgBjpE,EAAO4kE,aACvBsE,EAAkBlpE,EAAO6kE,gBAExB2D,EAAWC,SACR/vE,QAAQ+Z,IAAI,CAACkxD,EAAOhyE,OAAQuzE,EAAQvzE,UAKxC,gBAAC60E,EAAe,aAAEQ,GAAgBlB,GACpC0C,EAAWC,EAAYO,EAAgBC,EAAeC,EACtDnD,GASJ,OAPIpC,IAAWL,GACbK,EAAO/vE,UAELsxE,IAAYR,GACdQ,EAAQtxE,UAGH,CACL4yE,gBAAiBxM,GAASwM,EAAiB,SAC3CQ,aAAc12B,GAAO02B,EAAc,SAEvC,ECIO,MAAMmC,GAAiBjiD,GAAG,CAACkiD,gBA1ClC,SACIC,EAAsBpyE,GACE,IADsBqyE,EAAYhzE,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,IAAAA,UAAA,GAC1DizE,EAAgBjzE,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,IAAAA,UAAA,GAClB,MAAMkzE,EAAUjjD,GAAgB8iD,EAAQ,SAAU,kBAElDx3D,EACqB,IAAjB23D,EAAQjwE,MAA+B,IAAjBiwE,EAAQjwE,KAC9B,IAAM,mEAAAxF,OACMy1E,EAAQjwE,KAAI,MAC5BsY,EACoB,IAAhB5a,EAAK9C,OACL,IAAM,gEAAAJ,OACCkD,EAAI,MACf4a,GACyB,IAArB03D,IAA+C,IAAjBD,EAC9B,IAAM,qFAGV,IAAIG,EAAcD,EACdhtB,GAAe,EACE,IAAjBgtB,EAAQjwE,OACVijD,GAAe,EACfitB,EAAcvtB,GACVstB,EAAS,CAAC,EAAGA,EAAQl2E,MAAM,GAAIk2E,EAAQl2E,MAAM,GAAIk2E,EAAQl2E,MAAM,MAGrE,QAAW2D,EAELwa,EAA+B,CAAC43D,OAAQI,GACxC5rD,EAA6B,CAACyrD,eAAcC,mBAAkBtyE,QAG9DkmB,EAAMI,GAAOC,UACHrU,GAAgBsI,EAChBoM,GAEhB,OAAI2+B,EACKN,GAAQ/+B,EAAK,CAACA,EAAI7pB,MAAM,GAAI6pB,EAAI7pB,MAAM,GAAI6pB,EAAI7pB,MAAM,KAEtD6pB,CACT,ICMO,MAAMusD,GAAwBxiD,GAAG,CAACyiD,uBA7CzC,SACIN,EAAsBpyE,GACE,IADsBqyE,EAAYhzE,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,IAAAA,UAAA,GAC1DizE,EAAgBjzE,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,IAAAA,UAAA,GAClB,MAAMkzE,EAAUjjD,GAAgB8iD,EAAQ,SAAU,yBAElDx3D,EACqB,IAAjB23D,EAAQjwE,MAA+B,IAAjBiwE,EAAQjwE,KAC9B,IAAM,0EAAAxF,OACMy1E,EAAQjwE,KAAI,MAC5BsY,EACoB,IAAhB5a,EAAK9C,OACL,IACI,uEAAAJ,OACGkD,EAAI,MACf4a,EACsB,YAAlB23D,EAAQj2E,OAAyC,UAAlBi2E,EAAQj2E,MACvC,IAAM,oDACVse,GACyB,IAArB03D,IAA+C,IAAjBD,EAC9B,IAAM,4FAEV,IAAIG,EAAcD,EACdhtB,GAAe,EACE,IAAjBgtB,EAAQjwE,OACVijD,GAAe,EACfitB,EAAcvtB,GACVstB,EAAS,CAAC,EAAGA,EAAQl2E,MAAM,GAAIk2E,EAAQl2E,MAAM,GAAIk2E,EAAQl2E,MAAM,MAErE,QAAW2D,EAELwa,EAAsC,CAAC43D,OAAQI,GAC/C5rD,EAC2B,CAACyrD,eAAcC,mBAAkBtyE,QAG5DkmB,EAAMI,GAAOC,UACHvU,GAAuBwI,EACvBoM,GAEhB,OAAI2+B,EACKN,GAAQ/+B,EAAK,CAACA,EAAI7pB,MAAM,GAAI6pB,EAAI7pB,MAAM,GAAI6pB,EAAI7pB,MAAM,KAEtD6pB,CACT,ICwEO,MAAMysD,GAAY1iD,GAAG,CAAE2iD,WA1G9B,SACIlgD,GAGiB,IAFjBsT,EAAM3mC,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,SACTwzE,EAAQxzE,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,IAAAA,UAAA,GACRyzE,EAAWzzE,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,GAEd,MAAMotE,EAASn9C,GAAgBoD,EAAO,QAAS,aAQzCqgD,EAAqBtG,EAAOpwE,MAAM,GAAKowE,EAAOpwE,MAAM,GAE1D,IACIoC,EAAGqa,EAAGta,EAAGw0E,EADTC,EAAah7D,GAAI8qD,GAAS,CAAC+P,IAAe,KAuB9C,GApBAl4D,EACoB,IAAhB6xD,EAAOnqE,KACP,IAAM,4CAA2C,gBAAAxF,OAC7B2vE,EAAOnqE,KAAI,MAEnCsY,EACwB,IAApB6xD,EAAOpwE,MAAM,IAA+B,IAAnBowE,EAAOpwE,MAAM,GACtC,IAAM,kEAC2C,WAAAS,OAClC2vE,EAAOpwE,MAAM,GAAE,MAElCue,EACmB,UAAjB6xD,EAAOnwE,OAAsC,YAAjBmwE,EAAOnwE,MACnC,IAAM,wDAAuD,iBAAAQ,OACxC2vE,EAAOnwE,MAAK,MAEnCse,EACa,SAAXorB,GAAgC,WAAXA,EACrB,IAAM,0CAANlpC,OAAgDkpC,IAE1B,IAApBymC,EAAOpwE,MAAM,GAAU,EACtBoC,EAAGqa,EAAGta,GAAKiK,GAAMgkE,EAAQ,CAAC,EAAG,EAAG,IAAK,GACtC,MAAMyG,EAAKj7D,GAAIxZ,EA9BQ,OA+BjB00E,EAAKl7D,GAAIa,EA9BU,MA+BnBuvB,EAAKpwB,GAAIzZ,EA9BS,MA+BxBw0E,EAAY16D,GAAIA,GAAI46D,EAAIC,GAAK9qC,E,MAE7B2qC,EAAYtgD,EAGhB,GAAe,SAAXsT,EAAmB,CAInBitC,EAWR,SAAcG,EAAqBC,GAE/B,IAGIC,EAAYC,EAAaC,EACzBC,EAASC,EAAkBC,EAJ3BC,EAAa7Q,GAAS,EAAE,IACxB8Q,EAAe9Q,GAAS,CAAC,IACzB+Q,EAAY/Q,GAAS,CAAC,IAI1B,IAAK,IAAI5lE,EAAQ,EAAGA,EAAQi2E,EAAUpzE,KAAK,EAAG7C,IAAS,CAEnDm2E,EAAanxE,GAAMixE,EAAW,EAAGj2E,EAAQ,GAEzCo2E,EAAcpxE,GAAMixE,EAAUj2E,EAAQ,GAEtCu2E,EAAmBz7B,GAAI95C,GAAIm1E,GAAYD,GAEvCM,EAAa17B,GAAI95C,GAAIo1E,GAAaF,GAElC,MAAMU,EAAgB51E,GAAI8Z,GAAIq7D,EAAYvW,GAAM,EAAGuW,EAAWtzE,QAE9DwzE,EAAYv7B,GAAI87B,EAAe51E,GAAIm1E,IAEnC,MAAMU,EAAc53D,GAAKm3D,EAAYl3E,MAAOi3E,EAAWtzE,MACjDi0E,EAAa37D,GAAIykD,GAAM,EAAEwW,EAAYvzE,MAAMg0E,GAC3CE,EAAaj8D,GAAIs7D,EAAcU,GACrCR,EAAUx7B,GAAI95C,GAAI+1E,GAAa/1E,GAAIo1E,IAEnC,MAAMY,EAAgB34B,GAAIg4B,EAAWC,GAC/BW,EAAgB54B,GAAIg4B,EAAWC,GAC/BY,EAAep8D,GAAIy7D,EAAkBC,GAC3CG,EAAY77D,GAAIA,GAAIo8D,EAAaF,GAAgBC,GAEjD,MAAMlnB,EAAYqE,GAAQuiB,EAAWD,GAErCA,EAAe7mB,GAAME,EAAW4mB,EAAWD,GAE3CD,EAAa5mB,GAAME,EAAW6V,GAAS,CAAC5lE,IAASy2E,E,CAGrD,OAAOA,CACX,CAnDqBU,CAHMhsB,GAAShpC,GAAK3F,GAAMq5D,GAAY,SAC/C7xD,GAAO,IACP,KAC0B4xD,E,CAGlC,MAAMwB,EAAe1B,EACjBzgB,GAAU4gB,EAAWC,GAAc1hB,GAAQyhB,EAAWC,GAI1D,OAFe3zD,GAAKrH,GAAIs8D,EAAa,KAAM,QAG/C,IC1BO,MAAMC,GAAYvkD,GAAG,CAACwkD,WAnC7B,SACI/hD,EAA4BgiD,GAGE,IAF9BC,EAAAt1E,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAsC,UACtCu1E,EAAAv1E,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAkD,WAAYiuE,EAASjuE,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,EAC1EyrD,EAA8BzrD,UAAAnC,OAAA,EAAAmC,UAAA,QAAAC,EAChC,MAAMmtE,EAASn9C,GAAgBoD,EAAO,QAAS,YAAa,WACtDmiD,EACFvlD,GAAgBolD,EAAY,aAAc,YAAa,WAE3D95D,EACoB,IAAhB6xD,EAAOnqE,KACP,IAAM,4CAA2C,gBAAAxF,OAC7B2vE,EAAOnqE,KAAI,MAEnCsY,EACyB,IAArBi6D,EAAYvyE,OACPuyE,EAAYx4E,MAAM,KAAOowE,EAAOpwE,MAAM,IACb,IAAzBw4E,EAAYx4E,MAAM,KACM,IAAzBw4E,EAAYx4E,MAAM,GACtB,IAAM,oEAEVue,EACmB,MAAfkwC,GAA8C,IAAvBA,EAAY5tD,OACnC,IACI,oEAAmE,WAAAJ,OACxDguD,EAAW,MAE9B,MAAMtwC,EAA0B,CAACkY,MAAO+5C,EAAQiI,WAAYG,GACtDjuD,EACe,CAAC+tD,gBAAeC,WAAUtH,YAAWxiB,eAE1D,OAAOxkC,GAAOC,UACVhS,GAAWiG,EAAgCoM,EACjD,ICmCO,MAAMkuD,GAAW7kD,GAAG,CAAC8kD,UApD5B,SACIx2E,EAAiBy2E,EAAkBC,GACrCn2E,EACIk2E,EAAW,IAAM,EACjB,IAAM,gDAANl4E,OAAsDk4E,EAAQ,MAClEl2E,EACIm2E,EAAW,IAAM,EACjB,IAAM,gDAANn4E,OAAsDm4E,EAAQ,MAElE,MAAM7sC,EAAK9Y,GAAgB/wB,EAAG,IAAK,YAEnCO,EACIspC,EAAG9lC,MAAQ,EACX,IAAM,4CAANxF,OAAkDsrC,EAAG9lC,KAAI,MAE7D,MAAMjG,EAAQ+rC,EAAG/rC,OACV64E,EAAGC,GAAK/sC,EAAG/rC,MAAM8F,OAAO,GAE/B,KAAM6yE,GAAYE,GAChB,MAAM,IAAIr4E,MACN,yBAAAC,OAAyBk4E,EAAQ,sDAAAl4E,OACgBo4E,EAAC,OAExD,KAAMD,GAAYE,GAChB,MAAM,IAAIt4E,MACN,yBAAAC,OAAyBm4E,EAAQ,yDAAAn4E,OACmBq4E,EAAC,OAGvDH,EAAW,IACbA,EAAWE,GAETD,EAAW,IACbA,EAAWE,GAGb,MAAM92E,EAAI4mD,GAAQ8X,GAAM,EAAGmY,EAAG,EAAG,SAAU,EAAE,EAAG,IAC1ClyE,EAAI+5D,GAAM,EAAGoY,EAAG,EAAG,SACnBC,EAAK55B,GAAIn9C,EAAG2E,GAEZqyE,EAASxhB,GACXzB,GAAUgjB,EAAI/7B,IAAQ27B,EAAU,UAChCvjB,GAAa2jB,EAAI/7B,IAAQ47B,EAAU,WAEjCK,EAAO9nB,GAAM,CAAC0nB,EAAGC,GAAI/sC,EAAG9rC,OAE9B,OAAO2oD,GACI5/B,GAAM4+C,GAAQhf,GAAQ7c,EAAI,EAAE,EAAG8sC,EAAGC,KACvB5yE,IAAIgzE,GAAOvoB,GAAMqoB,EAAQE,EAAKD,KACzCj5E,EACb,ICfO,MAAMm5E,GAAcvlD,GAAG,CAACwlD,aAjD/B,SAAsBnqD,GACpB,IAAIoqD,EACJ,GAAI/1E,MAAMC,QAAQ0rB,GAAK,CACrBoqD,GAAkB,EAClB52E,EACU,MAANwsB,GAAcA,EAAGpuB,OAAS,EAC1B,IAAM,qEAEV,MAAMutC,EAAMnf,EAAG,GAAGjvB,MAAM,GACxB,IAAK,IAAIgC,EAAI,EAAGA,EAAIitB,EAAGpuB,SAAUmB,EAC/BS,EACIwsB,EAAGjtB,GAAGhC,MAAM,KAAOouC,EACnB,IACI,gEAA+D,IAAA3tC,OAC1DwuB,EAAkBjtB,GAAGhC,MAAM,GAAE,SAAAS,OAAQ2tC,EAAG,K,MAGvDirC,GAAkB,EAClBpqD,EAAK7iB,GAAM6iB,EAAIA,EAAGjvB,MAAM,GAAI,GAAGkG,IAAI5E,GAAK4kE,GAAQ5kE,EAAG,CAAC,KAGtDmB,EACIwsB,EAAGpuB,QAAUouB,EAAG,GAAGjvB,MAAM,GACzB,IAAM,oCAAAS,OACKwuB,EAAkBpuB,OAAM,uCAAAJ,OACLwuB,EAAkB,GAAGjvB,MAAM,GAAE,OAE/D,MAAMs5E,EAAiB,GACjBC,EAAOtqD,EACb,IAAK,IAAIjtB,EAAI,EAAGA,EAAIitB,EAAGpuB,SAAUmB,EAC/Bs3E,EAAG71E,KAAKwmB,GAAOX,KAAK,KAClB,IAAIhoB,EAAIi4E,EAAKv3E,GACb,GAAIA,EAAI,EACN,IAAK,IAAI2E,EAAI,EAAGA,EAAI3E,IAAK2E,EAAG,CAC1B,MAAM6yE,EAAO59D,GAAI9Z,GAAI8Z,GAAI09D,EAAG3yE,GAAIrF,IAAKg4E,EAAG3yE,IACxCrF,EAAI69C,GAAI79C,EAAGk4E,E,CAGf,OAAO59B,GAAIt6C,EAAGoyD,GAAKpyD,EAAG,iBAI1B,OAAI+3E,EACKrwD,GAAMswD,EAAI,GAEVA,CAEX,ICaA,SAASG,GAAKn4E,GAAiC,IAApBo4E,EAAY12E,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,IAAAA,UAAA,GACrC,OAAOinB,GAAOX,KAAK,KACjB7mB,EACuB,IAAnBnB,EAAEtB,MAAMa,OACR,IAAM,0CAANJ,OACIa,EAAEtB,MAAMa,OAAM,cAEtB,MAAM24B,EAAIl4B,EAAEtB,MAAM,GACZyE,EAAInD,EAAEtB,MAAM,GAElB,IAAI25E,EAAInlB,GAAIh7B,GACRp3B,EAAI4gB,GAAM1hB,GAEd,MAAMs4E,EAAQjT,GAAS,CAAC,CAAC,IAAK,CAAC,EAAG,IAClC,IAAI7qD,EAAckH,GAAM42D,GAExB,MAAMC,EAAQrgD,GAAK/0B,EAAIA,EAAI+0B,EAC3B,IAAK,IAAI7yB,EAAI,EAAGA,EAAIkzE,IAASlzE,EAAG,CAG9B,MAAMmzE,EAAQ13E,EACR23E,EAAQj+D,EACRk+D,EAAQL,GACb79D,EAAG1Z,EAAGu3E,GAAK1vD,GAAOX,KAAK,KAEtB,MAAM2wD,EAASn0E,GAAM1D,EAAG,CAACuE,EAAGA,GAAI,CAAC6yB,EAAI7yB,EAAG,IAClCuzE,EAAQxmB,GAAKumB,GACbE,EAAMr0E,GAAM1D,EAAG,CAACuE,EAAGA,GAAI,CAAC,EAAG,IAG3BR,EAAIwqD,GAAMuE,GAAQilB,EAAK,GAAIxT,GAAS,CAAC,EAAE,KAAMA,GAAS,CAAC,CAAC,MAExDyT,EAAKj7B,GAAIg7B,EAAKv+D,GAAIzV,EAAG+zE,IACrBG,EAAOz+B,GAAIq+B,EAAQG,GAEvBt+D,EADoB,IAAlBu+D,EAAKr6E,MAAM,GACTgjB,GAAM42D,GAENn5E,GACA,CACEm5E,EACA9zE,GAAMu0E,EAAM,CAAC,EAAG,GAAI,CAACA,EAAKr6E,MAAM,GAAK,EAAGq6E,EAAKr6E,MAAM,MAGrD,GAEN,MAAMs6E,EAAMztC,GAAI+O,GAAIjQ,GAAOxlC,EAAGi0E,GAAKF,IAG7BK,EAAWz0E,GAAM1D,EAAG,CAACuE,EAAG,GAAI,CAAC6yB,EAAI7yB,EAAGlC,IACpC+1E,EAAsB5+D,GAAI0+D,EAAKx+D,GAC/B2+D,EAAeztC,GAAUlxB,GAC/B,GAAU,IAANnV,EACFvE,EAAI+8C,GAAIo7B,EAAU5uC,GAAO6uC,EAAW7uC,GAAO8uC,EAAIF,SAC1C,CACL,MAAMG,EACFv7B,GAAIo7B,EAAU5uC,GAAO6uC,EAAW7uC,GAAO8uC,EAAIF,KAC/Cn4E,EAAI3B,GAAO,CAACqF,GAAM1D,EAAG,CAAC,EAAG,GAAI,CAACuE,EAAGlC,IAAKi2E,GAAY,E,CAEpD,MAAMC,EAAuB3tC,GAAUwtC,GACjCI,EAAW90E,GAAM6zE,EAAG,CAAC,EAAGhzE,GAAI,CAAC6yB,EAAGmgD,EAAE35E,MAAM,GAAK2G,IACnD,GAAU,IAANA,EACFgzE,EAAIx6B,GAAIy7B,EAAUjvC,GAAOA,GAAOivC,EAAU9+D,GAAI6+D,QACzC,CACL,MAAME,EACF17B,GAAIy7B,EAAUjvC,GAAOA,GAAOivC,EAAU9+D,GAAI6+D,IAC9ChB,EAAIl5E,GAAO,CAACqF,GAAM6zE,EAAG,CAAC,EAAG,GAAI,CAACngD,EAAG7yB,IAAKk0E,GAAY,E,CAEpD,MAAO,CAAC/+D,EAAG1Z,EAAGu3E,KAEhBr5E,GAAQ,CAACw5E,EAAOC,EAAOC,G,CAQzB,OALKN,GAAgBlgD,EAAI/0B,IACvBk1E,EAAI7zE,GAAM6zE,EAAG,CAAC,EAAG,GAAI,CAACngD,EAAG/0B,IACzBrC,EAAI0D,GAAM1D,EAAG,CAAC,EAAG,GAAI,CAACqC,EAAGA,KAGpB,CAACk1E,EAAGv3E,IAEf,CAEO,MAAM04E,GAAKlnD,GAAG,CAACmnD,IArHtB,SAAaz5E,GAA+B,IAApBo4E,EAAY12E,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,IAAAA,UAAA,GAMlC,GALAP,EACInB,EAAE2E,MAAQ,EACV,IAAM,gEAANxF,OACIa,EAAE2E,OAEK,IAAX3E,EAAE2E,KACJ,OAAOwzE,GAAKn4E,EAAeo4E,GACtB,CAKL,MAAMsB,EAAgB15E,EAAEtB,MAAM8F,MAAM,EAAGxE,EAAEtB,MAAMa,OAAS,GAC7BqI,OAAO,CAACpK,EAAO2K,IAAS3K,EAAQ2K,GACrDwxE,EAAOrT,GACThf,GACItnD,EACA,CACE05E,EAAe15E,EAAEtB,MAAMsB,EAAEtB,MAAMa,OAAS,GACxCS,EAAEtB,MAAMsB,EAAEtB,MAAMa,OAAS,KAE/B,GACEq6E,EAAmB,GACnBC,EAAmB,GACzBF,EAAKnzE,QAAQszE,IACX,MAAOC,EAAKC,GAAO7B,GAAK2B,EAAiB1B,GACzCwB,EAAKz3E,KAAK43E,GACVF,EAAK13E,KAAK63E,KAIZ,MAAO,CAFG1yB,GAAQ5/B,GAAMkyD,EAAM,GAAI55E,EAAEtB,OAC1B4oD,GAAQ5/B,GAAMmyD,EAAM,GAAI75E,EAAEtB,O,CAGxC,ICpGO,IAAKu7E,IAAZ,SAAYA,GACVA,EAAAA,EAAA,eACAA,EAAAA,EAAA,eACAA,EAAAA,EAAA,aACAA,EAAAA,EAAA,kDACD,CALD,CAAYA,KAAAA,GAAS,KCkEd,MAAMC,GAAsB5nD,GAAG,CAAC6nD,qBAzCvC,SACIC,EAAsBriD,GACsB,IAA5CsiD,EAAS34E,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAGu4E,GAAUK,uBACxB,MAAMC,EAAU5oD,GAAgByoD,EAAQ,SAAU,uBAClD,IAAIvvB,EAAmB,KACR,MAAX9yB,IACF8yB,EAAWl5B,GAAgBoG,EAAS,UAAW,wBAGjD,MAAMyiD,EAA4B,MAAZ3vB,EAAoB0vB,EAAUjgE,GAAIigE,EAAS1vB,GAEjE,GAAIwvB,IAAcJ,GAAUQ,KAC1B,OAAOD,EAET,GAAIH,IAAcJ,GAAUS,IAC1B,OAAOl6E,GAAIg6E,GAEb,GAAIH,IAAcJ,GAAUU,KAAM,CAChC,GAAgB,MAAZ9vB,EACF,OAAOhB,GAAK2wB,GACP,CACL,MAAMI,EAAkBL,EAAQl4E,KAAOwoD,EAASxoD,KAC1CrB,EAASs5C,GAAI95C,GAAIg6E,GAAeh6E,GAAIqqD,IAC1C,OAAO+vB,EAAkB,EAAItgC,GAAIt5C,EAAQ06C,GAAOk/B,IACnB55E,C,EAGjC,GAAIq5E,IAAcJ,GAAUK,uBAAwB,CAClD,GAAgB,MAAZzvB,EACF,OAAOvQ,GAAI95C,GAAIg6E,GAAe9+B,GAAO6+B,EAAQl4E,OACxC,CACL,MAAMw4E,EAAqBvgE,GAAIuwC,EAAUl8B,GAAK4rD,EAAQ77E,QAEhDo8E,EACFn5D,GAAKnhB,GAAIm5D,GAASkhB,EAAoBn/B,GAAO,KAAM,WACvD,OAAOpB,GAAI95C,GAAIg6E,GAAeM,E,EAIlC,MAAM57E,MAAM,sBAADC,OAAuBk7E,GACpC,ICrBO,MAAMU,GAAqBzoD,GAAG,CAAC0oD,oBAlBtC,SACI/uC,EAAsBC,EACtBnU,GAC4C,IAA5CsiD,EAAS34E,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAGu4E,GAAUK,uBACxB,MAAMluC,EAAUza,GAAgBsa,EAAQ,SAAU,sBAC5CI,EACF1a,GAAgBua,EAAa,cAAe,sBAChD,IAAI2e,EAAmB,KACR,MAAX9yB,IACF8yB,EAAWl5B,GAAgBoG,EAAS,UAAW,uBAEjDz2B,EACI8qC,EAAQ1tC,MAAO2tC,EAAa3tC,MAAO,iCAEvC,MAAM07E,EAASthC,GAAI+E,GAAIzR,EAASC,IAChC,OAAO6tC,GAAoBE,EAAQvvB,EAAUwvB,EAC/C,ICIO,MAAMY,GAAiB3oD,GAAG,CAAC4oD,gBAlBlC,SACIjvC,EAAsBC,EAA2BxnC,EACjDqzB,GAC4C,IAA5CsiD,EAAS34E,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAGu4E,GAAUK,uBACxB,MAAMluC,EAAUza,GAAgBsa,EAAQ,SAAU,kBAC5CI,EACF1a,GAAgBua,EAAa,cAAe,kBAChD,IAAI2e,EAAmB,KACR,MAAX9yB,IACF8yB,EAAWl5B,GAAgBoG,EAAS,UAAW,mBAEjDz2B,EACI8qC,EAAQ1tC,MAAO2tC,EAAa3tC,MAAO,6BAEvC,MAAMopE,EAAMpsB,GAAO,GACb0+B,EAASv8B,GAAIiqB,EAAKtnE,GAAI8Z,GAAI8xB,EAASC,GAAe3nC,GAAM,IAC9D,OAAOw1E,GAAoBE,EAAQvvB,EAAUwvB,EAC/C,ICAO,MAAMc,GAAY7oD,GAAG,CAAC8oD,WAlB7B,SACInvC,EAAsBC,EACtBnU,GAC4C,IAA5CsiD,EAAS34E,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAGu4E,GAAUK,uBACpBluC,EAAUza,GAAgBsa,EAAQ,SAAU,aAChD,MAAMI,EAAe1a,GAAgBua,EAAa,cAAe,aACjE,IAAI2e,EAAmB,KACR,MAAX9yB,IACF8yB,EAAWl5B,GAAgBoG,EAAS,UAAW,cAEjDz2B,EAAkB8qC,EAAQ1tC,MAAO2tC,EAAa3tC,MAAO,wBAErD,MAAMopE,EAAMpsB,GAAO,GAEnBtP,EAAUyR,GAAIvjC,GAAIohC,GAAO,GAAItP,GAAU07B,GACvC,MAAMsS,EAASha,GAAKviB,GAAIiqB,EAAKxtD,GAAI8xB,EAASC,KAC1C,OAAO6tC,GAAoBE,EAAQvvB,EAAUwvB,EAC/C,ICSO,MAAMgB,GAAY/oD,GAAG,CAACgpD,WArB7B,SACIrvC,EAAsBC,EACtBnU,GAC4C,IADfwjD,EAAK75E,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,EACrC24E,EAAS34E,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAGu4E,GAAUK,uBACxB,MAAMluC,EAAUza,GAAgBsa,EAAQ,SAAU,aAC5CI,EAAe1a,GAAgBua,EAAa,cAAe,aACjE,IAAI2e,EAAmB,KACR,MAAX9yB,IACF8yB,EAAWl5B,GAAgBoG,EAAS,UAAW,cAEjDz2B,EAAkB8qC,EAAQ1tC,MAAO2tC,EAAa3tC,MAAO,wBAErD,MAAM88E,EAAc9/B,GAAO6/B,GACrBjzD,EAAQwwB,GAAI+E,GAAIxR,EAAcD,IAC9BqvC,EAAYtjB,GAAQ7vC,EAAOkzD,GAC3BE,EAAS79B,GAAIv1B,EAAOmzD,GAEpBrB,EACFz/D,GAAIL,GAAIohC,GAAO,IAAMhB,GAAO+gC,IAAanhE,GAAIkhE,EAAaE,IAC9D,OAAOxB,GAAoBE,EAAQvvB,EAAUwvB,EAC/C,ICAO,MAAMsB,GAAUrpD,GAAG,CAACspD,SArB3B,SACI3vC,EAAsBC,EACtBnU,GAC4C,IADfh5B,EAAO2C,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,KACvC24E,EAAS34E,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAGu4E,GAAUK,uBACxB,MAAMluC,EAAUza,GAAgBsa,EAAQ,SAAU,WAC5CI,EAAe1a,GAAgBua,EAAa,cAAe,WACjE,IAAI2e,EAAmB,KACR,MAAX9yB,IACF8yB,EAAWl5B,GAAgBoG,EAAS,UAAW,YAEjDz2B,EAAkB8qC,EAAQ1tC,MAAO2tC,EAAa3tC,MAAO,sBAErD,MAAMopE,EAAMpsB,GAAO,GACbmgC,EAAgBngC,GAAO38C,GAEvB+8E,EAAKvwC,GAAIjxB,GAAI8xB,EAAS30B,GAAIkD,GAAI0xB,EAAcwvC,MAC5CE,EACFzhE,GAAIujC,GAAIiqB,EAAK17B,GAAU30B,GAAIkD,GAAIkjC,GAAIiqB,EAAKz7B,GAAewvC,KACrDzB,EAASv8B,GAAIi+B,EAAIC,GACvB,OAAO7B,GAAoBE,EAAQvvB,EAAUwvB,EAC/C,ICTO,MAAM2B,GAAmB1pD,GAAG,CAAC2pD,kBAjBpC,SACIhwC,EAAsBC,EACtBnU,GAC4C,IAA5CsiD,EAAS34E,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAGu4E,GAAUK,uBACxB,MAAMluC,EAAUza,GAAgBsa,EAAQ,SAAU,oBAC5CI,EACF1a,GAAgBua,EAAa,cAAe,oBAChD,IAAI2e,EAAmB,KACR,MAAX9yB,IACF8yB,EAAWl5B,GAAgBoG,EAAS,UAAW,qBAEjDz2B,EACI8qC,EAAQ1tC,MAAO2tC,EAAa3tC,MAAO,+BAEvC,MAAM07E,EAAS1V,GAAkBt4B,EAASC,GAC1C,OAAO6tC,GAAoBE,EAAQvvB,EAAUwvB,EAC/C,IC8DO,MAAM6B,GAAsB5pD,GAAG,CAAC6pD,qBA5BvC,SACIC,EAAgCzmB,EAChC59B,GAC4C,IADfskD,EAAc36E,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,EAC9C24E,EAAS34E,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAGu4E,GAAUK,uBACpBgC,EAAoB3qD,GACpByqD,EAAkB,mBAAoB,uBAC1C,MAAMxmB,EAAUjkC,GAAgBgkC,EAAQ,SAAU,uBAClD,IAAI9K,EAAmB,KAOvB,GANe,MAAX9yB,IACF8yB,EAAWl5B,GAAgBoG,EAAS,UAAW,wBAEjDz2B,EACIg7E,EAAkB59E,MAAOk3D,EAAQl3D,MAAO,kCAExC29E,EAAiB,EAAG,CACtB,MAAME,EAAuB7gC,GAAO2gC,GAC9BvU,EAAMpsB,GAAO,GACb2oB,EAAO3oB,GAAO,IAEpB4gC,EACI3hE,GAAIL,GAAIgiE,EAAmBz+B,GAAIiqB,EAAKyU,IAChCjiE,GAAI+pD,EAAMkY,G,CAEpB,MAAMnC,EAhFR,SACInuC,EAAsB0pB,GACxB,MAAMvpB,EACFza,GAAgBsa,EAAQ,SAAU,iCAChC2pB,EACFjkC,GAAgBgkC,EAAQ,SAAU,iCACtCr0D,EACI8qC,EAAQ1tC,MAAOk3D,EAAQl3D,MAAO,4CAsBlC,MAAM89E,EAAYpc,GAAKxK,GACjB6mB,EAAgBniE,GAAIs7C,EAASxpB,GAC7BswC,EAAgBxnB,GAAMryD,GAAI0oC,GAAIuN,GAAI8c,MAExC,OAAOj7C,GAAIkjC,GAAI2+B,EAAWC,GAAgBC,EAC5C,CA8CiBC,CAA+BL,EAAmB1mB,GAEjE,OAAOskB,GAAoBE,EAAQvvB,EAAUwvB,EAC/C,ICqCO,MAAMuC,GAAsBtqD,GAAG,CAACuqD,qBA/BvC,SACIC,EAA4BnnB,EAC5B59B,GAC4C,IADfskD,EAAc36E,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,EAC9C24E,EAAS34E,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAGu4E,GAAUK,uBACpByC,EACAprD,GAAgBmrD,EAAc,eAAgB,uBAClD,MAAMlnB,EAAUjkC,GAAgBgkC,EAAQ,SAAU,uBAClD,IAAI9K,EAAmB,KASvB,GAPe,MAAX9yB,IACF8yB,EAAWl5B,GAAgBoG,EAAS,UAAW,wBAGjDz2B,EACIy7E,EAAcr+E,MAAOk3D,EAAQl3D,MAAO,kCAEpC29E,EAAiB,EAAG,CACtB,MAAME,EAAuB7gC,GAAO2gC,GAC9BvU,EAAMpsB,GAAO,GACbvP,EAAauP,GAAOqhC,EAAcr+E,MAAM,IAE9Cq+E,EACIpiE,GAAIL,GAAIyiE,EAAel/B,GAAIiqB,EAAKyU,IAC5BjiC,GAAIiiC,EAAsBpwC,G,CAGpC,MAAMiuC,EAvFR,SACInuC,EAAW0pB,GAAmB,IAAR7oB,EAAGprC,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,IAAI,EAK/B,IAJa,IAATorC,IACFA,EAAM6oB,EAAOhxD,KAAO,GAGlBmoC,IAAQ6oB,EAAOhxD,KAAO,EACxB,MAAMzF,MACF,sGAAAC,OACuCw2D,EAAOhxD,KAAI,KAAG,eAAAxF,OACtC2tC,IAGrB,MAAM0oB,EACFpmC,GAAW,CAAC6c,EAAgB0pB,EAAgBpmC,KAI1C,MACMytD,EAAMhnB,GAAUL,EAAQ,CAAC7oB,IADd,GAEXmwC,EAAYp/B,GAAIl8B,GAAKg0C,EAAQ,WAAYqnB,GAC/CztD,EAAK,CAAC0c,EAAQgxC,IAEd,MAAMC,EAAa3xC,GAAIjxB,GAAI2iE,EAAWhxC,IAatC,MAAO,CAACzuC,MAZSgD,GAAI08E,EAAY,CAACpwC,IAYnBhgB,SAVEA,CAAC/D,EAAOY,KACvB,MAAOsiB,EAAQgxC,GAAatzD,EACtBwzD,EAAU1rB,GAAqB1oC,EAAGrqB,MAAO,CAACouC,IAChD,MAAO,CACLxyB,GAAIgtC,GAAQv+B,EAAIo0D,GACZt/B,GAAIl8B,GAAKsqB,EAAQ,WAAYppC,GAAIo6E,KACrC3iE,GAAIgtC,GAAQv+B,EAAIo0D,GACZt/B,GAAIh7C,GAAIo6E,GAAYt7D,GAAKsqB,EAAQ,kBAM/C,OAAOupB,EAASvpB,EAAQ0pB,EAC1B,CA+CiBynB,CAA+BL,EAAennB,GAE7D,OAAOskB,GAAoBE,EAAQvvB,EAAUwvB,EAC/C,IC3BO,MAAMgD,GAAsB/qD,GAAG,CAACgrD,qBA7CvC,SACIlsD,EAA8B3yB,EAC9B8+E,EACAlgB,GACF,MAAM+K,EACFz2C,GAAgBP,EAAS,UAAW,sBAAuB,SACzD4lC,EAAUrlC,GAAgBlzB,EAAQ,SAAU,uBAC5C++E,EACF7rD,GAAgB4rD,EAAY,aAAc,sBAAuB,SAC/D1U,EAAgBl3C,GAClB0rC,EAAc,eAAgB,sBAAuBrG,EAAQr4D,OAEjE,GAAsB,IAAlBypE,EAASzjE,KACX,MAAM,IAAIzF,MAAM,0DAADC,OACTipE,EAAS1pE,QAEjB,GAAqB,IAAjBs4D,EAAQryD,KACV,MAAM,IAAIzF,MAAM,gDAADC,OACqC63D,EAAQt4D,QAE9D,GAAyB,IAArB8+E,EAAY74E,KACd,MAAM,IAAIzF,MAAM,qDAADC,OACXq+E,EAAY9+E,QAElB,GAA2B,IAAvBmqE,EAAclkE,KAChB,MAAM,IAAIzF,MAAM,uDAADC,OACX0pE,EAAcnqE,QAGpB,MAAMme,EAAoC,CACxCuU,QAASg3C,EACT3pE,OAAQu4D,EACRumB,WAAYC,EACZngB,aAAcwL,GAGV7nE,EAAmB2nB,GAAOC,UAAUhT,GAAqBiH,GAC/D,MAAO,CACL4gE,cAAez8E,EAAO,GACtB08E,aAAc18E,EAAO,GACrB28E,kBAAmB38E,EAAO,GAC1B48E,gBAAiB58E,EAAO,GAE5B,ICjCO,MAAM68E,GAAgBvrD,GAAG,CAACwrD,eAhCjC,SACIC,EAAmC5/D,EACnC5Z,GACF,MAAMy5E,EACFrsD,GAAgBosD,EAAc,eAAgB,gBAAiB,SAC7DE,EACFtsD,GAAgBxT,EAAY,aAAc,gBAAiB,SACzD+/D,EACFvsD,GAAgBptB,EAAU,WAAY,gBAAiB,SAE3D,GAA2B,IAAvBy5E,EAAcr5E,KAChB,MAAM,IAAIzF,MAAM,gEAADC,OACT6+E,EAAct/E,QAEtB,GAAyB,IAArBu/E,EAAYt5E,KACd,MAAM,IAAIzF,MAAM,qDAADC,OACX8+E,EAAYv/E,QAElB,GAAuB,IAAnBw/E,EAAUv5E,KACZ,MAAM,IAAIzF,MAAM,mDAADC,OACwC++E,EAAUx/E,QAGnE,MAAMme,EAA8B,CAClCkhE,aAAcC,EACd7/D,WAAY8/D,EACZ15E,SAAU25E,GAENl9E,EAAmB2nB,GAAOC,UAAU/S,GAAegH,GACzD,MAAO,CAAC4gE,cAAez8E,EAAO,GAAImsD,YAAansD,EAAO,GACxD,ICAO,MAAMm9E,GAAoB7rD,GAAG,CAAC8rD,mBA/BrC,SACIrhF,EAAyBq0B,EACzB+0C,GACF,MAAMpd,EAAQp3B,GAAgB50B,EAAM,OAAQ,qBACtCqrE,EACFz2C,GAAgBP,EAAS,UAAW,oBAAqB,SACvDi1C,EACF10C,GAAgBw0C,EAAY,aAAc,oBAAqB,SAEnE,GAAIpd,EAAMpkD,KAAO,EACf,MAAM,IAAIzF,MAAM,6DAGlB,GAAsB,IAAlBkpE,EAASzjE,KACX,MAAM,IAAIzF,MAAM,4DAADC,OACPipE,EAAS1pE,QAEnB,GAAyB,IAArB2nE,EAAY1hE,KACd,MAAM,IAAIzF,MAAM,gEAADC,OACPknE,EAAY3nE,QAGtB,MAAMme,EAAkC,CACtC9f,KAAMgsD,EACN33B,QAASg3C,EACTjC,WAAYE,GAGd,OAAO19C,GAAOC,UAAU9S,GAAmB+G,EAC7C,ICEO,MAAMwhE,GAAmB/rD,GAAG,CAACgsD,kBA/BpC,SACIvhF,EAAyBq0B,EACzB+0C,GACF,MAAMpd,EAAQp3B,GAAgB50B,EAAM,OAAQ,oBACtCqrE,EACFz2C,GAAgBP,EAAS,UAAW,mBAAoB,SACtDi1C,EACF10C,GAAgBw0C,EAAY,aAAc,mBAAoB,SAElE,GAAIpd,EAAMpkD,KAAO,EACf,MAAM,IAAIzF,MAAM,6DAGlB,GAAsB,IAAlBkpE,EAASzjE,KACX,MAAM,IAAIzF,MAAM,2DAADC,OACRipE,EAAS1pE,QAElB,GAAyB,IAArB2nE,EAAY1hE,KACd,MAAM,IAAIzF,MAAM,+DAADC,OACRknE,EAAY3nE,QAGrB,MAAMme,EAAiC,CACrC9f,KAAMgsD,EACN33B,QAASg3C,EACTjC,WAAYE,GAGd,OAAO19C,GAAOC,UAAU7S,GAAkB8G,EAC5C,ICWO,MAAM0hE,GAAejsD,GAAG,CAACksD,cAhChC,SACIzhF,EAA2B0hF,EAA+BC,EAC1DC,EAAuBC,EAAiBt7E,EAAkBu7E,EAC1DC,GACF,MAAM/1B,EAAQp3B,GAAgB50B,EAAM,OAAQ,eAAgB,UAC5D,GAAoB,WAAhBgsD,EAAMpqD,MACR,MAAM,IAAIO,MAAM,mCAElB,GAA2B,IAAvB6pD,EAAMrqD,MAAMa,OACd,MAAM,IAAIL,MAAM,+BAADC,OAAgC4pD,EAAMrqD,QAGvD,MAAMqgF,EAAcptD,GAAgB8sD,EAAY,aAAc,gBAC9D,GAA0B,UAAtBM,EAAYpgF,MACd,MAAM,IAAIO,MAAM,yCAGlB,MAAM+pB,EAA2B,CAC/By1D,YACAC,cACAC,UACAt7E,WACAu7E,WACAC,0BAGIjiE,EAA6B,CAAC9f,KAAMgsD,EAAO01B,WAAYM,GACvD/9E,EACF2nB,GAAOC,UAAUxS,GAAcyG,EAAcoM,GACjD,MAAO,CAAC+1D,OAAQh+E,EAAO,GAAIi+E,aAAcj+E,EAAO,GAClD,IChBO,MAAMk+E,GAAc5sD,GAAG,CAAC6sD,aAvB/B,SACIjhE,EAA4BkhE,GACZ,IAAhBC,IAAS39E,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,KAAAA,UAAA,GACX,MAAM49E,EAAS3tD,GAAgBzT,EAAO,QAAS,cAAe,UACxDqhE,EACF5tD,GAAgBytD,EAAW,YAAa,cAAe,UAE3D,GAAoB,IAAhBE,EAAO36E,KACT,MAAM,IAAIzF,MAAM,+CAADC,OACoCmgF,EAAO5gF,QAE5D,GAAwB,IAApB6gF,EAAW56E,KACb,MAAM,IAAIzF,MAAM,mDAADC,OACwCogF,EAAW7gF,QAGpE,MAAMuqB,EAA0B,CAACo2D,aAC3BxiE,EAA4B,CAACqB,MAAOohE,EAAQF,UAAWG,GACvDv+E,EACF2nB,GAAOC,UAAUvS,GAAawG,EAAcoM,GAChD,MAAO,CAACmI,QAASpwB,EAAO,GAAIvC,OAAQuC,EAAO,GAAItC,MAAOsC,EAAO,GAC/D,ICnBO,MAAMw+E,GAAyBltD,GAAG,CAACmtD,wBAd1C,SACIvhE,EAA0BwhE,GAC5B,MAAMJ,EACF3tD,GAAgBzT,EAAO,QAAS,yBAA0B,UACxD+K,EAAqC,CAACy2D,cAE5C,GAAIA,GAAc,EAChB,MAAM,IAAIxgF,MAAM,wCAGlB,MAAM2d,EAAuC,CAACqB,MAAOohE,GACrD,OAAO32D,GAAOC,UAAUtS,GAAwBuG,EAAcoM,EAChE,IC0KM02D,GAAW,CACf3c,IAAG,GACHE,KAAI,GACJa,KAAI,GACJX,MAAKA,IASD0K,GAAS,CACbN,cAAa,GACbE,WAAU,GACVE,MAAK,GACLO,KAAIA,IAkBAp5C,GAAQ,CACZm6C,cAAa,GACbE,eAAc,GACd0F,sBAAqB,GACrBP,eAAc,GACd/E,iBAAgB,GAChBhB,cAAa,GACb4B,kBAAiB,GACjBsD,uBAAsB,GACtBI,2BAA0B,GAC1BE,gCAA+B,GAC/BC,wBAAuB,GACvBE,6BAA4B,GAC5Ba,UAAS,GACT6B,UAASA,IAOL+I,GAAS,CACbzI,SAAQ,GACRU,YAAW,GACX2B,GAAEA,IAaEY,GAAS,CACbW,mBAAkB,GAClBb,oBAAmB,GACnBe,eAAc,GACdE,UAAS,GACTE,UAAS,GACTM,QAAO,GACPK,iBAAgB,GAChBE,oBAAmB,GACnBU,oBAAmBA,IAOf1nC,GAAS,CACbmoC,oBAAmB,GACnBQ,cAAa,GACbM,kBAAiB,GACjBE,iBAAgBA,IAOZwB,GAAS,CACbtB,aAAY,GACZW,YAAW,GACXM,uBAAsBA,IC1SXM,GAAQ,CACnB7+B,IAAKD,GAAsBC,IAC3BlB,SAAUiB,GAAsBjB,SAChCqB,SAAUJ,GAAsBI,SAChCE,QAASN,GAAsBM,QAC/BJ,QAASF,GAAsBE,QAC/BG,OAAQL,GAAsBK,OAC9BF,KAAMH,GAAsBG,MCrBxB4+B,GACiC,qBAA1BC,sBACFA,sBAC0B,qBAAjBC,aACTA,aAEDhiF,GAAgBA,IAa1B,SAASiiF,KACP,OAAO,IAAIp8E,QAAcC,GAAWg8E,GAAc,IAAMh8E,KAC1D,CCnBM,SAAUo8E,GAAuBC,EAAoB17E,GACzD,MAAMC,EAAOy7E,EAAO,GAAG7gF,OACvB6gF,EAAO55E,QAAQ,CAAC9H,EAAOgC,KACrBuc,EACIve,EAAMa,SAAWoF,EACjB,IACI,kBAAAxF,OAAkBwF,EAAI,uBAAAxF,OAAsBuB,EAAC,mDAAAvB,OACjBwF,EAAI,QAG1CsY,EACIvY,GAAQ,GAAKA,EAAOC,EACpB,IAAM,kBAANxF,OAAwBwF,EAAI,kCAAAxF,OAAiCwF,EAAO,EAAC,MAEzE,MAAM07E,EAAaD,EAAO,GAC1BA,EAAO55E,QAAQ,CAAC9H,EAAOgC,KACrB,IAAK,IAAII,EAAI,EAAGA,EAAI6D,EAAM7D,IACxBmc,EACKnc,IAAM4D,GAAUhG,EAAMoC,KAAOu/E,EAAWv/E,GACzC,IAAM,kBAAA3B,OAAkBwF,EAAI,wBAAAxF,OAAuBuB,EAAC,OAAAvB,OAAMT,EAAK,+CAAAS,OAClBkhF,EAAU,MAAI,mCAAAlhF,OACpBuB,EAAC,OAGlD,CAEM,SAAUixC,GAAgByuC,EAAoB17E,GAClD,MAAMyoD,EAAcizB,EAAO,GAAG57E,QAC9B,IAAK,IAAI9D,EAAI,EAAGA,EAAI0/E,EAAO7gF,OAAQmB,IACjCysD,EAAYzoD,IAAS07E,EAAO1/E,GAAGgE,GAEjC,OAAOyoD,CACT,CClCO,IAAKmzB,GASN,SAAUC,GACZC,EAAoB9hF,EAAiB+hF,GAKvC,IAAItzB,EAAwB,IAAInrD,MAChC,GAAkB,MAAdy+E,GAA+B,MAAT/hF,EACxB,OAAOyuD,EAGT,GAAa,MAATzuD,EAEF,KAAOyuD,EAAY5tD,OAASihF,EAAaC,EAAWlhF,QAClD4tD,EAAYhrD,MAAM,QAGpBgrD,EAAczuD,EAAM8F,QAEtB,GAAkB,MAAdi8E,EACF,OAAOtzB,EAGT,GAAIqzB,EAAaC,EAAWlhF,SAAW4tD,EAAY5tD,OACjD,MAAM,IAAIL,MAAM,4BAADC,OACiBT,EAAK,uCAAAS,OAC7BqhF,EACAC,EAAWlhF,OAAM,uBAAAJ,OAAsBguD,EAAY5tD,SAG7D,IAAK,IAAImB,EAAI,EAAGA,EAAI+/E,EAAWlhF,SAAUmB,EAAG,CAC1C,MAAMggF,EAAWD,EAAW//E,GACtBigF,EACFxzB,EAAYA,EAAY5tD,OAASkhF,EAAWlhF,OAASmB,GACnDkgF,EAAiBzzB,EAAYwzB,GAEnC,GAAID,GAAY,EACd,GAAIE,GAAkB,GACpB,GAAIA,IAAmBF,EACrB,MAAM,IAAIxhF,MAAM,4BAADC,OACXT,EAAK,sCAAAS,OAAqCuB,EAAI8/E,EAAU,QAAArhF,OACxDuhF,EAAQ,eAAAvhF,OAAcuB,EAAI8/E,EAAU,QAAArhF,OAAOyhF,SAGjDzzB,EAAYwzB,GAAuBD,C,CAIzC,OAAOvzB,CACT,CAEM,SAAU0zB,GAA2BC,GACzC,MAAMC,EAAe,CACnB,eAAkBT,GAAiBU,eACnC,aAAgBV,GAAiBW,aACjC,YAAeX,GAAiBY,YAChC,WAAcZ,GAAiBa,WAC/B,WAAcb,GAAiBc,WAC/B,WAAcd,GAAiBe,YAG3BrgF,EAA6B,GACnC,IAAK,MAAMsgF,KAAWR,EAAyB,CAC7C,KAAIQ,KAAWP,GAGb,MAFA//E,EAAOmB,KAAK4+E,EAAaO,G,CAM7B,OAAOtgF,CACT,CAEM,SAAUugF,GAAchkB,GAC5B,OAAiC,IAA7BA,EAAkBh+D,OACb,EAELg+D,EAAkB,KAAO+iB,GAAiBU,eACrCzjB,EAAkBh+D,OAAS,EAE7Bg+D,EAAkBh+D,MAC3B,CAEM,SAAUiiF,GACZC,EAA6BhB,GAC/B,GAAyB,MAArBgB,GAA2C,MAAdhB,EAC/B,OAGF,MAAMiB,EAAeD,EAAkBliF,OACjCoiF,EAAclB,EAAWlhF,OAC/B,GAAImiF,GAAgBC,EAClB,MAAM,IAAIziF,MAAM,sBAADC,OACXsiF,EAAiB,wCAAAtiF,OACjBshF,EAAU,4CAAAthF,OACVuiF,EAAY,6DAAAviF,OACZwiF,EAAW,MAEjB,IAAK,IAAIjhF,EAAI,EAAGA,EAAIjB,KAAKM,IAAI2hF,EAAcC,EAAc,KAAMjhF,EAAG,CAChE,MAAMkhF,EAAaH,EAAkB/gF,GAC/BggF,EAAWD,EAAW//E,EAAI,GAChC,GAAIkhF,GAAc,GAAKlB,GAAY,GAAoB,IAAfkB,GACpCA,IAAelB,EACjB,MAAM,IAAIxhF,MAAM,sBAADC,OACXsiF,EAAiB,+CAAAtiF,OACjBshF,EAAU,0CAAAthF,OACVuB,EAAI+gF,EAAkBliF,OAAM,QAAAJ,OAC5ByiF,EAAU,8CAAAziF,OACVuB,EAAI+gF,EAAkBliF,OAAM,QAAAJ,OAAOuhF,G,CAG7C,EAxHA,SAAYJ,GACVA,EAAAA,EAAA,mCACAA,EAAAA,EAAA,+BACAA,EAAAA,EAAA,6BACAA,EAAAA,EAAA,2BACAA,EAAAA,EAAA,2BACAA,EAAAA,EAAA,0BACD,CAPD,CAAYA,KAAAA,GAAgB,KCMrB,MAAMuB,GAAwB,GAS/B,SAAUC,GAAyBC,GACvC,OAAIA,GAAUF,GACLE,EAEF96E,GAAe86E,EAAQtiF,KAAKkJ,MAAMlJ,KAAKwD,KAAK8+E,IACrD,CCnBM,SAAUC,GACZpS,EAAiCqS,EACjCC,GAKF,MAAO,CAHHA,GAAgC,kBAAXtS,EAAsBA,EAASA,EAAO,IAE3DqS,GAAiC,kBAAXrS,EAAsBA,EAASA,EAAO,IAElE,CCDM,SAAUuS,GACZhkE,EAAsBqrC,EAAsBE,GACzB,IACjB04B,EAAqB,GACzB,KAFc1gF,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,KAAAA,UAAA,GAGZ0gF,EAAWA,EAASjjF,OAAOqqD,EAAWhlD,MAAM,IAC5C49E,EAASjgF,KAAKgc,EAAW,GAAKurC,GAC9B04B,EAAWA,EAASjjF,OAAOgf,EAAW3Z,MAAM,QACvC,CACL49E,EAAWA,EAASjjF,OAAOgf,EAAW,IACtC,MAAMkkE,EAAgB74B,EAAWjqD,OACjC,IAAK,IAAImB,EAAI,EAAGA,EAAI2hF,IAAiB3hF,EACnC0hF,EACIA,EAASjjF,OAAO,CAACgf,EAAWzd,EAAI,GAAK8oD,EAAW9oD,GAAI8oD,EAAW9oD,KAErE0hF,EAAWA,EAASjjF,OAAOgf,EAAW3Z,MAAM69E,EAAgB,G,CAE9D,OAAOD,CACT,CAWM,SAAUE,GACZC,EAAsBC,GAExB,MAAMC,EAAW,GACjB,KAFc/gF,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,KAAAA,UAAA,GAEI,CAChB+gF,EAAStgF,KAAKqgF,GACd,IAAK,IAAI9hF,EAAI8hF,EAAiB,EAAG9hF,EAAI6hF,IAAgB7hF,EAC/CA,GAAK,EAAI8hF,GACXC,EAAStgF,KAAKzB,GACd+hF,EAAStgF,KAAKzB,GAAK8hF,EAAiB,KAEpCC,EAAStgF,KAAKzB,E,KAGb,CACL,MAAMgiF,EAAsB,GACtBC,EAAqB,GAC3B,IAAK,IAAIjiF,EAAI,EAAGA,EAAI6hF,IAAgB7hF,EAC9BA,GAAsB,EAAjB8hF,EAAqB,GAAK9hF,EAAI,IAAM,EAC3CiiF,EAAmBxgF,KAAKzB,GAExBgiF,EAAoBvgF,KAAKzB,GAG7B+hF,EAAStgF,QAAQugF,GACjBD,EAAStgF,KAAK,GACdsgF,EAAStgF,QAAQwgF,E,CAEnB,OAAOF,CACT,CAWM,SAAUG,GACZzkE,EAAsBqrC,EAAsBE,GACzB,IAAnBm5B,IAAYnhF,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,KAAAA,UAAA,GACd,MAAMohF,EAAmB,GAErBD,EACFC,EAAiB3gF,KAAKgc,EAAW,GAAKurC,GAEtCo5B,EAAiB3gF,KAAKgc,EAAW,GAAKurC,GAGxC,IAAK,IAAIhpD,EAAI,EAAGA,EAAIyd,EAAW5e,SAAUmB,EACnCA,GAAK8oD,EAAWjqD,OACdsjF,EACFC,EAAiB3gF,KAAKqnD,EAAW9oD,EAAI,GAAKyd,EAAWzd,IAErDoiF,EAAiB3gF,KAAKgc,EAAWzd,GAAK8oD,EAAW9oD,EAAI,IAGvDoiF,EAAiB3gF,KAAKgc,EAAWzd,IAIrC,OAAOoiF,CACT,CAMM,SAAUC,GACZt5B,EAAmBD,GACrB,MAAMw5B,EAAmB,CAAC,GAC1B,IAAK,IAAItiF,EAAI,EAAGA,EAAI8oD,IAAc9oD,EAChCsiF,EAAiB7gF,KAAKsnD,EAAM/oD,GAAG,IAEjC,OAAOsiF,CACT,CAaM,SAAUC,GACZC,EAA0Bz5B,EAAmBD,GAC/C,MAAM/Y,EAAYyyC,EAAe1+E,MAAM,EAAG,GAC1C,IAAK,IAAI9D,EAAI,EAAGA,EAAI8oD,IAAc9oD,EAChC+vC,EAAUtuC,KAAK+gF,EAAexiF,EAAI,GAAK+oD,EAAM/oD,GAAG,GAAK+oD,EAAM/oD,GAAG,IAGhE,OAAO+vC,CACT,CCvIO,MAAM0yC,GAAkB,mBAClBC,GAAa,mBCDbC,GAAQ,SACRC,GAAS,WACTC,IAAU,WACVC,GAAS,YACTC,IAAU,YACVC,GAAS,YCUhB,SAAUC,GACZ7wD,EAAoBC,GACtB,GAAID,EAAKvzB,SAAWwzB,EAAKxzB,OACvB,MAAM,IAAIL,MACN,mEAAAC,OACG2zB,EAAKvzB,OAAM,YAAAJ,OAAW4zB,EAAKxzB,OAAM,MAE1C,MAAMyB,EAAS,IAAIuE,aAA2B,EAAdutB,EAAKvzB,QACrC,IAAK,IAAImB,EAAI,EAAGA,EAAIM,EAAOzB,OAAQmB,GAAK,EACtCM,EAAON,GAAKoyB,EAAKpyB,EAAI,GACrBM,EAAON,EAAI,GAAKqyB,EAAKryB,EAAI,GAE3B,OAAOM,CACT,CAgBM,SAAU4iF,GAAuBhxD,GAErC,MAAME,EAAO,IAAIvtB,aAAaqtB,EAAQrzB,OAAS,GACzCwzB,EAAO,IAAIxtB,aAAaqtB,EAAQrzB,OAAS,GAC/C,IAAK,IAAImB,EAAI,EAAGA,EAAIkyB,EAAQrzB,OAAQmB,GAAK,EACvCoyB,EAAKpyB,EAAI,GAAKkyB,EAAQlyB,GACtBqyB,EAAKryB,EAAI,GAAKkyB,EAAQlyB,EAAI,GAE5B,MAAO,CAACoyB,OAAMC,OAChB,CAMM,SAAU8wD,GAAqBjxD,GAEnC,MAAMjrB,EAAMlI,KAAKuD,KAAK4vB,EAAQrzB,OAAS,GACjCuzB,EAAO,IAAIvtB,aAAaoC,GACxBorB,EAAO,IAAIxtB,aAAaoC,GAC9B,IAAK,IAAIjH,EAAI,EAAGA,EAAIkyB,EAAQrzB,OAAQmB,GAAK,EACvCoyB,EAAKrzB,KAAKkJ,MAAMjI,EAAI,IAAMkyB,EAAQlyB,GAClCqyB,EAAKtzB,KAAKkJ,MAAMjI,EAAI,IAAMkyB,EAAQlyB,EAAI,GAExC,MAAO,CAACoyB,OAAMC,OAChB,CAMM,SAAU+wD,GAAoBlxD,GAElC,MAAMjrB,EAAMlI,KAAKkJ,MAAMiqB,EAAQrzB,OAAS,GAClCuzB,EAAO,IAAIvtB,aAAaoC,GACxBorB,EAAO,IAAIxtB,aAAaoC,GAC9B,IAAK,IAAIjH,EAAI,EAAGA,EAAIkyB,EAAQrzB,OAAQmB,GAAK,EACvCoyB,EAAKrzB,KAAKkJ,MAAMjI,EAAI,IAAMkyB,EAAQlyB,GAClCqyB,EAAKtzB,KAAKkJ,MAAMjI,EAAI,IAAMkyB,EAAQlyB,EAAI,GAExC,MAAO,CAACoyB,OAAMC,OAChB,CAOM,SAAUgxD,GACZnxD,EAAuBpzB,GAGzB,MAAO,CAACszB,KAFKF,EAAgB,EAARpzB,GAEPuzB,KADDH,EAAgB,EAARpzB,EAAY,GAEnC,CAQM,SAAUwkF,GACZjnF,EAAkB+1B,EAAcC,EAAcvzB,GAChDzC,EAAa,EAARyC,GAAaszB,EAClB/1B,EAAa,EAARyC,EAAY,GAAKuzB,CACxB,CAKM,SAAUkxD,GACZ9gF,EAAW+gF,GACb,MAAMpxD,EAAO,IAAIvtB,aAAapC,EAAI,GAC5B4vB,EAAO,IAAIxtB,aAAapC,EAAI,GAClC,IAAK,IAAIzC,EAAI,EAAGA,EAAIjB,KAAKuD,KAAKG,EAAI,GAAIzC,IAAK,CACzC,MAAMV,GAAKkkF,EAAU,GAAK,GAAKzkF,KAAK0qE,IAAMzpE,EAAIyC,GAC9C2vB,EAAKpyB,GAAKjB,KAAKmuD,IAAI5tD,GACnB+yB,EAAKryB,GAAKjB,KAAK0iE,IAAIniE,E,CAErB,MAAO,CAAC8yB,OAAMC,OAChB,CAKM,SAAUoxD,GACZhgE,EAAWhhB,EAAW+gF,GACxB,MAAMlkF,GAAKkkF,EAAU,GAAK,GAAKzkF,KAAK0qE,IAAMhmD,EAAIhhB,GAG9C,MAAO,CAAC2vB,KAFKrzB,KAAKmuD,IAAI5tD,GAER+yB,KADDtzB,KAAK0iE,IAAIniE,GAExB,CC/HA,MAAMokF,GAAQ,KACRC,GAAc,MACdC,GAAQ,IACRC,GAAW,MAeX,SAAUC,GAAqB5zB,EAAkBnsC,GAMrD,MAAMggE,IADN7zB,EAAWA,EAASvlD,QAAQ,MAAO,KAErB9L,OAASqxD,EAASvlD,QAAQg5E,GAAa,IAAI9kF,QACrD6kF,GAAM7kF,OACV,GAAIklF,EAAY,EACd,MAAM,IAAIvlF,MAAM,iDACX,GAAIulF,EAAY,EACrB,MAAM,IAAIvlF,MAAM,6CAADC,OAA8CilF,GAAK,QAEpE,MAAOM,EAAaC,GAAgB/zB,EAAS9lD,MAAMs5E,IACnDjjF,GACuC,IAAnCujF,EAAY5yD,QAAQyyD,IACpB,IAAM,2BAANplF,OAAiColF,GAAQ,6BAC7C,MAAMK,EAAaF,EAAY55E,MAAMw5E,IAC/BO,EAAYD,EAAWrlF,OAC7B,GAAIklB,IAAeogE,EACjB,MAAM,IAAI3lF,MAAM,YAADC,OACC0lF,EAAS,6BAAA1lF,OAA4BslB,IAEvD,GAAIogE,EAAY,EACd,MAAM,IAAI3lF,MACN,iEAGN,MAAM4lF,EAAoB,GAC1B,IAAK,IAAIpkF,EAAI,EAAGA,EAAIikF,EAAaplF,SAAUmB,EAAG,CAC5C,MAAMqkF,EAAUJ,EAAajkF,GAC7B,IAAKkkF,EAAWlhE,KAAKshE,IAA6C,IAAhCA,EAAUlzD,QAAQizD,IAClD,MAAM,IAAI7lF,MACN,uCAAAC,OAAuC4lF,EAAO,8CAGlB,IAA9BD,EAAQhzD,QAAQizD,IAClBD,EAAQ3iF,KAAK4iF,E,CAGjB,IAAK,IAAIrkF,EAAI,EAAGA,EAAIgkF,EAAYnlF,SAAUmB,EAAG,CAC3C,MAAMqkF,EAAUL,EAAYhkF,IACM,IAA9BokF,EAAQhzD,QAAQizD,IAAmBA,IAAYT,IACjDQ,EAAQ3iF,KAAK4iF,E,CAIjB,MAAME,EAAqB,IAAIjjF,MAAgB4iF,EAAWrlF,QAC1D,IAAK,IAAImB,EAAI,EAAGA,EAAImkF,IAAankF,EAAG,CAClC,GAAI,IAAIojB,IAAI8gE,EAAWlkF,GAAGoK,MAAM,KAAKzI,OAASuiF,EAAWlkF,GAAGnB,OAC1D,MAAM,IAAIL,MACN,2CAAAC,OAA2CylF,EAAWlkF,GAAE,qEAG9DukF,EAAOvkF,GAAK,GACZ,IAAK,IAAI2E,EAAI,EAAGA,EAAIu/E,EAAWlkF,GAAGnB,SAAU8F,EAC1C4/E,EAAOvkF,GAAGyB,KAAK2iF,EAAQhzD,QAAQ8yD,EAAWlkF,GAAG2E,I,CAIjD,MAAM2jE,EAAU8b,EAAQvlF,OAElB2lF,EAAuB,GAC7B,IAAK,IAAIxkF,EAFUikF,EAAaplF,OAEPmB,EAAIsoE,IAAWtoE,EACtCwkF,EAAW/iF,KAAKzB,GAElB,MAAO,CAACokF,UAASI,aAAYD,SAC/B,CAaM,SAAUE,GAAqBC,EAAeH,GAElD,IAAII,EAA+B,IAAIrjF,MAAcojF,GACrDC,EAAmB5mE,MAAM,GACzB,IAAK,IAAI/d,EAAI,EAAGA,EAAIukF,EAAO1lF,SAAUmB,EACnC2kF,EAAmBJ,EAAOvkF,IAAMA,EAElC,MAAMkyD,EAAuB,GAC7B,IAAK,IAAIlyD,EAAI,EAAGA,EAAI0kF,IAAS1kF,GACI,IAA3B2kF,EAAmB3kF,IACrBkyD,EAAWzwD,KAAKzB,GAIpB,OADA2kF,EAAqBA,EAAmBx5D,OAAOpkB,IAAY,IAAPA,GAC7C,CAAC49E,qBAAoBzyB,aAC9B,CAMM,SAAU0yB,GACZF,EAAeH,EAAoBv6D,GACrC,MAAM66D,EAAqB,IAAIvjF,MAAcojF,GAC7C,IAAK,IAAI1kF,EAAI,EAAGA,EAAIgqB,EAAQnrB,SAAUmB,EAAG,CACvC,MAAMhC,EAAkBgsB,EAAQhqB,GAAGhC,MACnC,IAAK,IAAI2G,EAAI,EAAGA,EAAI4/E,EAAOvkF,GAAGnB,SAAU8F,OACP1D,IAA3B4jF,EAASN,EAAOvkF,GAAG2E,IACrBkgF,EAASN,EAAOvkF,GAAG2E,IAAM3G,EAAM2G,GAE/BlE,EACIokF,EAASN,EAAOvkF,GAAG2E,MAAQ3G,EAAM2G,GACjC,IAAM,sBAAAlG,OAAsBomF,EAASN,EAAOvkF,GAAG2E,IAAG,aAAAlG,OAAYkG,EAAC,wBAAAlG,OACxC+1B,KAAKC,UAAUz2B,GAAM,MAAI,qBAAAS,OACvBT,EAAM2G,I,CAI3C,CAiBM,SAAUmgF,GAAqBN,EAAsBD,GAEzD,MAAM/oE,EAAiBgpE,EACjBO,EAAoB,GAC1B,IAAIC,EAAS,EACa,IAAtBR,EAAW3lF,QAEb2c,EAAK/Z,MAAM,GAEbujF,EAASR,EAAW3lF,OAAS,EAC7B,IAAK,IAAImB,EAAI,EAAGA,EAAIglF,IAAUhlF,EAC5B+kF,EAAMtjF,KAAK,IAEb,MAAMwjF,EAAgC,GACtC,IAAK,IAAIjlF,EAAI,EAAGA,EAAIwb,EAAK3c,SAAUmB,EAAG,CACpC,MACMklF,EAAcC,GAAiBZ,EADnB/oE,EAAKxb,IAEvB,IAAK,MAAMolF,KAAaF,GAC0B,IAA5CD,EAAoB7zD,QAAQg0D,KAC9BL,EAAM/kF,GAAGyB,KAAK2jF,GACdH,EAAoBxjF,KAAK2jF,G,CAI/B,MAAO,CAAC5pE,OAAMupE,QAChB,CAGM,SAAUM,GAAsBn6C,GACpC,OAAOA,EAAK9mC,MAAM,CAACgoC,EAAattC,IAAkBstC,IAAQttC,EAC5D,CAEA,SAASqmF,GAAiBZ,EAAoBn4C,GAC5C,MAAM84C,EAAwB,GAC9B,IAAK,IAAIllF,EAAI,EAAGA,EAAIukF,EAAO1lF,SAAUmB,EACV,IAArBukF,EAAOvkF,GAAGnB,SAA4C,IAA5B0lF,EAAOvkF,GAAGoxB,QAAQgb,KAAwB,IAATA,GAC7D84C,EAAYzjF,KAAKzB,GAGrB,OAAOklF,CACT,CClMM,SAAUI,GACZhmF,EAAsB8jE,GACd,IAARp/D,EAAIhD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,EACLukF,EAAa,GACjB,GAAiC,kBAArBniB,EACV3iE,EACInB,EAAEtB,MAAMgG,GAAQo/D,IAAoB,EACpC,IAAM,iDACVmiB,EACI,IAAIjkF,MAAM8hE,GAAiBrlD,KAAKze,EAAEtB,MAAMgG,GAAQo/D,OAC/C,CAOL3iE,EANkB2iE,EAAgBl8D,OAAO,CAACs+E,EAAO1oF,MAChC,IAAXA,IACF0oF,GAAS,GAEJA,GACN,IAEc,EACb,IAAM,2DACV,MAAMC,EAAWriB,EAAgBhyC,SAAS,GAG1C,IAAkB,IAAdq0D,EAAiB,CACnB,MAAMzQ,EAAQ5R,EAAgBl8D,OAAO,CAAChH,EAAGC,IAAMA,EAAI,EAAID,EAAIC,EAAID,GAC/DkjE,EAAgBqiB,GAAYnmF,EAAEtB,MAAMgG,GAAQgxE,C,CAE9Cv0E,EACInB,EAAEtB,MAAMgG,KAAUo/D,EAAgBl8D,OAAO,CAAChH,EAAGC,IAAMD,EAAIC,GACvD,IAAM,+DACVolF,EAAaniB,C,CAGf,OAAOmiB,CACT,CCrCM,SAAUG,GACZC,GACF,MAAO,0EAAPlnF,OACqBknF,EACvB,CAQM,SAAUC,GACZ9mF,EAAehC,GACjB,MAAO,WAAP2B,OAAkBK,EAAK,qBAAAL,OAAoB3B,EAAK,OAClD,CASM,SAAU+oF,GACZ/mF,EAAehC,EAAegpF,GAChC,MAAO,WAAPrnF,OAAkBK,EAAK,qBAAAL,OAAoB3B,EAAK,QAAA2B,OAAOqnF,EACzD,CCzBM,SAAUC,GACZC,EAAcC,GAChB,MAAO,iDAAPxnF,OAAwDunF,EAAI,SAAAvnF,OAAQwnF,EACtE,CAQM,SAAUC,GACZ95C,EAAatvC,GACf,MAAO,QAAP2B,OAAe2tC,EAAG,+BAAA3tC,OAA8B3B,EAClD,CAMM,SAAUqpF,KACd,MAAO,+GAET,CAQM,SAAUC,GACZ3oE,EAAsBgvC,GACxB,MAAM45B,EAAY3kF,GAAc+b,GAC1BizB,EAAahvC,GAAc+qD,GACjC,MAAO,2CAAPhuD,OAAkD4nF,EAAS,qEAAA5nF,OAEvDiyC,EAAU,iBAAAjyC,OAAgBgf,EAAU,kBAAAhf,OAAiBguD,EAC3D,CAQM,SAAU65B,GACZ7oE,EAAsBgvC,GACxB,MAAM45B,EAAY3kF,GAAc+b,GAC1BizB,EAAahvC,GAAc+qD,GACjC,MAAO,qCAAPhuD,OACI4nF,EAAS,+CAAA5nF,OACTiyC,EAAU,iBAAAjyC,OAAgBgf,EAAU,iBAAAhf,OAAgBguD,EAC1D,CCxDM,SAAU85B,KACd,MAAO,0BACT,CAMM,SAAUC,KACd,MAAO,gCACT,CAQM,SAAUC,GACZC,EAAmB5hC,GACrB,MAAO,cAAPrmD,OAAqBioF,EAAS,sBAAAjoF,OAC1BqmD,EAAU,sDAChB,CASM,SAAU6hC,GACZ7nF,EAAe8nF,EAAoBhiC,GACrC,MAAO,gBAAPnmD,OAAuBK,EAAK,SAAAL,OAAQmoF,EAAU,sBAAAnoF,OAC1CmmD,EAAS,IACf,CC3BM,SAAUiiC,GACZxF,EAAgB3b,GAClB,IACI79C,EADApQ,GAAO,EAUX,IAPI4pE,GAAUF,IACZt5D,EAAMw5D,EACN5pE,GAAO,GAEPoQ,EAAMthB,GAAe86E,EAAQtiF,KAAKkJ,MAAMlJ,KAAKwD,KAAK8+E,MAG5C5pE,GACFoQ,EAAM69C,GAAe79C,IAAQw5D,EAC/B5pE,GAAO,EAEPoQ,EAAMthB,GAAe86E,EAAQx5D,EAAM,GAGvC,OAAOA,CACT,CAEM,SAAUopB,GACZ6f,EAAkB9sD,EAAc0hE,GAClC,MAAMz5B,EAAW,GACXhoC,EAAO6sD,EAAOjyD,OACpB,IAAK,IAAIutC,EAAM,EAAGA,EAAMnoC,EAAMmoC,IACxBA,IAAQpoC,EACVioC,EAASxqC,KAAKqvD,EAAO1kB,IAErBH,EAASxqC,KAAKikE,GAGlB,OAAOz5B,CACT,CAUM,SAAU66C,GACZxnF,EAAeoxB,EAAqB1sB,EACpCivD,GACF,MAAMvjB,EAAchf,EAAQ1yB,MAAMa,OAC5B80C,EAAQr0C,EAAEtB,MAAMa,OAEtB,GAAkB,IAAdo0D,IACEA,GAAavjB,GAAeujB,EAAYvjB,GAC1C,MAAM,IAAIlxC,MAAM,sCAADC,OAAuCixC,EAAW,MAAAjxC,OAC7DixC,EAAW,eAAAjxC,OAAcw0D,IAQjC,GAJIA,EAAY,IACdA,GAAavjB,GAGXujB,EAAYtf,EACd,MAAM,IAAIn1C,MAAM,cAADC,OAAew0D,EAAS,uCAAAx0D,OACrCk1C,EAAK,OAGT,GAAI3vC,EAAOivD,EACT,MAAM,IAAIz0D,MAAM,cAADC,OACXw0D,EAAS,0CAAAx0D,OAAyCuF,EAAI,OAG5D,IAAK,IAAIhE,EAAI,EAAGA,EAAIizD,IAAajzD,EAC/B,GAAIV,EAAEtB,MAAMgC,KAAO0wB,EAAQ1yB,MAAMgC,GAC/B,MAAM,IAAIxB,MAAM,WAADC,OACAuB,EAAC,OAAAvB,OAAMa,EAAEtB,MAAMgC,GAAE,sCAAAvB,OACxBuB,EAAC,OAAAvB,OAAMiyB,EAAQ1yB,MAAMgC,GAAE,MAGnC,MAAM4H,EAAUtI,EAAEtB,MAAMgG,GAElByoD,EAAwB,GAC9B,IAAIhJ,EAAY,EACZsjC,EAAY,EACZh3C,EAAY,EAEhB,IAAK,IAAI/vC,EAAI,EAAGA,EAAIizD,IAAajzD,EAC/BysD,EAAYhrD,KAAKnC,EAAEtB,MAAMgC,IACzByjD,GAAankD,EAAEtB,MAAMgC,GAGvB,IAAK,IAAIA,EAAIizD,EAAWjzD,EAAIgE,EAAMhE,IAChCysD,EAAYhrD,KAAKnC,EAAEtB,MAAMgC,IACzB+mF,GAAaznF,EAAEtB,MAAMgC,GAGvB,IAAK,IAAIA,EAAIizD,EAAWjzD,EAAI0vC,EAAa1vC,IACvCysD,EAAYhrD,KAAKivB,EAAQ1yB,MAAMgC,IAGjC,IAAK,IAAIA,EAAIgE,EAAO,EAAGhE,EAAI2zC,EAAO3zC,IAChCysD,EAAYhrD,KAAKnC,EAAEtB,MAAMgC,IACzB+vC,GAAazwC,EAAEtB,MAAMgC,GAGvB,MAAO,CAACyjD,YAAW1T,YAAWg3C,YAAWn/E,UAAS6kD,cACpD,CClFM,SAAUu6B,GAAuB9hF,GACrC,IAEE,OAAOA,EAAKhB,IAAIzE,GAAOmc,GAAanc,G,CACpC,MAAOsnB,IACP,MAAM,IAAIvoB,MAAM,4DAADC,OACiDsoB,I,CAEpE,CAEM,SAAUkgE,GAAuBC,GACrC,OAAOA,EAAQhjF,IAAIC,GAAK8W,GAAa9W,GACvC,CClCO,IAAKgjF,GAmTKC,GC9TLr+E,KAGRI,aAAa,4BAA6B,KAAM,EAAOqoB,IACrDA,GACFvoB,QAAQC,KACJ,mPDKR,SAAYi+E,GAGVA,EAAAA,EAAA,2BAIAA,EAAAA,EAAA,uBACAA,EAAAA,EAAA,yBACAA,EAAAA,EAAA,uBACAA,EAAAA,EAAA,uBACAA,EAAAA,EAAA,uBACAA,EAAAA,EAAA,qBACAA,EAAAA,EAAA,yBACAA,EAAAA,EAAA,+BACAA,EAAAA,EAAA,uBACAA,EAAAA,EAAA,sBACAA,EAAAA,EAAA,wBACAA,EAAAA,EAAA,0BACAA,EAAAA,EAAA,0BACAA,EAAAA,EAAA,8BACAA,EAAAA,EAAA,0BACAA,EAAAA,EAAA,4BACAA,EAAAA,EAAA,0BACAA,EAAAA,EAAA,kCACAA,EAAAA,EAAA,sBACAA,EAAAA,EAAA,8BACAA,EAAAA,EAAA,4BACAA,EAAAA,EAAA,0BACAA,EAAAA,EAAA,0BAIAA,EAAAA,EAAA,iCACAA,EAAAA,EAAA,mCACAA,EAAAA,EAAA,iCACAA,EAAAA,EAAA,iCACAA,EAAAA,EAAA,iCACAA,EAAAA,EAAA,+BACAA,EAAAA,EAAA,mCACAA,EAAAA,EAAA,yCACAA,EAAAA,EAAA,iCACAA,EAAAA,EAAA,+BACAA,EAAAA,EAAA,iCACAA,EAAAA,EAAA,mCACAA,EAAAA,EAAA,mCACAA,EAAAA,EAAA,uCACAA,EAAAA,EAAA,mCACAA,EAAAA,EAAA,qCACAA,EAAAA,EAAA,mCACAA,EAAAA,EAAA,2CACAA,EAAAA,EAAA,+BACAA,EAAAA,EAAA,uCACAA,EAAAA,EAAA,qCACAA,EAAAA,EAAA,mCACAA,EAAAA,EAAA,kCACD,CAxDD,CAAYA,KAAAA,GAAQ,KAmTpB,SAAiBC,GAEf,IAAYC,GAAZ,SAAYA,GAAyBA,EAAAA,EAAA,mBAAcA,EAAAA,EAAA,WAAUA,EAAAA,EAAA,UAAS,CAAtE,CAAYA,EAAAD,EAAAC,0BAAAD,EAAAC,wBAAuB,IACpC,CAHD,CAAiBD,KAAAA,GAAQ,KE7TzB,MAAME,GAAwC,CAAC,EA8CzC,SAAUC,GAAgBx8E,GAC9B,OAAOu8E,GAAWv8E,EACpB,CC5CM,SAAUy8E,GACZC,EAAmBl6D,EAAYm6D,EAC/BC,EAA2BC,GAC7B,MAAMC,EAAat6D,EAAKu6D,YAAYL,GACpC,GAAII,QAA6C5mF,IAA/B4mF,EAAWE,gBAA+B,CAC1D,MAAMvhF,EAAQqhF,EAAWE,gBACnBltE,EAAmC,IAA7BgtE,EAAWG,mBACnB/mF,OAC8BA,IAA7B4mF,EAAWG,cAA8BxhF,EAAQ,EACRqhF,EAAWG,cACzD,GAAwB,WAApBH,EAAWnlE,KACb,OAAOulE,GACH16D,EAAK26D,WAAWL,EAAWE,iBAAkBL,EAAWC,EACxDC,GAEN,GAAwB,YAApBC,EAAWnlE,KAAoB,CAGjC,OAFe6K,EAAK26D,WAAWpkF,MAAM0C,EAAOqU,GAE9B3W,IACV6G,GAAQk9E,GAAUl9E,EAAM28E,EAAWC,EAASC,G,CAElD,MAAM9kE,EAASmlE,GACX16D,EAAK26D,WAAWpkF,MAAM0C,GAAO,GAAIkhF,EAAWC,EAASC,GACnDvrF,EAAOymB,EAAOrG,WACpB,MAA2B,WAApBorE,EAAWnlE,KACdrmB,EAAK,GACLkgB,GAAmBuG,EAAO9kB,MAAO3B,E,CAEvC,MAAM8rF,EAAY56D,EAAK66D,WAAWX,GAClC,OAAOU,GAAaA,EAAUrrF,KAChC,CASM,SAAUmrF,GACZl9E,EAAcs9E,EAA6BV,EAC3CC,GACF,MAAOU,EAAUxpF,GAASypF,GAAcx9E,GAExC,GAAuB,MAAnB68E,EAAyB,CAC3B,MAAM9kE,EAAS8kE,EAAgBY,yBAAyBF,GACxD,GAAc,MAAVxlE,EACF,OAAOA,C,CAIX,MAAM2lE,EAAYd,EAAQe,kBAAkBC,KAAKF,KACtCJ,EAAWO,GAAyBN,EAAUG,KAGzD,YAAqBxnF,IAAdwnF,EACHJ,EAAWO,GAAyBN,EAAUG,IAAY3pF,QAC1DmC,CACN,CAqBM,SAAU4nF,GACZ59D,EAAmB08D,GACrB,MAAOW,EAAUxpF,EAAOgqF,GAAcP,GAAct9D,GAEpD,MAAO,CACL29D,GAAyBN,EAAUX,GAAWA,EAAQoB,kBACtDjqF,EAAOgqF,EAEX,CAEA,SAASF,GAAyB79E,EAAc09E,GAC9C,OAASA,EAAY,GAAHhqF,OAAMsM,EAAI,KAAAtM,OAAIgqF,GAAc19E,CAChD,CAEM,SAAUw9E,GAAcx9E,GAC5B,MAAMi+E,EAAQj+E,EAAKX,MAAM,KACzB,GAAqB,IAAjB4+E,EAAMnqF,OACR,MAAO,CAACkM,EAAM,OAAG9J,GAGnB,MAAMqnF,EAAWU,EAAM,GACjBF,EAA8B,IAAjBE,EAAMnqF,OAAemqF,EAAM,QAAK/nF,EAEnD,MAAO,CAACqnF,EADM9nF,OAAOwoF,EAAMA,EAAMnqF,OAAS,IACjBiqF,EAC3B,CASM,SAAUG,GACZ17D,EAAYm6D,EACZC,GACF,IAAIlpE,EAAM+oE,GAAc,MAAOj6D,EAAMm6D,EAAWC,GAChD,GAAY,aAARlpE,EAAoB,CAEtBA,EAAM+oE,GAAc,mBAAoBj6D,EAAMm6D,EAAWC,GACzD,MAAMuB,EAEF,CAAC,CAAC,EAAG,GAAI,CAAC,EAAG,GAAI,CAAC,EAAG,GAAI,CAAC,EAAG,IACjC,IAAK,IAAIlpF,EAAI,EAAGA,EAAI,EAAGA,IACrBkpF,EAAgBlpF,GAAG,GAAMye,EAAqB,EAAJze,GAC1CkpF,EAAgBlpF,GAAG,GAAMye,EAAqB,EAAJze,EAAQ,GAEpD,OAAOkpF,C,CAET,OAAOzqE,CACT,CAWM,SAAU0qE,GAAYrmE,GAC1B,OAAOA,EAAO1C,KAAO0C,EAAS9B,GAAM8B,EACtC,CClJO,MAAMqlB,GAAmB,CAC9B,CACE,SAAY,MACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,QACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,OACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,IAAO,EACP,KAAQ,UACR,KAAQ,aAId,CACE,SAAY,UACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,GAElB,CACE,OAAU,cACV,KAAQ,aACR,KAAQ,SACR,cAAgB,KAItB,CACE,SAAY,MACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,UACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,MACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,WACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,WACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,MACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,UACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,UACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,MACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,oBACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,MACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,WACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,MCvXXA,GAAmB,CAC9B,CACE,SAAY,MACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,OACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,OACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,OACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,QACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,OACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,cACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,eACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,eACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,UACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,OACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,OACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,aACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,MACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,OACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,MACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,MACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,QACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,MACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,OACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,GAElB,CACE,OAAU,OACV,KAAQ,aACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,MACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,OACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,GAElB,CACE,OAAU,OACV,KAAQ,aACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,QACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,QACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,OACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,QACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,OACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,UACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,MACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,OACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,OACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,QACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,SACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,MACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,OACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,OACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,QACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,QACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,QACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,aACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,WACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,QACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,QACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,QACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,MACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,OACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,OACR,KAAQ,aAGZ,MAAS,CACP,CACE,OAAU,YACV,KAAQ,WACR,KAAQ,OACR,cAAgB,GAElB,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,YACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,QACV,KAAQ,QACR,KAAQ,SACR,aAAgB,IAElB,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,QACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,MCp2BXA,GAAmB,CAC9B,CACE,SAAY,kBACZ,SAAY,UACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,eACR,KAAQ,SAEV,CACE,MAAS,EACT,KAAQ,iBACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,gBACV,KAAQ,eACR,KAAQ,WAId,CACE,SAAY,WACZ,SAAY,UACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,OACR,KAAQ,YAId,CACE,SAAY,SACZ,SAAY,UACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,OACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,OACR,KAAQ,YAId,CACE,SAAY,QACZ,SAAY,UACZ,OAAU,CACR,CACE,MAAS,EACT,IAAO,EACP,KAAQ,UACR,KAAQ,aAId,CACE,SAAY,QACZ,SAAY,UACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,SACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,GAElB,CACE,OAAU,aACV,KAAQ,YACR,KAAQ,UAEV,CACE,OAAU,cACV,KAAQ,aACR,KAAQ,UAId,CACE,SAAY,OACZ,SAAY,UACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,SACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,gBACZ,SAAY,UACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,SACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,gBACZ,SAAY,UACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,OACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,QACV,KAAQ,QACR,KAAQ,SAEV,CACE,OAAU,gBACV,KAAQ,eACR,KAAQ,SAEV,CACE,OAAU,eACV,KAAQ,cACR,KAAQ,QAEV,CACE,OAAU,mBACV,KAAQ,iBACR,KAAQ,QAEV,CACE,OAAU,2BACV,KAAQ,yBACR,KAAQ,QAEV,CACE,OAAU,oBACV,KAAQ,OACR,KAAQ,YAId,CACE,SAAY,qBACZ,SAAY,UACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,gBACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,QACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,SACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,SACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,oBACZ,SAAY,UACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,gBACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,QACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,SACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,QACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,sBACZ,SAAY,UACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,gBACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,UACR,KAAQ,YAEV,CACE,MAAS,EACT,KAAQ,SACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,QACV,KAAQ,QACR,KAAQ,SAEV,CACE,OAAU,gBACV,KAAQ,eACR,KAAQ,WAId,CACE,SAAY,uBACZ,SAAY,UACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,gBACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,UACR,KAAQ,YAEV,CACE,MAAS,EACT,KAAQ,SACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,SACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,WAId,CACE,SAAY,sBACZ,SAAY,UACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,gBACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,SACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,QACV,KAAQ,QACR,KAAQ,SAEV,CACE,OAAU,wBACV,KAAQ,sBACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,qBACZ,SAAY,UACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,gBACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,SACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,UACR,KAAQ,YAEV,CACE,MAAS,EACT,KAAQ,SACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,WAId,CACE,SAAY,oBACZ,SAAY,UACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,gBACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,SACR,KAAQ,YAId,CACE,SAAY,qBACZ,SAAY,UACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,gBACR,KAAQ,YAId,CACE,SAAY,cACZ,SAAY,UACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,OACR,KAAQ,UAEV,CACE,MAAS,EACT,IAAO,EACP,KAAQ,OACR,KAAQ,YAGZ,MAAS,CACP,CACE,OAAU,cACV,KAAQ,aACR,KAAQ,QAEV,CACE,OAAU,cACV,KAAQ,aACR,KAAQ,UAId,CACE,SAAY,KACZ,SAAY,UACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,OACR,KAAQ,UAEV,CACE,MAAS,EACT,IAAO,EACP,KAAQ,OACR,KAAQ,YAGZ,MAAS,CACP,CACE,OAAU,cACV,KAAQ,aACR,KAAQ,QAEV,CACE,OAAU,cACV,KAAQ,aACR,KAAQ,UAId,CACE,SAAY,iBACZ,SAAY,UACZ,OAAU,CACR,CACE,MAAS,EACT,IAAO,EACP,KAAQ,OACR,KAAQ,YAGZ,MAAS,CACP,CACE,OAAU,OACV,KAAQ,OACR,KAAQ,QAEV,CACE,OAAU,OACV,KAAQ,OACR,KAAQ,UAId,CACE,SAAY,QACZ,SAAY,UACZ,OAAU,CACR,CACE,MAAS,EACT,IAAO,EACP,KAAQ,OACR,KAAQ,YAGZ,MAAS,CACP,CACE,OAAU,OACV,KAAQ,OACR,KAAQ,QAEV,CACE,OAAU,OACV,KAAQ,OACR,KAAQ,UAId,CACE,SAAY,oBACZ,SAAY,UACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,SACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,UACR,KAAQ,YAEV,CACE,MAAS,EACT,KAAQ,eACR,KAAQ,UAGZ,MAAS,CACP,CACE,OAAU,gBACV,KAAQ,eACR,KAAQ,WAId,CACE,SAAY,sBACZ,SAAY,UACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,SACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,UACR,KAAQ,YAEV,CACE,MAAS,EACT,KAAQ,eACR,KAAQ,SAEV,CACE,MAAS,EACT,KAAQ,cACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,gBACV,KAAQ,eACR,KAAQ,WAId,CACE,SAAY,mBACZ,SAAY,UACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,eACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,UACR,KAAQ,YAEV,CACE,MAAS,EACT,KAAQ,eACR,KAAQ,UAGZ,MAAS,CACP,CACE,OAAU,gBACV,KAAQ,eACR,KAAQ,WAId,CACE,SAAY,oBACZ,SAAY,UACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,eACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,QACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,eACR,KAAQ,UAGZ,MAAS,CACP,CACE,OAAU,gBACV,KAAQ,eACR,KAAQ,WAId,CACE,SAAY,oBACZ,SAAY,UACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,eACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,QACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,SACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,gBACV,KAAQ,eACR,KAAQ,WAId,CACE,SAAY,oBACZ,SAAY,UACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,eACR,KAAQ,SAEV,CACE,MAAS,EACT,KAAQ,cACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,gBACV,KAAQ,eACR,KAAQ,WAId,CACE,SAAY,uBACZ,SAAY,UACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,SACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,eACR,KAAQ,UAGZ,MAAS,CACP,CACE,OAAU,gBACV,KAAQ,eACR,KAAQ,WAId,CACE,SAAY,kBACZ,SAAY,UACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,eACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,eACR,KAAQ,UAGZ,MAAS,CACP,CACE,OAAU,gBACV,KAAQ,eACR,KAAQ,SAEV,CACE,OAAU,eACV,KAAQ,cACR,KAAQ,WAId,CACE,SAAY,kBACZ,SAAY,UACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,SACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,eACR,KAAQ,SAEV,CACE,MAAS,EACT,KAAQ,UACR,KAAQ,aAGZ,MAAS,CACP,CACE,OAAU,gBACV,KAAQ,eACR,KAAQ,WAId,CACE,SAAY,mBACZ,SAAY,UACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,eACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,gBACV,KAAQ,eACR,KAAQ,SAEV,CACE,OAAU,gBACV,KAAQ,eACR,KAAQ,WAId,CACE,SAAY,qBACZ,SAAY,UACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,eACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,gBACV,KAAQ,eACR,KAAQ,SAEV,CACE,OAAU,gBACV,KAAQ,eACR,KAAQ,WAId,CACE,SAAY,oBACZ,SAAY,UACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,eACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,eACR,KAAQ,UAGZ,MAAS,CACP,CACE,OAAU,gBACV,KAAQ,eACR,KAAQ,WAId,CACE,SAAY,qBACZ,SAAY,UACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,eACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,SACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,gBACV,KAAQ,eACR,KAAQ,WAId,CACE,SAAY,mBACZ,SAAY,UACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,eACR,KAAQ,YAId,CACE,SAAY,mBACZ,SAAY,UACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,eACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,OACR,KAAQ,aC31BHA,GAAmB,CAC9B,CACE,SAAY,UACZ,SAAY,cACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,UACV,KAAQ,UACR,KAAQ,YAEV,CACE,OAAU,UACV,KAAQ,MACR,KAAQ,UAEV,CACE,OAAU,cACV,KAAQ,aACR,KAAQ,SACR,cAAgB,GAElB,CACE,OAAU,QACV,KAAQ,aACR,KAAQ,YAEV,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,UACZ,SAAY,cACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,UACV,KAAQ,UACR,KAAQ,YAEV,CACE,OAAU,UACV,KAAQ,MACR,KAAQ,UAEV,CACE,OAAU,cACV,KAAQ,aACR,KAAQ,SACR,cAAgB,GAElB,CACE,OAAU,QACV,KAAQ,aACR,KAAQ,YAEV,CACE,OAAU,oBACV,KAAQ,mBACR,KAAQ,WACR,aAAgB,GAChB,cAAgB,GAElB,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,oBACZ,SAAY,cACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,UACV,KAAQ,UACR,KAAQ,YAEV,CACE,OAAU,UACV,KAAQ,MACR,KAAQ,UAEV,CACE,OAAU,QACV,KAAQ,aACR,KAAQ,YAEV,CACE,OAAU,yBACV,KAAQ,sBACR,KAAQ,QAEV,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,YACZ,SAAY,cACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,UACV,KAAQ,UACR,KAAQ,YAEV,CACE,OAAU,UACV,KAAQ,MACR,KAAQ,UAEV,CACE,OAAU,cACV,KAAQ,aACR,KAAQ,SACR,cAAgB,GAElB,CACE,OAAU,QACV,KAAQ,aACR,KAAQ,YAEV,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,YACZ,SAAY,cACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,UACV,KAAQ,UACR,KAAQ,YAEV,CACE,OAAU,UACV,KAAQ,MACR,KAAQ,UAEV,CACE,OAAU,cACV,KAAQ,aACR,KAAQ,SACR,cAAgB,GAElB,CACE,OAAU,QACV,KAAQ,aACR,KAAQ,YAEV,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,SACZ,SAAY,cACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,SACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,SACV,KAAQ,SACR,KAAQ,UAEV,CACE,OAAU,UACV,KAAQ,MACR,KAAQ,UAEV,CACE,OAAU,cACV,KAAQ,aACR,KAAQ,SACR,aAAgB,OAElB,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,GAElB,CACE,OAAU,WACV,KAAQ,WACR,KAAQ,SACR,aAAgB,KAItB,CACE,SAAY,SACZ,SAAY,cACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,SACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,GAElB,CACE,OAAU,UACV,KAAQ,UACR,KAAQ,YAEV,CACE,OAAU,UACV,KAAQ,MACR,KAAQ,UAEV,CACE,OAAU,gBACV,KAAQ,gBACR,KAAQ,QAEV,CACE,OAAU,cACV,KAAQ,aACR,KAAQ,SACR,aAAgB,QAElB,CACE,OAAU,oBACV,KAAQ,mBACR,KAAQ,WACR,aAAgB,IAElB,CACE,OAAU,YACV,KAAQ,YACR,KAAQ,cAId,CACE,SAAY,eACZ,SAAY,cACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,SACR,KAAQ,UAEV,CACE,MAAS,EACT,IAAO,EACP,KAAQ,OACR,KAAQ,YAGZ,MAAS,CACP,CACE,OAAU,WACV,KAAQ,UACR,KAAQ,UAEV,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,GAElB,CACE,OAAU,UACV,KAAQ,UACR,KAAQ,YAEV,CACE,OAAU,UACV,KAAQ,MACR,KAAQ,UAEV,CACE,OAAU,oBACV,KAAQ,mBACR,KAAQ,WACR,aAAgB,IAElB,CACE,OAAU,mBACV,KAAQ,gBACR,KAAQ,OACR,cAAgB,GAElB,CACE,OAAU,cACV,KAAQ,aACR,KAAQ,SACR,aAAgB,QAElB,CACE,OAAU,YACV,KAAQ,YACR,KAAQ,WACR,aAAgB,CACd,EACA,EACA,EACA,IAGJ,CACE,OAAU,YACV,KAAQ,WACR,KAAQ,WACR,aAAgB,IAElB,CACE,OAAU,UACV,KAAQ,UACR,KAAQ,SACR,aAAgB,MAElB,CACE,OAAU,kBACV,KAAQ,iBACR,KAAQ,SACR,aAAgB,MAItB,CACE,SAAY,sBACZ,SAAY,cACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,SACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,cACR,KAAQ,aAGZ,MAAS,CACP,CACE,OAAU,UACV,KAAQ,UACR,KAAQ,YAEV,CACE,OAAU,UACV,KAAQ,MACR,KAAQ,UAEV,CACE,OAAU,cACV,KAAQ,aACR,KAAQ,SACR,cAAgB,GAElB,CACE,OAAU,oBACV,KAAQ,mBACR,KAAQ,WACR,aAAgB,IAElB,CACE,OAAU,YACV,KAAQ,YACR,KAAQ,WACR,cAAgB,KAItB,CACE,SAAY,kBACZ,SAAY,cACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,QACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,SACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,UACV,KAAQ,UACR,KAAQ,YAEV,CACE,OAAU,UACV,KAAQ,MACR,KAAQ,UAEV,CACE,OAAU,cACV,KAAQ,aACR,KAAQ,SACR,aAAgB,QAElB,CACE,OAAU,oBACV,KAAQ,mBACR,KAAQ,WACR,aAAgB,IAElB,CACE,OAAU,YACV,KAAQ,YACR,KAAQ,cAId,CACE,SAAY,wBACZ,SAAY,cACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,QACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,SACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,UACV,KAAQ,UACR,KAAQ,YAEV,CACE,OAAU,UACV,KAAQ,MACR,KAAQ,UAEV,CACE,OAAU,cACV,KAAQ,aACR,KAAQ,SACR,aAAgB,QAElB,CACE,OAAU,oBACV,KAAQ,mBACR,KAAQ,WACR,aAAgB,IAElB,CACE,OAAU,YACV,KAAQ,YACR,KAAQ,cAId,CACE,SAAY,6BACZ,SAAY,cACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,SACR,KAAQ,UAEV,CACE,MAAS,EACT,IAAO,EACP,KAAQ,OACR,KAAQ,YAGZ,MAAS,CACP,CACE,OAAU,WACV,KAAQ,UACR,KAAQ,UAEV,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,GAElB,CACE,OAAU,UACV,KAAQ,UACR,KAAQ,YAEV,CACE,OAAU,UACV,KAAQ,MACR,KAAQ,UAEV,CACE,OAAU,cACV,KAAQ,aACR,KAAQ,SACR,aAAgB,QAElB,CACE,OAAU,YACV,KAAQ,YACR,KAAQ,WACR,aAAgB,CACd,EACA,EACA,EACA,IAGJ,CACE,OAAU,YACV,KAAQ,WACR,KAAQ,WACR,aAAgB,IAElB,CACE,OAAU,oBACV,KAAQ,mBACR,KAAQ,WACR,aAAgB,MAItB,CACE,SAAY,SACZ,SAAY,cACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,SACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,UACV,KAAQ,UACR,KAAQ,YAEV,CACE,OAAU,UACV,KAAQ,MACR,KAAQ,UAEV,CACE,OAAU,cACV,KAAQ,aACR,KAAQ,SACR,aAAgB,QAElB,CACE,OAAU,YACV,KAAQ,YACR,KAAQ,cAId,CACE,SAAY,aACZ,SAAY,cACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,SACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,UACV,KAAQ,UACR,KAAQ,YAEV,CACE,OAAU,QACV,KAAQ,YACR,KAAQ,YAEV,CACE,OAAU,UACV,KAAQ,MACR,KAAQ,aC5qBHA,GAAmB,CAC9B,CACE,SAAY,OACZ,SAAY,WACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,QACR,KAAQ,YAEV,CACE,MAAS,EACT,KAAQ,QACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,WAId,CACE,SAAY,WACZ,SAAY,WACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,QACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,OACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,MACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,SACZ,SAAY,WACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,UACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,QACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,UACR,KAAQ,SACR,aAAgB,GAElB,CACE,MAAS,EACT,KAAQ,WACR,KAAQ,SACR,aAAgB,IAGpB,MAAS,CACP,CACE,OAAU,OACV,KAAQ,OACR,KAAQ,SACR,cAAgB,GAElB,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,WAId,CACE,SAAY,OACZ,SAAY,WACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,QACR,KAAQ,aAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,WAId,CACE,SAAY,WACZ,SAAY,WACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,QACV,KAAQ,QACR,KAAQ,WAId,CACE,SAAY,uBACZ,SAAY,WACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,QACR,KAAQ,aAGZ,MAAS,CACP,CACE,OAAU,OACV,KAAQ,OACR,KAAQ,SACR,aAAgB,GAElB,CACE,OAAU,QACV,KAAQ,QACR,KAAQ,SACR,aAAgB,EAChB,cAAgB,GAElB,CACE,OAAU,QACV,KAAQ,QACR,KAAQ,SAEV,CACE,OAAU,IACV,KAAQ,IACR,KAAQ,SACR,cAAgB,KAItB,CACE,SAAY,gBACZ,SAAY,WACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,QACR,KAAQ,aAGZ,MAAS,CACP,CACE,OAAU,SACV,KAAQ,SACR,KAAQ,SACR,aAAgB,GAElB,CACE,OAAU,SACV,KAAQ,SACR,KAAQ,SACR,aAAgB,GAElB,CACE,OAAU,QACV,KAAQ,QACR,KAAQ,SAEV,CACE,OAAU,OACV,KAAQ,OACR,KAAQ,SACR,aAAgB,GAElB,CACE,OAAU,QACV,KAAQ,QACR,KAAQ,SACR,aAAgB,EAChB,cAAgB,GAElB,CACE,OAAU,IACV,KAAQ,IACR,KAAQ,SACR,cAAgB,KAItB,CACE,SAAY,QACZ,SAAY,WACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,QACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,OACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,OACR,KAAQ,SACR,aAAgB,IAGpB,MAAS,CACP,CACE,OAAU,OACV,KAAQ,QACR,KAAQ,WAId,CACE,SAAY,kBACZ,SAAY,WACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,QACR,KAAQ,aAGZ,MAAS,CACP,CACE,OAAU,QACV,KAAQ,OACR,KAAQ,SACR,aAAgB,GAElB,CACE,OAAU,SACV,KAAQ,SACR,KAAQ,SACR,aAAgB,GAElB,CACE,OAAU,OACV,KAAQ,OACR,KAAQ,UAEV,CACE,OAAU,QACV,KAAQ,QACR,KAAQ,SACR,aAAgB,EAChB,cAAgB,GAElB,CACE,OAAU,QACV,KAAQ,QACR,KAAQ,SAEV,CACE,OAAU,IACV,KAAQ,IACR,KAAQ,SACR,cAAgB,KAItB,CACE,SAAY,QACZ,SAAY,WACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,QACR,KAAQ,aAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,WAId,CACE,SAAY,YACZ,SAAY,WACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,WAId,CACE,SAAY,cACZ,SAAY,WACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,SACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,aACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,OACV,KAAQ,OACR,KAAQ,UAEV,CACE,OAAU,QACV,KAAQ,QACR,KAAQ,UAEV,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,SAEV,CACE,OAAU,eACV,KAAQ,eACR,KAAQ,YC3WHA,GAAmB,CAC9B,CACE,SAAY,sBACZ,SAAY,UACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,QACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,SACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,gBACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,eACR,KAAQ,YAId,CACE,SAAY,sBACZ,SAAY,UACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,QACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,SACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,gBACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,eACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,iBACR,KAAQ,YAId,CACE,SAAY,sBACZ,SAAY,UACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,QACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,SACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,gBACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,eACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,iBACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,GAElB,CACE,OAAU,cACV,KAAQ,YACR,KAAQ,QACR,cAAgB,GAElB,CACE,OAAU,yBACV,KAAQ,qBACR,KAAQ,UAId,CACE,SAAY,sBACZ,SAAY,UACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,QACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,SACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,gBACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,eACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,iBACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,eACR,KAAQ,YAId,CACE,SAAY,QACZ,SAAY,UACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,YACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,WACZ,SAAY,UACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,MCvLXA,GAAmB,CAC9B,CACE,SAAY,aACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,iBACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,SACR,KAAQ,YAId,CACE,SAAY,SACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,SACV,KAAQ,SACR,KAAQ,UAId,CACE,SAAY,aACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,iBACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,SACR,KAAQ,YAId,CACE,SAAY,SACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,YAId,CACE,SAAY,WACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,OACR,KAAQ,aC/EHA,GAAmB,CAC9B,CACE,SAAY,yBACZ,SAAY,QACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,UACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,QACV,KAAQ,QACR,KAAQ,SAEV,CACE,OAAU,QACV,KAAQ,QACR,KAAQ,WAId,CACE,SAAY,cACZ,SAAY,QACZ,MAAS,CACP,CACE,OAAU,QACV,KAAQ,QACR,KAAQ,SAEV,CACE,OAAU,QACV,KAAQ,QACR,KAAQ,WAId,CACE,SAAY,QACZ,SAAY,SAEd,CACE,SAAY,WACZ,SAAY,QACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,YAId,CACE,SAAY,YACZ,SAAY,QACZ,OAAU,CACR,CACE,MAAS,EACT,IAAO,EACP,KAAQ,IACR,KAAQ,aAId,CACE,SAAY,WACZ,SAAY,QACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,YAId,CACE,SAAY,OACZ,SAAY,QACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,YAId,CACE,SAAY,OACZ,SAAY,QACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,YAId,CACE,SAAY,QACZ,SAAY,QACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,YAId,CACE,SAAY,SACZ,SAAY,QACZ,OAAU,CACR,CACE,MAAS,EACT,IAAO,EACP,KAAQ,IACR,KAAQ,aAId,CACE,SAAY,QACZ,SAAY,QACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,OACR,KAAQ,YAGZ,MAAS,CACP,CACE,OAAU,UACV,KAAQ,UACR,KAAQ,UAEV,CACE,OAAU,UACV,KAAQ,SACR,KAAQ,SACR,cAAgB,GAElB,CACE,OAAU,YACV,KAAQ,YACR,KAAQ,SACR,aAAgB,KAItB,CACE,SAAY,OACZ,SAAY,QACZ,OAAU,IAEZ,CACE,SAAY,eACZ,SAAY,QACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,YAId,CACE,SAAY,0BACZ,SAAY,QACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,MACV,KAAQ,MACR,KAAQ,UAEV,CACE,OAAU,MACV,KAAQ,MACR,KAAQ,aCjMHA,GAAmB,CAC9B,CACE,SAAY,YACZ,SAAY,aACZ,OAAU,GACV,MAAS,CACP,CACE,OAAU,cACV,KAAQ,aACR,KAAQ,UAEV,CACE,OAAU,wBACV,KAAQ,qBACR,KAAQ,QAEV,CACE,OAAU,YACV,KAAQ,WACR,KAAQ,SAEV,CACE,OAAU,cACV,KAAQ,aACR,KAAQ,WAId,CACE,SAAY,cACZ,SAAY,aACZ,OAAU,GACV,MAAS,CACP,CACE,OAAU,cACV,KAAQ,aACR,KAAQ,UAEV,CACE,OAAU,wBACV,KAAQ,qBACR,KAAQ,QAEV,CACE,OAAU,YACV,KAAQ,WACR,KAAQ,SAEV,CACE,OAAU,cACV,KAAQ,aACR,KAAQ,WAId,CACE,SAAY,oBACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,cACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,OACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,SACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,MACV,KAAQ,MACR,KAAQ,QACR,cAAgB,GAElB,CACE,OAAU,OACV,KAAQ,OACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,sBACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,cACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,OACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,SACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,MACV,KAAQ,MACR,KAAQ,QACR,cAAgB,GAElB,CACE,OAAU,OACV,KAAQ,OACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,kBACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,cACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,OACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,eACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,MACV,KAAQ,MACR,KAAQ,QACR,cAAgB,GAElB,CACE,OAAU,OACV,KAAQ,OACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,oBACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,cACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,OACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,eACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,MACV,KAAQ,MACR,KAAQ,QACR,cAAgB,GAElB,CACE,OAAU,OACV,KAAQ,OACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,kBACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,cACR,KAAQ,YAId,CACE,SAAY,oBACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,cACR,KAAQ,aCrNHA,GAAmB,CAC9B,CACE,SAAY,iBACZ,SAAY,QACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,SACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,OACR,KAAQ,aAGZ,MAAS,CACP,CACE,OAAU,gBACV,KAAQ,eACR,KAAQ,QAEV,CACE,OAAU,qBACV,KAAQ,mBACR,KAAQ,QAEV,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,wBACZ,SAAY,QACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,SACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,OACR,KAAQ,aAGZ,MAAS,CACP,CACE,OAAU,gBACV,KAAQ,eACR,KAAQ,QAEV,CACE,OAAU,qBACV,KAAQ,mBACR,KAAQ,QAEV,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,gBACZ,SAAY,QACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,QACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,QACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,SACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,WACR,KAAQ,aAGZ,MAAS,CACP,CACE,OAAU,SACV,KAAQ,SACR,KAAQ,UAEV,CACE,OAAU,sBACV,KAAQ,qBACR,KAAQ,YAId,CACE,SAAY,6BACZ,SAAY,QACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,SACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,aACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,cACR,KAAQ,YAEV,CACE,MAAS,EACT,KAAQ,YACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,gBACV,KAAQ,gBACR,KAAQ,UAEV,CACE,OAAU,YACV,KAAQ,WACR,KAAQ,aC7IHA,GAAmB,CAC9B,CACE,SAAY,QACZ,SAAY,UACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,WACZ,SAAY,UACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,UACZ,SAAY,UACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,eACZ,SAAY,UACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,OACZ,SAAY,UACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,YACZ,SAAY,UACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,aACZ,SAAY,UACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,aACZ,SAAY,UACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,YACZ,SAAY,UACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,SACZ,SAAY,UACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,YACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,WACZ,SAAY,UACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,YACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,MC1QXA,GAAmB,CAC9B,CACE,SAAY,eACZ,SAAY,WACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,IAAO,EACP,KAAQ,OACR,KAAQ,YAGZ,MAAS,CACP,CACE,OAAU,WACV,KAAQ,UACR,KAAQ,UAEV,CACE,OAAU,YACV,KAAQ,WACR,KAAQ,WACR,aAAgB,IAElB,CACE,OAAU,UACV,KAAQ,UACR,KAAQ,SACR,aAAgB,MAElB,CACE,OAAU,cACV,KAAQ,aACR,KAAQ,OACR,cAAgB,GAElB,CACE,OAAU,cACV,KAAQ,aACR,KAAQ,OACR,cAAgB,GAElB,CACE,OAAU,kBACV,KAAQ,iBACR,KAAQ,SACR,aAAgB,IAElB,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,SACZ,SAAY,WACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,cACV,KAAQ,aACR,KAAQ,OACR,cAAgB,GAElB,CACE,OAAU,cACV,KAAQ,aACR,KAAQ,OACR,cAAgB,GAElB,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,cACZ,SAAY,WACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,QACV,KAAQ,aACR,KAAQ,OACR,cAAgB,GAElB,CACE,OAAU,QACV,KAAQ,aACR,KAAQ,OACR,cAAgB,GAElB,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,gBACZ,SAAY,WACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,QACV,KAAQ,aACR,KAAQ,OACR,cAAgB,GAElB,CACE,OAAU,QACV,KAAQ,aACR,KAAQ,OACR,cAAgB,GAElB,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,YACZ,SAAY,WACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,OACR,KAAQ,aAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,SACZ,SAAY,WACZ,OAAU,CACR,CACE,MAAS,EACT,IAAO,EACP,KAAQ,UACR,KAAQ,YAGZ,MAAS,CACP,CACE,OAAU,WACV,KAAQ,WACR,KAAQ,UAEV,CACE,OAAU,IACV,KAAQ,IACR,KAAQ,SACR,aAAgB,GAElB,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,YChOHA,GAAmB,CAC9B,CACE,SAAY,gBACZ,SAAY,gBACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,OACR,KAAQ,aAGZ,MAAS,CACP,CACE,OAAU,YACV,KAAQ,WACR,KAAQ,OACR,cAAgB,KAItB,CACE,SAAY,iBACZ,SAAY,gBACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,QACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,SACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,OACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,WACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,UACV,KAAQ,UACR,KAAQ,SACR,aAAgB,MAElB,CACE,OAAU,cACV,KAAQ,aACR,KAAQ,SACR,cAAgB,KAItB,CACE,SAAY,mBACZ,SAAY,gBACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,QACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,SACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,OACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,WACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,UACV,KAAQ,UACR,KAAQ,SACR,aAAgB,MAElB,CACE,OAAU,cACV,KAAQ,aACR,KAAQ,SACR,cAAgB,KAItB,CACE,SAAY,mBACZ,SAAY,gBACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,QACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,SACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,OACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,WACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,UACV,KAAQ,UACR,KAAQ,SACR,aAAgB,MAElB,CACE,OAAU,cACV,KAAQ,aACR,KAAQ,SACR,cAAgB,KAItB,CACE,SAAY,MACZ,SAAY,gBACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,eACV,KAAQ,SACR,KAAQ,SACR,aAAgB,GAElB,CACE,OAAU,OACV,KAAQ,OACR,KAAQ,SACR,aAAgB,GAElB,CACE,OAAU,QACV,KAAQ,QACR,KAAQ,SACR,aAAgB,GAElB,CACE,OAAU,OACV,KAAQ,OACR,KAAQ,SACR,aAAgB,MAItB,CACE,SAAY,UACZ,SAAY,gBACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,YAId,CACE,SAAY,aACZ,SAAY,gBACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,YAId,CACE,SAAY,gBACZ,SAAY,gBACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,gBACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,cACR,KAAQ,YAEV,CACE,MAAS,EACT,KAAQ,eACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,eACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,mBACV,KAAQ,kBACR,KAAQ,OACR,cAAgB,EAChB,cAAgB,MC1PXA,GAAmB,CAC9B,CACE,SAAY,WACZ,SAAY,YACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,OACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,UACR,KAAQ,YAId,CACE,SAAY,gBACZ,SAAY,YACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,OACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,UACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,gBACV,KAAQ,eACR,KAAQ,UAId,CACE,SAAY,MACZ,SAAY,YACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,OACR,KAAQ,aAGZ,MAAS,CACP,CACE,OAAU,YACV,KAAQ,WACR,KAAQ,UAId,CACE,SAAY,OACZ,SAAY,YACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,OACR,KAAQ,aAGZ,MAAS,CACP,CACE,OAAU,YACV,KAAQ,WACR,KAAQ,UAId,CACE,SAAY,MACZ,SAAY,YACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,OACR,KAAQ,aAGZ,MAAS,CACP,CACE,OAAU,YACV,KAAQ,WACR,KAAQ,UAId,CACE,SAAY,MACZ,SAAY,YACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,OACR,KAAQ,aAGZ,MAAS,CACP,CACE,OAAU,YACV,KAAQ,WACR,KAAQ,UAId,CACE,SAAY,MACZ,SAAY,YACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,OACR,KAAQ,aAGZ,MAAS,CACP,CACE,OAAU,YACV,KAAQ,WACR,KAAQ,UAId,CACE,SAAY,MACZ,SAAY,YACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,OACR,KAAQ,aAGZ,MAAS,CACP,CACE,OAAU,YACV,KAAQ,WACR,KAAQ,UAId,CACE,SAAY,SACZ,SAAY,YACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,OACR,KAAQ,YAId,CACE,SAAY,SACZ,SAAY,YACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,OACR,KAAQ,YAId,CACE,SAAY,OACZ,SAAY,YACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,OACR,KAAQ,aAGZ,MAAS,CACP,CACE,OAAU,YACV,KAAQ,WACR,KAAQ,UAId,CACE,SAAY,UACZ,SAAY,YACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,OACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,YACV,KAAQ,YACR,KAAQ,QAEV,CACE,OAAU,UACV,KAAQ,UACR,KAAQ,UAId,CACE,SAAY,SACZ,SAAY,YACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,OACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,YACV,KAAQ,YACR,KAAQ,QAEV,CACE,OAAU,UACV,KAAQ,UACR,KAAQ,WCvSHA,GAAmB,CAC9B,CACE,SAAY,WACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,EACR,KAAQ,UACR,KAAQ,WAEV,CACE,OAAU,EACV,KAAQ,OACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,IACR,KAAQ,SACR,aAAgB,KAItB,CACE,SAAY,SACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,IAAO,EACP,KAAQ,UACR,KAAQ,WAEV,CACE,MAAS,EACT,KAAQ,OACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,IACR,KAAQ,SACR,aAAgB,KAItB,CACE,SAAY,WACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,UACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,OACR,KAAQ,SACR,aAAgB,IAGpB,MAAS,CACP,CACE,OAAU,aACV,KAAQ,YACR,KAAQ,SACR,aAAgB,KAItB,CACE,SAAY,SACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,UACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,mBACV,KAAQ,kBACR,KAAQ,OACR,cAAgB,KAItB,CACE,SAAY,UACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,OACR,KAAQ,YAId,CACE,SAAY,YACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,OACR,KAAQ,cAId,CACE,SAAY,QACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,QACR,KAAQ,YAEV,CACE,MAAS,EACT,KAAQ,OACR,KAAQ,cAId,CACE,SAAY,eACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,QACR,KAAQ,YAEV,CACE,MAAS,EACT,KAAQ,MACR,KAAQ,YAEV,CACE,MAAS,EACT,KAAQ,UACR,KAAQ,aAGZ,MAAS,CACP,CACE,OAAU,aACV,KAAQ,YACR,KAAQ,SACR,aAAgB,GAElB,CACE,OAAU,WACV,KAAQ,UACR,KAAQ,SACR,aAAgB,GAElB,CACE,OAAU,gBACV,KAAQ,cACR,KAAQ,SACR,aAAgB,GAElB,CACE,OAAU,gBACV,KAAQ,eACR,KAAQ,SACR,aAAgB,GAElB,CACE,OAAU,mBACV,KAAQ,iBACR,KAAQ,SACR,aAAgB,KAItB,CACE,SAAY,OACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,IAAO,EACP,KAAQ,UACR,KAAQ,YAGZ,MAAS,CACP,CACE,OAAU,OACV,KAAQ,OACR,KAAQ,SACR,aAAgB,KAItB,CACE,SAAY,SACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,SACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,OACV,KAAQ,OACR,KAAQ,SACR,aAAgB,GAElB,CACE,OAAU,MACV,KAAQ,MACR,KAAQ,SACR,aAAgB,EAChB,cAAgB,KAItB,CACE,SAAY,OACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,OACR,KAAQ,cAId,CACE,SAAY,QACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,OACR,KAAQ,SACR,aAAgB,GAElB,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,YACV,KAAQ,kBACR,KAAQ,SACR,aAAgB,KAItB,CACE,SAAY,SACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,kBACR,KAAQ,YAEV,CACE,MAAS,EACT,KAAQ,OACR,KAAQ,SACR,aAAgB,KAItB,CACE,SAAY,YACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,UACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,SACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,QACR,KAAQ,cAId,CACE,SAAY,WACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,UACR,KAAQ,YAId,CACE,SAAY,gBACZ,SAAY,aACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,gBACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,cACR,KAAQ,YAEV,CACE,MAAS,EACT,KAAQ,eACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,eACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,mBACV,KAAQ,kBACR,KAAQ,OACR,cAAgB,EAChB,cAAgB,MCzYXA,GAAmB,CAC9B,CACE,SAAY,sBACZ,SAAY,SACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,UACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,SACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,aACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,eACR,KAAQ,YAId,CACE,SAAY,gBACZ,SAAY,SACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,eACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,aACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,WACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,IACV,KAAQ,QACR,KAAQ,QACR,cAAgB,KAItB,CACE,SAAY,oBACZ,SAAY,SACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,OACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,UACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,aACR,KAAQ,YAId,CACE,SAAY,mBACZ,SAAY,SACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,OACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,UACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,aACR,KAAQ,aC9FHA,GAAmB,CAC9B,CACE,SAAY,MACZ,SAAY,WACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,YAId,CACE,SAAY,OACZ,SAAY,WACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,YAId,CACE,SAAY,OACZ,SAAY,WACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,aACR,KAAQ,SACR,cAAgB,KAItB,CACE,SAAY,QACZ,SAAY,WACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,aACR,KAAQ,SACR,cAAgB,MCrDXA,GAAmB,CAC9B,CACE,SAAY,eACZ,SAAY,SACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,OACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,aACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,YACV,KAAQ,YACR,KAAQ,UAEV,CACE,OAAU,eACV,KAAQ,cACR,KAAQ,YAEV,CACE,OAAU,WACV,KAAQ,UACR,KAAQ,UAEV,CACE,OAAU,YACV,KAAQ,WACR,KAAQ,UAEV,CACE,OAAU,YACV,KAAQ,WACR,KAAQ,UAEV,CACE,OAAU,2BACV,KAAQ,yBACR,KAAQ,SAGZ,QAAW,CACT,SACA,kBAGJ,CACE,SAAY,cACZ,SAAY,SACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,QACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,YACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,aACV,KAAQ,YACR,KAAQ,SAGZ,QAAW,CACT,UACA,SACA,UAGJ,CACE,SAAY,yBACZ,SAAY,SACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,QACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,cACV,KAAQ,aACR,KAAQ,aC/FHA,GAAmB,CAC9B,CACE,SAAY,OACZ,SAAY,iBACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,OACV,KAAQ,SACR,KAAQ,QACR,cAAgB,GAElB,CACE,OAAU,OACV,KAAQ,QACR,KAAQ,WAId,CACE,SAAY,aACZ,SAAY,iBACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,OACR,KAAQ,YAId,CACE,SAAY,YACZ,SAAY,iBACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,UACR,KAAQ,aAGZ,MAAS,CACP,CACE,OAAU,OACV,KAAQ,OACR,KAAQ,YAId,CACE,SAAY,MACZ,SAAY,iBACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,UACR,KAAQ,aAGZ,MAAS,CACP,CACE,OAAU,iBACV,KAAQ,gBACR,KAAQ,SACR,aAAgB,KAItB,CACE,SAAY,QACZ,SAAY,iBACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,UACR,KAAQ,YAEV,CACE,MAAS,EACT,KAAQ,gBACR,KAAQ,SACR,aAAgB,KAItB,CACE,SAAY,UACZ,SAAY,iBACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,QACR,KAAQ,cAId,CACE,SAAY,UACZ,SAAY,iBACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,OACV,iBAAoB,eACpB,KAAQ,OACR,KAAQ,cAId,CACE,SAAY,iBACZ,SAAY,iBACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,aACR,KAAQ,YAEV,CACE,MAAS,EACT,KAAQ,WACR,KAAQ,cAId,CACE,SAAY,iBACZ,SAAY,iBACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,aACR,KAAQ,YAEV,CACE,MAAS,EACT,KAAQ,QACR,KAAQ,cAId,CACE,SAAY,eACZ,SAAY,iBACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,WAGZ,MAAS,CACP,CACE,OAAU,aACV,KAAQ,YACR,KAAQ,UAEV,CACE,OAAU,cACV,KAAQ,aACR,KAAQ,YAId,CACE,SAAY,cACZ,SAAY,iBACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,IACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,QACR,KAAQ,aAGZ,MAAS,IAEX,CACE,SAAY,gBACZ,SAAY,iBACZ,OAAU,CACR,CACE,MAAS,EACT,KAAQ,KACR,KAAQ,UAEV,CACE,MAAS,EACT,KAAQ,KACR,KAAQ,WAGZ,MAAS,KC1NP,MAAOihD,GAMJ,mBAAWC,GAChB,OAAO3sF,KAAK4sF,YAAc5sF,KAAK4sF,UAAY,IAAI5sF,KACjD,CAGAR,WAAAA,GACE,MAKMqtF,EAA0B,GAAG9qF,UALvB,CACV+qF,EAAYC,EAAWC,EAASC,EAAaC,EAAUC,EACvDC,EAAYC,EAAOC,EAAW31D,EAAO41D,EAASC,EAAUC,EACxDxQ,EAAWyQ,EAAW51C,EAAQyqC,EAAUE,EAAQkL,GAEDnmF,IAAI0tB,GAAMA,EAAGuW,OAE9DzrC,KAAK4tF,UAAYf,EAAYriF,OACzB,CAAChD,EAAKqmF,KACJrmF,EAAIqmF,EAAOC,UAAYD,EAChBrmF,GAET,CAAC,EACP,CAIAumF,cAAAA,CACIV,GACwC,IAAxC/zD,EAAAh1B,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAsC,CAAC,EACzC,MAAM0pF,EAAUX,EAAMx8D,KAChBo9D,EAAuB,GACvBtzD,EAAkB,GAClBuzD,EAAoB,GACpBC,EAAQH,EAAQxjF,OAA8B,CAAChD,EAAKqpB,KACxDrpB,EAAIqpB,EAAKxiB,MAAQrO,KAAKouF,QAAQv9D,GAC1BA,EAAKqE,GAAG6J,WAAW,eACrBkvD,EAAalpF,KAAKyC,EAAIqpB,EAAKxiB,OACN,UAAZwiB,EAAKqE,GACdyF,EAAQ51B,KAAKyC,EAAIqpB,EAAKxiB,OACC,MAAdwiB,EAAK/P,OAAuC,IAAtB+P,EAAK/P,MAAM3e,QAC1C+rF,EAAUnpF,KAAKyC,EAAIqpB,EAAKxiB,OAEnB7G,GACN,CAAC,GAEJ,IAAIiY,EAAiB,GACrB,MAAMC,EAAkB,GACxB,IAAI2uE,EAA8C,CAAC,EAC/CC,EAA+C,CAAC,EACnC,MAAbh1D,IACF+0D,EAAqBruF,KAAKuuF,oBAAoBj1D,EAAU7Z,QACxD6uE,EAAsBtuF,KAAKuuF,oBAAoBj1D,EAAU5Z,UAE3D,MAAM8uE,EAAWphF,OAAOkc,KAAK6kE,GAC7BK,EAASplF,QAAQwE,IACf,MAAMijB,EAAOs9D,EAAMvgF,GACnBijB,EAAK26D,WAAWpiF,QAAQ,CAACiF,EAAMjM,KAC7B,MAAOwpF,EAAS,CAAGQ,GAAcD,GAAoB99E,GAC/CogF,EAAYN,EAAMvC,GACxB,GAAyB,MAArB6C,EAAU/uE,QAAiB,CAC7B,MAAMgvE,EAAcD,EAAU/uE,QAAQgV,QAAQ03D,GAC9C,IAAqB,IAAjBsC,EAAoB,CACtB,MAAMngE,EAAY,GAAHxsB,OAAM6pF,EAAQ,KAAA7pF,OAAI2sF,GAEjC79D,EAAK26D,WAAWppF,GAASmsB,C,EAG7BsC,EAAKpR,OAAO1a,KAAK0pF,GACjBA,EAAUE,SAAS5pF,KAAK8rB,OAMoB,IAA5CzjB,OAAOkc,KAAKglE,GAAqBnsF,OACnCqsF,EAASplF,QAAQwE,IACf,MAAMijB,EAAOs9D,EAAMvgF,GACU,IAAzBijB,EAAK89D,SAASxsF,QAChBud,EAAQ3a,KAAK8rB,KAIjBzjB,OAAOkc,KAAKglE,GAAqBllF,QAAQiF,IACvC,MAAOu9E,GAAcO,GAAoB99E,GACnCwiB,EAAOs9D,EAAMvC,GACP,MAAR/6D,IACFA,EAAK+9D,aAAeN,EAAoBjgF,GACxCqR,EAAQ3a,KAAK8rB,MAKfzjB,OAAOkc,KAAK+kE,GAAoBlsF,OAAS,EAC3CiL,OAAOkc,KAAK+kE,GAAoBjlF,QAAQiF,IACtC,MAAOu9E,GAAcO,GAAoB99E,GACnCwiB,EAAOs9D,EAAMvC,GACf/6D,IACFA,EAAK+9D,aAAeP,EAAmBhgF,GACvCoR,EAAO1a,KAAK8rB,MAIhBpR,EAASwuE,EAGX,IAAIY,EAAY,CAAC,EACI,MAAjBxB,EAAMyB,SAA6C,MAA1BzB,EAAMyB,QAAQC,WACzCF,EAAYxB,EAAMyB,QAAQC,SAASvkF,OAAO,CAACqkF,EAAWG,KACpDH,EAAUG,EAAK11D,UAAUjrB,MAAQrO,KAAKivF,YAAYD,GAC3CH,GACN,CAAC,IAGN,MAAMjrF,EACF,CAACuqF,QAAO1uE,SAAQC,UAASib,UAASszD,eAAc30D,YAAWu1D,aAM/D,OAJIX,EAAU/rF,OAAS,IACrByB,EAAOsqF,UAAYA,GAGdtqF,CACT,CAEQ2qF,mBAAAA,CAAoBzzE,GAC1B,OAAO1N,OAAOkc,KAAKxO,GAAW,CAAC,GAC1BtQ,OAAgC,CAACO,EAAMC,KACtCD,EAAK+P,EAAQ9P,GAAMqD,MAAQrD,EACpBD,GACN,CAAC,EACV,CAEQqjF,OAAAA,CAAQv9D,GAGd,MAAMg9D,EACFhD,GAAgBh6D,EAAKqE,KAAOl1B,KAAK4tF,UAAU/8D,EAAKqE,KAAO,CAAC,EAC3C,MAAbrE,EAAKi6B,OACPj6B,EAAKi6B,KAAO,CAAC,GAGf,MAAMokC,EAAgB,CACpB7gF,KAAMwiB,EAAKxiB,KACX6mB,GAAIrE,EAAKqE,GACTi6D,SAAUtB,EAAOsB,SACjB3D,YACK36D,EAAK/P,OACL,IAAItZ,IAAIsZ,GAASA,EAAMie,WAAW,KAAOje,EAAM1Z,MAAM,GAAK0Z,GAC/DrB,OAAQ,GACRkvE,SAAU,GACVvD,YAAa,CAAC,EACdM,WAAY,CAAC,EACb0D,SAAUv+D,EAAKi6B,KACfprC,QAASmuE,EAAOnuE,SAuIlB,OApIqB,MAAjBmuE,EAAOpuE,SACTyvE,EAAQ9D,YACJyC,EAAOpuE,OAAOjV,OACV,CAAChD,EAAKgiD,KACJhiD,EAAIgiD,EAAMn7C,MAAQ,CAChB2X,KAAMwjC,EAAMxjC,KACZqlE,gBAAiB7hC,EAAM1/C,MACvBwhF,cAAe9hC,EAAMrrC,KAEhB3W,GAET,CAAC,IAES,MAAhBqmF,EAAOhiE,QACTqjE,EAAQxD,WACJmC,EAAOhiE,MAAMrhB,OAAoC,CAAChD,EAAKgiD,KACrD,MAAMxjC,EAAOwjC,EAAMxjC,KACnB,IAAI5lB,EACJ,OAAQopD,EAAMxjC,MACZ,IAAK,SACH5lB,EAAQivF,GACJx+D,EAAKi6B,KAAMtB,EAAM8lC,OAAQ9lC,EAAMyW,mBAErB17D,IAAVnE,GAAyBopD,EAAM+lC,mBACjCnvF,EAAQivF,GACJx+D,EAAKi6B,KAAMtB,EAAM+lC,iBACjB/lC,EAAMyW,eAEZ,MACF,IAAK,WACH7/D,EAAQovF,GACJ3+D,EAAKi6B,KAAMtB,EAAM8lC,OAAQ9lC,EAAMyW,mBAErB17D,IAAVnE,GAAyBopD,EAAM+lC,mBACjCnvF,EAAQovF,GACJ3+D,EAAKi6B,KAAMtB,EAAM+lC,iBACjB/lC,EAAMyW,eAEZ,MACF,IAAK,SACH7/D,EAAQqvF,GACJ5+D,EAAKi6B,KAAMtB,EAAM8lC,OAChB9lC,EAAMyW,cAAgB,QACb17D,IAAVnE,GAAyBopD,EAAM+lC,mBACjCnvF,EAAQqvF,GACJ5+D,EAAKi6B,KAAMtB,EAAM+lC,iBACjB/lC,EAAMyW,eAEZ,MACF,IAAK,WACH7/D,EAAQsvF,GACJ7+D,EAAKi6B,KAAMtB,EAAM8lC,OAAQ9lC,EAAMyW,mBACrB17D,IAAVnE,GAAyBopD,EAAM+lC,mBACjCnvF,EAAQsvF,GACJ7+D,EAAKi6B,KAAMtB,EAAM+lC,iBACjB/lC,EAAMyW,eAEZ,MACF,IAAK,OACH7/D,EAAQuvF,GACJ9+D,EAAKi6B,KAAMtB,EAAM8lC,OAAQ9lC,EAAMyW,mBACrB17D,IAAVnE,GAAyBopD,EAAM+lC,mBACjCnvF,EAAQuvF,GACJ9+D,EAAKi6B,KAAMtB,EAAM+lC,iBACjB/lC,EAAMyW,eAEZ,MACF,IAAK,SACH7/D,EAAQwvF,GACJ/+D,EAAKi6B,KAAMtB,EAAM8lC,OAAQ9lC,EAAMyW,mBACrB17D,IAAVnE,GAAyBopD,EAAM+lC,mBACjCnvF,EAAQwvF,GACJ/+D,EAAKi6B,KAAMtB,EAAM+lC,iBACjB/lC,EAAMyW,eAEZ,MACF,IAAK,QACH7/D,EAAQyvF,GACJh/D,EAAKi6B,KAAMtB,EAAM8lC,OAAQ9lC,EAAMyW,mBACrB17D,IAAVnE,GAAyBopD,EAAM+lC,mBACjCnvF,EAAQyvF,GACJh/D,EAAKi6B,KAAMtB,EAAM+lC,iBACjB/lC,EAAMyW,eAEZ,MACF,IAAK,UACH7/D,EAAQ0vF,GACJj/D,EAAKi6B,KAAMtB,EAAM8lC,OAAQ9lC,EAAMyW,mBACrB17D,IAAVnE,GAAyBopD,EAAM+lC,mBACjCnvF,EAAQ0vF,GACJj/D,EAAKi6B,KAAMtB,EAAM+lC,iBACjB/lC,EAAMyW,eAEZ,MACF,IAAK,QACH7/D,EAAQ2vF,GACJl/D,EAAKi6B,KAAMtB,EAAM8lC,OAAQ9lC,EAAMyW,mBACrB17D,IAAVnE,GAAyBopD,EAAM+lC,mBACjCnvF,EAAQ2vF,GACJl/D,EAAKi6B,KAAMtB,EAAM+lC,iBACjB/lC,EAAMyW,eAEZ,MACF,IAAK,UACH7/D,EAAQ4vF,GACJn/D,EAAKi6B,KAAMtB,EAAM8lC,OAAQ9lC,EAAMyW,mBACrB17D,IAAVnE,GAAyBopD,EAAM+lC,mBACjCnvF,EAAQ4vF,GACJn/D,EAAKi6B,KAAMtB,EAAM+lC,iBACjB/lC,EAAMyW,eAEZ,MACF,IAAK,OACH7/D,EAAQ6vF,GACJp/D,EAAKi6B,KAAMtB,EAAM8lC,OAAQ9lC,EAAMyW,mBACrB17D,IAAVnE,GAAyBopD,EAAM+lC,mBACjCnvF,EAAQ6vF,GACJp/D,EAAKi6B,KAAMtB,EAAM+lC,iBACjB/lC,EAAMyW,eAEZ,MACF,IAAK,SACL,IAAK,UACH,MACF,QACE,MAAM,IAAIn+D,MAAM,2BAADC,OACgBynD,EAAMxjC,KAAI,aAAAjkB,OAAY8uB,EAAKqE,KAG9D,OADA1tB,EAAIgiD,EAAMn7C,MAAQ,CAACjO,QAAO4lB,QACnBxe,GACN,CAAC,IAEH0nF,CACT,CAGQD,WAAAA,CAAYiB,GAClB,MAAMlC,EAAUkC,EAAYC,QAEtBx1D,EAAkB,GACxB,IAAIwzD,EAA+B,CAAC,EACrB,MAAXH,IACFG,EAAQH,EAAQxjF,OAA8B,CAAChD,EAAKqpB,KAClDrpB,EAAIqpB,EAAKxiB,MAAQrO,KAAKouF,QAAQv9D,GACd,UAAZA,EAAKqE,IACPyF,EAAQ51B,KAAKyC,EAAIqpB,EAAKxiB,OAEjB7G,GACN,CAAC,IAEN,MAAMiY,EAAiB,GACjBC,EAAkB,GAExBwwE,EAAY52D,UAAU82D,SAAShnF,QAAQyrB,IACrC,MAAO+2D,GAAcO,GAAoBt3D,EAAIxmB,MACvCwiB,EAAa,CACjBxiB,KAAMu9E,EACN12D,GAAI,cACJzV,OAAQ,GACR+rE,WAAY,GACZ2D,SAAU,QACV/D,YAAa,CAAC,EACdM,WAAY,CAACnqF,MAAO,CAACnB,MAAOiwF,GAAgBx7D,EAAI7O,MAAOA,KAAM,UAC7D2oE,SAAU,IAEZ99D,EAAK+9D,aAAe/5D,EAAIxmB,KACxBoR,EAAO1a,KAAK8rB,GACZs9D,EAAMvC,GAAY/6D,IAGHzjB,OAAOkc,KAAK6kE,GACpB/kF,QAAQwE,IACf,MAAMijB,EAAOs9D,EAAMvgF,GACnBijB,EAAK26D,WAAWpiF,QAAQ,CAACiF,EAAMjM,KAC7B,MAAOwpF,EAAS,CAAGQ,GAAcD,GAAoB99E,GAC/CogF,EAAYN,EAAMvC,GACxB,GAAyB,MAArB6C,EAAU/uE,QAAiB,CAC7B,MAAMgvE,EAAcD,EAAU/uE,QAAQgV,QAAQ03D,GAC9C,IAAqB,IAAjBsC,EAAoB,CACtB,MAAMngE,EAAY,GAAHxsB,OAAM6pF,EAAQ,KAAA7pF,OAAI2sF,GAEjC79D,EAAK26D,WAAWppF,GAASmsB,C,EAG7BsC,EAAKpR,OAAO1a,KAAK0pF,GACjBA,EAAUE,SAAS5pF,KAAK8rB,OAI5B,MAAMy/D,EAAgBJ,EAAY9lF,IAElC8lF,EAAY52D,UAAUi3D,UAAUnnF,QAAQ0W,IACtC,MAAO8rE,EAAUxpF,GAAS+pF,GAAoBmE,EAAcxwE,EAAOzR,OAC7DwiB,EAAOs9D,EAAMvC,GACP,MAAR/6D,IACFA,EAAK2/D,cAAgBpuF,EACrBsd,EAAQ3a,KAAK8rB,MAIjB,MAAMyI,EAAYt5B,KAAKywF,mBAAmBP,GAC1C,MAAO,CAAC/B,QAAO1uE,SAAQC,UAASib,UAASszD,aA/DZ,GA+D0B30D,YACzD,CAEQm3D,kBAAAA,CAAmBP,GAEzB,MAAO,CACLQ,WAAYR,EAAY52D,UAAUjrB,KAClCoR,OAAQywE,EAAY52D,UAAU82D,SAAS5lF,OACnC,CAAChD,EAAKqtB,KACJrtB,EAAIqtB,EAAIxmB,MAAQrO,KAAK2wF,mBAAmB97D,GACjCrtB,GAET,CAAC,GACLkY,QAASwwE,EAAY52D,UAAUi3D,UAAU/lF,OACrC,CAAChD,EAAKqtB,KACJrtB,EAAIqtB,EAAIxmB,MAAQrO,KAAK2wF,mBAAmB97D,EAAKq7D,EAAY9lF,KAClD5C,GAET,CAAC,GAET,CAEQmpF,kBAAAA,CACJ97D,EACA+7D,GACF,IAAIviF,EAAOwmB,EAAIxmB,KAIf,OAHe,MAAXuiF,IACFviF,EAAOuiF,EAAQviF,IAEV,CAACA,OAAM9M,MAAOszB,EAAI7O,KAC3B,EAgBI,SAAU6qE,GAAiBppF,EAAcqpF,GAC7C,MAAM1wF,EACFwE,MAAMC,QAAQ4C,GAAK6B,OAAOq3B,aAAa/2B,MAAM,KAAMnC,GAfnD,SAAuBg8B,GAC3B,MAAM73B,EAASS,KAAMT,OACrB,GAA2B,qBAAhBA,EAAOysB,KAChB,OAAOzsB,EAAOysB,KAAKoL,GACd,GAAsB,qBAAXtL,OAChB,OAAO,IAAIA,OAAOsL,EAAM,UAAU7iB,WAElC,MAAM,IAAI9e,MACN,mFAGR,CAI8DivF,CAAatpF,GACzE,OAAOqpF,EAAW1wF,EAAQA,EAAMyN,aAClC,CAEM,SAAUwhF,GACZxjE,EAA+Cxd,EAAc2iF,GAC7C,IAAhBF,EAAQxsF,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,IAAAA,UAAA,GACV,MAAMklD,EAAQ39B,EAAMxd,GACpB,OAAa,MAATm7C,EACKqnC,GAAiBrnC,EAAM/hD,EAAGqpF,GAE5BE,CACT,CAEM,SAAUrB,GACZ9jE,EAA+Cxd,EAC/C2iF,GACF,MAAMxnC,EAAQ39B,EAAMxd,GACpB,OAAOm7C,EAAQA,EAAM/lD,EAAIutF,CAC3B,CAEM,SAAUvB,GACZ5jE,EAA+Cxd,EAC/C2iF,GACF,MAAMxnC,EAAQ39B,EAAMxd,IAAS,CAAC,EACxBjO,EACY,MAAdopD,EAAS,EAAYA,EAAS,EAAmB,MAAdA,EAAS,EAAYA,EAAS,EAAIwnC,EACzE,MAAyB,kBAAV5wF,EAAsBA,EAAQ6wF,SAAS7wF,EAAO,GAC/D,CAEM,SAAUiwF,GAAgBjwF,GAK9B,OAJuB,kBAAXA,IAEVA,EAAQ8wF,GAAoB9wF,IAEtBA,GACN,KAAK8wF,GAAoBC,SACzB,KAAKD,GAAoBE,QACvB,MAAO,UACT,KAAKF,GAAoBG,SACzB,KAAKH,GAAoBI,SACzB,KAAKJ,GAAoBK,QACzB,KAAKL,GAAoBM,SACvB,MAAO,QACT,KAAKN,GAAoBO,QACvB,MAAO,OACT,KAAKP,GAAoBQ,UACvB,MAAO,UACT,KAAKR,GAAoBS,UACvB,MAAO,SACT,QAGE,OAAO,KAEb,CAEM,SAAU1B,GACZpkE,EAA+Cxd,EAC/C2iF,GACF,MAAMxnC,EAAQ39B,EAAMxd,GACpB,OAAIm7C,GAASA,EAAMwlC,KACVxlC,EAAMwlC,KAAK3gF,KAEb2iF,CACT,CAEM,SAAUjB,GACZlkE,EAA+Cxd,EAC/C2iF,GACF,MAAMxnC,EAAQ39B,EAAMxd,GACpB,OAAIm7C,GAASA,EAAMxjC,KACVqqE,GAAgB7mC,EAAMxjC,MAExBgrE,CACT,CAEM,SAAUhB,GACZnkE,EAA+Cxd,EAC/C2iF,GACF,MAAMxnC,EAAQ39B,EAAMxd,GACpB,OAAIm7C,GAASA,EAAMhjC,MAAQgjC,EAAMhjC,KAAKR,KAC7BwjC,EAAMhjC,KAAKR,KAAKxe,IAAIyV,GAAKozE,GAAgBpzE,IAE3C+zE,CACT,CAEM,SAAUY,GAAsBtwF,GAEpC,IAAIA,EAAMuwF,YAGV,OAAiB,MAAbvwF,EAAMouC,IACDpuC,EAAMouC,IAAIloC,IACbkoC,GACyB,kBAAbA,EAAIzqC,KAAqByqC,EAAIzqC,KAAOgsF,SAASvhD,EAAIzqC,KAAM,KAElE,EACT,CAEM,SAAU4qF,GACZhkE,EAA+Cxd,EAC/C2iF,GACF,MAAMxnC,EAAQ39B,EAAMxd,GACpB,OAAIm7C,GAASA,EAAMloD,MACVswF,GAAsBpoC,EAAMloD,OAE9B0vF,CACT,CAEM,SAAUtB,GACZ7jE,EAA+Cxd,EAC/C2iF,GACF,MAAMxnC,EAAQ39B,EAAMxd,GACpB,OAAIm7C,IACOA,EAAMhjC,KAAK3lB,GAAK2oD,EAAMhjC,KAAK3lB,EAAEsB,OAASqnD,EAAMhjC,KAAK3lB,EACX2oD,EAAMhjC,KAAKljB,IAClD,IACHkE,IAAIyV,GAAmB,kBAANA,EAAkBA,EAAIg0E,SAASh0E,EAAG,KAEnD+zE,CACT,CAEM,SAAUxB,GACZ3jE,EAA+Cxd,EAAc2iF,GAC7C,IAAhBF,EAAQxsF,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,IAAAA,UAAA,GACV,MAAMklD,EAAQ39B,EAAMxd,GACpB,OAAIm7C,GAASA,EAAMhjC,MAAQgjC,EAAMhjC,KAAK/e,EAC7B+hD,EAAMhjC,KAAK/e,EAAED,IAAKyV,GAChB4zE,GAAiB5zE,EAAG6zE,IAGxBE,CACT,CAEM,SAAUlB,GACZjkE,EAA+Cxd,EAC/C2iF,GACF,MAAMxnC,EAAQ39B,EAAMxd,GACpB,OAAIm7C,GAASA,EAAMhjC,MAAQgjC,EAAMhjC,KAAKllB,MAC7BkoD,EAAMhjC,KAAKllB,MAAMkG,IAAKyV,GACpB20E,GAAsB30E,IAG1B+zE,CACT,CAEM,SAAUpB,GACZ/jE,EAA+Cxd,EAC/C2iF,GACF,MAAMxnC,EAAQ39B,EAAMxd,GACpB,OAAIm7C,GAASA,EAAMhjC,MAAQgjC,EAAMhjC,KAAK/iB,EAC7B+lD,EAAMhjC,KAAK/iB,EAEbutF,CACT,CClkBM,MAAOc,GAGXtyF,WAAAA,CACYqxB,EAAoBm6D,EACpBC,GADA,KAAAp6D,KAAAA,EAAoB,KAAAm6D,UAAAA,EACpB,KAAAC,QAAAA,EAJI,KAAAxrE,OAAmB,GACnB,KAAAoM,MAAoC,CAAC,EAInD7rB,KAAKyf,OAASoR,EAAK26D,WAAWhkF,IAAI6G,GAAQrO,KAAK+xF,SAAS1jF,IACnC,MAAjBwiB,EAAKu+D,WACPpvF,KAAK6rB,MAAQze,OAAOkc,KAAKuH,EAAKu+D,UACZ5kF,OAAO,CAACqhB,EAAmCje,KAC1Cie,EAAMje,GAAO5N,KAAKgyF,QAAQpkF,GACnBie,GACN,CAAC,GAEzB,CAMQkmE,QAAAA,CAAS1jF,GACf,OAAOk9E,GAAUl9E,EAAMrO,KAAKgrF,UAAWhrF,KAAKirF,QAC9C,CAMQ+G,OAAAA,CAAQ3jF,EAAc4xD,GAC5B,MAAM7/D,EAAQJ,KAAK6wB,KAAKu+D,SAAS/gF,GACjC,GAAoB,MAAhBjO,EAAMgmB,OACR,OAAOmlE,GAAUl9E,EAAMrO,KAAKgrF,UAAWhrF,KAAKirF,SAE9C,GAAe,MAAX7qF,EAAMkD,GAAwB,MAAXlD,EAAMS,EAC3B,OAAO4uF,GAAezvF,KAAK6wB,KAAKu+D,SAAU/gF,EAAM4xD,GAElD,GAAe,MAAX7/D,EAAMqH,EACR,OAAO4nF,GAAervF,KAAK6wB,KAAKu+D,SAAU/gF,EAAM4xD,GAElD,GAAe,MAAX7/D,EAAMqD,EACR,OAAOksF,GAAa3vF,KAAK6wB,KAAKu+D,SAAU/gF,EAAM4xD,GAEhD,GAAmB,MAAf7/D,EAAMkB,MACR,OAAOuuF,GACH7vF,KAAK6wB,KAAKu+D,SAAU/gF,EAAM4xD,GAEhC,GAAkB,MAAd7/D,EAAM4lB,KACR,OAAO+pE,GAAc/vF,KAAK6wB,KAAKu+D,SAAU/gF,EAAM4xD,GAEjD,GAAkB,MAAd7/D,EAAMomB,KAAc,CACtB,GAAoB,MAAhBpmB,EAAMomB,KAAKljB,GAA6B,MAAhBlD,EAAMomB,KAAK3lB,EACrC,OAAO6uF,GACH1vF,KAAK6wB,KAAKu+D,SAAU/gF,EAAM4xD,GAEhC,GAAoB,MAAhB7/D,EAAMomB,KAAK/e,EACb,OAAO+nF,GACHxvF,KAAK6wB,KAAKu+D,SAAU/gF,EAAM4xD,GAEhC,GAAwB,MAApB7/D,EAAMomB,KAAKllB,MACb,OAAOwuF,GACH9vF,KAAK6wB,KAAKu+D,SAAU/gF,EAAM4xD,GAEhC,GAAoB,MAAhB7/D,EAAMomB,KAAK/iB,EACb,OAAOmsF,GACH5vF,KAAK6wB,KAAKu+D,SAAU/gF,EAAM4xD,GAEhC,GAAuB,MAAnB7/D,EAAMomB,KAAKR,KACb,OAAOgqE,GACHhwF,KAAK6wB,KAAKu+D,SAAU/gF,EAAM4xD,E,CAIlC,OAAOA,CACT,ECrEI,SAAUgyB,GACZ9tF,EAAyBC,GACF,IAAvBC,EAAkBC,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,GAEvB,GAAsB,kBAAXH,GAAyC,kBAAXC,EAAzC,CAGAyb,EACI1b,EAAOhC,SAAWiC,EAAOjC,OACzB,IAAMkC,EAAqB,WAAHtC,OAAcoC,EAAM,SAAApC,OAAQqC,EAAM,gBAC9D,IAAK,IAAId,EAAI,EAAGA,EAAIa,EAAOhC,OAAQmB,IAAK,CACtC,MAAM4uF,EAAO/tF,EAAOb,GACdgmF,EAAOllF,EAAOd,GACpBuc,EACIqyE,EAAO,GAAK5I,EAAO,GAAK4I,IAAS5I,EACjC,IACIjlF,EAAqB,WAAHtC,OAAcoC,EAAM,SAAApC,OAAQqC,EAAM,e,EAEhE,CAEM,SAAU+tF,GAAiBC,GAC/B,MAA4B,kBAAjBA,IAA6BA,EAAa9rE,KAAKopB,GAAOA,EAAM,EAIzE,CAQM,SAAU2iD,GACZC,EAAmChlE,EACnC8kE,GACF,IAAIG,EAAeC,GAAkBF,EAAkBF,GACvD,MAAMK,GAAuBN,GAAiBI,GAC9C,GAAIE,GAA0C,IAAnBnlE,EAAQnrB,OACjC,MAAM,IAAIL,MACN,wFAAAC,OACyCwwF,IAO/C,GALIE,GACFnlE,EAAQlkB,QAAQgd,IACdmsE,EAAeC,GAAkBpsE,EAAO9kB,MAAOixF,MAG9CJ,GAAiBI,GACpB,MAAM,IAAIzwF,MAAM,mCAADC,OAAoCwwF,IAErD,OAAOA,CACT,CAEM,SAAUC,GACZE,EAAgCC,GAElC,GAA6B,kBAAlBD,EACT,OAAOC,EAET,GAA6B,kBAAlBA,EACT,OAAOD,EAGT,GAAIA,EAAcvwF,SAAWwwF,EAAcxwF,OACzC,MAAM,IAAIL,MAAM,oCAADC,OAAqC2wF,EAAa,SAAA3wF,OAC7D4wF,IAGN,MAAM/uF,EAAmB,GACzB,IAAK,IAAIN,EAAI,EAAGA,EAAIovF,EAAcvwF,SAAUmB,EAAG,CAC7C,MAAM4uF,EAAOQ,EAAcpvF,GACrBgmF,EAAOqJ,EAAcrvF,GAC3B,GAAI4uF,GAAQ,GAAK5I,GAAQ,GAAK4I,IAAS5I,EACrC,MAAM,IAAIxnF,MAAM,oCAADC,OAAqC2wF,EAAa,SAAA3wF,OAC7D4wF,IAEN/uF,EAAON,GAAK4uF,GAAQ,EAAIA,EAAO5I,C,CAEjC,OAAO1lF,CACT,CCjFM,MAAOgvF,GAIXpzF,WAAAA,CACa6O,EAAuB9M,EAAyBsxF,EACjDT,EAAiCU,EAChCC,EAA+BC,GAF/B,KAAA3kF,KAAAA,EAAuB,KAAA9M,MAAAA,EAAyB,KAAAsxF,QAAAA,EACjD,KAAAT,aAAAA,EAAiC,KAAAU,uBAAAA,EAChC,KAAAC,YAAAA,EAA+B,KAAAC,eAAAA,EANpC,KAAA1lE,QAA6B,GAC7B,KAAA2lE,SAAU,EAMhBjzF,KAAKkzF,SAAW50C,GAAO,GACvB/wB,GAAKvtB,KAAKkzF,SACZ,CAEA,MAAIzvE,GACF,OAAOzjB,KAAKkzF,SAASzvE,EACvB,CAEA,UAAI0vE,GACF,OAAOnzF,KAAKizF,OACd,CAKAG,aAAAA,CAAcC,GACZrzF,KAAKstB,QAAQlkB,QAAQgd,IACJ,MAAXitE,GAAoBA,EAAQpzF,IAAImmB,EAAOA,OAAO3C,KAChD2C,EAAOA,OAAOxkB,YAGlB5B,KAAKstB,QAAU,GACfttB,KAAKizF,SAAU,EACfjzF,KAAKkzF,SAAStxF,SAChB,CAEAqD,IAAAA,GACE,OAAOjF,KAAKstB,QAAQnrB,MACtB,CAMArB,IAAAA,CAAKsB,GACH,GAAIpC,KAAKizF,QACP,MAAM,IAAInxF,MAAM,eAADC,OAAgB/B,KAAKqO,KAAI,8BAG1C,GAAIjM,EAAQ,GAAKA,GAASpC,KAAKiF,OAC7B,MAAM,IAAInD,MAAM,4BAADC,OAA6BK,EAAK,yBAAAL,OAC7C/B,KAAKiF,SAGX,MAAMquF,EAAkBtzF,KAAKstB,QAAQlrB,GACrC,GAAIkxF,EAAgBC,QAClB,MAAM,IAAIzxF,MACN,eAAAC,OAAe/B,KAAKqO,KAAI,2BAAAtM,OACpBK,EAAK,4GASf,OALIpC,KAAKgzF,iBACPM,EAAgBC,SAAU,GAG5BD,EAAgBxyF,MAAO,EAChBwyF,EAAgBltE,MACzB,CAKAotE,QAAAA,CAASx/D,GACP,OAAOA,EAAQxsB,IAAIpF,GAASpC,KAAKc,KAAKsB,GACxC,CAOAhB,KAAAA,CAAMgB,EAAegkB,GACnB,GAAIpmB,KAAKizF,QACP,MAAM,IAAInxF,MAAM,eAADC,OAAgB/B,KAAKqO,KAAI,8BAG1C,GAAIjM,EAAQ,IAAMpC,KAAK+yF,aAAe3wF,GAASpC,KAAK6yF,QAClD,MAAM,IAAI/wF,MAAM,2BAADC,OACXK,EAAK,+CAAAL,OAA8C/B,KAAK6yF,UAG9D,MAAM1kF,EAAInO,KAAKstB,QAAQlrB,IAAU,CAAC,EAElC,GAAIgkB,EAAO7kB,QAAUvB,KAAKuB,MACxB,MAAM,IAAIO,MAAM,eAADC,OACX/B,KAAKqO,KAAI,2CAAAtM,OAA0CK,EAAK,4CAAAL,OAExDqkB,EAAO7kB,MAAK,+BAAAQ,OAA8B/B,KAAKuB,MAAK,MAc1D,GAVoB,IAAhBvB,KAAKiF,QACiB,MAArBjF,KAAKoyF,cAAqD,IAA7BpyF,KAAKoyF,aAAajwF,SAClDnC,KAAKoyF,aAAehsE,EAAO9kB,OAG7B2wF,GACIjyF,KAAKoyF,aAAchsE,EAAO9kB,MAAK,eAAAS,OAChB/B,KAAKqO,KAAI,2CAAAtM,OACpBK,EAAK,MAET+L,EAAErN,KACJ,MAAM,IAAIgB,MAAM,eAADC,OACI/B,KAAKqO,KAAI,2CAAAtM,OACpBK,EAAK,wCAGf,GAAI+L,EAAEslF,QACJ,MAAM,IAAI3xF,MAAM,eAADC,OACI/B,KAAKqO,KAAI,2CAAAtM,OACpBK,EAAK,2CAGf+L,EAAEiY,OAASA,EACXmH,GAAKnH,GACLjY,EAAEslF,SAAU,EAEZzzF,KAAKstB,QAAQlrB,GAAS+L,CACxB,CAKAulF,SAAAA,CAAU1/D,EAAmB1G,GAC3B,GAAI0G,EAAQ7xB,SAAWmrB,EAAQnrB,OAC7B,MAAM,IAAIL,MACN,eAAAC,OAAe/B,KAAKqO,KAAI,kEAAAtM,OAEpBiyB,EAAQ7xB,OAAM,sCAAAJ,OACdurB,EAAQnrB,OAAM,MAGxB6xB,EAAQ5qB,QAAQ,CAAC9F,EAAGlB,IAAUpC,KAAKoB,MAAMkC,EAAGgqB,EAAQlrB,IACtD,CAUAi0D,MAAAA,CAAOriC,EAAoBzyB,GACzB,GAAMA,GAASA,IAAUvB,KAAKuB,MAC5B,MAAM,IAAIO,MAAM,wBAADC,OACX/B,KAAKuB,MAAK,gCAAAQ,OAA+BR,IAG/C,GAAKyyB,EAMHA,EAAUA,EAAQ5sB,MAAM,EAAGpH,KAAKiF,YANpB,CACZ+uB,EAAU,GACV,IAAK,IAAI1wB,EAAI,EAAGA,EAAItD,KAAKiF,OAAQ3B,IAC/B0wB,EAAQjvB,KAAKzB,E,CAMjB,GAAuB,IAAnB0wB,EAAQ7xB,OACV,OAAOikB,GAAO,GAAI,CAAC,GAAGrkB,OAAO/B,KAAKoyF,eAKpC,MAAM9kE,EAAUttB,KAAKwzF,SAASx/D,GAK9B,OAHAi+D,GACIjyF,KAAKoyF,aAAc9kE,EAAQ,GAAGhsB,MAAO,gCAElCgpB,GAAMgD,EAAS,EACxB,CAKAvrB,MAAAA,CAAOR,GACL,GAAMA,GAASA,IAAUvB,KAAKuB,MAC5B,MAAM,IAAIO,MAAM,wBAADC,OACX/B,KAAKuB,MAAK,gCAAAQ,OAA+BR,IAG/C,GAAoB,IAAhBvB,KAAKiF,OACP,OAAOmhB,GAAO,GAAI,CAAC,GAAGrkB,OAAO/B,KAAKoyF,eAGpC,MAAMp+D,EAAU,GAChB,IAAK,IAAI1wB,EAAI,EAAGA,EAAItD,KAAKiF,OAAQ3B,IAC/B0wB,EAAQjvB,KAAKzB,GAGf,MAAMgqB,EAAUttB,KAAKwzF,SAASx/D,GAO9B,OALAi+D,GACIjyF,KAAKoyF,aAAc9kE,EAAQ,GAAGhsB,MAAK,mDAAAS,OAE/B/B,KAAKoyF,aAAY,6BAAArwF,OAA4BurB,EAAQ,GAAGhsB,MAAK,MAE9DS,GAAOurB,EAAS,EACzB,CAQAqmE,OAAAA,CAAQ3/D,EAAmB5N,GACzB,GAAIA,EAAO7kB,QAAUvB,KAAKuB,MACxB,MAAM,IAAIO,MAAM,wBAADC,OACX/B,KAAKuB,MAAK,0BAAAQ,OAAyBqkB,EAAO7kB,QAGhD,GAAIyyB,EAAQ7xB,SAAWikB,EAAO9kB,MAAM,GAClC,MAAM,IAAIQ,MAAM,sDAADC,OACXiyB,EAAQ7xB,OAAM,SAAAJ,OAAQqkB,EAAO9kB,MAAM,KAGzC,MAAMsyF,EAAWvxF,KAAKQ,OAAOmxB,GAE7B,IAAKh0B,KAAK+yF,aAAea,GAAY5zF,KAAK6yF,QACxC,MAAM,IAAI/wF,MAAM,mCAADC,OACwB6xF,EAAQ,UAAA7xF,OAAS/B,KAAK6yF,QAAO,MAGtE7yF,KAAK0zF,UAAU1/D,EAASk1C,GAAQ9iD,EAAQ,GAC1C,CAQA1Y,KAAAA,CAAMvL,EAAkBikB,GACtB,GAAIA,EAAO7kB,QAAUvB,KAAKuB,MACxB,MAAM,IAAIO,MAAM,wBAADC,OACX/B,KAAKuB,MAAK,0BAAAQ,OAAyBqkB,EAAO7kB,QAEhD,IAAIsyF,EAAc,EAClB,MAAMC,EAAoB3xF,EAAOqF,IAAI+C,IACnCspF,GAAetpF,EACRspF,IAGT,GAAIA,IAAgBztE,EAAO9kB,MAAM,GAC/B,MAAM,IAAIQ,MAAM,qGAADC,OAEX8xF,EAAW,6BAAA9xF,OAA4BqkB,EAAO9kB,QAGpD,IAAKtB,KAAK+yF,aAAe5wF,EAAOA,SAAWnC,KAAK6yF,QAC9C,MAAM,IAAI/wF,MACN,2DAAAC,OACI/B,KAAK6yF,QAAO,SAAA9wF,OAAQI,EAAOA,OAAM,OACrC,+DAGN,MAAM4xF,EAAgC,IAAhBF,EAAoB,EAAIztE,EAAOnhB,KAAO4uF,EACtDvmE,EAAoB,GAC1B1C,GAAK,KACHxE,EAAS8jC,GAAQ9jC,EAAQ,CAAC,EAAGytE,EAAaE,IAC1C,IAAK,IAAIzwF,EAAI,EAAGA,EAAInB,EAAOA,SAAUmB,EAAG,CACtC,MACM0wB,EAAU,CAAC,EADa,IAAN1wB,EAAW,EAAIwwF,EAAkBxwF,EAAI,GACzB,GAC9B0wF,EAAQ,CAAC,EAAG7xF,EAAOmB,GAAIywF,GAC7BzmE,EAAQhqB,GAAK4mD,GAAQ9iD,GAAMgf,EAAQ4N,EAASggE,GAAQh0F,KAAKoyF,a,CAE3D,OAAO9kE,IAET,MAAM0G,EAAU,GAChB,IAAK,IAAI1wB,EAAI,EAAGA,EAAInB,EAAOA,OAAQmB,IACjC0wB,EAAQ1wB,GAAKA,EAEftD,KAAK0zF,UAAU1/D,EAAS1G,EAC1B,ECtRI,MAAO2mE,GAgBXz0F,WAAAA,CACa8tB,EAA4B8kE,EAC5B8B,GAA2C,IAAnBC,EAAc7vF,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,IAAI,EAD1C,KAAAgpB,QAAAA,EAA4B,KAAA8kE,aAAAA,EAC5B,KAAA8B,aAAAA,EACI,MAAX5mE,GACFA,EAAQlkB,QAAQgd,IACd,GAAI8tE,IAAiB9tE,EAAO7kB,MAC1B,MAAM,IAAIO,MAAM,mCAADC,OACXmyF,EAAY,wBAAAnyF,OAAuBqkB,EAAO7kB,QAEhD0wF,GACIG,EAAchsE,EAAO9kB,MAAO,+BAEhCisB,GAAKnH,KAGTpmB,KAAKkzF,SAAW50C,GAAO,GACvBt+C,KAAKm0F,eAAiBA,EACtB5mE,GAAKvtB,KAAKkzF,SACZ,CA9BA,MAAIzvE,GACF,OAAOzjB,KAAKkzF,SAASzvE,EACvB,CAiCA2wE,IAAAA,GACE,OAAO,IAAIH,GACP,IAAIj0F,KAAKstB,SAAUttB,KAAKoyF,aAAcpyF,KAAKk0F,aACjD,CAKAd,aAAAA,CAAcC,GACZrzF,KAAKstB,QAAQlkB,QAAQgd,IACJ,MAAXitE,GAAoBA,EAAQpzF,IAAImmB,EAAO3C,KACzC2C,EAAOxkB,YAGX5B,KAAKstB,QAAQnrB,OAAS,EACtBnC,KAAKkzF,SAAStxF,SAChB,CAIAqD,IAAAA,GACE,OAAOjF,KAAKstB,QAAQnrB,MACtB,CASAmoB,KAAAA,CAAM8nE,EAAwB8B,GAAwC,IAAhBG,EAAW/vF,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,IAAI,EAEnE,GAAI4vF,IAAiBl0F,KAAKk0F,aACxB,MAAM,IAAIpyF,MAAM,mCAADC,OACXmyF,EAAY,wBAAAnyF,OAAuB/B,KAAKk0F,eAE9C,IAAqB,IAAjBG,GAAsBr0F,KAAKstB,QAAQnrB,SAAWkyF,EAChD,MAAM,IAAIvyF,MAAM,kCAADC,OACXsyF,EAAW,kCAAAtyF,OACX/B,KAAKstB,QAAQnrB,OAAM,eAEzB8vF,GACIG,EAAcpyF,KAAKoyF,aAAc,+BACrC,MAAMkC,EACFjC,GAAkBryF,KAAKoyF,aAAcpyF,KAAKstB,QAAS8kE,GACvD,OAAOxnE,GAAK,KACV,MAAM2pE,EACFv0F,KAAKstB,QAAQ9lB,IAAI4e,GAAU8jC,GAAQ9jC,EAAQkuE,IAC/C,OAAOhqE,GAAMiqE,EAAiB,IAElC,CAOAC,OAAAA,CAAQpC,EAAwB8B,GAC9B,GAAIA,IAAiBl0F,KAAKk0F,aACxB,MAAM,IAAIpyF,MAAM,mCAADC,OACXmyF,EAAY,wBAAAnyF,OAAuB/B,KAAKk0F,eAG9C,GAAoB,IAAhBl0F,KAAKiF,OACP,MAAM,IAAInD,MAAM,qCAElB,MAAMwyF,EACFjC,GAAkBryF,KAAKoyF,aAAcpyF,KAAKstB,QAAS8kE,GACjDhsE,EAASpmB,KAAKstB,QAAQ8C,MAM5B,OALAhK,EAAO1C,MAAO,EAEduuE,GACI7rE,EAAO9kB,MAAO8wF,EAAc,+BAEzBloC,GAAQ9jC,EAAQkuE,EACzB,CAMAG,QAAAA,CAASruE,GACP,GAAIA,EAAO7kB,QAAUvB,KAAKk0F,aACxB,MAAM,IAAIpyF,MAAM,mCAADC,OACXqkB,EAAO7kB,MAAK,wBAAAQ,OAAuB/B,KAAKk0F,eAM9C,GAHAjC,GACI7rE,EAAO9kB,MAAOtB,KAAKoyF,aAAc,+BAEjCpyF,KAAKm0F,iBAAmBn0F,KAAKiF,OAC/B,MAAM,IAAInD,MAAM,4CAElByrB,GAAKnH,GACLpmB,KAAKstB,QAAQvoB,KAAKqhB,EACpB,CAMAsuE,MAAAA,CAAOzvF,GACL,GAAIA,EAAO,EACT,MAAM,IAAInD,MAAM,0DAADC,OAC+CkD,IAGhE,IAA6B,IAAzBjF,KAAKm0F,gBAAyBlvF,EAAOjF,KAAKm0F,eAC5C,MAAM,IAAIryF,MAAM,+BAADC,OACXkD,EAAI,8BAAAlD,OAA6B/B,KAAKm0F,eAAc,MAG1D,MAAMQ,EAA6B,IAAIV,GACnC,GAAIj0F,KAAKoyF,aAAcpyF,KAAKk0F,aAAcl0F,KAAKm0F,gBACnDQ,EAAernE,QAAQnrB,OAAS8C,EAChC,IAAK,IAAI3B,EAAI,EAAGA,EAAIjB,KAAKM,IAAI3C,KAAKstB,QAAQnrB,OAAQ8C,KAAS3B,EACzDqxF,EAAernE,QAAQhqB,GAAKtD,KAAKstB,QAAQhqB,GAE3C,OAAOqxF,CACT,CAQA5zD,OAAAA,CAAQ6zD,EAAsBxC,EAAwB8B,GAEpD,GAAIA,IAAiBl0F,KAAKk0F,aACxB,MAAM,IAAIpyF,MAAM,mCAADC,OACXmyF,EAAY,wBAAAnyF,OAAuB/B,KAAKk0F,eAE9C,GAAIU,EAAe,GAAKA,EAAe50F,KAAKstB,QAAQnrB,OAClD,MAAM,IAAIL,MAAM,4BAADC,OACX6yF,EAAY,oBAAA7yF,OAAmB/B,KAAKstB,QAAQnrB,OAAM,eAGxD,GAAkC,MAA9BnC,KAAKstB,QAAQsnE,GACf,MAAM,IAAI9yF,MAAM,oBAADC,OAAqB6yF,EAAY,cAGlD3C,GACIjyF,KAAKstB,QAAQsnE,GAActzF,MAAO8wF,EAClC,+BACJ,MAAMkC,EACFjC,GAAkBryF,KAAKoyF,aAAcpyF,KAAKstB,QAAS8kE,GACvD,OAAOloC,GAAQlqD,KAAKstB,QAAQsnE,GAAeN,EAC7C,CAOA7zD,OAAAA,CAAQm0D,EAAsBxuE,GAC5B,GAAIA,EAAO7kB,QAAUvB,KAAKk0F,aACxB,MAAM,IAAIpyF,MAAM,mCAADC,OACXqkB,EAAO7kB,MAAK,wBAAAQ,OAAuB/B,KAAKk0F,eAG9C,GAAIU,EAAe,IACU,IAAzB50F,KAAKm0F,gBAAyBS,GAAgB50F,KAAKm0F,eACrD,MAAM,IAAIryF,MAAM,yBAADC,OACX6yF,EAAY,wBAAA7yF,OAAuB/B,KAAKm0F,eAAc,eAG5DlC,GACIjyF,KAAKoyF,aAAchsE,EAAO9kB,MAAO,+BACrCisB,GAAKnH,GAG6B,MAA9BpmB,KAAKstB,QAAQsnE,KACf50F,KAAKstB,QAAQsnE,GAAclxE,MAAO,GAGpC1jB,KAAKstB,QAAQsnE,GAAgBxuE,CAC/B,CASAiwC,MAAAA,CAAOriC,EAAmBkgE,EAAwB9B,GAEhD,GAAI8B,IAAiBl0F,KAAKk0F,aACxB,MAAM,IAAIpyF,MAAM,mCAADC,OACXmyF,EAAY,wBAAAnyF,OAAuB/B,KAAKk0F,eAG9CjC,GACIjyF,KAAKoyF,aAAcA,EAAc,+BAIrCp+D,EAAUA,EAAQ5sB,MAAM,EAAGpH,KAAKiF,QAChC,MAAMqvF,EACFjC,GAAkBryF,KAAKoyF,aAAcpyF,KAAKstB,QAAS8kE,GACvD,OAAuB,IAAnBp+D,EAAQ7xB,OACHikB,GAAO,GAAI,CAAC,GAAGrkB,OAAOuyF,IAGxB1pE,GAAK,KACV,MAAM0C,EACF0G,EAAQxsB,IAAIlE,GAAK4mD,GAAQlqD,KAAKstB,QAAQhqB,GAAIgxF,IAC9C,OAAOhqE,GAAMgD,EAAS,IAE1B,CAOAvrB,MAAAA,CAAOmyF,EAAwB9B,GAC7B,GAAM8B,GAAgBA,IAAiBl0F,KAAKk0F,aAC1C,MAAM,IAAIpyF,MAAM,uBAADC,OACX/B,KAAKk0F,aAAY,gCAAAnyF,OAA+BmyF,IAGtDjC,GACIjyF,KAAKoyF,aAAcA,EAAc,+BACrC,MAAMkC,EACFjC,GAAkBryF,KAAKoyF,aAAcpyF,KAAKstB,QAAS8kE,GAEvD,OAAoB,IAAhBpyF,KAAKiF,OACAmhB,GAAO,GAAI,CAAC,GAAGrkB,OAAOuyF,IAExB1pE,GAAK,KACV,MAAM0C,EAAUttB,KAAKstB,QAAQ9lB,IAAI2G,GAAK+7C,GAAQ/7C,EAAGmmF,IACjD,OAAOvyF,GAAOurB,EAAS,IAE3B,EC5RK,MAAMunE,GAAqCz+D,MAC9CvF,EAAYm6D,EACZC,KACF,OAAQp6D,EAAKqE,IACX,IAAK,KACL,IAAK,cAAe,CAClB,MAAM4/D,EACFhK,GAAc,aAAcj6D,EAAMm6D,EAAWC,GAC3C8J,EACFjK,GAAc,aAAcj6D,EAAMm6D,EAAWC,GAC3C+J,EAAOlK,GAAc,OAAQj6D,EAAMm6D,EAAWC,GAC9CrtC,EAAOktC,GAAc,OAAQj6D,EAAMm6D,EAAWC,GAEpD,aADwB+J,EAAKr1F,QACf,GACLsrF,EAAQgK,YAAYH,GAAUI,qBACjCt3C,EAAMqtC,EAAQkK,eAAgBlK,EAAQmK,eAEnCnK,EAAQgK,YAAYF,GAAUG,qBACjCt3C,EAAMqtC,EAAQkK,eAAgBlK,EAAQmK,c,CAG9C,IAAK,QACL,IAAK,iBAAkB,CACrB,MAAMC,EACFvK,GAAc,OAAQj6D,EAAMm6D,EAAWC,GACrCqK,EACFxK,GAAc,OAAQj6D,EAAMm6D,EAAWC,GACrCrtC,EAAOktC,GAAc,OAAQj6D,EAAMm6D,EAAWC,GAG9CsK,QACKtK,EAAQgK,YAAYK,GAAUJ,qBACjCt3C,EAAMqtC,EAAQkK,eAAgBlK,EAAQmK,eACxCI,EAAS53C,EAAKp2C,IAAI4e,GAAUA,EAAO3C,IACzC,IAAIgyE,QAAkBF,EAAW,GAAG51F,OAEpC41F,EAAWnsF,QAAQgd,IACZA,EAAO1C,OAAuC,IAA/B8xE,EAAO9gE,QAAQtO,EAAO3C,KACxC2C,EAAOxkB,YAIX,IAAIgC,EAAmBg6C,EAEvB,KAAO63C,EAAU,IAAI,CAEnB,MAAMC,EAAa9xF,EAEnBA,QAAeqnF,EAAQgK,YAAYI,GAAUH,qBACzCtxF,EAAQqnF,EAAQkK,eAAgBlK,EAAQmK,eAC5C,MAAMO,EAAY/xF,EAAO4D,IAAI4e,GAAUA,EAAO3C,IAI9CiyE,EAAWtsF,QAAQgd,IACZA,EAAO1C,OAAuC,IAA/B8xE,EAAO9gE,QAAQtO,EAAO3C,MACJ,IAAlCkyE,EAAUjhE,QAAQtO,EAAO3C,KAC3B2C,EAAOxkB,YAKX,MAAM2zF,QACKtK,EAAQgK,YAAYK,GAAUJ,qBACjCtxF,EAAQqnF,EAAQkK,eAAgBlK,EAAQmK,eAChDK,QAAkBF,EAAW,GAAG51F,OAEhC41F,EAAWnsF,QAAQgd,IACZA,EAAO1C,OAAuC,IAA/B8xE,EAAO9gE,QAAQtO,EAAO3C,MACJ,IAAlCkyE,EAAUjhE,QAAQtO,EAAO3C,KAC3B2C,EAAOxkB,W,CAIb,OAAOgC,C,CAET,IAAK,WAEH,MAAO,CAAC6oF,GADK3B,GAAc,OAAQj6D,EAAMm6D,EAAWC,KAGtD,IAAK,SAAU,CACb,MAAM2K,EAAO9K,GAAc,OAAQj6D,EAAMm6D,EAAWC,GACpD,IAAItrF,EAAOmrF,GAAc,OAAQj6D,EAAMm6D,EAAWC,GAKlD,OAJKtrF,EAAK+jB,OACR/jB,EAAO8sF,GAAY9sF,WAGPi2F,EAAKj2F,QAAQ,GAAK,MAAC4E,EAAW5E,GAAQ,CAACA,OAAM4E,E,CAE7D,IAAK,QAAS,CACZ,MAAMgqB,EAAYsC,EAAK26D,WAAWS,KAC9B59E,QAAgD9J,IAAxCgnF,GAAUl9E,EAAM28E,EAAWC,IACvC,GAAI18D,EAAW,CAEb,MAAO,CAACk+D,GADKlB,GAAUh9D,EAAWy8D,EAAWC,I,CAG/C,M,CAEF,IAAK,QAAS,CACZ,MAAM4K,EACF/K,GAAc,YAAaj6D,EAAMm6D,EAAWC,GAC1CtrF,EAAOmrF,GAAc,SAAUj6D,EAAMm6D,EAAWC,GAEtD,OADAA,EAAQ6K,WAAWD,GACZ,CAACpJ,GAAY9sF,G,CAEtB,IAAK,OAAQ,CACX,MAAMA,EAAOmrF,GAAc,SAAUj6D,EAAMm6D,EAAWC,GAEtD,OADAA,EAAQ8K,YACD,CAACtJ,GAAY9sF,G,CAEtB,IAAK,gBAAiB,CACpB,MAAMA,EAAOmrF,GAAc,SAAUj6D,EAAMm6D,EAAWC,GAEtD,OADAA,EAAQ+K,gBACD,CAACvJ,GAAY9sF,G,CAEtB,IAAK,gBAAiB,CACpB,MAAMsF,EAAO6lF,GAAc,OAAQj6D,EAAMm6D,EAAWC,GAC9C1pF,EACFupF,GAAc,QAASj6D,EAAMm6D,EAAWC,GACtCmH,EACFtH,GAAc,eAAgBj6D,EAAMm6D,EAAWC,GAC7C8H,EACFjI,GAAc,cAAej6D,EAAMm6D,EAAWC,GAC5C+H,EACFlI,GAAc,iBAAkBj6D,EAAMm6D,EAAWC,GAC/C6H,EACFhI,GAAc,yBAA0Bj6D,EAAMm6D,EAAWC,GAEvD58E,EAAOy8E,GAAc,OAAQj6D,EAAMm6D,EAAWC,GAC9CgL,EAAc,IAAIrD,GACpBvkF,EAAM9M,EAAO0D,EAAMmtF,EAAcU,EAAwBC,EACzDC,GAEJ,OADA/H,EAAQiL,eAAeD,GAChB,CAACA,EAAY/C,SAAU50C,GAAO,G,CAEvC,IAAK,qBAAsB,CACzB,MAAM76B,EACFqnE,GAAc,gBAAiBj6D,EAAMm6D,EAAWC,GAC9C7oF,EAAQ0oF,GAAc,QAASj6D,EAAMm6D,EAAWC,GAChDkL,EACFrL,GAAc,SAAUj6D,EAAMm6D,EAAWC,GACvCmL,EAAmBnL,EAAQoL,eAAe5yE,EAAGA,IAEnD,OADA2yE,EAAiBh1F,MAAMgB,EAAO+zF,GACvB,CAACC,EAAiBlD,S,CAE3B,IAAK,oBAAqB,CACxB,MAAMoD,EACFxL,GAAc,gBAAiBj6D,EAAMm6D,EAAWC,GAC9CsL,EACFzL,GAAc,QAASj6D,EAAMm6D,EAAWC,GAE5C,MAAO,CADiBA,EAAQoL,eAAeC,EAAO7yE,IAC9B3iB,KAAKy1F,G,CAE/B,IAAK,sBAAuB,CAC1B,MAAMC,EACF1L,GAAc,gBAAiBj6D,EAAMm6D,EAAWC,GAC9CwL,EACF3L,GAAc,UAAWj6D,EAAMm6D,EAAWC,GACxCyL,EACF5L,GAAc,QAASj6D,EAAMm6D,EAAWC,GAE5C,MAAO,CADmBA,EAAQoL,eAAeG,EAAS/yE,IAChC4yC,OAAOogC,EAAeC,G,CAElD,IAAK,uBAAwB,CAC3B,MAAMC,EACF7L,GAAc,gBAAiBj6D,EAAMm6D,EAAWC,GAC9C2L,EACF9L,GAAc,UAAWj6D,EAAMm6D,EAAWC,GACxC4L,EACF/L,GAAc,SAAUj6D,EAAMm6D,EAAWC,GACvC6L,EAAqB7L,EAAQoL,eAAeM,EAAUlzE,IAE5D,OADAqzE,EAAmBnD,QAAQiD,EAAgBC,GACpC,CAACC,EAAmB5D,S,CAE7B,IAAK,sBAAuB,CAC1B,MAAM6D,EACFjM,GAAc,gBAAiBj6D,EAAMm6D,EAAWC,GAC9C+L,EAAoB/L,EAAQoL,eAAeU,EAAStzE,IACpDwzE,EACFnM,GAAc,QAASj6D,EAAMm6D,EAAWC,GAC5C,MAAO,CAAC+L,EAAkBj1F,OAAOk1F,G,CAEnC,IAAK,qBAAsB,CACzB,MAAMC,EACFpM,GAAc,gBAAiBj6D,EAAMm6D,EAAWC,GAC9CkM,EACFrM,GAAc,SAAUj6D,EAAMm6D,EAAWC,GACvCmM,EACFtM,GAAc,UAAWj6D,EAAMm6D,EAAWC,GACxCoM,EAAmBpM,EAAQoL,eAAea,EAAQzzE,IAExD,OADA4zE,EAAiB3pF,MAAM0pF,EAASD,GACzB,CAACE,EAAiBnE,S,CAE3B,IAAK,oBAAqB,CACxB,MAAMoE,EACFxM,GAAc,gBAAiBj6D,EAAMm6D,EAAWC,GAEpD,MAAO,CAAC3sC,GADgB2sC,EAAQoL,eAAeiB,EAAO7zE,IACvBxe,OAAQ,S,CAEzC,IAAK,qBAAsB,CACzB,MAAMsyF,EACFzM,GAAc,gBAAiBj6D,EAAMm6D,EAAWC,GAC9CuM,EAAmBvM,EAAQoL,eAAekB,EAAQ9zE,IAExD,OADA+zE,EAAiBpE,gBACV,CAACoE,EAAiBtE,S,CAE3B,IAAK,oBAAqB,CACxB,MAAMA,EACFpI,GAAc,eAAgBj6D,EAAMm6D,EAAWC,GAC7C7oF,EAAQ0oF,GAAc,QAASj6D,EAAMm6D,EAAWC,GAChDkL,EACFrL,GAAc,SAAUj6D,EAAMm6D,EAAWC,GACvC5kE,EAAa4kE,EAAQwM,cAAcvE,EAASzvE,IAElD,OADA4C,EAAWoa,QAAQr+B,EAAO+zF,GACnB,CAAC9vE,EAAW6sE,S,CAErB,IAAK,oBAAqB,CACxB,MAAMA,EACFpI,GAAc,eAAgBj6D,EAAMm6D,EAAWC,GAC7CsL,EACFzL,GAAc,QAASj6D,EAAMm6D,EAAWC,GACtCmH,EACFtH,GAAc,eAAgBj6D,EAAMm6D,EAAWC,GAE7CyM,EACF5M,GAAc,eAAgBj6D,EAAMm6D,EAAWC,GAEnD,MAAO,CADYA,EAAQwM,cAAcvE,EAASzvE,IAC/Bsd,QAAQw1D,EAAWnE,EAAcsF,G,CAEtD,IAAK,sBACL,IAAK,oBAAqB,CACxB,MAAMd,EACF9L,GAAc,UAAWj6D,EAAMm6D,EAAWC,GAOxC5kE,ED2FN,SACFD,EAAgB4N,EAAmBo+D,EACnCiC,GACF,GAAIrgE,EAAQ7xB,SAAWikB,EAAO9kB,MAAM,GAClC,MAAM,IAAIQ,MAAM,sDAADC,OACXiyB,EAAQ7xB,OAAM,SAAAJ,OAAQqkB,EAAO9kB,MAAM,KAGzC,MAAMsyF,EAAWvxF,KAAKQ,OAAOmxB,GAE7B,GAAmB,MAAfqgE,IAAwC,IAAjBA,GAAsBT,GAAYS,EAC3D,MAAM,IAAIvyF,MAAM,mCAADC,OACwB6xF,EAAQ,UAAA7xF,OAASsyF,EAAW,MAGrE,MAAM7tE,EAAO,IAAIytE,GAAW,GAAI7B,EAAchsE,EAAO7kB,MAAO8yF,GACtD/mE,EAAU47C,GAAQ9iD,EAAQ,GAIhC,OAHA4N,EAAQ5qB,QAAQ,CAAChJ,EAAOgC,KACtBokB,EAAKia,QAAQrgC,EAAOktB,EAAQlrB,MAEvBokB,CACT,CC/GUmtE,CANA7I,GAAc,SAAUj6D,EAAMm6D,EAAWC,GAMlB2L,EAJvB9L,GAAc,eAAgBj6D,EAAMm6D,EAAWC,GAE/CH,GAAc,cAAej6D,EAAMm6D,EAAWC,IAIlD,OADAA,EAAQ0M,cAActxE,GACf,CAACA,EAAW6sE,S,CAErB,IAAK,oBACL,IAAK,kBAAmB,CACtB,MAAMd,EACFtH,GAAc,eAAgBj6D,EAAMm6D,EAAWC,GAC7CiJ,EACFpJ,GAAc,eAAgBj6D,EAAMm6D,EAAWC,GACnD,IAAI2M,EAGFA,EADc,sBAAZ/mE,EAAKqE,GACY,cAEA,iBAGrB,MAAMm/D,EACFvJ,GAAc8M,EAAkB/mE,EAAMm6D,EAAWC,GAE/C5kE,EDwDN,SACF+rE,EAAwB8B,EAAwBG,EAChDF,GACF,OAAO,IAAIF,GAAW,GAAI7B,EAAc8B,EAAcC,EACxD,CC3DU0D,CAAQzF,EAAc8B,EAAcG,EAFL,sBAAZxjE,EAAKqE,IAA8B,EAAIm/D,GAI9D,OADApJ,EAAQ0M,cAActxE,GACf,CAACA,EAAW6sE,S,CAErB,IAAK,mBAAoB,CACvB,MAAMsD,EACF1L,GAAc,eAAgBj6D,EAAMm6D,EAAWC,GAC7CwL,EACF3L,GAAc,UAAWj6D,EAAMm6D,EAAWC,GACxCmH,EACFtH,GAAc,eAAgBj6D,EAAMm6D,EAAWC,GAC7CiJ,EACFpJ,GAAc,eAAgBj6D,EAAMm6D,EAAWC,GAEnD,MAAO,CADYA,EAAQwM,cAAcjB,EAAS/yE,IAC/B4yC,OAAOogC,EAAevC,EAAc9B,G,CAEzD,IAAK,kBAAmB,CACtB,MAAMc,EACFpI,GAAc,eAAgBj6D,EAAMm6D,EAAWC,GAC7CmH,EACFtH,GAAc,eAAgBj6D,EAAMm6D,EAAWC,GAC7CiJ,EACFpJ,GAAc,eAAgBj6D,EAAMm6D,EAAWC,GAC7CoJ,EACFvJ,GAAc,cAAej6D,EAAMm6D,EAAWC,GAElD,MAAO,CADYA,EAAQwM,cAAcvE,EAASzvE,IAC/B6G,MAAM8nE,EAAc8B,EAAcG,G,CAEvD,IAAK,uBAAwB,CAC3B,MAMMhuE,EDLN,SACFD,EAAgBgsE,EAAwB8B,GAC1C,MAAM3yF,EAAQ6kB,EAAO7kB,MACrB,GAAI6kB,EAAO9kB,MAAMa,OAAS,EACxB,MAAM,IAAIL,MAAM,oDAADC,OACyCqkB,EAAO9kB,QAEjE,GAAI8kB,EAAO7kB,QAAU2yF,EACnB,MAAM,IAAIpyF,MAAM,mCAADC,OACXqkB,EAAO7kB,MAAK,wBAAAQ,OAAuBmyF,IAGzCjC,GAD2B7rE,EAAO9kB,MAAM8F,MAAM,GAEtBgrF,EAAc,+BACtC,MAAM/rE,EAAuB6iD,GAAQ9iD,GACrC,OAAO,IAAI6tE,GAAW5tE,EAAY+rE,EAAc7wF,EAClD,CCXyBu2F,CALfhN,GAAc,SAAUj6D,EAAMm6D,EAAWC,GAEzCH,GAAc,eAAgBj6D,EAAMm6D,EAAWC,GAE/CH,GAAc,eAAgBj6D,EAAMm6D,EAAWC,IAGnD,OADAA,EAAQ0M,cAActxE,GACf,CAACA,EAAW6sE,S,CAErB,IAAK,mBACL,IAAK,qBAAsB,CACzB,MAAM6D,EACFjM,GAAc,eAAgBj6D,EAAMm6D,EAAWC,GAC7C5kE,EAAa4kE,EAAQwM,cAAcV,EAAStzE,IAC5CwzE,EACFnM,GAAc,QAASj6D,EAAMm6D,EAAWC,GACtCmH,EACFtH,GAAc,eAAgBj6D,EAAMm6D,EAAWC,GACnD,MAAO,CAAC5kE,EAAWtkB,OAAOk1F,EAAa7E,G,CAEzC,IAAK,qBAAsB,CACzB,MAAMc,EACFpI,GAAc,eAAgBj6D,EAAMm6D,EAAWC,GAC7CkL,EACFrL,GAAc,SAAUj6D,EAAMm6D,EAAWC,GACvC5kE,EAAa4kE,EAAQwM,cAAcvE,EAASzvE,IAElD,OADA4C,EAAWouE,SAAS0B,GACb,CAAC9vE,EAAW6sE,S,CAErB,IAAK,oBAAqB,CACxB,MAAMA,EACFpI,GAAc,eAAgBj6D,EAAMm6D,EAAWC,GAC7CmH,EACFtH,GAAc,eAAgBj6D,EAAMm6D,EAAWC,GAC7CyM,EACF5M,GAAc,eAAgBj6D,EAAMm6D,EAAWC,GAEnD,MAAO,CADYA,EAAQwM,cAAcvE,EAASzvE,IAC/B+wE,QAAQpC,EAAcsF,G,CAE3C,IAAK,kBAAmB,CACtB,MAAMP,EACFrM,GAAc,SAAUj6D,EAAMm6D,EAAWC,GACvCmH,EACFtH,GAAc,eAAgBj6D,EAAMm6D,EAAWC,GAI7C5kE,EDqBN,SACFD,EAAgBjkB,EAAkBiwF,GACpC,IAAIyB,EAAc,EAClB,MAAMC,EAAoB3xF,EAAOqF,IAAI+C,IACnCspF,GAAetpF,EACRspF,IAGT,GAAIA,IAAgBztE,EAAO9kB,MAAM,GAC/B,MAAM,IAAIQ,MAAM,qGAADC,OAET8xF,EAAW,6BAAA9xF,OAA4BqkB,EAAO9kB,QAGtD,MACMgzF,EACF9B,GAFyBpsE,EAAO9kB,MAAM8F,MAAM,GAEJgrF,GACtC2B,EAAgC,IAAhBF,EAAoB,EAAIztE,EAAOnhB,KAAO4uF,EACtDvmE,EAAoB1C,GAAK,KAC7B,MAAM0C,EAAU,GAChBlH,EAAS8jC,GAAQ9jC,EAAQ,CAAC,EAAGytE,EAAaE,IAC1C,IAAK,IAAIzwF,EAAI,EAAGA,EAAInB,EAAOA,SAAUmB,EAAG,CACtC,MACM0wB,EAAU,CAAC,EADa,IAAN1wB,EAAW,EAAIwwF,EAAkBxwF,EAAI,GACzB,GAC9B0wF,EAAQ,CAAC,EAAG7xF,EAAOmB,GAAIywF,GAC7BzmE,EAAQhqB,GAAK4mD,GACT9iD,GAAMgf,EAAQ4N,EAASggE,GAAQM,E,CAGrC,OADAluE,EAAOxkB,UACA0rB,IAGH9G,EAAO,IAAIytE,GAAW,GAAI7B,EAAchsE,EAAO7kB,MAAOY,EAAOA,QAEnE,IAAK,IAAImB,EAAI,EAAGA,EAAIgqB,EAAQnrB,OAAQmB,IAClCkjB,EAAKia,QAAQn9B,EAAGgqB,EAAQhqB,IAE1B,OAAOkjB,CACT,CC3DyB9Y,CAAMypF,EAFrBrM,GAAc,UAAWj6D,EAAMm6D,EAAWC,GAECmH,GAE/C,OADAnH,EAAQ0M,cAActxE,GACf,CAACA,EAAW6sE,S,CAErB,IAAK,mBAAoB,CACvB,MAAMA,EACFpI,GAAc,eAAgBj6D,EAAMm6D,EAAWC,GAEnD,MAAO,CAAC3sC,GADW2sC,EAAQwM,cAAcvE,EAASzvE,IACxBxe,OAAQ,S,CAEpC,IAAK,mBAAoB,CACvB,MAAMiuF,EACFpI,GAAc,eAAgBj6D,EAAMm6D,EAAWC,GAC7ChmF,EAAO6lF,GAAc,OAAQj6D,EAAMm6D,EAAWC,GAG9C0J,EADgB1J,EAAQwM,cAAcvE,EAASzvE,IAChBixE,OAAOzvF,GAE5C,OADAgmF,EAAQ0M,cAAchD,GACf,CAACA,EAAezB,S,CAEzB,QACE,MAAMr4B,UAAU,aAAD94D,OAAc8uB,EAAKqE,GAAE,0BCxW1C,SAAS6iE,GACLlnE,EAAYm6D,EAA4BC,GAC1C,MAAO+M,EAASC,GACXnN,GAAc,WAAYj6D,EAAMm6D,EAAWC,GAE1CiN,EAAwB,YAAZF,EACZG,GAAaD,EACbE,EAA6B,UAAnBH,EACVI,EAA0B,mBAAZL,EAEdM,EACDxN,GAAc,UAAWj6D,EAAMm6D,EAAWC,GAC/C,GAAIiN,EAAW,CACb,GAAIE,GAAuB,IAAZE,EACb,MAAM,IAAIx2F,MACN,yGAGN,IAAKs2F,GAAWF,GAAyB,IAAZI,EAC3B,MAAM,IAAIx2F,MACN,mF,CAIR,GAAIu2F,EACF,MAAM,IAAIv2F,MACN,wEAEN,MAAM6gB,EAASmoE,GAAc,UAAWj6D,EAAMm6D,EAAWC,GACnDlpE,EAAMwqE,GAAW17D,EAAMm6D,EAAWC,GAClCllC,EACD+kC,GAAc,aAAcj6D,EAAMm6D,EAAWC,GACzCsN,cACHvyC,EACF8kC,GAAc,YAAaj6D,EAAMm6D,EAAWC,GAChD,IAAKuN,EAASC,GACV3N,GAAc,OAAQj6D,EAAMm6D,EAAWC,GACvCkN,IACFM,EAAWD,EACXA,OAAUj0F,GAKZ,MAAO,CACLoe,SACAZ,MACAgkC,aACAC,YACAwyC,UACAC,WACAR,iBACA/pB,eAVE4c,GAAc,iBAAkBj6D,EAAMm6D,EAAWC,GAYvD,CCrDA,SAASyN,GACL7nE,EAAYm6D,EAA4BC,GAY1C,MAAO,CACL3Z,MAZYwZ,GAAc,QAASj6D,EAAMm6D,EAAWC,GAapDvY,OAZaoY,GAAc,SAAUj6D,EAAMm6D,EAAWC,GAatDtY,cAXEmY,GAAc,gBAAiBj6D,EAAMm6D,EAAWC,GAYlDrY,aAVEkY,GAAc,eAAgBj6D,EAAMm6D,EAAWC,GAWjDpY,eATEiY,GAAc,iBAAkBj6D,EAAMm6D,EAAWC,GAUnDnY,aAREgY,GAAc,eAAgBj6D,EAAMm6D,EAAWC,GAUrD,CC1BM,MAAO0N,GAgBXn5F,WAAAA,CAAqBo5F,EAA6BC,GAA7B,KAAAD,SAAAA,EAA6B,KAAAC,WAAAA,EAChD74F,KAAK84F,OAASx6C,GAAO,GAErBt+C,KAAKgrF,UAAY,IAAI57E,IAErBme,GAAKvtB,KAAK84F,OACZ,CAhBA,MAAIr1E,GACF,OAAOzjB,KAAK84F,OAAOr1E,EACrB,CAmBA2vE,aAAAA,GACEpzF,KAAKgrF,UAAU5hF,QAAQhJ,GAASA,EAAMwB,WACtC5B,KAAKgrF,UAAU+N,QACf/4F,KAAK84F,OAAOl3F,SACd,CAKAqD,IAAAA,GACE,OAAOjF,KAAKgrF,UAAU/lF,IACxB,CAKA+zF,UAAAA,GACE,OAAOC,GAAaj5F,KAAKiF,OAAQ,QACnC,CAOA,YAAMi0F,CAAO5vE,EAAcjoB,GACzBrB,KAAKm5F,uBAAuB7vE,EAAMjoB,GAIlC,MAAM+3F,QAAc9vE,EAAK3pB,OAMzB,OAHAK,KAAKgrF,UAAU5hF,QAAQhJ,GAASA,EAAMwB,WACtC5B,KAAKgrF,UAAU+N,QAERnuE,GAAK,KACV,MAAMgvC,EAAUsP,GAAQ7nE,GAElBg4F,EAAaD,EAAMj3F,OACnBm3F,EAAe1/B,EAAQz3D,OAE7B0d,EACIw5E,IAAeC,EACf,IAAM,qDAAAv3F,OACCs3F,EAAU,8BAAAt3F,OAA6Bu3F,EAAY,KAAG,aAGjE,IAAK,IAAIh2F,EAAI,EAAGA,EAAI+1F,EAAY/1F,IAAK,CACnC,MAAMsK,EAAMwrF,EAAM91F,GACZlD,EAAQw5D,EAAQt2D,GAEtBiqB,GAAKntB,GACLJ,KAAKgrF,UAAU7qF,IAAIyN,EAAKxN,E,CAG1B,OAAOJ,KAAK84F,QAEhB,CAiBA,UAAM7M,CAAK3iE,EAAc22C,GACvBjgE,KAAKm5F,uBAAuB7vE,EAAM22C,GAElC,MAAMm5B,QAAc9vE,EAAK3pB,OAEzB,OAAOirB,GAAK,KACV,MAAMhnB,EAAmB,GAEzB,IAAK,IAAIN,EAAI,EAAGA,EAAI81F,EAAMj3F,OAAQmB,IAAK,CACrC,MAAMsK,EAAMwrF,EAAM91F,GAEZlD,EAAQJ,KAAKu5F,gBAAgB3rF,EAAKqyD,GACxCr8D,EAAOmB,KAAK3E,E,CAGd,OAAOkqB,GAAM1mB,IAEjB,CAGQ21F,eAAAA,CAAgB3rF,EAAUqyD,GAChC,MAAMr8D,EAAS5D,KAAKgrF,UAAUlrF,IAAI8N,GAElC,OAAiB,MAAVhK,EAAiBA,EAASq8D,CACnC,CAEQk5B,sBAAAA,CAAuBvrF,EAAaxN,GAC1C,GAAIwN,EAAIrM,QAAUvB,KAAK44F,SACrB,MAAM,IAAI92F,MACN,oBAAAC,OAAoB/B,KAAK44F,SAAQ,iBAAA72F,OAC9B6L,EAAIrM,QAGb,GAAInB,EAAMmB,QAAUvB,KAAK64F,WACvB,MAAM,IAAI/2F,MACN,sBAAAC,OAAsB/B,KAAK64F,WAAU,iBAAA92F,OAClC3B,EAAMmB,OAEjB,EC9GI,SAAUszF,GACZhkE,EAAYm6D,EAA4BC,EACxCC,GAAkD,IAAftgE,EAAItmB,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAGk1F,GAE5C,MAAMp5F,EACF,EAAEywB,EAAYm6D,EAA4BC,KACxC,OAAQp6D,EAAKs+D,UACX,IAAK,aACH,OAAOvkE,EAAK,ICjCpB,SAACiG,EAAYm6D,EACZC,GAAoD,IAAzBwO,EAAGn1F,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG20F,EAChC,OAAQpoE,EAAKqE,IACX,IAAK,UACL,IAAK,QACL,IAAK,MACH,MAAO,CAACukE,EAAIl8E,IACPutE,GAAc,IAAKj6D,EAAMm6D,EAAWC,GACrCH,GAAc,IAAKj6D,EAAMm6D,EAAWC,KAE1C,IAAK,OACH,MAAO,CAACwO,EAAIl1C,KACRumC,GAAc,UAAWj6D,EAAMm6D,EAAWC,KAEhD,IAAK,WACL,IAAK,MACH,MAAO,CAACwO,EAAIn+B,IACRwvB,GAAc,IAAKj6D,EAAMm6D,EAAWC,GACpCH,GAAc,IAAKj6D,EAAMm6D,EAAWC,KAC1C,IAAK,MACH,MAAO,CAACwO,EAAIv8E,IACR4tE,GAAc,IAAKj6D,EAAMm6D,EAAWC,GACpCH,GAAc,IAAKj6D,EAAMm6D,EAAWC,KAC1C,IAAK,UACL,IAAK,MACH,MAAO,CAACwO,EAAIv8C,IACR4tC,GAAc,IAAKj6D,EAAMm6D,EAAWC,GACpCH,GAAc,IAAKj6D,EAAMm6D,EAAWC,KAE1C,IAAK,WACH,MAAO,CAACwO,EAAInnC,SACRw4B,GAAc,IAAKj6D,EAAMm6D,EAAWC,GACpCH,GAAc,IAAKj6D,EAAMm6D,EAAWC,KAE1C,IAAK,WACH,MAAO,CAACwO,EAAIz8C,SACR8tC,GAAc,IAAKj6D,EAAMm6D,EAAWC,GACpCH,GAAc,IAAKj6D,EAAMm6D,EAAWC,KAE1C,IAAK,MACH,MAAO,CAACwO,EAAIh5C,IACRqqC,GAAc,IAAKj6D,EAAMm6D,EAAWC,GACpCH,GAAc,IAAKj6D,EAAMm6D,EAAWC,KAE1C,IAAK,UACH,MAAO,CAACwO,EAAI1+B,QACR+vB,GAAc,IAAKj6D,EAAMm6D,EAAWC,GACpCH,GAAc,IAAKj6D,EAAMm6D,EAAWC,KAE1C,IAAK,UACH,MAAO,CAACwO,EAAI73C,QACRkpC,GAAc,IAAKj6D,EAAMm6D,EAAWC,GACpCH,GAAc,IAAKj6D,EAAMm6D,EAAWC,KAE1C,IAAK,MACH,MAAO,CAACwO,EAAIp5C,IACRyqC,GAAc,IAAKj6D,EAAMm6D,EAAWC,GACpCH,GAAc,IAAKj6D,EAAMm6D,EAAWC,KAE1C,IAAK,oBACH,MAAO,CAACwO,EAAInyB,kBACRwjB,GAAc,IAAKj6D,EAAMm6D,EAAWC,GACpCH,GAAc,IAAKj6D,EAAMm6D,EAAWC,KAE1C,QACE,MAAMpwB,UAAU,aAAD94D,OAAc8uB,EAAKqE,GAAE,wBAE1C,CDlC0B43D,CAAqBj8D,EAAMm6D,EAAWC,IAC1D,IAAK,aACH,OAAOrgE,EAAK,IEnCpB,SAACiG,EAAYm6D,EACZC,GAAoD,IAAzBwO,EAAGn1F,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG20F,EAChC,OAAQpoE,EAAKqE,IACX,IAAK,MACL,IAAK,aACH,MAAO,CAACukE,EAAI/9C,IACRovC,GAAc,IAAKj6D,EAAMm6D,EAAWC,KAC1C,IAAK,OACH,MAAO,CAACwO,EAAIt1C,KACR2mC,GAAc,IAAKj6D,EAAMm6D,EAAWC,KAC1C,IAAK,QACH,MAAO,CAACwO,EAAIp1C,MACRymC,GAAc,IAAKj6D,EAAMm6D,EAAWC,KAC1C,IAAK,OACH,MAAO,CAACwO,EAAIt0C,KACR2lC,GAAc,IAAKj6D,EAAMm6D,EAAWC,KAC1C,IAAK,QACH,MAAO,CAACwO,EAAIp0C,MACRylC,GAAc,IAAKj6D,EAAMm6D,EAAWC,KAC1C,IAAK,OACH,MAAO,CAACwO,EAAIl0C,KACRulC,GAAc,IAAKj6D,EAAMm6D,EAAWC,KAC1C,IAAK,QACH,MAAO,CAACwO,EAAIh0C,MACRqlC,GAAc,IAAKj6D,EAAMm6D,EAAWC,GACpCH,GAAc,IAAKj6D,EAAMm6D,EAAWC,KAC1C,IAAK,QACH,MAAO,CAACwO,EAAI9zC,MACRmlC,GAAc,IAAKj6D,EAAMm6D,EAAWC,KAC1C,IAAK,OACH,MAAO,CAACwO,EAAI7zF,KACRklF,GAAc,IAAKj6D,EAAMm6D,EAAWC,KAC1C,IAAK,UACH,MAAO,CAACwO,EAAIjkE,QACRs1D,GAAc,OAAQj6D,EAAMm6D,EAAWC,GACvCH,GAAc,OAAQj6D,EAAMm6D,EAAWC,KAC7C,IAAK,MACH,MAAO,CAACwO,EAAIjpC,IACRs6B,GAAc,IAAKj6D,EAAMm6D,EAAWC,KAC1C,IAAK,OACH,MAAO,CAACwO,EAAI/oC,KACRo6B,GAAc,IAAKj6D,EAAMm6D,EAAWC,KAC1C,IAAK,MACH,MAAO,CAACwO,EAAIhmC,IACRq3B,GAAc,IAAKj6D,EAAMm6D,EAAWC,KAC1C,IAAK,MACH,MAAO,CAACwO,EAAI9lC,IACRm3B,GAAc,IAAKj6D,EAAMm6D,EAAWC,KAC1C,IAAK,MACH,MAAO,CAACwO,EAAIh0F,IACRqlF,GAAc,IAAKj6D,EAAMm6D,EAAWC,KAC1C,IAAK,QACH,MAAO,CAACwO,EAAI/jC,MACRo1B,GAAc,IAAKj6D,EAAMm6D,EAAWC,KAE1C,IAAK,QACH,MAAO,CAACwO,EAAIluF,MACRu/E,GAAc,IAAKj6D,EAAMm6D,EAAWC,KAC1C,IAAK,MACH,MAAO,CAACwO,EAAIp/E,IACRywE,GAAc,IAAKj6D,EAAMm6D,EAAWC,KAC1C,IAAK,QACH,MAAO,CAACwO,EAAI3hC,MACRgzB,GAAc,IAAKj6D,EAAMm6D,EAAWC,KAE1C,IAAK,OACH,MAAO,CAACwO,EAAI9jE,KACRm1D,GAAc,IAAKj6D,EAAMm6D,EAAWC,KAE1C,IAAK,MACH,MAAO,CAACwO,EAAItrD,IACR28C,GAAc,IAAKj6D,EAAMm6D,EAAWC,KAC1C,IAAK,aACH,MAAO,CAACwO,EAAI32B,WACRgoB,GAAc,IAAKj6D,EAAMm6D,EAAWC,KAE1C,IAAK,OACH,MAAO,CAACwO,EAAI/jE,KACRo1D,GAAc,IAAKj6D,EAAMm6D,EAAWC,KAC1C,IAAK,OACH,MAAO,CAACwO,EAAIz2B,KACR8nB,GAAc,IAAKj6D,EAAMm6D,EAAWC,KAC1C,IAAK,QACH,MAAO,CAACwO,EAAI76E,MACRksE,GAAc,IAAKj6D,EAAMm6D,EAAWC,KAE1C,IAAK,OACH,MAAO,CAACwO,EAAIz1B,KACR8mB,GAAc,IAAKj6D,EAAMm6D,EAAWC,KAC1C,IAAK,UACH,MAAO,CAACwO,EAAI1uC,QACR+/B,GAAc,IAAKj6D,EAAMm6D,EAAWC,KAC1C,IAAK,MACH,MAAO,CAACwO,EAAI10B,IACR+lB,GAAc,IAAKj6D,EAAMm6D,EAAWC,KAC1C,IAAK,OACH,MAAO,CAACwO,EAAI50B,KACRimB,GAAc,IAAKj6D,EAAMm6D,EAAWC,KAE1C,IAAK,OACH,MAAO,CAACwO,EAAIx0B,KACR6lB,GAAc,IAAKj6D,EAAMm6D,EAAWC,KAE1C,IAAK,WACH,MAAO,CAACwO,EAAIzhC,SACR8yB,GAAc,IAAKj6D,EAAMm6D,EAAWC,KAE1C,IAAK,OACH,MAAO,CAACwO,EAAI5zF,KACRilF,GAAc,IAAKj6D,EAAMm6D,EAAWC,KAE1C,IAAK,SACH,MAAO,CAACwO,EAAIn8C,OACRwtC,GAAc,IAAKj6D,EAAMm6D,EAAWC,KAE1C,IAAK,OACH,MAAO,CAACwO,EAAIn0F,KACRwlF,GAAc,IAAKj6D,EAAMm6D,EAAWC,KAE1C,IAAK,MACH,MAAO,CAACwO,EAAI3xB,IACRgjB,GAAc,IAAKj6D,EAAMm6D,EAAWC,KAC1C,IAAK,cACH,MAAO,CAACwO,EAAIrrC,YACR08B,GAAc,IAAKj6D,EAAMm6D,EAAWC,GACpCH,GAAc,eAAgBj6D,EAAMm6D,EAAWC,GAC/CH,GAAc,eAAgBj6D,EAAMm6D,EAAWC,KAErD,IAAK,QACH,MAAO,CAACwO,EAAIv2B,MACR4nB,GAAc,IAAKj6D,EAAMm6D,EAAWC,KAC1C,IAAK,QACH,MAAO,CAACwO,EAAI31B,MACRynB,GAAU16D,EAAK26D,WAAW,GAAIR,EAAWC,KAC/C,IAAK,OACH,MAAO,CAACwO,EAAIntC,KACRw+B,GAAc,IAAKj6D,EAAMm6D,EAAWC,GACpCH,GAAc,OAAQj6D,EAAMm6D,EAAWC,KAC7C,IAAK,YACH,MAAO,CAACwO,EAAIziC,UACR8zB,GAAc,IAAKj6D,EAAMm6D,EAAWC,GACpCH,GAAc,QAASj6D,EAAMm6D,EAAWC,KAC9C,IAAK,QACH,MAAO,CAACwO,EAAIp6B,MACRyrB,GAAc,IAAKj6D,EAAMm6D,EAAWC,GACpCH,GAAc,QAASj6D,EAAMm6D,EAAWC,KAC9C,IAAK,QACH,MAAO,CAACwO,EAAI/wF,MACR6iF,GAAU16D,EAAK26D,WAAW,GAAIR,EAAWC,KAC/C,QACE,MAAMpwB,UAAU,aAAD94D,OAAc8uB,EAAKqE,GAAE,wBAE1C,CFrH0B63D,CAAoBl8D,EAAMm6D,EAAWC,IACzD,IAAK,UACH,OAAO+B,GAAkBn8D,EAAMm6D,EAAWC,GAC5C,IAAK,cACH,OAAOrgE,EAAK,IHiBpB,SAACiG,EAAYm6D,EACZC,GAAoD,IAAzBwO,EAAGn1F,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG20F,EAChC,OAAQpoE,EAAKqE,IACX,IAAK,SAAU,CACb,MAAMvS,EACFmoE,GAAc,SAAUj6D,EAAMm6D,EAAWC,GACvClpE,EAAM+oE,GAAc,MAAOj6D,EAAMm6D,EAAWC,GAC5CllC,EACD+kC,GAAc,aAAcj6D,EAAMm6D,EAAWC,GACzCsN,cACH9uC,EACFqhC,GAAc,WAAYj6D,EAAMm6D,EAAWC,GAC/C,MAAO,CAACwO,EAAItqC,OACR27B,GAAc,IAAKj6D,EAAMm6D,EAAWC,GACpCH,GAAc,SAAUj6D,EAAMm6D,EAAWC,GACzCtoE,EAAQZ,EAAyBgkC,EACjC0D,G,CAEN,IAAK,SAAU,CACb,MAAM9mC,EACFmoE,GAAc,UAAWj6D,EAAMm6D,EAAWC,GACxClpE,EAAMwqE,GAAW17D,EAAMm6D,EAAWC,GAClCllC,EACD+kC,GAAc,aAAcj6D,EAAMm6D,EAAWC,GACzCsN,cACHvyC,EACF8kC,GAAc,YAAaj6D,EAAMm6D,EAAWC,GAChD,MAAO,CAACwO,EAAIzqC,OACR87B,GAAc,IAAKj6D,EAAMm6D,EAAWC,GAEpCH,GAAc,SAAUj6D,EAAMm6D,EAAWC,GACzC,CAACtoE,EAAO,GAAIA,EAAO,IAAKZ,EACxBgkC,EAA+B,CAACC,EAAU,GAAIA,EAAU,K,CAE9D,IAAK,eAAgB,CACnB,MAAM,OACJrjC,EAAM,IACNZ,EAAG,WACHgkC,EAAU,UACVC,EAAS,QACTwyC,EAAO,SACPC,EAAQ,eACRR,EAAc,eACd/pB,GACE6pB,GAA4BlnE,EAAMm6D,EAAWC,GAEjD,MAAO,CAACwO,EAAIC,MAAM1qC,OAAO,CACvBpsD,EAAGkoF,GAAc,IAAKj6D,EAAMm6D,EAAWC,GAEvCx8D,OAAQq8D,GAAc,SAAUj6D,EAAMm6D,EAAWC,GAEjDjhF,QAAS,CAAC2Y,EAAO,GAAIA,EAAO,IAC5BZ,IAAKA,EACLgkC,WAAYA,EACZC,UAAW,CAACA,EAAU,GAAIA,EAAU,IACpC2R,KAAM6gC,EACN7qB,WAAYsqB,EACZhqB,uBAAwBwqB,EACxBvqB,mB,CAIJ,IAAK,6BAA8B,CACjC,MAAM,OACJvrD,EAAM,IACNZ,EAAG,WACHgkC,EAAU,UACVC,EAAS,QACTwyC,EAAO,SACPC,EAAQ,eACRR,EAAc,eACd/pB,GACE6pB,GAA4BlnE,EAAMm6D,EAAWC,GAEjD,MAAO,CAACwO,EAAIC,MAAMjoC,gBAAgB,CAChC7uD,EAAGkoF,GAAc,IAAKj6D,EAAMm6D,EAAWC,GAEvCx8D,OAAQq8D,GAAc,SAAUj6D,EAAMm6D,EAAWC,GAEjDjhF,QAAS,CAAC2Y,EAAO,GAAIA,EAAO,IAC5BZ,IAAKA,EACLgkC,WAAYA,EACZC,UAAW,CAACA,EAAU,GAAIA,EAAU,IACpC2R,KAAM6gC,EACN7qB,WAAYsqB,EACZhqB,uBAAwBwqB,EACxBvqB,mB,CAGJ,IAAK,sBACL,IAAK,kBAAmB,CACtB,MAAM5sE,EAAQwpF,GACI,cAAej6D,EAAMm6D,EACrBC,GAEZtoE,EACFmoE,GAAc,UAAWj6D,EAAMm6D,EAAWC,GACxClpE,EAAMwqE,GAAW17D,EAAMm6D,EAAWC,GACxC,MAAO,CAACwO,EAAI5pC,gBACRi7B,GAAc,IAAKj6D,EAAMm6D,EAAWC,GAEpCH,GAAc,SAAUj6D,EAAMm6D,EAAWC,GACzC3pF,EAAO,CAACqhB,EAAO,GAAIA,EAAO,IAAKZ,G,CAErC,IAAK,wBACL,IAAK,kBAAmB,CACtB,MAAMY,EACFmoE,GAAc,UAAWj6D,EAAMm6D,EAAWC,GACxClpE,EAAMwqE,GAAW17D,EAAMm6D,EAAWC,GAClCjlC,EACF8kC,GAAc,YAAaj6D,EAAMm6D,EAAWC,GAC1CllC,EACD+kC,GAAc,aAAcj6D,EAAMm6D,EAAWC,GACzCsN,cAET,MAAO,CAACkB,EAAIhoC,gBACRq5B,GAAc,QAASj6D,EAAMm6D,EAAWC,GAExCH,GAAc,SAAUj6D,EAAMm6D,EAAWC,GACzC,CAACtoE,EAAO,GAAIA,EAAO,IAAKZ,EACxBgkC,EAA+B,CAACC,EAAU,GAAIA,EAAU,K,CAE9D,IAAK,SAAU,CACb,MAAMrjC,EACFmoE,GAAc,UAAWj6D,EAAMm6D,EAAWC,GACxClpE,EAAM+oE,GAAc,MAAOj6D,EAAMm6D,EAAWC,GAC5CllC,EACD+kC,GAAc,aAAcj6D,EAAMm6D,EAAWC,GACzCsN,cACHvyC,EACF8kC,GAAc,YAAaj6D,EAAMm6D,EAAWC,GAChD,MAAO,CAACwO,EAAIzpC,OACR86B,GAAc,IAAKj6D,EAAMm6D,EAAWC,GAEpCH,GAAc,SAAUj6D,EAAMm6D,EAAWC,GAEzC,CAACtoE,EAAO,GAAIA,EAAO,GAAIA,EAAO,IAAKZ,EACnCgkC,EACA,CAACC,EAAU,GAAIA,EAAU,GAAIA,EAAU,K,CAE7C,IAAK,UAAW,CACd,MAAMrjC,EACFmoE,GAAc,UAAWj6D,EAAMm6D,EAAWC,GACxClpE,EAAM+oE,GAAc,MAAOj6D,EAAMm6D,EAAWC,GAC5C0O,EACF7O,GAAc,aAAcj6D,EAAMm6D,EAAWC,GAEjD,MAAO,CAACwO,EAAIrvC,QACR0gC,GAAc,IAAKj6D,EAAMm6D,EAAWC,GAEpC,CAAC0O,EAAW,GAAIA,EAAW,IAAK,CAACh3E,EAAO,GAAIA,EAAO,IACnDZ,G,CAEN,IAAK,UAAW,CACd,MAAMY,EACFmoE,GAAc,UAAWj6D,EAAMm6D,EAAWC,GACxClpE,EAAM+oE,GAAc,MAAOj6D,EAAMm6D,EAAWC,GAC5C0O,EACF7O,GAAc,aAAcj6D,EAAMm6D,EAAWC,GAEjD,MAAO,CAACwO,EAAIv/B,QACR4wB,GAAc,IAAKj6D,EAAMm6D,EAAWC,GAEpC,CAAC0O,EAAW,GAAIA,EAAW,IAAK,CAACh3E,EAAO,GAAIA,EAAO,IACnDZ,G,CAEN,IAAK,oBAAqB,CACxB,MAAMY,EACFmoE,GAAc,UAAWj6D,EAAMm6D,EAAWC,GACxClpE,EAAM+oE,GAAc,MAAOj6D,EAAMm6D,EAAWC,GAC5C0O,EACF7O,GAAc,aAAcj6D,EAAMm6D,EAAWC,GAC3CzwB,EACFswB,GAAc,sBAAuBj6D,EAAMm6D,EAAWC,IAEpD,OAACrnF,EAAM,QAAE62D,GAAWg/B,EAAIn/B,kBAC1BwwB,GAAc,IAAKj6D,EAAMm6D,EAAWC,GACpC,CAAC0O,EAAW,GAAIA,EAAW,IAAK,CAACh3E,EAAO,GAAIA,EAAO,IACnDZ,EAAyBy4C,GAC7B,MAAO,CAAC52D,EAAQ62D,E,CAElB,IAAK,YAAa,CAChB,MAAM93C,EACFmoE,GAAc,UAAWj6D,EAAMm6D,EAAWC,GACxClpE,EAAM+oE,GAAc,MAAOj6D,EAAMm6D,EAAWC,GAC5C0O,EACF7O,GAAc,aAAcj6D,EAAMm6D,EAAWC,GAEjD,MAAO,CAACwO,EAAIhvC,UACRqgC,GAAc,IAAKj6D,EAAMm6D,EAAWC,GACpC,CAAC0O,EAAW,GAAIA,EAAW,GAAIA,EAAW,IAC1C,CAACh3E,EAAO,GAAIA,EAAO,GAAIA,EAAO,IAAKZ,G,CAGzC,IAAK,YAAa,CAChB,MAAMY,EACFmoE,GAAc,UAAWj6D,EAAMm6D,EAAWC,GACxClpE,EAAM+oE,GAAc,MAAOj6D,EAAMm6D,EAAWC,GAC5C0O,EACF7O,GAAc,aAAcj6D,EAAMm6D,EAAWC,GAEjD,MAAO,CAACwO,EAAIr/B,UACR0wB,GAAc,IAAKj6D,EAAMm6D,EAAWC,GACpC,CAAC0O,EAAW,GAAIA,EAAW,GAAIA,EAAW,IAC1C,CAACh3E,EAAO,GAAIA,EAAO,GAAIA,EAAO,IAAKZ,G,CAGzC,IAAK,aAAc,CACjB,MAAM/X,EACF8gF,GAAc,UAAWj6D,EAAMm6D,EAAWC,GACxClpE,EAAM+oE,GAAc,MAAOj6D,EAAMm6D,EAAWC,GAC5CjlC,EACF8kC,GAAc,YAAaj6D,EAAMm6D,EAAWC,GAG1C7jC,EAAep9C,EAAQ,GACvBq9C,EAAcr9C,EAAQ,GAGtBs9C,EAAiBtB,EAAU,GAC3BuB,EAAgBvB,EAAU,GAEhC,MAAO,CAACyzC,EAAI5nC,WACRi5B,GAAc,IAAKj6D,EAAMm6D,EAAWC,GAEpCH,GAAc,SAAUj6D,EAAMm6D,EAAWC,GACzC,CAAC7jC,EAAcC,GAActlC,EAC7B,CAACulC,EAAgBC,GAAgB,Q,CAGvC,QACE,MAAMsT,UAAU,aAAD94D,OAAc8uB,EAAKqE,GAAE,wBAE1C,CG1P0B+3D,CAAsBp8D,EAAMm6D,EAAWC,IAC3D,IAAK,WACH,OAAOrgE,EAAK,IGzCpB,SAACiG,EAAYm6D,EAA4BC,GACf,IAAzBwO,EAAGn1F,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG20F,EACL,OAAQpoE,EAAKqE,IACX,IAAK,OAAQ,CACX,MAAM5zB,EACFwpF,GAAc,QAASj6D,EAAMm6D,EAAWC,GACtC1pF,EACFupF,GAAc,QAASj6D,EAAMm6D,EAAWC,GACtC7qF,EACF0qF,GAAc,QAASj6D,EAAMm6D,EAAWC,GAC5C,MAAO,CAACwO,EAAIp4E,KAAK/f,EAAOlB,EAAOmB,G,CAEjC,IAAK,WAAY,CACf,MAAMuI,EACFghF,GAAc,QAASj6D,EAAMm6D,EAAWC,GACtCv0C,EACFo0C,GAAc,OAAQj6D,EAAMm6D,EAAWC,GACrCxiF,EAAMqiF,GAAc,MAAOj6D,EAAMm6D,EAAWC,GAClD,MAAO,CAACwO,EAAIliC,SAASztD,EAAO4sC,EAAMjuC,G,CAEpC,IAAK,cAAe,CAClB,MAAM8vD,EACFuyB,GAAc,SAAUj6D,EAAMm6D,EAAWC,GACvC9uB,EACF2uB,GAAc,aAAcj6D,EAAMm6D,EAAWC,GAC3CvtE,EACFotE,GAAc,OAAQj6D,EAAMm6D,EAAWC,GAC3C,MAAO,CAACwO,EAAIx9B,YAAY1D,EAAQ4D,EAAYz+C,G,CAE9C,IAAK,SAAU,CACb,MAAMsW,EACF82D,GAAc,UAAWj6D,EAAMm6D,EAAWC,GACxCx9C,EACFq9C,GAAc,QAASj6D,EAAMm6D,EAAWC,GACtCv9C,EACFo9C,GAAc,UAAWj6D,EAAMm6D,EAAWC,GACxCt9C,EACFm9C,GAAc,WAAYj6D,EAAMm6D,EAAWC,GACzC1pF,EACFupF,GAAc,QAASj6D,EAAMm6D,EAAWC,GAC5C,MAAO,CAACwO,EAAIlsD,OAAOvZ,EAASyZ,EAAOC,EAASC,EAAUpsC,G,CAExD,IAAK,OACH,MAAO,CAACk4F,EAAIloE,KACRu5D,GAAc,QAASj6D,EAAMm6D,EAAWC,GACxCH,GAAc,QAASj6D,EAAMm6D,EAAWC,KAE9C,IAAK,WACH,MAAO,CAACwO,EAAIh9B,SACRquB,GAAc,IAAKj6D,EAAMm6D,EAAWC,KAE1C,IAAK,uBACH,MAAO,CAACwO,EAAIl3B,qBACRuoB,GAAc,QAASj6D,EAAMm6D,EAAWC,GACxCH,GAAc,QAASj6D,EAAMm6D,EAAWC,GAExCH,GAAc,OAAQj6D,EAAMm6D,EAAWC,KAE7C,IAAK,gBACH,MAAO,CAACwO,EAAIh3B,cAERqoB,GAAc,QAASj6D,EAAMm6D,EAAWC,GACxCH,GAAc,SAAUj6D,EAAMm6D,EAAWC,GACzCH,GAAc,SAAUj6D,EAAMm6D,EAAWC,GACzCH,GAAc,QAASj6D,EAAMm6D,EAAWC,KAE9C,IAAK,QAAS,CACZ,MAAMnhF,EACFghF,GAAc,QAASj6D,EAAMm6D,EAAWC,GACtCv0C,EACFo0C,GAAc,OAAQj6D,EAAMm6D,EAAWC,GACrCpoB,EACFioB,GAAc,OAAQj6D,EAAMm6D,EAAWC,GAC3C,MAAO,CAACwO,EAAIz3B,MACRl4D,EAAO4sC,EAAMmsB,EACbioB,GAAc,QAASj6D,EAAMm6D,EAAWC,I,CAG9C,IAAK,kBAAmB,CACtB,MAAM3pF,EACFwpF,GAAc,QAASj6D,EAAMm6D,EAAWC,GACtCx+B,EACFq+B,GAAc,OAAQj6D,EAAMm6D,EAAWC,GACrCtqB,EACFmqB,GAAc,SAAUj6D,EAAMm6D,EAAWC,GACvCvtE,EACFotE,GAAc,OAAQj6D,EAAMm6D,EAAWC,GAC3C,MAAO,CAACwO,EAAIhxB,gBACRnnE,EAAOmrD,EAAMkU,EACbmqB,GAAc,QAASj6D,EAAMm6D,EAAWC,GAExCvtE,G,CAEN,IAAK,QACH,MAAO,CAAC+7E,EAAIhnC,MACRq4B,GAAc,QAASj6D,EAAMm6D,EAAWC,GACxCH,GAAc,QAASj6D,EAAMm6D,EAAWC,KAE9C,IAAK,YACH,MAAO,CAACwO,EAAIj8C,UACRstC,GAAc,IAAKj6D,EAAMm6D,EAAWC,KAE1C,QACE,MAAMpwB,UAAU,aAAD94D,OAAc8uB,EAAKqE,GAAE,wBAE1C,CHhE0Bg4D,CAAmBr8D,EAAMm6D,EAAWC,IACxD,IAAK,UACH,OFpBsC70D,eAC9CvF,EAAYm6D,EACZC,EAA2BC,GACO,IAAlCuO,EAAGn1F,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG20F,EACR,OAAQpoE,EAAKqE,IACX,IAAK,sBAAuB,CAC1B,MAAM,MACJo8C,EAAK,OACLoB,EAAM,cACNC,EAAa,aACbC,EAAY,eACZC,EAAc,aACdC,GACE4lB,GAAU7nE,EAAMm6D,EAAWC,GAEzBrnF,QAAe61F,EAAI9hE,MAAMi/C,gCAC3BtF,EAAmBoB,EAAoBC,EAAeC,EACtDC,EAAgBC,GAEpB,MAAO,CAAClvE,EAAO4wE,gBAAiB5wE,EAAO6wE,e,CAEzC,IAAK,sBAAuB,CAC1B,MAAM,MAACnD,EAAK,OAAEoB,EAAM,cAAEC,EAAa,aAAEC,EAAY,eAAEC,GAC/C6lB,GAAU7nE,EAAMm6D,EAAWC,GAEzBlX,EACF+W,GAAc,qBAAsBj6D,EAAMm6D,EAAWC,GAGnDrnF,QAAe61F,EAAI9hE,MAAMo/C,6BAC3BzF,EAAmBoB,EAAoBC,EAAeC,EACtDC,EAAgBkB,GAEpB,MAAO,CAACnwE,EAAO4wE,gBAAiB5wE,EAAOoxE,a,CAEzC,IAAK,sBACL,IAAK,sBAAuB,CAC1B,MAAM,MAAC1D,EAAK,OAAEoB,EAAM,cAAEC,EAAa,aAAEC,EAAY,eAAEC,GAC/C6lB,GAAU7nE,EAAMm6D,EAAWC,GAE/B,MAAO,OAAOwO,EAAI9hE,MAAM2+C,uBACpBhF,EAAmBoB,EAAoBC,EAAeC,EACtDC,G,CAEN,IAAK,QAAS,CACZ,MAAM1gB,EAAYsnC,EAAIl1E,KACjBumE,GAAc,YAAaj6D,EAAMm6D,EAAWC,GAC7C,QACErnF,EAAS,OAAO61F,EAAIhwB,WAAWtX,IAErC,OADAA,EAAUvwD,UACHgC,C,CAET,IAAK,WACH,OAAO61F,EAAIh1B,eACPqmB,GAAc,IAAKj6D,EAAMm6D,EAAWC,GACpCH,GAAc,IAAKj6D,EAAMm6D,EAAWC,IAE1C,QACE,MAAMpwB,UAAU,aAAD94D,OAAc8uB,EAAKqE,GAAE,wBAE1C,CExCmBi4D,CAAkBt8D,EAAMm6D,EAAWC,GAC5C,IAAK,aACH,OAAOrgE,EAAK,II7CpB,SAACiG,EAAYm6D,EAA4BC,GAE1B,IADdwO,EAAGn1F,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG20F,EAED,OAAQpoE,EAAKqE,IACX,IAAK,aAAc,CACjB,MAAMukC,EACFqxB,GAAc,iBAAkBj6D,EAAMm6D,EAAWC,GAE/C5pF,EACFypF,GAAc,SAAUj6D,EAAMm6D,EAAWC,GAC7C,MAAO,CAACwO,EAAIx/B,WAAWR,EAAgBp4D,G,CAEzC,IAAK,SAAU,CACb,MAAMuB,EAAIkoF,GAAc,IAAKj6D,EAAMm6D,EAAWC,GACxClkE,EAAI+jE,GAAc,IAAKj6D,EAAMm6D,EAAWC,GACxC1iB,EACFuiB,GAAc,SAAUj6D,EAAMm6D,EAAWC,GACvCrnF,EAAS61F,EAAIpxB,KAAKzlE,EAAGmkB,EAAGwhD,GAC9B,MAAO,CAAC3kE,EAAOvC,OAAQuC,EAAOowB,Q,CAEhC,IAAK,aAAc,CACjB,MAAMylC,EACFqxB,GAAc,iBAAkBj6D,EAAMm6D,EAAWC,GAE/C5pF,EACFypF,GAAc,SAAUj6D,EAAMm6D,EAAWC,GAC7C,MAAO,CAACwO,EAAIrwB,WAAW3P,EAAgBp4D,G,CAEzC,IAAK,SAAU,CACb,MAAMuB,EAAIkoF,GAAc,IAAKj6D,EAAMm6D,EAAWC,GACxCrnF,EAAS61F,EAAI9wB,OAAO/lE,GAC1B,MAAO,CAACgB,EAAOvC,OAAQuC,EAAOowB,Q,CAEhC,IAAK,WAAY,CACf,MAAMpxB,EAAIkoF,GAAc,IAAKj6D,EAAMm6D,EAAWC,GACxC3jF,EACFwjF,GAAc,OAAQj6D,EAAMm6D,EAAWC,GACrCrnF,EAAS61F,EAAI9wB,OAAO/lE,EAAG0E,GAC7B,MAAO,CAAC1D,EAAOvC,OAAQuC,EAAOowB,Q,CAEhC,QACE,MAAM6mC,UAAU,aAAD94D,OAAc8uB,EAAKqE,GAAE,wBAE1C,CJEsBk4D,CAAqBv8D,EAAMm6D,EAAWC,IAC1D,IAAK,QACH,OAAOrgE,EAAK,IK/CpB,SAACiG,EAAYm6D,EACZC,GAAoD,IAAzBwO,EAAGn1F,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG20F,EAChC,OAAQpoE,EAAKqE,IACX,IAAK,iBAAkB,CACrB,MAAMmiD,EACFyT,GAAc,SAAUj6D,EAAMm6D,EAAWC,GACvChmF,EACF6lF,GAAc,OAAQj6D,EAAMm6D,EAAWC,GACrC3T,EACFwT,GAAc,eAAgBj6D,EAAMm6D,EAAWC,GAE7C1T,EACFuT,GAAc,mBAAoBj6D,EAAMm6D,EAAWC,GAEvD,MAAO,CAACwO,EAAI9hE,MAAMw/C,eACdE,EAA+B,CAACpyE,EAAK,GAAIA,EAAK,IAAKqyE,EACnDC,G,CAEN,IAAK,wBAAyB,CAC5B,MAAMF,EACFyT,GAAc,SAAUj6D,EAAMm6D,EAAWC,GACvChmF,EACF6lF,GAAc,OAAQj6D,EAAMm6D,EAAWC,GACrC3T,EACFwT,GAAc,eAAgBj6D,EAAMm6D,EAAWC,GAE7C1T,EACFuT,GAAc,mBAAoBj6D,EAAMm6D,EAAWC,GAEvD,MAAO,CAACwO,EAAI9hE,MAAM+/C,sBACdL,EAA+B,CAACpyE,EAAK,GAAIA,EAAK,IAAKqyE,EACnDC,G,CAEN,IAAK,gBAAiB,CACpB,MAAM5/C,EACFmzD,GAAc,QAASj6D,EAAMm6D,EAAWC,GACtC3Z,EACFwZ,GAAc,QAASj6D,EAAMm6D,EAAWC,GACtC1Z,EACFuZ,GAAc,SAAUj6D,EAAMm6D,EAAWC,GACvCzZ,EACFsZ,GAAc,WAAYj6D,EAAMm6D,EAAWC,GACzChgD,EACF6/C,GAAc,SAAUj6D,EAAMm6D,EAAWC,GACvCxZ,EACFqZ,GAAc,qBAAsBj6D,EAAMm6D,EAAWC,GAEzD,MAAO,CAACwO,EAAI9hE,MAAMy5C,cACdz5C,EAAmB25C,EAAmBC,EACtCC,EAA8BvmC,EAC9BwmC,G,CAEN,IAAK,6BAA8B,CACjC,MAAM4F,EACFyT,GAAc,SAAUj6D,EAAMm6D,EAAWC,GACvCtR,EACFmR,GAAc,aAAcj6D,EAAMm6D,EAAWC,GAC3Cl7B,EACF+6B,GAAc,cAAej6D,EAAMm6D,EAAWC,GAE5C1Y,EACFuY,GAAc,YAAaj6D,EAAMm6D,EAAWC,GAC1CrR,EACFkR,GAAc,gBAAiBj6D,EAAMm6D,EAAWC,GAE9CpR,EACFiR,GAAc,WAAYj6D,EAAMm6D,EAAWC,GAC/C,MAAO,CAACwO,EAAI9hE,MAAM8hD,UACdpC,EACAsC,EACAC,EAAc/rE,cACdgsE,EAAShsE,cACT0kE,EACAxiB,G,CAEN,QACE,MAAM8K,UAAU,aAAD94D,OAAc8uB,EAAKqE,GAAE,wBAE1C,CL/B0ByC,CAAgB9G,EAAMm6D,EAAWC,IACrD,IAAK,QACH,OAAOrgE,EAAK,IMjDpB,SAACiG,EAAYm6D,EACZC,GAAoD,IAAzBwO,EAAGn1F,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG20F,EAChC,OAAQpoE,EAAKqE,IACX,IAAK,QACH,OAAO81D,EAAUn6D,EAAKxiB,MAExB,IAAK,yBACH,MAAM2iF,EACFlG,GAAc,UAAWj6D,EAAMm6D,EAAWC,GAC9C,MAAO,CAACM,GAAU16D,EAAKxiB,KAAM28E,EAAWC,IAAY+F,GACtD,IAAK,cACH,MAAO,CAACzF,GAAU16D,EAAKxiB,KAAM28E,EAAWC,IAC1C,IAAK,WACL,IAAK,eACL,IAAK,0BAOL,IAAK,WAGH,MAAO,CAACwB,GADH3B,GAAc,IAAKj6D,EAAMm6D,EAAWC,KAL3C,IAAK,YACH,OAAQH,GAAc,IAAKj6D,EAAMm6D,EAAWC,GACvCzjF,IAAK2G,GAAcs+E,GAAYt+E,IAKtC,IAAK,QACH,MAAO,CAACsrF,EAAIzxB,SACP8iB,GAAc,IAAKj6D,EAAMm6D,EAAWC,GAAoB3pF,MACzD,UACN,IAAK,SACH,OAAQwpF,GAAc,IAAKj6D,EAAMm6D,EAAWC,GACvCzjF,IAAK2G,GAAcsrF,EAAIzxB,SAAS75D,EAAE7M,QACzC,IAAK,OACH,MAAO,CAACm4F,EAAIn7C,OACPwsC,GAAc,IAAKj6D,EAAMm6D,EAAWC,GAAoBhmF,KACzD,UACN,IAAK,OACH,MAAO,CAACw0F,EAAIn7C,OACPwsC,GAAc,IAAKj6D,EAAMm6D,EAAWC,GAAoB1jF,KACzD,UACN,IAAK,OACH,MAAO,CAACkyF,EAAIn7C,OAAO,IACrB,IAAK,QACH,MAAMx9B,EAAQgqE,GAAc,IAAKj6D,EAAMm6D,EAAWC,GAC5CtrF,EACFmrF,GAAc,OAAQj6D,EAAMm6D,EAAWC,GACrC1gE,EACFugE,GAAc,UAAWj6D,EAAMm6D,EAAWC,GACxC2O,EACF9O,GAAc,YAAaj6D,EAAMm6D,EAAWC,GAChD1+E,QAAQC,KACJ,kGAEJD,QAAQ8N,IAAIkQ,GACZ,IAAK,IAAIjnB,EAAI,EAAGA,EAAI3D,EAAKwC,OAAQmB,IAC/BiJ,QAAQ8N,IAAIzV,MAAMi1F,UAAUzyF,MAAMuC,KAAKhK,EAAK2D,GAAGyc,YAC9B3Y,MAAM,EAAGwyF,IAE5B,MAAO,CAAC94E,GAEV,QACE,MAAM+5C,UAAU,aAAD94D,OAAc8uB,EAAKqE,GAAE,wBAE1C,CNd0Bm4D,CAAgBx8D,EAAMm6D,EAAWC,IACrD,IAAK,UACH,OAAOrgE,EAAK,IOnDpB,SAACiG,EAAYm6D,EACZC,GAAoD,IAAzBwO,EAAGn1F,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG20F,EAChC,OAAQpoE,EAAKqE,IACX,IAAK,QACH,MAAO,CAACukE,EAAI1nC,MACR+4B,GAAc,IAAKj6D,EAAMm6D,EAAWC,GACpCH,GAAc,IAAKj6D,EAAMm6D,EAAWC,KAE1C,IAAK,WACH,MAAO,CAACwO,EAAIl9B,SACRuuB,GAAc,IAAKj6D,EAAMm6D,EAAWC,GACpCH,GAAc,IAAKj6D,EAAMm6D,EAAWC,KAE1C,IAAK,UACH,MAAO,CAACwO,EAAIjjC,QACRs0B,GAAc,IAAKj6D,EAAMm6D,EAAWC,GACpCH,GAAc,IAAKj6D,EAAMm6D,EAAWC,KAE1C,IAAK,eACH,MAAO,CAACwO,EAAI/iC,aACRo0B,GAAc,IAAKj6D,EAAMm6D,EAAWC,GACpCH,GAAc,IAAKj6D,EAAMm6D,EAAWC,KAE1C,IAAK,OACH,MAAO,CAACwO,EAAItiC,KACR2zB,GAAc,IAAKj6D,EAAMm6D,EAAWC,GACpCH,GAAc,IAAKj6D,EAAMm6D,EAAWC,KAE1C,IAAK,YACH,MAAO,CAACwO,EAAIpiC,UACRyzB,GAAc,IAAKj6D,EAAMm6D,EAAWC,GACpCH,GAAc,IAAKj6D,EAAMm6D,EAAWC,KAE1C,IAAK,aACH,MAAO,CAACwO,EAAI3gC,WACRgyB,GAAc,IAAKj6D,EAAMm6D,EAAWC,GACpCH,GAAc,IAAKj6D,EAAMm6D,EAAWC,KAE1C,IAAK,aACH,MAAO,CAACwO,EAAIzgC,WACR8xB,GAAc,IAAKj6D,EAAMm6D,EAAWC,KAE1C,IAAK,YACH,MAAO,CAACwO,EAAIvgC,UACR4xB,GAAc,IAAKj6D,EAAMm6D,EAAWC,GACpCH,GAAc,IAAKj6D,EAAMm6D,EAAWC,KAE1C,IAAK,SACL,IAAK,WACH,MAAO,CAACwO,EAAIxnC,MACR64B,GAAc,YAAaj6D,EAAMm6D,EAAWC,GAC5CH,GAAc,IAAKj6D,EAAMm6D,EAAWC,GACpCH,GAAc,IAAKj6D,EAAMm6D,EAAWC,KAE1C,QACE,MAAMpwB,UAAU,aAAD94D,OAAc8uB,EAAKqE,GAAE,wBAE1C,CPN0Bq4D,CAAkB18D,EAAMm6D,EAAWC,IACvD,IAAK,WACH,OAAOrgE,EAAK,IQrDpB,SAACiG,EAAYm6D,EACZC,GAAoD,IAAzBwO,EAAGn1F,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG20F,EAChC,OAAQpoE,EAAKqE,IACX,IAAK,cACL,IAAK,gBACL,IAAK,SACH,MAAO,CAACukE,EAAIxsD,OACR69C,GAAc,IAAKj6D,EAAMm6D,EAAWC,GACpCH,GAAc,IAAKj6D,EAAMm6D,EAAWC,GACpCH,GAAc,aAAcj6D,EAAMm6D,EAAWC,GAC7CH,GAAc,aAAcj6D,EAAMm6D,EAAWC,KAGnD,IAAK,SACH,MAAO,CAACwO,EAAInmC,OACRw3B,GAAc,WAAYj6D,EAAMm6D,EAAWC,MACxCH,GAAc,UAAWj6D,EAAMm6D,EAAWC,KAGnD,IAAK,YACH,MAAO,CAACwO,EAAInrD,UACRw8C,GAAc,IAAKj6D,EAAMm6D,EAAWC,GACpCH,GAAc,OAAQj6D,EAAMm6D,EAAWC,KAE7C,IAAK,eACH,MAAO+M,EAASC,GACXnN,GAAc,WAAYj6D,EAAMm6D,EAAWC,GAE1CiN,EAAwB,YAAZF,EACZI,EAA6B,UAAnBH,EAEVK,EACDxN,GAAc,UAAWj6D,EAAMm6D,EAAWC,GACzC/c,EACF4c,GAAc,iBAAkBj6D,EAAMm6D,EAAWC,GAGrD,GAAIiN,EAAW,CACb,GAAIE,GAAuB,IAAZE,EACb,MAAM,IAAIx2F,MACN,sFAGN,IAAKs2F,GAAuB,IAAZE,EACd,MAAM,IAAIx2F,MACN,gE,CAGR,MAAO02F,EAASC,GACZ3N,GAAc,OAAQj6D,EAAMm6D,EAAWC,GAC3C,MAAO,CAACwO,EAAIC,MAAMzsD,OAAO,CACvBzpC,EAAGsnF,GAAc,IAAKj6D,EAAMm6D,EAAWC,GACvCxnF,EAAGqnF,GAAc,IAAKj6D,EAAMm6D,EAAWC,GACvC99C,WAAY29C,GAAc,aAAcj6D,EAAMm6D,EAAWC,GAEzD79C,WAAY09C,GAAc,aAAcj6D,EAAMm6D,EAAWC,GAEzDtzB,KAAM6gC,EACN7qB,WAAYsqB,EACZhqB,uBAAwBwqB,EACxBvqB,oBAGJ,QACE,MAAMrT,UAAU,aAAD94D,OAAc8uB,EAAKqE,GAAE,wBAE1C,CRb0Bs4D,CAAmB38D,EAAMm6D,EAAWC,IACxD,IAAK,gBACH,OAAOrgE,EACH,ISxDZ,SAACiG,EAAYm6D,EACZC,GAAoD,IAAzBwO,EAAGn1F,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG20F,EAChC,OAAQpoE,EAAKqE,IACX,IAAK,gBACH,MAAO,CAACukE,EAAIpkC,cACRy1B,GAAc,IAAKj6D,EAAMm6D,EAAWC,GACpCH,GAAc,OAAQj6D,EAAMm6D,EAAWC,GACvCH,GAAc,WAAYj6D,EAAMm6D,EAAWC,KACjD,IAAK,iBACL,IAAK,mBASL,IAAK,mBACH,MAAO,CAACwO,EAAIltC,UACRu+B,GAAc,IAAKj6D,EAAMm6D,EAAWC,GACpCH,GAAc,OAAQj6D,EAAMm6D,EAAWC,GACvCH,GAAc,WAAYj6D,EAAMm6D,EAAWC,GAC3CH,GAAc,SAAUj6D,EAAMm6D,EAAWC,GACzCH,GAAc,QAASj6D,EAAMm6D,EAAWC,GACxCH,GAAc,UAAWj6D,EAAMm6D,EAAWC,KAEhD,IAAK,MACH,MAAO,CAACwO,EAAIjiC,2BACRszB,GAAc,IAAKj6D,EAAMm6D,EAAWC,GAEpCH,GAAc,SAAUj6D,EAAMm6D,EAAWC,GACzCH,GAAc,OAAQj6D,EAAMm6D,EAAWC,GACvCH,GAAc,QAASj6D,EAAMm6D,EAAWC,GACxCH,GAAc,OAAQj6D,EAAMm6D,EAAWC,KAE7C,IAAK,UACH,MAAO,CAACwO,EAAI9gC,QACRmyB,GAAc,IAAKj6D,EAAMm6D,EAAWC,KAE1C,IAAK,aACH,MAAO,CAACwO,EAAIphC,WACRyyB,GAAc,IAAKj6D,EAAMm6D,EAAWC,KAE1C,IAAK,gBACH,MAAO,CAACwO,EAAItuB,cACR2f,GAAc,gBAAiBj6D,EAAMm6D,EAAWC,GAEhDH,GAAc,cAAej6D,EAAMm6D,EAAWC,GAC9CH,GAAc,eAAgBj6D,EAAMm6D,EAAWC,GAE/CH,GAAc,eAAgBj6D,EAAMm6D,EAAWC,KAGrD,QACE,MAAMpwB,UAAU,aAAD94D,OAAc8uB,EAAKqE,GAAE,wBAE1C,CTDkBu4D,CAAwB58D,EAAMm6D,EAAWC,IACrD,IAAK,YACH,OAAOrgE,EAAK,IU1DpB,SAACiG,EAAYm6D,EACZC,GAAoD,IAAzBwO,EAAGn1F,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG20F,EAChC,OAAQpoE,EAAKqE,IACX,IAAK,MAAO,CACV,MAAM5tB,EACFwjF,GAAc,OAAQj6D,EAAMm6D,EAAWC,GACrCrmC,EACFkmC,GAAc,WAAYj6D,EAAMm6D,EAAWC,GAC/C,MAAO,CAACwO,EAAI52F,IACRioF,GAAc,IAAKj6D,EAAMm6D,EAAWC,GAAoB3jF,EACxDs9C,G,CAEN,IAAK,OAAQ,CACX,MAAMt9C,EACFwjF,GAAc,OAAQj6D,EAAMm6D,EAAWC,GACrCrmC,EACFkmC,GAAc,WAAYj6D,EAAMm6D,EAAWC,GAC/C,MAAO,CAACwO,EAAIhtC,KACRq+B,GAAc,IAAKj6D,EAAMm6D,EAAWC,GAAoB3jF,EACxDs9C,G,CAEN,IAAK,MAAO,CACV,MAAMt9C,EACFwjF,GAAc,OAAQj6D,EAAMm6D,EAAWC,GACrCrmC,EACFkmC,GAAc,WAAYj6D,EAAMm6D,EAAWC,GAC/C,MAAO,CAACwO,EAAI92F,IACRmoF,GAAc,IAAKj6D,EAAMm6D,EAAWC,GAAoB3jF,EACxDs9C,G,CAEN,IAAK,MAAO,CACV,MAAMt9C,EACFwjF,GAAc,OAAQj6D,EAAMm6D,EAAWC,GACrCrmC,EACFkmC,GAAc,WAAYj6D,EAAMm6D,EAAWC,GAC/C,MAAO,CAACwO,EAAIr2F,IACR0nF,GAAc,IAAKj6D,EAAMm6D,EAAWC,GAAoB3jF,EACxDs9C,G,CAEN,IAAK,MAAO,CACV,MAAMt9C,EACFwjF,GAAc,OAAQj6D,EAAMm6D,EAAWC,GACrCrmC,EACFkmC,GAAc,WAAYj6D,EAAMm6D,EAAWC,GAC/C,MAAO,CAACwO,EAAIh5E,IACRqqE,GAAc,IAAKj6D,EAAMm6D,EAAWC,GAAoB3jF,EACxDs9C,G,CAEN,IAAK,MAAO,CACV,MAAMt9C,EACFwjF,GAAc,OAAQj6D,EAAMm6D,EAAWC,GACrCrmC,EACFkmC,GAAc,WAAYj6D,EAAMm6D,EAAWC,GAC/C,MAAO,CAACwO,EAAI50C,IACRimC,GAAc,IAAKj6D,EAAMm6D,EAAWC,GAAoB3jF,EACxDs9C,G,CAEN,IAAK,SAAU,CACb,MAAMt9C,EACFwjF,GAAc,OAAQj6D,EAAMm6D,EAAWC,GAC3C,MAAO,CAACwO,EAAI10C,OACR+lC,GAAc,IAAKj6D,EAAMm6D,EAAWC,GAAoB3jF,G,CAE9D,IAAK,SAAU,CACb,MAAMA,EACFwjF,GAAc,OAAQj6D,EAAMm6D,EAAWC,GAC3C,MAAO,CAACwO,EAAIx0C,OACR6lC,GAAc,IAAKj6D,EAAMm6D,EAAWC,GAAoB3jF,G,CAE9D,IAAK,OAAQ,CACX,MAAMA,EACFwjF,GAAc,OAAQj6D,EAAMm6D,EAAWC,GACrCrmC,EACFkmC,GAAc,WAAYj6D,EAAMm6D,EAAWC,GAC/C,MAAO,CAACwO,EAAIntC,KACRw+B,GAAc,IAAKj6D,EAAMm6D,EAAWC,GAAoB3jF,EACxDs9C,G,CAEN,IAAK,UAAW,CACd,MAAMt9C,EACFwjF,GAAc,OAAQj6D,EAAMm6D,EAAWC,GACrCn6B,EACFg6B,GAAc,YAAaj6D,EAAMm6D,EAAWC,GAC1Cv8C,EACFo8C,GAAc,UAAWj6D,EAAMm6D,EAAWC,GAC9C,MAAO,CAACwO,EAAI7oC,QACRk6B,GAAc,IAAKj6D,EAAMm6D,EAAWC,GAAoB3jF,EACxDwpD,EAAWpiB,G,CAEjB,IAAK,SAAU,CACb,MAAMpnC,EACFwjF,GAAc,OAAQj6D,EAAMm6D,EAAWC,GACrCn6B,EACFg6B,GAAc,YAAaj6D,EAAMm6D,EAAWC,GAC1Cv8C,EACFo8C,GAAc,UAAWj6D,EAAMm6D,EAAWC,GAC9C,MAAO,CAACwO,EAAI1oC,OACR+5B,GAAc,IAAKj6D,EAAMm6D,EAAWC,GAAoB3jF,EACxDwpD,EAAWpiB,G,CAEjB,IAAK,WACH,MAAM9rC,EAAIkoF,GAAc,IAAKj6D,EAAMm6D,EAAWC,GACxCtwD,EACFmwD,GAAc,UAAWj6D,EAAMm6D,EAAWC,GACxChmF,EACF6lF,GAAc,OAAQj6D,EAAMm6D,EAAWC,GAE3C,MAAO,CAACwO,EAAIlsC,SAAS3qD,EAAG+3B,EAAS11B,IACnC,IAAK,gBAAiB,CACpB,MAAMrC,EAAIkoF,GAAc,IAAKj6D,EAAMm6D,EAAWC,GAExCtwD,EACFmwD,GAAc,UAAWj6D,EAAMm6D,EAAWC,GAExChmF,EACF6lF,GAAc,OAAQj6D,EAAMm6D,EAAWC,GAErC95B,EACF25B,GAAc,eAAgBj6D,EAAMm6D,EAAWC,GAGnD,MAAO,CAACwO,EAAIxoC,cAAcruD,EAAG+3B,EAAS11B,EAAMksD,G,CAE9C,QACE,MAAM0J,UAAU,aAAD94D,OAAc8uB,EAAKqE,GAAE,wBAE1C,CVpE0B+nD,CAAoBpsD,EAAMm6D,EAAWC,IACzD,IAAK,aACH,OAAOrgE,EAAK,IW5DpB,SAACiG,EAAYm6D,EACZC,GAAoD,IAAzBwO,EAAGn1F,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG20F,EAChC,OAAQpoE,EAAKqE,IACX,IAAK,WACL,IAAK,SAAU,CACb,MAAMnvB,EAAI+kF,GAAc,IAAKj6D,EAAMm6D,EAAWC,GACxC3jF,EACFwjF,GAAc,OAAQj6D,EAAMm6D,EAAWC,GAC3C,IAAIxrE,EACAqrE,GAAc,UAAWj6D,EAAMm6D,EAAWC,GAE9C,OADAxrE,EAASA,EAAOrY,MAAM,EAAGrB,GAClB,CAAC0zF,EAAI13F,OAAO0d,EAAQnY,G,CAE7B,IAAK,SAAU,CACb,MAAMwZ,EAAQgqE,GAAc,IAAKj6D,EAAMm6D,EAAWC,GAC5Cj3D,EACF82D,GAAc,UAAWj6D,EAAMm6D,EAAWC,GAC9C,MAAO,CAACwO,EAAIpjC,OAAOv1C,EAAO24E,EAAIl1E,KAAKyP,EAAS,SAAU,G,CAExD,IAAK,WAAY,CACf,MAAM1sB,EACFwjF,GAAc,OAAQj6D,EAAMm6D,EAAWC,GACrC10B,EACFu0B,GAAc,YAAaj6D,EAAMm6D,EAAWC,GAC1CnqE,EAAQgqE,GAAc,IAAKj6D,EAAMm6D,EAAWC,GAC5Cj3D,EACF82D,GAAc,UAAWj6D,EAAMm6D,EAAWC,GAC9C,MAAO,CAACwO,EAAIpjC,OACRv1C,EAAO24E,EAAIl1E,KAAKyP,EAAS,SAAU1sB,EAAMivD,G,CAE/C,IAAK,UAAW,CACd,MAAM9mB,EACFq7C,GAAc,OAAQj6D,EAAMm6D,EAAWC,GACrC3jF,EAAO,GACb,IAAK,IAAIhE,EAAI,EAAGA,EAAImsC,EAAKttC,OAAQmB,IAC3BmsC,EAAKnsC,IACPgE,EAAKvC,KAAKzB,GAGd,MAAMwd,EAAQgqE,GAAc,IAAKj6D,EAAMm6D,EAAWC,GAClD,MAAO,CAACwO,EAAI/qD,QAAQ5tB,EAAOxZ,G,CAE7B,IAAK,YAAa,CAChB,MAAMA,EACFwjF,GAAc,OAAQj6D,EAAMm6D,EAAWC,GACrCnqE,EAAQgqE,GAAc,IAAKj6D,EAAMm6D,EAAWC,GAClD,MAAO,CAACwO,EAAI/qD,QAAQ5tB,EAAOxZ,G,CAE7B,IAAK,QAAS,CAEZ,MAAM8sC,EAAQ02C,GAAc,QAASj6D,EAAMm6D,EAAWC,GAEhDhmF,EAAO6lF,GAAc,OAAQj6D,EAAMm6D,EAAWC,GACpD,MAAO,CAACwO,EAAIryF,MACR0jF,GAAc,IAAKj6D,EAAMm6D,EAAWC,GAAoB72C,EACxDnvC,G,CAEN,IAAK,eAAgB,CACnB,MAAMmvC,EACF02C,GAAc,QAASj6D,EAAMm6D,EAAWC,GACtC9sE,EACF2sE,GAAc,MAAOj6D,EAAMm6D,EAAWC,GACpCjhF,EACF8gF,GAAc,UAAWj6D,EAAMm6D,EAAWC,GACxC71C,EACF01C,GAAc,YAAaj6D,EAAMm6D,EAAWC,GAC1C51C,EACFy1C,GAAc,UAAWj6D,EAAMm6D,EAAWC,GACxC31C,EACFw1C,GAAc,eAAgBj6D,EAAMm6D,EAAWC,GAC7C5zC,EACFyzC,GAAc,cAAej6D,EAAMm6D,EAAWC,GAC5C3zC,EACFwzC,GAAc,iBAAkBj6D,EAAMm6D,EAAWC,GAE/C7kE,EAAS0kE,GAAc,IAAKj6D,EAAMm6D,EAAWC,GAEnD,MAAO,CAACwO,EAAI7xB,aACRxhD,EAAQguB,EAAOj2B,EAAKnU,EAASorC,EAAWC,EAASC,EACjD+B,EAAaC,G,CAEnB,IAAK,OACH,OAAO1sB,GAAK,KACV,MAAMtjB,EACFwjF,GAAc,OAAQj6D,EAAMm6D,EAAWC,GACrC39D,EACFw9D,GAAc,UAAWj6D,EAAMm6D,EAAWC,GAGxC3pF,EAAQgsB,EAAQ,GAAGhsB,MACnBw4F,EAAgBL,EAAIjyB,QAAQl6C,EAAQ,IAAIhsB,MACxCy4F,EAASzsE,EAAQ9lB,IAAI4e,IACzB,MAAM4zE,EAAYn6E,GAAiBuG,EAAO9kB,MAAOA,GACjD,IAAK04F,IACAn6E,GACG45E,EAAIjyB,QAAQphD,GAAQ9kB,MAAOw4F,GACjC,MAAM,IAAIh4F,MAAM,0CAElB,OAAOk4F,EAAY5zE,EAASqzE,EAAIvvC,QAAQ9jC,EAAQ9kB,KAElD,MAAO,CAACm4F,EAAInvE,MAAMyvE,EAAQzyF,MAG9B,IAAK,SAAU,CACb,MAAMA,EACFwjF,GAAc,OAAQj6D,EAAMm6D,EAAWC,GACrC7kE,EACF0kE,GAAc,SAAUj6D,EAAMm6D,EAAWC,GAC7C,OAAOwO,EAAIvwB,QAAQ9iD,EAAQ9e,E,CAE7B,IAAK,OAAQ,CACX,MAAM4mD,EACF48B,GAAc,OAAQj6D,EAAMm6D,EAAWC,GAC3C,MAAO,CAACwO,EAAI7jC,KACRk1B,GAAc,IAAKj6D,EAAMm6D,EAAWC,GAAoB/8B,G,CAE9D,IAAK,QACL,IAAK,SAAU,CACb,MAAM5mD,EACFwjF,GAAc,OAAQj6D,EAAMm6D,EAAWC,GACrCvkB,EACFokB,GAAc,kBAAmBj6D,EAAMm6D,EAAWC,GAGhD7kE,EAAS0kE,GAAc,IAAKj6D,EAAMm6D,EAAWC,GAEnD,OAAOwO,EAAI/rF,MAAM0Y,EAAQsgD,EAAiBp/D,E,CAE5C,IAAK,YAAa,CAChB,MAAM0sB,EACF82D,GAAc,UAAWj6D,EAAMm6D,EAAWC,GACxC5pF,EACFypF,GAAc,SAAUj6D,EAAMm6D,EAAWC,GACvC3pF,EACFwpF,GAAc,QAASj6D,EAAMm6D,EAAWC,GAC5C,MAAO,CAACwO,EAAI3uB,UAAU92C,EAAS3yB,EAAQC,G,CAEzC,IAAK,WAAY,CACf,MAAMsB,EAAIkoF,GAAc,IAAKj6D,EAAMm6D,EAAWC,GACxCj3D,EACF82D,GAAc,UAAWj6D,EAAMm6D,EAAWC,GAC9C,MAAO,CAACwO,EAAI1tB,SAASnpE,EAAGoxB,G,CAE1B,IAAK,gBAAiB,CACpB,MAAMA,EACF82D,GAAc,gBAAiBj6D,EAAMm6D,EAAWC,GAE9C3pF,EACFwpF,GAAc,cAAej6D,EAAMm6D,EAAWC,GAE5C3f,EACFwf,GAAc,eAAgBj6D,EAAMm6D,EAAWC,GAC7ChrB,EACF6qB,GAAc,eAAgBj6D,EAAMm6D,EAAWC,GACnD,MAAO,CAACwO,EAAItuB,cACRn3C,EAASs3C,EAAchqE,EACvBgqE,EAAa/pE,QAAU0+D,EAAa1+D,MAChC0+D,EACAw5B,EAAIl1E,KAAK07C,EAAcqL,EAAa/pE,Q,CAE9C,QACE,MAAMs5D,UAAU,aAAD94D,OAAc8uB,EAAKqE,GAAE,wBAE1C,CXvG0Bw4D,CAAoB78D,EAAMm6D,EAAWC,IACzD,IAAK,SACH,OAAOrgE,EAAK,IY9DpB,SAACiG,EAAYm6D,EACZC,GAAoD,IAAzBwO,EAAGn1F,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG20F,EAChC,OAAQpoE,EAAKqE,IACX,IAAK,sBAAuB,CAC1B,MAAM,cACJmrD,EAAa,aACbC,EAAY,kBACZC,EAAiB,gBACjBC,GAEEiZ,EAAI3hD,OAAOmoC,oBACP6K,GAAc,UAAWj6D,EAAMm6D,EAAWC,GAE1CH,GAAc,SAAUj6D,EAAMm6D,EAAWC,GACzCH,GAAc,aAAcj6D,EAAMm6D,EAAWC,GAE7CH,GAAc,eAAgBj6D,EAAMm6D,EAAWC,IAEvD,MAAO,CACL5K,EAAeC,EAAcC,EAAmBC,E,CAGpD,IAAK,gBAAiB,CACpB,MAAM,cAACH,EAAa,YAAEtwB,GAAe0pC,EAAI3hD,OAAO2oC,cAC5CqK,GAAc,eAAgBj6D,EAAMm6D,EAAWC,GAE/CH,GAAc,aAAcj6D,EAAMm6D,EAAWC,GAC7CH,GAAc,WAAYj6D,EAAMm6D,EAAWC,IAC/C,MAAO,CAAC5K,EAAetwB,E,CAEzB,IAAK,oBAMH,MAAO,CALY0pC,EAAI3hD,OAAOipC,kBAC1B+J,GAAc,OAAQj6D,EAAMm6D,EAAWC,GACvCH,GAAc,UAAWj6D,EAAMm6D,EAAWC,GAC1CH,GAAc,aAAcj6D,EAAMm6D,EAAWC,KAInD,IAAK,mBAMH,MAAO,CALYwO,EAAI3hD,OAAOmpC,iBAC1B6J,GAAc,OAAQj6D,EAAMm6D,EAAWC,GACvCH,GAAc,UAAWj6D,EAAMm6D,EAAWC,GAC1CH,GAAc,aAAcj6D,EAAMm6D,EAAWC,KAInD,QACE,MAAMpwB,UAAU,aAAD94D,OAAc8uB,EAAKqE,GAAE,wBAE1C,CZa0B4iB,CAAiBjnB,EAAMm6D,EAAWC,IACtD,IAAK,WACH,OAAOrgE,EAAK,IahEpB,SAACiG,EAAYm6D,EAA4BC,GACf,IAAzBwO,EAAGn1F,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG20F,EACD,OAAQpoE,EAAKqE,IACX,IAAK,MACH,MAAO,CAACukE,EAAI7zB,IACRklB,GAAc,IAAKj6D,EAAMm6D,EAAWC,KAE1C,IAAK,OACH,MAAO,CAACwO,EAAI3zB,KACRglB,GAAc,IAAKj6D,EAAMm6D,EAAWC,KAE1C,IAAK,OACH,MAAO,CAACwO,EAAI9yB,KACRmkB,GAAc,IAAKj6D,EAAMm6D,EAAWC,KAE1C,IAAK,QACH,MAAO,CAACwO,EAAIzzB,MACR8kB,GAAc,IAAKj6D,EAAMm6D,EAAWC,KAE1C,QACE,MAAMpwB,UAAU,aAAD94D,OAAc8uB,EAAKqE,GAAE,wBAE1C,Cb0CsBqtD,CAAmB1xD,EAAMm6D,EAAWC,IACxD,IAAK,SACH,OAAOrgE,EAAK,IclEpB,SAACiG,EAAYm6D,EACZC,GAAoD,IAAzBwO,EAAGn1F,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG20F,EAChC,OAAQpoE,EAAKqE,IACX,IAAK,eAAgB,CACnB,MAAM,OAAC0sD,EAAM,aAAEC,GAAgB4X,EAAIhX,OAAOtB,aACtC2J,GAAc,OAAQj6D,EAAMm6D,EAAWC,GACvCH,GAAc,aAAcj6D,EAAMm6D,EAAWC,GAC7CH,GAAc,YAAaj6D,EAAMm6D,EAAWC,GAC5CH,GAAc,cAAej6D,EAAMm6D,EAAWC,GAE9CH,GAAc,UAAWj6D,EAAMm6D,EAAWC,GAC1CH,GAAc,WAAYj6D,EAAMm6D,EAAWC,GAC3CH,GAAc,WAAYj6D,EAAMm6D,EAAWC,GAC3CH,GACI,yBAA0Bj6D,EAAMm6D,EAAWC,IAEnD,MAAO,CAACrJ,EAAQC,E,CAElB,IAAK,cAAe,CAClB,MAAM,QAAC7tD,EAAO,OAAE3yB,EAAM,MAAEC,GAASm4F,EAAIhX,OAAOX,YACxCgJ,GAAc,QAASj6D,EAAMm6D,EAAWC,GACxCH,GAAc,YAAaj6D,EAAMm6D,EAAWC,GAC5CH,GAAc,YAAaj6D,EAAMm6D,EAAWC,IAChD,MAAO,CAACj3D,EAAS3yB,EAAQC,E,CAE3B,IAAK,yBAIH,MAAO,CAHQm4F,EAAIhX,OAAOL,uBACtB0I,GAAc,QAASj6D,EAAMm6D,EAAWC,GACxCH,GAAc,aAAcj6D,EAAMm6D,EAAWC,KAGnD,QACE,MAAMpwB,UAAU,aAAD94D,OAAc8uB,EAAKqE,GAAE,wBAE1C,CdgC0ButD,CAAiB5xD,EAAMm6D,EAAWC,IACtD,IAAK,iBACH,OAAOrgE,EACH,IerEZ,SAACiG,EAAYm6D,EACZC,GAAoD,IAAzBwO,EAAGn1F,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG20F,EAChC,OAAQpoE,EAAKqE,IACX,IAAK,OACH,MAAO,CAACukE,EAAIl1E,KACRumE,GAAc,IAAKj6D,EAAMm6D,EAAWC,GACpCH,GAAc,QAASj6D,EAAMm6D,EAAWC,KAG9C,IAAK,aAAc,CACjB,MAAM3jF,EACFwjF,GAAc,OAAQj6D,EAAMm6D,EAAWC,GAC3C,MAAO,CAACwO,EAAIjkC,WACRs1B,GAAc,IAAKj6D,EAAMm6D,EAAWC,GAAoB3jF,G,CAE9D,IAAK,UAAW,CACd,MAAMA,EACFwjF,GAAc,OAAQj6D,EAAMm6D,EAAWC,GAC3C,MAAO,CAACwO,EAAIjyB,QACRsjB,GAAc,IAAKj6D,EAAMm6D,EAAWC,GAAoB3jF,G,CAG9D,IAAK,UACH,MAAO,CAACmyF,EAAIvvC,QACR4gC,GAAc,IAAKj6D,EAAMm6D,EAAWC,GACpCH,GAAc,QAASj6D,EAAMm6D,EAAWC,KAE9C,IAAK,YACH,MAAO,CAACwO,EAAIx+B,UACR6vB,GAAc,IAAKj6D,EAAMm6D,EAAWC,GACpCH,GAAc,UAAWj6D,EAAMm6D,EAAWC,GAE1CH,GAAc,OAAQj6D,EAAMm6D,EAAWC,KAG7C,IAAK,QACL,IAAK,MACH,MAAO,CAACwO,EAAI13E,IACR+oE,GAAc,IAAKj6D,EAAMm6D,EAAWC,GACpCH,GAAc,UAAWj6D,EAAMm6D,EAAWC,GAE1CH,GAAc,gBAAiBj6D,EAAMm6D,EAAWC,KAGtD,IAAK,iBAAkB,CACrB,MAAM7+B,EACF0+B,GAAc,aAAcj6D,EAAMm6D,EAAWC,GAC3C9vB,EACF2vB,GAAc,WAAYj6D,EAAMm6D,EAAWC,GAC/C,MAAO,CAACwO,EAAI57B,eACRitB,GAAc,IAAKj6D,EAAMm6D,EAAWC,GACpC7+B,EAAY+O,G,CAElB,IAAK,iBAAkB,CACrB,MAAM/O,EACF0+B,GAAc,aAAcj6D,EAAMm6D,EAAWC,GAC3C5+B,EACFy+B,GAAc,QAASj6D,EAAMm6D,EAAWC,GAC5C,MAAO,CAACwO,EAAIvtC,eACR4+B,GAAc,IAAKj6D,EAAMm6D,EAAWC,GACpC7+B,EAAYC,G,CAElB,IAAK,eAAgB,CACnB,MAAMiF,EACFw5B,GAAc,YAAaj6D,EAAMm6D,EAAWC,GAC1CllC,EACD+kC,GAAc,aAAcj6D,EAAMm6D,EAAWC,GACrCsN,cAEb,MAAO,CAACkB,EAAIroC,aACR05B,GAAc,IAAKj6D,EAAMm6D,EAAWC,GACpC35B,EAAWvL,G,CAEjB,IAAK,cACH,MAAO,CAAC0zC,EAAIzrC,YACR88B,GAAc,IAAKj6D,EAAMm6D,EAAWC,GACpCH,GAAc,QAASj6D,EAAMm6D,EAAWC,KAE9C,IAAK,gBACH,MAAO,CAACwO,EAAI/rC,cACRo9B,GAAc,KAAMj6D,EAAMm6D,EAAWC,GACrCH,GAAc,KAAMj6D,EAAMm6D,EAAWC,KAE3C,QACE,MAAMpwB,UAAU,aAAD94D,OAAc8uB,EAAKqE,GAAE,wBAE1C,CfjBkBy4D,CAAyB98D,EAAMm6D,EAAWC,IACtD,IAAK,aACH,MgBxEsC70D,OAC9CvF,EAAYm6D,EAA4BC,EACxCC,KACF,OAAQr6D,EAAKqE,IACX,IAAK,YACL,IAAK,cAAe,CAClB,MAAM0jE,EACF9N,GAAc,WAAYj6D,EAAMm6D,EAAWC,GACzC4N,EACF/N,GAAc,aAAcj6D,EAAMm6D,EAAWC,GAE3CqC,EAAY,IAAIqL,GAAUC,EAAUC,GAE1C,OADA3N,EAAgB+O,aAAappE,EAAKxiB,KAAMi/E,GACjC,CAACA,EAAUwL,O,CAEpB,IAAK,oBACL,IAAK,sBAAuB,CAC1B,MAAMA,EAAShO,GACI,cAAej6D,EAAMm6D,EAAWC,EAChCC,GACb5hE,EAAOwhE,GAAc,OAAQj6D,EAAMm6D,EAAWC,GAC9C5pF,EACFypF,GAAc,SAAUj6D,EAAMm6D,EAAWC,GAEvCqC,EAAYpC,EAAgBgP,iBAAiBpB,EAAOr1E,IAE1D,MAAO,OAAO6pE,EAAU4L,OAAO5vE,EAAMjoB,G,CAEvC,IAAK,kBACL,IAAK,oBAAqB,CACxB,MAAMy3F,EAAShO,GACI,cAAej6D,EAAMm6D,EAAWC,EAChCC,GACb5hE,EAAOwhE,GAAc,OAAQj6D,EAAMm6D,EAAWC,GAC9ChrB,EACF6qB,GAAc,eAAgBj6D,EAAMm6D,EAAWC,GAE7CqC,EAAYpC,EAAgBgP,iBAAiBpB,EAAOr1E,IAC1D,MAAO,OAAO6pE,EAAUrB,KAAK3iE,EAAM22C,G,CAErC,IAAK,kBACL,IAAK,oBAAqB,CACxB,MAAM64B,EAAShO,GACI,cAAej6D,EAAMm6D,EAAWC,EAChCC,GAGnB,MAAO,CADWA,EAAgBgP,iBAAiBpB,EAAOr1E,IACxCu1E,a,CAEpB,QACE,MAAMn+B,UAAU,aAAD94D,OAAc8uB,EAAKqE,GAAE,0BhBsBvBo4D,CACHz8D,EAAMm6D,EAAWC,EAASC,GAChC,IAAK,SACH,MAAMiP,EAAWtP,GAAgBh6D,EAAKqE,IACtC,GAAIilE,GAAYA,EAASC,eACvB,OAAOD,EAASC,eACZ,IAAItI,GAAcjhE,EAAMm6D,EAAWC,IAEvC,MAAMpwB,UAAU,aAAD94D,OAAc8uB,EAAKqE,GAAE,wBAExC,QACE,MAAM2lC,UACF,eAAA94D,OAAe8uB,EAAKqE,GAAE,wBAAtB,mHAIT,EAzDD,CAyDGrE,EAAMm6D,EAAWC,GACxB,OAAIuO,GAAmBp5F,GACdA,EAAMqL,KAAM9L,GAAS,GAAGoC,OAAOpC,IAEjC,GAAGoC,OAAO3B,EACnB,CiBhFM,MAAOi6F,GAMX76F,WAAAA,GAIgE,IAHnD86F,EAAAh2F,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAA6B,CAAC,EAC9B6wF,EAAA7wF,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAiC,CAAC,EAClC8wF,EAAA9wF,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAA+B,CAAC,EAChC2wF,EAAA3wF,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAiD,CAAC,EAHlD,KAAAg2F,UAAAA,EACA,KAAAnF,eAAAA,EACA,KAAAC,cAAAA,EACA,KAAAH,YAAAA,EATL,KAAAsF,YAAc,CAAC92E,GAAI,EAAG+2E,UAAW,GAAIC,YAAa,GAClD,KAAAC,SAAmC,CAAC16F,KAAKu6F,aACzC,KAAAI,OAAS,EAQf36F,KAAK46F,2BACP,CAEQC,QAAAA,CAASp3E,EAAY+2E,GAC3B,MAAO,CAAC/2E,KAAI+2E,YAAWC,YAAa,EACtC,CAOA,kBAAIK,CAAeJ,GACb16F,KAAK06F,WAAaA,IACpB16F,KAAK06F,SAAWA,EAChB16F,KAAK46F,4BAET,CAEA,kBAAIE,GACF,OAAO96F,KAAK06F,QACd,CAKA,oBAAIrO,GACF,OAAOrsF,KAAK+6F,mBAAmB,EACjC,CAMA,qBAAI/O,GACF,OAAOhsF,KAAK+6F,kBACd,CAEQH,yBAAAA,GACN,MAAMnkE,EAAQ,GACd,IAAK,IAAInzB,EAAI,EAAGA,EAAItD,KAAK06F,SAASv4F,OAAS,EAAGmB,IAAK,CACjD,MAAMo3F,EAAW16F,KAAK06F,SAAStzF,MAAM,EAAGpH,KAAK06F,SAASv4F,OAASmB,GAC/DmzB,EAAM1xB,KAAK/E,KAAKg7F,qBAAqBN,G,CAEvCjkE,EAAM1xB,KAAK,IACX/E,KAAK+6F,mBAAqBtkE,CAC5B,CAEQukE,oBAAAA,CAAqBN,GAC3B,OAAOA,EACHA,EACKlzF,IACGyjF,GAA2B,IAAfA,EAAQxnE,IAAoC,IAAxBwnE,EAAQwP,YACpC,GAAE,GAAA14F,OACCkpF,EAAQuP,UAAS,KAAAz4F,OAAIkpF,EAAQwP,cACvCjsF,KAAK,KACV,EACN,CAMAsnF,UAAAA,CAAWD,GACL71F,KAAK06F,WACP16F,KAAK26F,SACL36F,KAAK06F,SAAW16F,KAAK06F,SAAStzF,QAC9BpH,KAAK06F,SAAS31F,KAAK/E,KAAK66F,SAAS76F,KAAK26F,OAAQ9E,IAC9C71F,KAAK+6F,mBAAmBprD,QAAQ3vC,KAAKg7F,qBAAqBh7F,KAAK06F,WAEnE,CAMA3E,SAAAA,GACE,KAAI/1F,KAAK06F,UAAY16F,KAAK06F,SAASv4F,OAAS,GAK1C,MAAM,IAAIL,MAAM,2CAJhB9B,KAAK06F,SAAW16F,KAAK06F,SAAStzF,QAC9BpH,KAAK06F,SAAS9lD,QAAQ,GACtB50C,KAAKgsF,kBAAkBpvE,OAI3B,CAMAo5E,aAAAA,GACE,KAAIh2F,KAAK06F,UAAY16F,KAAK06F,SAASv4F,OAAS,GAW1C,MAAM,IAAIL,MAAM,yDAX6B,CAC7C9B,KAAK06F,SAAW16F,KAAK06F,SAAStzF,QAC9BpH,KAAK26F,SACL,MAAM1P,EACF79E,OAAOC,OAAO,CAAC,EAAGrN,KAAK06F,SAAS16F,KAAK06F,SAASv4F,OAAS,IAC3D8oF,EAAQwP,aAAe,EACvBxP,EAAQxnE,GAAKzjB,KAAK26F,OAClB36F,KAAK06F,SAAS9lD,QAAQ,EAAG,EAAGq2C,GAC5BjrF,KAAK+6F,mBAAmBnmD,OACpB,EAAG,EAAG50C,KAAKg7F,qBAAqBh7F,KAAK06F,U,CAI7C,CAEAO,SAAAA,CAAU5sF,GACR,OAAOrO,KAAKs6F,UAAUjsF,EACxB,CAEA6nF,cAAAA,CAAeD,GACbj2F,KAAKm1F,eAAec,EAAYxyE,IAAMwyE,CACxC,CAEAI,cAAAA,CAAe5yE,GACb,OAAOzjB,KAAKm1F,eAAe1xE,EAC7B,CAEAk0E,aAAAA,CAActxE,GACZrmB,KAAKo1F,cAAc/uE,EAAW5C,IAAM4C,CACtC,CAEAoxE,aAAAA,CAAch0E,GACZ,OAAOzjB,KAAKo1F,cAAc3xE,EAC5B,CAEA7hB,OAAAA,CAAQyxF,GACN,IAAK,MAAMzlF,KAAO5N,KAAKm1F,eACrBn1F,KAAKm1F,eAAevnF,GAAKwlF,cAAcC,GAGzC,IAAK,MAAMzlF,KAAO5N,KAAKo1F,cACrBp1F,KAAKo1F,cAAcxnF,GAAKwlF,cAAcC,EAE1C,ECjJI,SAAU6H,GACZz7E,EAAwBC,EAAiB46E,EACzCpM,GACF,MAAMiN,EAAY,IAAIz0E,IAChB00E,EAA0B,GAChC,IAAIC,EAAoB,KACpBC,EAAuB,KAI3B,MAAM10E,EAAO,IAAIF,IACX60E,EACFnuF,OAAOkc,KAAK7J,GAAQjY,IAAI6G,GAAQw9E,GAAcx9E,GAAM,IAExD,IAAImtF,EAA0B,GACb,MAAbtN,IACFsN,EAAgBtN,EAAU1mF,IAAIqpB,GAAQg7D,GAAch7D,EAAKxiB,MAAM,KAGjE,MAAMotF,EAAW,IAAI/7E,GACrB,KAAO+7E,EAASt5F,OAAS,GAAG,CAC1B,MAAM0uB,EAAO4qE,EAASrrE,OAClBsrE,GAAc7qE,IAAS8qE,GAAe9qE,IAAS+qE,GAAY/qE,KAC1C,MAAfwqE,IACFA,EAAcxqE,EACdyqE,EAAaD,EAAY1M,SAASnnF,IAAIq0F,GAASA,EAAMxtF,MACnCogB,OAAOpgB,GAAQ8sF,EAAUl7F,IAAIoO,KAGnD8sF,EAAU59E,IAAIsT,EAAKxiB,MAGS,MAAxBisF,EAAUzpE,EAAKxiB,SAIwB,IAAvCktF,EAAe7mE,QAAQ7D,EAAKxiB,QAIU,IAAtCmtF,EAAc9mE,QAAQ7D,EAAKxiB,QAGJ,IAAvBwiB,EAAKpR,OAAOtd,OAIhB0uB,EAAKpR,OAAOrW,QAAQ0X,IAEd8F,EAAK3mB,IAAI6gB,EAAMzS,QAGnBuY,EAAKrJ,IAAIuD,EAAMzS,MACfotF,EAAS12F,KAAK+b,MATds6E,EAAcr2F,KAAK8rB,EAAKxiB,O,CAY5B,MAAO,CAACoR,SAAQC,UAASy7E,YAAWC,gBAAeC,cAAaC,aAClE,CAmDA,MAAMQ,GAAmB,CACvB,SAAU,QAAS,QAAS,OAAQ,gBAAiB,cACrD,iBAAkB,KAAM,SAEpBC,GAAoB,CACxB,sBAAuB,sBAAuB,sBAAuB,SAEjEC,GAAiB,CACrB,YAAa,cAAe,oBAAqB,sBACjD,kBAAmB,oBAAqB,kBAAmB,qBAGvD,SAAUN,GAAc7qE,GAC5B,OAAOirE,GAAiBpnE,QAAQ7D,EAAKqE,KAAO,CAC9C,CAEM,SAAUymE,GAAe9qE,GAC7B,OAAOkrE,GAAkBrnE,QAAQ7D,EAAKqE,KAAO,CAC/C,CAEM,SAAU0mE,GAAY/qE,GAC1B,OAAOmrE,GAAetnE,QAAQ7D,EAAKqE,KAAO,CAC5C,CCvIM,MAAO+mE,GAmGXz8F,WAAAA,CAAoB6tF,EAAsB6O,GAAtB,KAAA7O,MAAAA,EAAsB,KAAA6O,OAAAA,EAlGlC,KAAAC,YAAmC,IAAI/sF,IACvC,KAAAgtF,WAA8B,CAAC,EAM/B,KAAAC,UAAY,IACZ,KAAAC,WAAqC,CAAC,EACtC,KAAAC,qBAA0D,CAAC,EAE3D,KAAAC,oBAAuC,CAAC,EAGxC,KAAAC,oBAAqB,EAqF3Bz8F,KAAK08F,SAAWrP,EAAM3tE,QACtB1f,KAAK28F,QAAUtP,EAAM5tE,OACrBzf,KAAK48F,WAAavP,EAAMa,UACxBluF,KAAK68F,WAAaxP,EAAM/zD,UACxBt5B,KAAKs8F,WAAajP,EAAMwB,UAED,MAAnBxB,EAAMwB,WACRzhF,OAAOkc,KAAK+jE,EAAMwB,WAAWzlF,QAAQiF,IACnCrO,KAAKu8F,qBAAqBluF,GACtB,IAAI4tF,GAAc5O,EAAMwB,UAAUxgF,GAAOrO,OAGnD,CA/FA,aAAI88F,GACF,OAAO98F,KAAKk8F,OAASl8F,KAAKk8F,OAAOY,UAAY98F,KAAK+8F,UACpD,CAEA,uBAAIC,GACF,OAAOh9F,KAAKk8F,OAASl8F,KAAKk8F,OAAOc,oBACZh9F,KAAKu8F,oBAC5B,CAEA,aAAIjC,GACF,OAAOt6F,KAAKk8F,OAASl8F,KAAKk8F,OAAO5B,UAAYt6F,KAAKo8F,UACpD,CAEA,aAAI9B,CAAUA,GACZ,MAAMwC,EAAY1vF,OAAOkc,KAAKgxE,GAAW9yF,IACrCoG,GAAO0sF,EAAU1sF,GAAKpG,IAAI4e,GAAUA,EAAO3C,KAC/CzjB,KAAK+8F,WAAa,GAAGh7F,UAAU+6F,GAC/B98F,KAAKo8F,WAAa9B,CACpB,CAMA,mBAAIpP,CAAgBA,GAClBlrF,KAAKi9F,iBAAmB/R,CAC1B,CAEA,UAAIzrE,GACF,OAAOzf,KAAK28F,QAAQn1F,IAAIqpB,IACf,CACLxiB,KAAMwiB,EAAKxiB,KACX/M,MAAOuvB,EAAK66D,WAAkB,MAC1B76D,EAAK66D,WAAkB,MAAEtrF,WACzBmE,EACJhD,MAAOsvB,EAAK66D,WAAkB,MAC1B76D,EAAK66D,WAAkB,MAAEtrF,WACzBmE,IAGV,CAEA,WAAImb,GACF,OAAO1f,KAAK08F,SAASl1F,IAAIqpB,IAChB,CACLxiB,KAAMwiB,EAAKxiB,KACX/M,MAAOuvB,EAAK66D,WAAkB,MAC1B76D,EAAK66D,WAAkB,MAAEtrF,WACzBmE,EACJhD,MAAOsvB,EAAK66D,WAAkB,MAC1B76D,EAAK66D,WAAkB,MAAEtrF,WACzBmE,IAGV,CAEA,cAAI24F,GACF,OAAOl9F,KAAK28F,QAAQn1F,IAAIqpB,GAAQA,EAAK+9D,cAAgB/9D,EAAKxiB,KAC5D,CAEA,eAAI8uF,GACF,OAAOn9F,KAAK08F,SAASl1F,IAAKqpB,IACxB,MAAMxiB,EAAOwiB,EAAK+9D,cAAgB/9D,EAAKxiB,KACvC,OAAOwiB,EAAK2/D,cAAgB,GAAHzuF,OAAOsM,EAAI,KAAAtM,OAAI8uB,EAAK2/D,eAAmBniF,GAEpE,CAEA,aAAIwgF,GACF,OAAOzhF,OAAOkc,KAAKtpB,KAAKs8F,YAAY9xF,OAAO,CAAChD,EAAKoG,KAC/CpG,EAAIoG,GAAO5N,KAAKs8F,WAAW1uF,GAAK0rB,UACzB9xB,GACN,CAAC,EACN,CAyBQ41F,iBAAAA,CAAkB39E,EAAgBC,GACxC,MAAM29E,EAAe59E,EAAOjY,IAAIqpB,GAAQA,EAAKxiB,MAAMrG,OAC7Cs1F,EAAgB59E,EAAQlY,IAAIqpB,GAAQA,EAAKxiB,MAAMrG,OACrD,OAAOq1F,EAAa7uF,KAAKxO,KAAKq8F,WAAa,KACvCiB,EAAc9uF,KAAKxO,KAAKq8F,UAC9B,CAMQkB,OAAAA,CAAQ99E,EAAwBC,GACtC,MAAM89E,EACFtC,GAAqBz7E,EAAQC,EAAS1f,KAAKs6F,UAAWt6F,KAAK48F,aACzD,cAACxB,EAAa,YAAEC,EAAW,WAAEC,GAAckC,EACjD,GAAmB,MAAfnC,EACF,MAAM,IAAIv5F,MACN,qCAAAC,OAAqCs5F,EAAYhtF,KAAI,oCAAAtM,OAClCs5F,EAAYnmE,GAAE,kBAAgB,6DACW,oCAAAnzB,OACxBu5F,EAAU,MAGpD,GAAIF,EAAcj5F,OAAS,EAAG,CAC5B,MAAMs7F,EAAW/9E,EAAQlY,IAAIzB,GAAKA,EAAEsI,MAC9BqvF,EAAUtwF,OAAOkc,KAAK7J,GAC5B,MAAM,IAAI3d,MACN,+BAAAC,OAA+B07F,EAAQ,mCAAA17F,OACnC27F,EAAO,sCAAA37F,OAAqCq5F,EAAa,K,CAGnE,OD7EE,SACF/N,EAAciN,EACdkD,GACF,MAAM,UAACrC,EAAS,OAAE17E,GAAU+9E,EACtB/B,EAAmB,GACnByB,EAAa9vF,OAAOkc,KAAK7J,GACPjY,IAAI6G,GAAQw9E,GAAcx9E,GAAM,IAChC7G,IAAI6G,GAAQg/E,EAAMc,MAAM9/E,IAC1C6/E,EAAYb,EAAMa,UAExBgP,EAAW9zF,QAAQ0X,IACbq6E,EAAUl7F,IAAI6gB,EAAMzS,OACtBotF,EAAS12F,KAAK+b,KAGlBusE,EAAM1yD,QAAQvxB,QAAQ+sE,IAChBglB,EAAUl7F,IAAIk2E,EAAO9nE,OACvBotF,EAAS12F,KAAKoxE,KAGD,MAAb+X,GACFA,EAAU9kF,QAAQynB,IACZsqE,EAAUl7F,IAAI4wB,EAAKxiB,OACrBotF,EAAS12F,KAAK8rB,KAIpB,MAAMjK,EAAO,IAAIF,IACXi3E,EAAuB,GAC7B,KAAOlC,EAASt5F,OAAS,GAAG,CAC1B,MAAM0uB,EAAO4qE,EAASrrE,MACtBxJ,EAAKrJ,IAAIsT,EAAKxiB,MACTisF,EAAUzpE,EAAKxiB,OAClBsvF,EAAa54F,KAAK8rB,GAEpBA,EAAK89D,SAASvlF,QAAQyyF,KACfj1E,EAAK3mB,IAAI47F,EAAMxtF,OAAS8sF,EAAUl7F,IAAI47F,EAAMxtF,OAC7CwtF,EAAMp8E,OAAO/X,MAAMoZ,GAAS8F,EAAK3mB,IAAI6gB,EAAMzS,QAC7CotF,EAAS12F,KAAK82F,I,CAIpB,OAAO8B,CACT,CCkCWC,CACH59F,KAAKqtF,MAAOrtF,KAAKs6F,UAAWkD,EAClC,CAWAK,OAAAA,CAAQp+E,EAAwBC,GAC9BD,EAASzf,KAAK89F,UAAUr+E,GACxB,MAAMgX,EAAQrpB,OAAOkc,KAAK7J,GAAQzX,OAClChI,KAAK+9F,YAAYt+E,GACjBzf,KAAKg+F,uBAAuBv+E,GAC5BC,EAAU1f,KAAKi+F,WAAWv+E,GAC1B1f,KAAKk+F,aAAax+E,GAClB,MAAMw9E,EACFzmE,EAAMjvB,IAAI6G,GAAQrO,KAAKqtF,MAAMc,MAAMtC,GAAcx9E,GAAM,KACrD8vF,EAAkBz+E,EAAQlY,IAAI6G,GAAQw9E,GAAcx9E,GAAM,IAChE,IAAI8uF,EAAcgB,EAAgB32F,IAAI6G,GAAQrO,KAAKqtF,MAAMc,MAAM9/E,IAC/DrO,KAAKo+F,2BAEsB,IAAvBjB,EAAYh7F,SACdg7F,EAAcn9F,KAAK08F,UAGrB,MAAM2B,EAAiBr+F,KAAKo9F,kBAAkBF,EAAYC,GAG1D,IAAIQ,EAAe39F,KAAKm8F,YAAYr8F,IAAIu+F,GACpB,MAAhBV,IACFA,EAAe39F,KAAKu9F,QAAQ99E,EAAQ09E,GACpCn9F,KAAKm8F,YAAYh8F,IAAIk+F,EAAgBV,IAGvC,MAAMxI,EAAiC,CAAC,EAClCC,EAA+B,CAAC,EAEtC,OAAOxqE,GAAK,KACV,MAAMqgE,EAAU,IAAIoP,GAChBr6F,KAAKs6F,UAAWnF,EAAgBC,EAChCp1F,KAAKg9F,qBACHrR,EAAUv+E,OAAAC,OAAA,GAAwBrN,KAAKs6F,WAE7CltF,OAAOkc,KAAK7J,GAAQrW,QAAQiF,IAC1B,MAAOu9E,EAAUxpF,GAASypF,GAAcx9E,GAClCif,EAAoB,GAC1BA,EAAQlrB,GAASqd,EAAOpR,GACxBs9E,EAAWC,GAAYt+D,IAGzB,MAAMgxE,EAAgBt+F,KAAKu+F,mBAAmB5S,GACxC6S,EAA2D,CAAC,EAClE,IAAK,IAAIl7F,EAAI,EAAGA,EAAIq6F,EAAax7F,OAAQmB,IAAK,CAC5C,MAAMutB,EAAO8sE,EAAar6F,GAC1B,IAAKqoF,EAAW96D,EAAKxiB,MAAO,CAC1B,MAAMif,EACFunE,GAAUhkE,EAAM86D,EAAYV,EAASjrF,KAAKi9F,kBAE9C,GAAIp9E,GAAeyN,GACjB,MAAM,IAAIxrB,MACN,4BAAAC,OAA4B8uB,EAAKqE,GAAE,sEAGzCy2D,EAAW96D,EAAKxiB,MAAQif,EACxBttB,KAAKy+F,uBACD5tE,EAAKxiB,KAAMwiB,EAAM86D,EAAYV,EAASqT,EACtCH,EAAiBK,E,EAOzB,OAHmB,MAAfx+F,KAAKk8F,QACPjR,EAAQrpF,QAAQ08F,GAEX5+E,EAAQlY,IAAI6G,GAAQk9E,GAAUl9E,EAAMs9E,EAAYV,KAE3D,CAEQsT,kBAAAA,CAAmBvT,GACzB,MAAM0T,EAAM,GAAG38F,OAAO6H,MAClB,GACAwD,OAAOkc,KAAK0hE,GACPxjF,IAAIoG,GAAOo9E,EAAUp9E,IACrBpG,IAAI8lB,GAAWA,EAAQ9lB,IAAI4e,GAAUA,EAAO3C,MACrD,OAAO,IAAIiD,IAAIg4E,EACjB,CACQD,sBAAAA,CACJ7S,EAAkB/6D,EAAYm6D,EAC9BC,EAA2BqT,EAC3BK,EACAH,GAGoB,YAAlB3tE,EAAKs+D,WAA6D,IAAnCwP,EAAYjqE,QAAQk3D,KAIvDZ,EAAUY,GAAUxiF,QAAQgd,IACZ,MAAVA,IACFo4E,EAAgCp4E,EAAO3C,KAClC+6E,EAAgCp4E,EAAO3C,KAAO,GAC/CoN,EAAK89D,SAASxsF,UAGtB0uB,EAAKpR,OAAOrW,QAAQ0X,IAGlB,GAAuB,YAAnBA,EAAMquE,SAAwB,CAChC,MAAM7hE,EhD3MR,SACFjf,EAAcs9E,EACdV,GACF,OAAOU,EAAWO,GAAyB79E,EAAM48E,EAAQoB,kBAC3D,CgDwMYuS,CAA6B99E,EAAMzS,KAAM28E,EAAWC,GACzC,MAAX39D,GACFA,EAAQlkB,QAAQgd,IACd,GAAIA,IAAWA,EAAO1C,OAAS46E,EAAcr+F,IAAImmB,EAAO3C,IAAK,CAC3D,MAAMqlE,EAAQ0V,EAAgCp4E,EAAO3C,IACrD,GAAc,IAAVqlE,EAAa,CACf,GAAK9oF,KAAKy8F,mBAEH,CACL,MAAO7Q,EAAUxpF,GACb+pF,GAAoBt7D,EAAKxiB,KAAM48E,GAC/BjrF,KAAKw8F,oBAAoB5Q,KAG3B5rF,KAAKw8F,oBAAoB5Q,GAAY,IAFrC5rF,KAAKw8F,oBAAoB5Q,GAAUxpF,GAASgkB,C,MAL9CA,EAAOxkB,iBAWF48F,EAAgCp4E,EAAO3C,G,MAC5B,MAATqlE,GAGT0V,EAAgCp4E,EAAO3C,K,OAOrD,CAWA,kBAAMo7E,CAAap/E,EAAwBC,GAEzC,OAAO1f,KAAK8+F,cAAcr/E,EAAQC,EACpC,CAEAq/E,0BAAAA,GACO/+F,KAAKw8F,sBAGVpvF,OAAOkc,KAAKtpB,KAAKw8F,qBACZpzF,QACGwE,GAAO5N,KAAKw8F,oBAAoB5uF,GAAKxE,QACjCgd,GAAUA,EAAOxkB,YAC7B5B,KAAKg/F,oBACP,CAEQA,iBAAAA,GACDh/F,KAAK2rF,YAGVv+E,OAAOkc,KAAKtpB,KAAK2rF,YAAYviF,QAAQwE,IACf5N,KAAK2rF,WAAW/9E,GACxBxE,QAAQgd,KACdA,GAAWA,EAAO1C,MAAS0C,EAAOjC,YACjCnkB,KAAKqzF,QAAQpzF,IAAImmB,EAAO3C,KAC3B2C,EAAOxkB,aAIf,CAEAq9F,sBAAAA,GACE,OAAOj/F,KAAK2rF,UACd,CAEQyS,wBAAAA,GACN,IAAK,MAAMxwF,KAAO5N,KAAKw8F,oBACrBx8F,KAAKw8F,oBAAoB5uF,GAAKxE,QAAQgd,GAAUA,EAAOxkB,kBAChD5B,KAAKw8F,oBAAoB5uF,EAEpC,CAgBQ,mBAAMkxF,CACVr/E,EAAwBC,GAES,IAFWw/E,EAAmB56F,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,IAAAA,UAAA,GAC/D6wF,EAAA7wF,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAiC,CAAC,EAClC8wF,EAAA9wF,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAA+B,CAAC,EAC7B46F,IACHz/E,EAASzf,KAAK89F,UAAUr+E,GACxBzf,KAAK+9F,YAAYt+E,GACjBzf,KAAKg+F,uBAAuBv+E,GAC5BC,EAAU1f,KAAKi+F,WAAWv+E,GAC1B1f,KAAKk+F,aAAax+E,IAIpB,IACE1f,KAAKy8F,mBAAqBpwF,KAAMC,QAAQ,4B,CACxC,MAAOwR,GACPvR,QAAQC,KAAKsR,EAAEyM,Q,CAEjBvqB,KAAKo+F,2BAEL,MAAMnT,EAAU,IAAIoP,GAChBr6F,KAAKs6F,UAAWnF,EAAgBC,EAChCp1F,KAAKg9F,qBAKTh9F,KAAK2rF,iBAAmB3rF,KAAKm/F,uBACzB1/E,EAAQwrE,EAASvrE,EAASw/E,GAC9B,MAAME,EACF1/E,EAAQlY,IAAI6G,GAAQk9E,GAAUl9E,EAAMrO,KAAK2rF,WAAYV,IAGnDoU,EAAYD,EAAQ53F,IAAI2G,GAAKA,EAAEsV,IAC/B67E,EAAWlyF,OAAOkc,KAAK7J,GAAQjY,IAAI6G,GAAQoR,EAAOpR,GAAMoV,IAY9D,OAXAzjB,KAAKqzF,QACD,IAAI3sE,IAAY,IAAI24E,KAAcC,KAAat/F,KAAK88F,YACnD98F,KAAKy8F,oBACRz8F,KAAKg/F,oBAIY,MAAfh/F,KAAKk8F,QACPjR,EAAQrpF,QAAQ5B,KAAKqzF,SAGhB+L,CACT,CAEA,0BAAMlK,CACFz1E,EAAkB01E,EAClBC,GACF,MAAMmK,EAAe9/E,EAAOjV,OAAO,CAAChD,EAAK4e,EAAQhkB,KAC/CoF,EAAIxH,KAAKyf,OAAOrd,GAAOiM,MAAQ+X,EACxB5e,GACN,CAAC,GAEJ,OAAOxH,KAAK8+F,cACRS,EAAcv/F,KAAKm9F,aAAa,EAAMhI,EAAgBC,EAC5D,CAaQ,4BAAM+J,CACV1/E,EAAwBwrE,EAA2B0T,EACnDO,GACF,MAAMzoE,EAAQrpB,OAAOkc,KAAK7J,GACpBy9E,EACFzmE,EAAMjvB,IAAI6G,GAAQrO,KAAKqtF,MAAMc,MAAMtC,GAAcx9E,GAAM,KACrD8vF,EAAkBQ,EAAYn3F,IAAI6G,GAAQw9E,GAAcx9E,GAAM,IACpE,IAAI8uF,EAAcgB,EAAgB32F,IAAI6G,GAAQrO,KAAKqtF,MAAMc,MAAM9/E,IAGpC,IAAvB8uF,EAAYh7F,SACdg7F,EAAcn9F,KAAK08F,UAGrB,MAAM,UAACvB,EAAS,cAAEC,EAAa,YAAEC,EAAW,WAAEC,GAC1CJ,GACIz7E,EAAQ09E,EAAan9F,KAAKs6F,UAAWt6F,KAAK48F,YAG5CtyE,EAA4B,IAC7B4yE,KAAel9F,KAAKqtF,MAAM1yD,WAAa36B,KAAK48F,YAAc,IAC7Dp1F,IAAIqpB,IACG,CAACA,OAAM6pE,SAAUzP,EAAQ6P,kBAE5BnP,EAAUv+E,OAAAC,OAAA,GAAwBrN,KAAKs6F,WAC7CltF,OAAOkc,KAAK7J,GAAQrW,QAAQiF,IAC1B,MAAOu9E,EAAUxpF,GAASypF,GAAcx9E,GAClCif,EAAoB,GAC1BA,EAAQlrB,GAASqd,EAAOpR,GACxBs9E,EAAWC,GAAYt+D,IAEzB,MAAMkxE,EAA2D,CAAC,EAC5DF,EAAgBt+F,KAAKu+F,mBAAmB5S,GACxC6T,EAAkC,CAAC,EACzC,KAAOl1E,EAAMnoB,OAAS,GAAG,CACvB,MAAMykC,EAAW5mC,KAAKy/F,aAClBvC,EAAY5yE,EAAO2gE,EAASU,EAAY6T,EAAOlB,EAC/CH,EAAiBK,EAAiCrD,SAChDz0F,QAAQ+Z,IAAImmB,E,CAED,MAAfy0D,GAAwB6D,GAC1B3yF,QAAQC,KACJ,mIAGN,MAAMkzF,EACFvC,EACK1uE,OACGoC,IAAS6qE,GAAc7qE,KAClB06D,GAAU16D,EAAKxiB,KAAMs9E,EAAYV,IACzCzjF,IAAIqpB,GAAQA,EAAKxiB,MAC1B,GAAIqxF,EAAev9F,OAAS,EAAG,CAC7B,IAAIw9F,EAAiB,GAMrB,MALmB,MAAftE,IACFsE,EACI,2FAAA59F,OAC2Bu5F,EAAU,MAErC,IAAIx5F,MACN,+BAAAC,OAA+B29F,EAAc,mCAAA39F,OAClC00B,EAAK,gDAA8C,IAAA10B,OAC1Dq5F,EAAa,OAAAr5F,OAAM49F,G,CAE7B,OAAOhU,CACT,CAEQ8T,YAAAA,CACJvC,EAAoB5yE,EAA2B2gE,EAC/CD,EAA4BwU,EAC5BlB,EAA4BK,EAC5BH,EACArD,GACF,MAAMv0D,EAAqC,GAC3C,KAAOtc,EAAMnoB,OAAS,GAAG,CACvB,MAAM6rB,EAAO1D,EAAM8F,MACnB66D,EAAQ6P,eAAiB9sE,EAAK0sE,SAC9B,IAAI9O,EAAW,GAWf,GAPqB,UAAjB59D,EAAK6C,KAAKqE,IACV41D,GAAc,aAAc98D,EAAK6C,KAAMm6D,EAAWC,MACnDW,GAAYO,GAAoBn+D,EAAK6C,KAAKxiB,KAAM48E,IAKlB,MAA7BD,EAAUh9D,EAAK6C,KAAKxiB,MAAe,CACrC,MAAMif,EACFunE,GAAU7mE,EAAK6C,KAAMm6D,EAAWC,EAASjrF,KAAKi9F,kBAC7CrR,KACFA,GAAYO,GAAoBn+D,EAAK6C,KAAKxiB,KAAM48E,IAEnD,MAAM6P,EAAiB7P,EAAQ6P,eAC3Bj7E,GAAeyN,GACjBsZ,EAAS7hC,KAAKuoB,EAAQ7hB,KAAK0C,IACzB68E,EAAUY,GAAYz9E,EACtB88E,EAAQ6P,eAAiBA,EACzB96F,KAAKy+F,uBACD7S,EAAU59D,EAAK6C,KAAMm6D,EAAWC,EAASqT,EACzCK,EAAaH,GACjBx+F,KAAK4/F,kBACD5xE,EAAK6C,KAAMvG,EAAO2gE,EAASD,EAAWwU,EAAOrE,GAC1ChtF,MAGT68E,EAAUY,GAAYt+D,EACtBttB,KAAKy+F,uBACD7S,EAAU59D,EAAK6C,KAAMm6D,EAAWC,EAASqT,EACzCK,EAAaH,GACjBx+F,KAAK4/F,kBACD5xE,EAAK6C,KAAMvG,EAAO2gE,EAASD,EAAWwU,EAAOrE,G,MAGnDn7F,KAAK4/F,kBACD5xE,EAAK6C,KAAMvG,EAAO2gE,EAASD,EAAWwU,EAAOrE,E,CAGrD,OAAOv0D,CACT,CAEQg5D,iBAAAA,CACJ/uE,EAAYvG,EAA2B2gE,EACvCD,EAA4BwU,EAC5BrE,GACFtqE,EAAK89D,SAASvlF,QAASy2F,IACrB,MAAOjU,GAAcO,GAAoB0T,EAAUxxF,KAAM48E,IACrDuU,EAAM5T,IAAcuP,EAAUl7F,IAAI4/F,EAAUxxF,QAI3B,UAAjBwxF,EAAU3qE,GACR2qE,EAAUrU,WAAWllE,KAAKjY,KACfk9E,GAAUl9E,EAAM28E,EAAWC,MAExCuU,EAAM5T,IAAY,EAClBthE,EAAMvlB,KAAK,CAAC21F,SAAUzP,EAAQ6P,eAAgBjqE,KAAMgvE,KAGhDA,EAAUrU,WAAW9jF,MAAM2G,KAChBk9E,GAAUl9E,EAAM28E,EAAWC,MAE5CuU,EAAM5T,IAAY,EAClBthE,EAAMvlB,KAAK,CAAC21F,SAAUzP,EAAQ6P,eAAgBjqE,KAAMgvE,OAG1D,CAKAj+F,OAAAA,GACEwL,OAAOkc,KAAKtpB,KAAKs6F,WACZlxF,QACGwE,GAAO5N,KAAKs6F,UAAU1sF,GAAKxE,QAAQgd,GAAUA,EAAOxkB,WAC9D,CAEQo8F,sBAAAA,CAAuBv+E,GAC7BrS,OAAOkc,KAAK7J,GAAQrW,QAAQiF,IAC1B,MAAMyS,EAAQrB,EAAOpR,IACdu9E,GAAcC,GAAcx9E,GAC7BwiB,EAAO7wB,KAAKqtF,MAAMc,MAAMvC,GAC9B,GAAI/6D,EAAK66D,WAAkB,OAAK76D,EAAK66D,WAAkB,MAAEtrF,MAAO,CAC9D,MAAMkB,EAAQuvB,EAAK66D,WAAkB,MAAEtrF,MAIvCyf,EAHcve,EAAMa,SAAW2e,EAAMxf,MAAMa,QACvC2e,EAAMxf,MAAMoG,MACR,CAACgoC,EAAKttC,KAA4B,IAAlBd,EAAMc,IAAiBd,EAAMc,KAAWstC,GAG5D,IAAM,sBAAA3tC,OAAsB8uB,EAAKxiB,KAAI,mDAAAtM,OACDT,EAAK,eAAa,IAAAS,OAC9C+e,EAAMxf,MAAK,K,CAErBuvB,EAAK66D,WAAkB,OAAK76D,EAAK66D,WAAkB,MAAEtrF,OACvDyf,EACIiB,EAAMvf,QAAUsvB,EAAK66D,WAAkB,MAAEtrF,MACzC,IAAM,sBAAA2B,OAAsB8uB,EAAKxiB,KAAI,kDACH,GAAAtM,OAC3B8uB,EAAK66D,WAAkB,MAAEtrF,MAAK,cAAA2B,OAAa+e,EAAMvf,SAGlE,CAEQu8F,SAAAA,CAAUr+E,GAChB,MAAM7b,EAAyB,CAAC,EAChC,IAAK,MAAM2qB,KAAa9O,EACtB,GAAuB,MAAnBzf,KAAK68F,YAAgD,MAA1B78F,KAAK68F,WAAWp9E,QACN,MAArCzf,KAAK68F,WAAWp9E,OAAO8O,GAAoB,CAE7C3qB,EADe5D,KAAK68F,WAAWp9E,OAAO8O,GACxBlgB,MAAQoR,EAAO8O,E,MAE7B3qB,EAAO2qB,GAAa9O,EAAO8O,GAG/B,OAAO3qB,CACT,CAEQm6F,WAAAA,CAAYt+E,GAClB,MAAMqgF,EAAa1yF,OAAOkc,KAAK7J,GAAQgP,OAAOpgB,IAC5C,MAAOu9E,GAAYC,GAAcx9E,GACjC,OAAqC,MAA9BrO,KAAKqtF,MAAMc,MAAMvC,KAE1B,GAAIkU,EAAW39F,OAAS,EACtB,MAAM,IAAIL,MACN,0DAAAC,OACU+9F,EAAU,gCAE5B,CAEQ7B,UAAAA,CAAWv+E,GACjB,OAAOA,EAAQlY,IAAI6G,IACjB,GAAuB,MAAnBrO,KAAK68F,YAAiD,MAA3B78F,KAAK68F,WAAWn9E,SACV,MAAjC1f,KAAK68F,WAAWn9E,QAAQrR,GAAe,CAEzC,OADerO,KAAK68F,WAAWn9E,QAAQrR,GACzBA,I,CAEhB,OAAOA,GACN,CAAC,EACN,CAEQ6vF,YAAAA,CAAax+E,GACnBA,EAAQtW,QAAQiF,IACd,MAAO0xF,GAAkBlU,GAAcx9E,GACvC,IAAKrO,KAAKqtF,MAAMc,MAAM4R,GACpB,MAAM,IAAIj+F,MAAM,eAADC,OAAgBsM,EAAI,iCAGzC,EC1pBI,MAAO2xF,GACXxgG,WAAAA,GAE4C,IAD/BygG,EAAA37F,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAwC,CAAC,EACzC47F,EAAA57F,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAA6B,CAAC,EAD9B,KAAA27F,sBAAAA,EACA,KAAAC,aAAAA,CAAkC,CAW/CjG,YAAAA,CAAa5rF,EAAci/E,GACzBttF,KAAKigG,sBAAsB5xF,GAAQi/E,EAAUwL,OAC7C94F,KAAKkgG,aAAa5S,EAAU7pE,IAAM6pE,CACpC,CAOAxB,wBAAAA,CAAyBz9E,GACvB,OAAOrO,KAAKigG,sBAAsB5xF,EACpC,CAMA6rF,gBAAAA,CAAiBz2E,GACf,OAAOzjB,KAAKkgG,aAAaz8E,EAC3B,CAKA7hB,OAAAA,GACE,IAAK,MAAMgM,KAAO5N,KAAKkgG,aACrBlgG,KAAKkgG,aAAatyF,GAAKwlF,uBAChBpzF,KAAKkgG,aAAatyF,GAG3B,IAAK,MAAMS,KAAQrO,KAAKigG,sBACtBjgG,KAAKigG,sBAAsB5xF,GAAMzM,iBAC1B5B,KAAKigG,sBAAsB5xF,EAEtC,EC7CK,MAAM8xF,GAAqB,oBACrBC,GAAqB,aAc5B,MAAOC,GA0DX7gG,WAAAA,CACY8gG,GACC,IAD2BnkE,EAAA73B,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAA8B,CAAC,EACnEi8F,EAAIj8F,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAGk8F,EADC,KAAAF,SAAAA,EAA4B,KAAAnkE,YAAAA,EAxDhC,KAAA2gB,QAAU,MA0DhB98C,KAAKwgG,GAAKD,EACS,MAAfpkE,IACFn8B,KAAKm8B,YAAc,CAAC,GAEtBn8B,KAAKkrF,gBAAkB,IAAI8U,EAC7B,CArDA,gBAAIS,GACF,OAAOzgG,KAAK88C,OACd,CAEA,cAAIogD,GACF,OAAOl9F,KAAK0gG,SAASxD,UACvB,CAEA,eAAIC,GACF,OAAOn9F,KAAK0gG,SAASvD,WACvB,CAEA,UAAI19E,GACF,OAAOzf,KAAK0gG,SAASjhF,MACvB,CAEA,WAAIC,GACF,OAAO1f,KAAK0gG,SAAShhF,OACvB,CAEA,WAAIib,GACF,OAAO36B,KAAK0gG,SAASpG,SACvB,CAEA,YAAIz5D,GACF,OAAO7gC,KAAK+4B,UAAUQ,mBACxB,CAEA,kBAAIonE,GACF,OAAO3gG,KAAKs5B,SACd,CAEA,6BAAIsnE,GACF,OAAO5gG,KAAK6gG,oBACd,CAqBQC,aAAAA,GAEN,MAAMhiF,EAAO9e,KAAKsgG,SAClB,GAAmC,MAA9BxhF,EAAsB6e,KAEzB39B,KAAKu8B,QAAUzd,OACV,GAAoC,MAAhC9e,KAAKm8B,YAAYgM,YAC1BnoC,KAAKu8B,QAAUv8B,KAAKwgG,GAAG/zD,mBACJ3tB,EAAgB9e,KAAKm8B,iBACnC,CACL,MAAM4kE,EACF/gG,KAAKwgG,GAAGtkE,gBAAgBpd,EAAgB9e,KAAKm8B,aACjD,GAAwB,IAApB4kE,EAAS5+F,OAGX4+F,EAASh8F,KACL/E,KAAKwgG,GAAG/zD,mBAAmB3tB,EAAgB9e,KAAKm8B,mBAC/C,GAAI4kE,EAAS5+F,OAAS,EAC3B,MAAM,IAAIL,MACN,wBAAAC,OAAwBg/F,EAAS5+F,OAAM,gCAAAJ,OAC/B,CAAC+c,GAAK,MAEpB9e,KAAKu8B,QAAUwkE,EAAS,E,CAE5B,CAMApjE,IAAAA,GAIE,GADA39B,KAAK8gG,gBACoB,MAArB9gG,KAAKu8B,QAAQoB,KACf,MAAM,IAAI77B,MACN,iHAON,MAAMk/F,EAAahhG,KAAKu8B,QAAQoB,OAChC,OAAI9d,GAAemhF,GACVA,EAAWv1F,KAAKstB,GAAa/4B,KAAKihG,SAASloE,IAG7C/4B,KAAKihG,SAASD,EACvB,CAQAC,QAAAA,CAASloE,GACP/4B,KAAK+4B,UAAYA,EACjB,MAAMs0D,EAAQrtF,KAAK+4B,UAAUE,cAE7B,IAAIK,EAAYt5B,KAAK+4B,UAAUO,UAC/B,GAA0C,MAAtCt5B,KAAK+4B,UAAUQ,oBAA6B,CAC9C,MAAMsH,EAAW7gC,KAAK+4B,UAAUQ,oBACN,MAAtBsH,EAASvH,YACXA,EAAYuH,EAASvH,WAGc,MAAjCuH,EAASggE,uBACX7gG,KAAK6gG,qBAAuBhgE,EAASggE,qB,CAGzC7gG,KAAKs5B,UAAYA,EAEjBt5B,KAAK88C,QAAU,GAAH/6C,OAAMsrF,EAAMr4D,SAASksE,SAAQ,KAAAn/F,OAAIsrF,EAAMr4D,SAASmsE,aAC5D,MAAM7G,EAAYt6F,KAAKwgG,GAAGxpE,cACtBh3B,KAAK+4B,UAAUc,WAAY75B,KAAK+4B,UAAUa,aAQ9C,GAPA55B,KAAK0gG,SAAW,IAAIzE,GAChBvP,GAAgBC,SAASoB,eAAeV,EAAOrtF,KAAKs5B,YACxDt5B,KAAK0gG,SAASpG,UAAYt6F,KAAKohG,6BAA6B9G,GAG5Dt6F,KAAK0gG,SAASxV,gBAAkBlrF,KAAKkrF,gBAEH,MAA9BnyD,EAAUS,kBACmD,MAA5DT,EAAUS,iBAA0C3I,KAAc,CACrE,MAAMwwE,EACF3U,GAAgBC,SAASoB,eAAeh1D,EAAUS,kBACtDx5B,KAAKqhG,YAAc,IAAIpF,GAAcoF,GACrCrhG,KAAKqhG,YAAY/G,UAAYt6F,KAAK0gG,SAASpG,UAI3Ct6F,KAAKqhG,YAAYnW,gBAAkBlrF,KAAKkrF,gBACxClrF,KAAKqhG,YAAYxC,aAAa,CAAC,EAAG,G,CAGpC,OAAO,CACT,CA8CA,UAAM1sE,CAAKmvE,EAAmCrmF,GAE5C,GAA4B,kBAAjBqmF,EAA2B,CACpC,MAAMP,EAAW/gG,KAAKwgG,GAAGzkE,gBAAgBulE,GACzC,GAAwB,IAApBP,EAAS5+F,OACX,MAAM,IAAIL,MAAM,0CAADC,OAC+Bu/F,EAAY,MACrD,GAAIP,EAAS5+F,OAAS,EAC3B,MAAM,IAAIL,MACN,wBAAAC,OAAwBg/F,EAAS5+F,OAAM,gCAAAJ,OAC/Bu/F,EAAY,MAE1BA,EAAeP,EAAS,E,CAE1B,GAAyB,MAArBO,EAAanvE,KACf,MAAM,IAAIrwB,MACN,+GAIN,OAAOw/F,EAAanvE,KAAKnyB,KAAK+4B,UAChC,CAyCAwoE,OAAAA,CAAQ9hF,EAAwCxE,GAE9C,MAAMumF,EAAgBxhG,KAAK69F,QAAQp+E,EAAQzf,KAAKm9F,aAChD,GAAIn9F,KAAK6gG,qBAAsB,CAC7B,MAEMY,EAAkC,CAAC,EAMzC,OAPID,aAAyBh+E,GAAS,CAACg+E,GAAiBA,GAGrCp4F,QACf,CAACs4F,EAAcp+F,IAAMm+F,EAAgBzhG,KAAK6gG,qBAAqBv9F,IAC3Do+F,GAEDD,C,CAET,OAAOD,CACT,CAEQG,eAAAA,CAAgBliF,GAEtB,KAAMA,aAAkB+D,MAAY5e,MAAMC,QAAQ4a,GAEhD,OAAOA,EAGT,IADAA,EAAS7a,MAAMC,QAAQ4a,GAAUA,EAAS,CAACA,IAChCtd,SAAWnC,KAAKk9F,WAAW/6F,OACpC,MAAM,IAAIL,MACN,+BAA8B,uBAAAC,OACP/B,KAAKk9F,WAAW/6F,OAAM,mBAAiB,mBAAAJ,OAC3C0d,EAAOtd,OAAM,oBAEtC,OAAOnC,KAAKk9F,WAAW1yF,OAAO,CAAChD,EAAK+mB,EAAWjrB,KAC7CkE,EAAI+mB,GAAc9O,EAAoBnc,GAC/BkE,GACN,CAAC,EACN,CAEQo6F,gBAAAA,CAAiBliF,GAEvB,OADAA,EAAUA,GAAW1f,KAAKm9F,YAClBv4F,MAAMC,QAAQ6a,GAAuBA,EAAZ,CAACA,EACpC,CAkBAm+E,OAAAA,CAAQp+E,EAAwCC,GAE9CD,EAASzf,KAAK2hG,gBAAgBliF,GAC9BC,EAAU1f,KAAK4hG,iBAAiBliF,GAChC,MAAM9b,EAAS5D,KAAK0gG,SAAS7C,QAAQp+E,EAAQC,GAC7C,OAAO9b,EAAOzB,OAAS,EAAIyB,EAASA,EAAO,EAC7C,CAiBA,kBAAMi7F,CACFp/E,EACAC,GACFD,EAASzf,KAAK2hG,gBAAgBliF,GAC9BC,EAAU1f,KAAK4hG,iBAAiBliF,GAChC,MAAM9b,QAAe5D,KAAK0gG,SAAS7B,aAAap/E,EAAQC,GACxD,OAAO9b,EAAOzB,OAAS,EAAIyB,EAASA,EAAO,EAC7C,CAQAq7F,sBAAAA,GACE,OAAOj/F,KAAK0gG,SAASzB,wBACvB,CAQAF,0BAAAA,GACE/+F,KAAK0gG,SAAS3B,4BAChB,CAEQqC,4BAAAA,CAA6B55F,GACnC,OAAO4F,OAAOkc,KAAK9hB,GAAKgD,OAAO,CAACq3F,EAAyBj0F,KACvDi0F,EAAOj0F,GAAO,CAACpG,EAAIoG,IACZi0F,GACN,CAAC,EACN,CAOAjgG,OAAAA,GACE5B,KAAK0gG,SAAS9+F,UAEV5B,KAAKqhG,aACPrhG,KAAKqhG,YAAYz/F,UAGnB5B,KAAKkrF,gBAAgBtpF,SACvB,EAkCKw0B,eAAe0rE,GAClBxB,GACS,IADsBr/F,EAAAqD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAA0B,CAAC,EAC1Di8F,EAAIj8F,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAGk8F,EACT,GAAgB,MAAZF,EACF,MAAM,IAAIx+F,MACN,0GAGS,MAAXb,IACFA,EAAU,CAAC,GAGTA,EAAQ8gG,WAAiC,kBAAbzB,IAC9BA,EAiEJ,SAAqBA,GACdA,EAASlrE,SAAS,OACrBkrE,GAAwB,KAE1B,MAAO,GAAPv+F,OAAUu+F,GAAQv+F,OAAGq+F,IAAkBr+F,OAAGo+F,GAC5C,CAtEe6B,CAAY1B,IAEzB,MAAM2B,EAAQ,IAAI5B,GAAWC,EAAUr/F,EAASs/F,GAEhD,aADM0B,EAAMtkE,OACLskE,CACT,C,0zDCldA,IAAAC,GAAA,WACE,SAAApkF,EACuBA,EACH3P,GADG,KAAA8zF,MAAAnkF,EACH,KAAAqkF,aAAAh0F,EAClB,IAAMpI,EACF/F,KAAKiiG,MAAMxiF,OAAO,GAAGne,MACzBue,GACwB,IAAnB9Z,EAAW,KAAkC,IAAnBA,EAAW,GACtC,WAAM,sBAAgBA,EAAW,QAAOA,EAAW,qCAyD3D,OAtCE+X,EAAA+7E,UAAA0H,QAAA,SAAQzjF,GAAR,IAAA3P,EAAA,KAME,OAAOyc,GAAQ,WACb,IAAM7kB,EAAUoI,EAAKi0F,gBAAgB79E,GAAQzG,EAAO,YAC9Cpa,EAAU8xD,GAAczvD,EAAS,GAEjC0rB,EADUtjB,EAAK8zF,MAAMV,QAAQ79F,GACM8D,IAAI,SAAAsW,GAAK,OAAA0pD,GAAW1pD,EAAA,CAAI,MAE3Dxa,EAAe6K,EAAKk0F,kBAAkB5wE,GAE5C,MAAO,CACL6wE,cAAev3C,GAAWznD,EAAai/F,SACvCC,QAASl/F,EAAak/F,QACtBC,gBAAiBn/F,EAAam/F,gBAC9BC,gBAAiBp/F,EAAao/F,gBAAA,IAiBpC5kF,EAAA+7E,UAAAj4F,QAAA,WACE5B,KAAKiiG,MAAMrgG,SAAA,EAAAkc,CAAA,CA/Df,GA+De6kF,GAAA,SAAA7kF,GCzEf,SAAA3P,IAAA,cAAA2P,GAAAA,EAAAlU,MAAA,KAAAtF,YAAA,KAUA,OAV+Bs+F,GAAAz0F,EAAA2P,GAC7B3P,EAAA0rF,UAAAuI,gBAAA,SAAgBtkF,GAEd,OAAO8M,GAAQ,WAAM,OAAA61B,GAAOvD,GAAOp/B,EAAO,OAAQ,MAGpD3P,EAAA0rF,UAAAwI,kBAAA,SAAkBvkF,GAEhB,MAAO,CAAC0kF,QAAA1kF,EAAA,GAASykF,QAAAzkF,EAAA,GAAS2kF,gBAAA3kF,EAAA,GAAiB4kF,gBAAA5kF,EAAA,KAAA3P,CAAA,CDiEhC,CCzEgB+zF,ICA/B,SAASj7B,GAAKnpD,GACZ,OAAOzb,KAAKkJ,MAAMuS,EAAI,GAGxB,IAAA+kF,GAAA,WAKE,SAAA/kF,EAAYA,EAAiB3P,GAC3BnO,KAAK8iG,cAAgB,IAAIl+F,MAAMkZ,GAC/B9d,KAAK+iG,kBAAoB,EACzB/iG,KAAKgjG,gBAAkB70F,CAAA,CAkE3B,OA/DS2P,EAAA+7E,UAAAoJ,QAAP,SAAenlF,GACb9d,KAAK8iG,gBAAgB9iG,KAAK+iG,kBAAoBjlF,EAC9C9d,KAAKkjG,KAAKljG,KAAK+iG,iBAAA,EAGVjlF,EAAA+7E,UAAAsJ,QAAP,WACE,IAAMrlF,EAAM9d,KAAK8iG,cAAc,GAI/B,OAHA9iG,KAAKojG,SAAS,EAAGpjG,KAAK+iG,oBACtB/iG,KAAKqjG,KAAK,GACVrjG,KAAK8iG,cAAc9iG,KAAK+iG,iBAAmB,GAAK,KACzCjlF,CAAA,EAGFA,EAAA+7E,UAAAyJ,MAAP,WACE,OAAkC,IAA3BtjG,KAAK+iG,gBAAA,EAGPjlF,EAAA+7E,UAAA50F,KAAP,WACE,OAAOjF,KAAK+iG,iBAAmB,GAG1BjlF,EAAA+7E,UAAAp5E,IAAP,WACE,OAAOzgB,KAAK8iG,cAAc17F,MAAM,EAAGpH,KAAK+iG,iBAAmB,IAGtDjlF,EAAA+7E,UAAAh3F,IAAP,WACE,OAAO7C,KAAK8iG,cAAc,IAGpBhlF,EAAA+7E,UAAAqJ,KAAR,SAAaplF,GACX,KAAOA,EAAI,GAAK9d,KAAKm3D,KAAK8P,GAAKnpD,GAAIA,IACjC9d,KAAKojG,SAAStlF,EAAGmpD,GAAKnpD,IACtBA,EAAImpD,GAAKnpD,EAAA,EAILA,EAAA+7E,UAAAwJ,KAAR,SAAavlF,GACX,KAAO,EAAIA,GAAK9d,KAAK+iG,kBAAkB,CACrC,IAAI50F,EAAI,EAAI2P,EAIZ,GAHI3P,EAAInO,KAAK+iG,kBAAoB/iG,KAAKm3D,KAAKhpD,EAAGA,EAAI,IAChDA,KAEGnO,KAAKm3D,KAAKr5C,EAAG3P,GAChB,MAEFnO,KAAKojG,SAAStlF,EAAG3P,GACjB2P,EAAI3P,CAAA,GAIA2P,EAAA+7E,UAAA0J,WAAR,SAAmBzlF,GACjB,OAAO9d,KAAKgjG,gBAAgBhjG,KAAK8iG,cAAchlF,GAAA,EAGzCA,EAAA+7E,UAAA1iC,KAAR,SAAar5C,EAAW3P,GACtB,OAAOnO,KAAKujG,WAAWzlF,GAAK9d,KAAKujG,WAAWp1F,EAAA,EAGtC2P,EAAA+7E,UAAAuJ,SAAR,SAAiBtlF,EAAW3P,GAC1B,IAAMpI,EAAI/F,KAAK8iG,cAAchlF,GAC7B9d,KAAK8iG,cAAchlF,GAAK9d,KAAK8iG,cAAc30F,GAC3CnO,KAAK8iG,cAAc30F,GAAKpI,CAAA,EAAA+X,CAAA,CAxE5B,GCLA,SAES0lF,GACL1lF,EAAoB3P,EAAepI,EAAkBrC,EACrD+tB,EAA4BnuB,GAM9B,IALM,IAAAmE,EAAAnE,EAAAhC,MAAC0b,EAAAvV,EAAA,GAAQjE,EAAAiE,EAAA,GAEXqa,GAAA,EACE+U,EAASx0B,KAAKQ,IAAIkD,EAAW0rB,EAAoB,GACjD/mB,EAAOrI,KAAKM,IAAIoD,EAAW0rB,EAAqB,EAAGzU,GAChD3S,EAAWwsB,EAAQxsB,EAAWK,IAAQL,EAAU,CAGvD,IAFA,IAAMxJ,EAASwB,KAAKQ,IAAIa,EAAW+tB,EAAoB,GACjDzT,EAAO3b,KAAKM,IAAIe,EAAW+tB,EAAqB,EAAGjuB,GAChDs3B,EAAWj6B,EAAQi6B,EAAW9c,IAAQ8c,EAC7C,GAAIx3B,EAAOxD,IAAIuK,EAAUywB,EAAUhd,GAAc3P,EAAO,CACtD2T,GAAA,EACA,MAGJ,IAAKA,EACH,MAIJ,OAAOA,CAAA,CCtBT,IAAa2hF,GAAA,CACX,OAAQ,UAAW,WAAY,UAAW,WAAY,eACtD,gBAAiB,YAAa,aAAc,YAAa,aACzD,UAAW,WAAY,WAAY,YAAa,YAAa,cAGlDC,GAAgBD,GAAUthG,OAM1BwhG,GACTF,GAAUj5F,OAAO,SAACsT,EAAoB3P,EAAWpI,GAE/C,OADA+X,EAAO3P,GAAapI,EACb+X,CAAA,MAGP,EACH,UAAW,iBAAkB,YAAa,iBAC1C,YAAa,cAAe,UAAW,aACvC,WAAY,cAAe,WAAY,kBACvC,aAAc,kBAAmB,aAAc,eAC/C,WAAY,cAAe,YAAa,eACxC,eAAgB,kBAAmB,UAAW,aAoBMtW,IACnD,SAACsW,GAAA,IAAC3P,EAAA2P,EAAA,GAAY/X,EAAA+X,EAAA,GAAgB,OAAE6lF,GAAQx1F,GAAaw1F,GAAQ59F,GAAA,GCjDjE,SAGgB69F,GACZ9lF,EAAW3P,EAAWpI,EAAkBrC,GAC1C,MAAO,CACL2Z,EAAG3Z,EAAQ5D,IAAIge,EAAG3P,EAAGpI,GACrBnD,EAAGc,EAAQ5D,IAAIge,EAAG3P,EAAGpI,EAAW29F,IAAA,CAIpC,SAAgBG,GACZ/lF,EAAY3P,EAAsBpI,GAC7B,IACDrC,EAAAkgG,GAAA9lF,EAAAgmF,SAAAhmF,EAAAimF,SAAAjmF,EAAA2F,GAAA1d,GAAC0rB,EAAA/tB,EAAA2Z,EAAG/Z,EAAAI,EAAAd,EACV,MAAO,CACLA,EAAGkb,EAAKimF,SAAW51F,EAAe7K,EAClC+Z,EAAGS,EAAKgmF,SAAW31F,EAAesjB,EAAA,CAItC,SAUgB/uB,GAAMob,EAAW3P,EAAapI,GAC5C,OAAI+X,EAAI3P,EACCA,EAEL2P,EAAI/X,EACCA,EAEF+X,CAAA,CAUT,SAAgBkmF,GAAWlmF,EAAa3P,GACtC,MAAO,CAACvL,EAAGkb,EAAElb,EAAIuL,EAAEvL,EAAGya,EAAGS,EAAET,EAAIlP,EAAEkP,EAAA,CCjDnC,IAMM4mF,GF+BO,EACV,OAAQ,YAAa,UAAW,YAAa,OAAQ,aACrD,WAAY,aAAc,OAAQ,iBAClC,eAAgB,cAAe,YAAa,cAC5C,eAAgB,YAAa,UAAW,aACxC,WAAY,cAAe,OAAQ,kBACnC,gBAAiB,eAAgB,aAAc,eAC/C,gBAAiB,aAAc,WAAY,cAC3C,YAAa,eEvCsCz8F,IAClD,SAACsW,GAAA,IAAC3P,EAAA2P,EAAA,GAAgB/X,EAAA+X,EAAA,GACd,OAAE6lF,GAAQx1F,GAAiBw1F,GAAQ59F,GAAA,GAErCm+F,GACFD,GAAqBz8F,IAAI,SAACsW,GAAqB,OAAAA,EAAA,KAE7CqmF,GACFF,GAAqBz8F,IAAI,SAACsW,GAEK,OAAAA,EAAA,KAWnC,SAASsmF,GACLtmF,EAAiB3P,EAAsBpI,EACvCrC,GACF,MAAO,CACL2Z,EAAG3a,GAAML,KAAKuc,MAAMd,EAAMT,EAAIlP,GAAe,EAAGpI,EAAS,GACzDnD,EAAGF,GAAML,KAAKuc,MAAMd,EAAMlb,EAAIuL,GAAe,EAAGzK,EAAQ,IAW5D,SAAS2gG,GACLvmF,EAAgB3P,EAA0BpI,EAC1CrC,EAA8B+tB,EAAyBnuB,EACvDmE,EAA+BuV,QAAA,IAAAA,IAAAA,EAAA,GAYjC,IAXM,IAAAxZ,EAAAE,EAAApC,MAACwgB,EAAAte,EAAA,GAAQqzB,EAAArzB,EAAA,GAMTkH,EAnCR,SACIoT,EAAgB3P,EAAiBpI,GACnC,IAAMrC,EAAWqC,EAAczE,MAAM,GAAK,EAC1C,MAAO,CACL+b,EAAGtX,EAAcjG,IAAIqO,EAAMkP,EAAGlP,EAAMvL,EAAGkb,GACvClb,EAAGmD,EAAcjG,IAAIqO,EAAMkP,EAAGlP,EAAMvL,EAAGc,EAAWoa,GAAA,CA+BhDwmF,CAAgBxmF,EAJUsmF,GAC1Bj2F,EAAequC,SAAUl5C,EAAcwe,EAAQ+U,GAGApvB,GAG/C4C,EADmB25F,GAAW71F,EAAequC,SAAU9xC,GAElD7J,EAAI,EAAGA,EAAImc,EAAkBnc,IAAK,CACzC,IAAMmd,EACFomF,GAAyB/5F,EAAgB/G,EAAcwe,EAAQ+U,GAE7DiE,EAAc8oE,GAChB5lF,EAAsBX,EAAGW,EAAsBpb,EAAGmD,EAClD0rB,GAEJpnB,EAAiB25F,GAAA,CAEXphG,EAAGob,EAAsBpb,EAAIU,EAC7B+Z,EAAGW,EAAsBX,EAAI/Z,GAAA,CAE9BV,EAAGk4B,EAAYl4B,EAAGya,EAAGyd,EAAYzd,GAAA,CAExC,IAAMU,EACFqmF,GAAyB/5F,EAAgB/G,EAAcwe,EAAQ+U,GAC7DnI,EAAQhrB,EAAa5D,IACvBie,EAAsBV,EAAGU,EAAsBnb,EAAGmD,GAEtD,MAAO,CAACy2C,SAAUnyC,EAAgBk6F,KAAMd,GAAU19F,GAAmBquE,MAAA1lD,EAAA,CASvE,SAAgB81E,GACZ1mF,EAAqB3P,EAAwBpI,EAC7CrC,EAAsB+tB,EACtBnuB,GACF,IAAMmE,EAAW0G,EAAO7M,MAAM,GACxB0b,EAAWknF,GAAmB/hG,OAE9BqB,EAAgC,IAAIoB,MAAM6C,GAEzCqa,EAAAhE,EAAAymF,KAAgB1tE,EAAA/Y,EAAAs2D,MACjB1pE,EAAYm5F,GAAe/hF,EAAUpe,EAAcqC,GAEzDvC,EAAkBse,EAAS2B,IAAA,CACzB2wD,MAAOv9C,EACP0tE,KAAMd,GAAU3hF,EAAS2B,IACzB+4B,SAAU9xC,GAKZ,IAAK,IAAIL,EAAO2S,EAAW,EAAG3S,GAAQ,IAAKA,EAAM,CAC/C,IAAMxJ,EAAmBqjG,GAAmB75F,GACtC2T,EAAmBmmF,GAAmB95F,GACxC7G,EAAkB3C,KACjB2C,EAAkBwa,KACrBxa,EAAkBwa,GAAoBqmF,GAClCh6F,EAAM7G,EAAkB3C,GAAmBmd,EAAkB7P,EAC7DpI,EAASrC,EAAcJ,GAAA,CAM/B,IAAS+G,EAAO,EAAGA,EAAO2S,IAAY3S,EAC9BxJ,EAAmBsjG,GAAmB95F,GACtC2T,EAAmBkmF,GAAmB75F,GACxC7G,EAAkB3C,KACjB2C,EAAkBwa,KACrBxa,EAAkBwa,GAAoBqmF,GAClCh6F,EAAM7G,EAAkB3C,GAAmBmd,EAAkB7P,EAC7DpI,EAASrC,EAAc+tB,IAI/B,OAAOjuB,CAAA,CCjIT,SAISihG,GACL3mF,EAAe3P,EAA0BpI,EACzCrC,GAAA,IAD0C+tB,EAAA1rB,EAAAnD,EAAGU,EAAAyC,EAAAsX,EAE/C,OAAOS,EAAMwI,KAAK,SAACxI,GAAA,IACX/X,EAAA+X,EAAA4mF,UAAkChhG,GAAY84C,SACpD,OF8BJ,SACI1+B,EAAY3P,EAAYpI,EAAYrC,GACtC,IAAM+tB,EAAK1rB,EAAK+X,EACVxa,EAAKI,EAAKyK,EAChB,OAAOsjB,EAAKA,EAAKnuB,EAAKA,CAAA,CElCbqhG,CACIrhG,EAAGmuB,EAAG1rB,EAAsBsX,EAAGtX,EAAsBnD,IAC5DuL,CAAA,GAQR,SAASy2F,GACL9mF,EAAuB3P,EACvBpI,GAUF,OATkCA,EAAkByE,OAChD,SAACzE,EAAQrC,EAAmB+tB,GAAA,IAAlBnuB,EAAAI,EAAA84C,SAAU/0C,EAAA/D,EAAA0wE,MAKlB,OAJKqwB,GACG3mF,EAAe3P,EAAkB7K,EAAUmuB,KACjD1rB,GAAU0B,GAEL1B,CAAA,EACN,GAE+BA,EAAkB5D,MAAA,CA+D1D,SAAgB0iG,GACZ/mF,EAA8B3P,EAC9BpI,EACArC,EAAwC+tB,EACxCnuB,EAA2BmE,EAAsBuV,QAAA,IAAAvV,IAAtBA,EAAA,aAAAuV,IAAsBA,EAAA,IAUnD,IATA,IAAMxZ,EAAA,GAEAse,EJrER,SACIhE,EAAwB3P,EACxBpI,GAMF,IALM,IAAArC,EAAAqC,EAAAzE,MAACmwB,EAAA/tB,EAAA,GAAQJ,EAAAI,EAAA,GAAO+D,EAAA/D,EAAA,GAEhBsZ,EAAQ,IAAI6lF,GACdpxE,EAASnuB,EAAQmE,EAAc,SAACqW,GAAY,OAAAA,EAAAs2D,KAAA,GAEvC5wE,EAAW,EAAGA,EAAWiuB,IAAUjuB,EAC1C,IAAK,IAAIse,EAAW,EAAGA,EAAWxe,IAASwe,EACzC,IAAK,IAAI+U,EAAa,EAAGA,EAAapvB,IAAgBovB,EAAY,CAChE,IAAMnsB,EAAQ3E,EAAOjG,IAAI0D,EAAUse,EAAU+U,GAIzCnsB,EAAQoT,GAKR0lF,GACI3sE,EAAYnsB,EAAOlH,EAAUse,EAAU3T,EACvCpI,IACNiX,EAAMimF,QAAA,CAAS7uB,MAAA1pE,EAAO65F,KAAA,CAAOT,SAAAtgG,EAAUugG,SAAAjiF,EAAU2B,GAAIoT,IAAA,CAM7D,OAAO7Z,CAAA,CIwCO8nF,CACVr9F,EAjEsB,EAiEeqW,GAEnC+Y,EAAmB7Z,EAAYA,EAI9BxZ,EAAMrB,OAASmB,IAAsBwe,EAAMwhF,SAAS,CAEzD,IAAM54F,EAAOoX,EAAMqhF,UAOnB,IAAIsB,GACIjhG,EAAOqzB,EAFXgtE,GAAen5F,EAAK65F,KAAM9yE,EAActjB,GAEMzD,EAAK65F,KAAK9gF,IAD5D,CAMA,IAAMpZ,EAAYm6F,GACd95F,EAAMoT,EAAc3P,EAAesjB,EAAc1rB,EACjDrC,GAEE7C,EAAQ+jG,GAAiBphG,EAAOqzB,EAAkBxsB,GAExD7G,EAAMuB,KAAA,CAAM2/F,UAAAr6F,EAAW+pE,MAAAvzE,GAAA,EAGzB,OAAO2C,CAAA,CC5HT,SAAgBuhG,GAASjnF,GACjB,IAAA3P,EAAA2P,EAAAxc,MAACyE,EAAAoI,EAAA,GAAQzK,EAAAyK,EAAA,GAAOsjB,EAAAtjB,EAAA,GAEtB,OAAOyc,GAAQ,WACb,IAAMzc,EAAW+7C,GAAWpsC,EAAA,CAAS/X,EAASrC,EAAO+tB,IAC/CnuB,EAASyhD,GAAU52C,EAAU,GAE7B1G,EAAU+tD,GAActY,GAAO55C,EAAQg7C,GAAU56C,EAAO,UAAW,GACnEsZ,EAAUw4C,GAlBpB,SAEa13C,EAAgB3P,GAC3B,OAAOyc,GAAQ,WACb,IAAM7kB,EAAUm3C,GAAOp/B,EAAGwgC,GAAUnwC,EAAG,UAEvC,OAAOsyC,GAAO3iC,EAAGZ,GAAOnX,EAASu4C,GAAUnwC,EAAG,aAYhBmtD,CAAIh4D,EAAuBI,GAAQ,GAEjE,OAAO3B,GAAA,CAAW0F,EAASuV,GAAU,KCDzC,SAASgoF,GACLlnF,EAAW3P,EAAWpI,EACtBrC,GACF,MAAO,CACL2Z,EAAG3Z,EAAc5D,IAAIge,EAAG3P,EAAGpI,GAC3BnD,EAAGc,EAAc5D,IAAIge,EAAG3P,EAAGpI,EAAW29F,IAAA,CAsB1C,SAAgBuB,GACZnnF,EAAkD3P,EAClDpI,GACF,OAAO6kB,GAAQ,WACb,IAAMlnB,EAtBV,SACIoa,EACA3P,GAGF,IAFA,IAAMpI,EAAA,GAEGrC,EAAW,EAAGA,EAAWggG,GAAehgG,IAAY,CAC3D,IAGM+tB,EAAAuzE,GAHWlnF,EAAoBhe,IAAI4D,EAAU,GAAGwhG,UACrCpnF,EAAoBhe,IAAI4D,EAAU,GAAGwhG,UAAAxhG,EAAAyK,GAE/C7K,EAAAmuB,EAAA7uB,EAAG6E,EAAAgqB,EAAApU,EAEVtX,EAAOhB,KAAK0C,GACZ1B,EAAOhB,KAAKzB,EAAA,CAGd,OAAO2kE,GAAYliE,EAAA,CAAS29F,GAAe,IAOnByB,CAAiBrnF,EAAqB/X,GAE5D,OAAOwX,GACEgH,GACGrH,GACCY,EAAoBqF,WAAYm7B,GAAUnwC,EAC7C,UAAW,WAAYzK,EAAA,GCjBrC,SAAsB0hG,GAClBtnF,EAA4B3P,EAC5BpI,GAAA,OAAAs/F,GAAA,kCAAA3hG,EAAA+tB,EAAAnuB,EAAAmE,EAAAuV,EAAAxZ,EAAAse,EAAA+U,EAAAnsB,EAAAL,EAAA,OAAAi7F,GAAA,cAAAzkG,GAAA,OAAAA,EAAA0kG,OAAA,OAKuB,OAJrB7hG,EAAa,EAEX+tB,EAAgBszE,GAASjnF,GAAA,GAEApX,QAAQ+Z,IAAA,CAClC3C,EAAc+F,SAAU1V,EAAQ0V,SAAU4N,EAAc5N,YAAA,OAQlC,OATrBvgB,EAAmBzC,EAAA2kG,OAGnB/9F,EAAenE,EAAiB,GAChC0Z,EAAgB1Z,EAAiB,GACjCE,EAAsBF,EAAiB,OAEvCwe,EACFmjF,GAAgBzhG,EAAqBuC,EAAciX,IACT6G,UAAA,OAoB9C,OApBMgT,EAAqBh2B,EAAA2kG,OAErB96F,EACF9F,MAAM4X,KD1DZ,SAKIsB,EACA3P,GAIF,IAHA,IAAMpI,EAAeoI,EAAc7M,MAAM,GACnCoC,EAAS,IAAIyE,aAAapC,GAEvB0rB,EAAW,EAAGA,EAAW1rB,EAAc0rB,IAAY,CAC1D,IAAMnuB,EAAI6K,EAAcrO,IAAI2xB,EAAU,GAChChqB,EAAI0G,EAAcrO,IAAI2xB,EAAU,GACtC/tB,EAAO+tB,GAAY3T,EAAche,IAAIwD,EAAGmE,EAAGgqB,EAAA,CAG7C,OAAO/tB,CAAA,CC0CQ+hG,CAAoBh+F,EAAcjE,IAE3C6G,EAAYK,EAAmBlD,IAAI,SAACsW,EAAO3P,GAE/C,OADAzK,GAAcoa,EAAA,CAEZ0+B,SAAA,CACEn/B,EAAGwZ,EAAmB/2B,IAAIqO,EAAY,GACtCvL,EAAGi0B,EAAmB/2B,IAAIqO,EAAY,IAExCo2F,KAAMd,GAAUt1F,GAChBimE,MAAAt2D,EAAA,GAIJ2T,EAAc7vB,UACdkgB,EAAalgB,UAAA,IAEL8iG,UAAAr6F,EAAW+pE,MAAO1wE,EAAa2G,EAAUlI,SAAA,KC3EnD,IAAMujG,GACF,2EACEC,GACF,0EAyBI,ICxBFC,GAAA,EAAiB,QAAS,OAAS,QAAAC,GAAA,SAAA/nF,GAEzC,SAAA3P,IAAA,cAAA2P,GAAAA,EAAAlU,MAAA,KAAAtF,YAAA,KASA,OAT4Bs+F,GAAAz0F,EAAA2P,GAC1B3P,EAAA0rF,UAAAuI,gBAAA,SAAgBtkF,GACd,OAAOP,GAAOO,EAAO8nF,GAAA,EAGvBz3F,EAAA0rF,UAAAwI,kBAAA,SAAkBvkF,GACT,IAAA3P,EAAA2P,EAAA,GAAiB/X,EAAA+X,EAAA,GACxB,MAAO,CAAC0kF,QAAA1kF,EAAA,GAASykF,QAAAzkF,EAAA,GAAS2kF,gBAAAt0F,EAAiBu0F,gBAAA38F,EAAA,EAAAoI,CAAA,CATN,CAEb+zF,ICoBrBp+F,OAAAivE,kBAAmBjvE,OAAAgiG,kBA0B1B,SAAsBC,GAAkBjoF,GAAA,OAAAunF,GAAA,qCAAAC,GAAA,cAAAn3F,GAEtC,MAAO,CAAP,EAAOzH,QAAQ+Z,IAAI3C,EAAQtW,IAAI,SAAAsW,GAAU,OAAAA,EAAO+F,QAAA,SA8ClD,SAAgBmiF,GACZloF,EAAyB3P,GAC3B,OAAI83F,GAAuBnoF,EAAiB3P,GACnC2P,EAGFzb,KAAKkJ,MAAMuS,EAAkB3P,GAAgBA,EAAe,EAGrE,SAAgB+3F,GAAwBpoF,GACtC+B,EAC+B,iBAApB/B,GACwB,iBAApBA,EACX,WAAM,iCAA2BA,EAAA,4DAGN,iBAApBA,IACT+B,EACqC,iBAA1B/B,EAAgBnY,MACvB,WAAM,8CACFmY,EAAgBnY,MAAA,2CACxBka,EACsC,iBAA3B/B,EAAgBozB,OACvB,WAAM,+CACFpzB,EAAgBozB,OAAA,4CAI5B,SAAgBi1D,GACZroF,EACA3P,GAEF,OADA+3F,GAAwBpoF,GACO,iBAApBA,EAAA,CAEPkoF,GAAuBloF,EAAgBozB,OAAQ/iC,GAC/C63F,GAAuBloF,EAAgBnY,MAAOwI,IAAA,CAI9C63F,GAAuBloF,EAAiB3P,GACxC63F,GAAuBloF,EAAiB3P,GAAA,CAK9C,IAAMi4F,GAAA,CAA+C,EAAG,GAAI,IAU5D,SAASH,GACLnoF,EAAoB3P,GACtB,OAAQ2P,EAAa,GAAK3P,GAAiB,EAqB7C,SAAgBk4F,GAAyBvoF,GAEvC,OAAOA,aAAiB0F,GAAA,CAAa1F,EAAMxc,MAAM,GAAIwc,EAAMxc,MAAM,KAC5Bwc,EAAMozB,OAAQpzB,EAAMnY,MAAA,CAO3D,SAcgB2gG,GACZxoF,EAAqB3P,GAAA,IAACpI,EAAAoI,EAAA,GAASzK,EAAAyK,EAAA,GAE3BsjB,EAAA40E,GAAAvoF,GAACxa,EAAAmuB,EAAA,GAAQhqB,EAAAgqB,EAAA,GACTzU,EAAetZ,EAAUqC,EAE3BvC,EAAA,UAACse,EAAAte,EAAA,GAAMqzB,EAAArzB,EAAA,GAAMkH,EAAAlH,EAAA,GAAM6G,EAAA7G,EAAA,GAsBvB,OAvBeiE,EAAQnE,EAEV0Z,GAEX8E,EAAO,EACP+U,EAAO,EACPnsB,EAAOrI,KAAKuc,MAAM,IAAO5B,EAAe1Z,EAASmE,IACjD4C,EAAOhI,KAAKuc,MAAM,IAAO5B,EAAe1Z,EAASmE,MAGjDqa,EAAOzf,KAAKuc,MAAM,IAAQ,EAAM5B,EAAgBvV,EAAQnE,IACxDuzB,EAAOx0B,KAAKuc,MAAM,IAAQ,EAAM5B,EAAgBvV,EAAQnE,IACxDoH,EAAO,EACPL,EAAO,IAUDk8F,QAPqB37E,GAAQ,WACnC,IAAIzc,EAxCR,SAA8B2P,GAC5B,OAAOA,aAAiB0F,GAAY1F,EAAQ0oF,GAAsB1oF,EAAA,CAuC9C2oF,CAAc3oF,GAGhC,OAFA3P,EAAcsvD,GAAStvD,EAAA,EAAe2T,EAAM+U,GAAA,CAAQnsB,EAAML,GAAA,CAAQ,EAAG,KAE9DstB,GAASw/C,eAAehpE,EAAA,CAAcpI,EAASrC,GAAA,GAGvCgjG,QAAA,CAAUjqD,IAAK36B,EAAM7e,KAAMyH,EAAMxH,MAAOmH,EAAMy9C,OAAQjxB,GAAA,CAGzE,SAAgB8vE,GACZ7oF,EAAe3P,EACfpI,EACArC,EAAkB+tB,GAAA,IAFFnuB,EAAA6K,EAAA,GAAQ1G,EAAA0G,EAAA,GACvB6O,EAAAjX,EAAA,GAAuBvC,EAAAuC,EAAA,GAOpB+b,EAzKR,SACIhE,EAAe3P,EAAgBpI,EAAgBrC,EAAa+tB,GAC9D,gBAAA/tB,IADiDA,EAAA,YAAA+tB,IAAaA,EAAA,GAC/C,IAAX1rB,GAA2B,IAAXoI,GAA4B,IAAZzK,GAA6B,IAAZ+tB,EAC5C3T,EAEFA,EAAMtW,IAAI,SAAAsW,GAAQ,OArB3B,SACIA,EAAY3P,EAAgBpI,EAAgBrC,EAC5C+tB,GACF,YAAO,IAAP/tB,IAF8CA,EAAA,YAAA+tB,IAC5CA,EAAA,IAEA2iD,MAAOt2D,EAAKs2D,MACZswB,UAAW5mF,EAAK4mF,UAAUl9F,IAAI,SAACsW,GAAA,IAACxa,EAAAwa,EAAAs2D,MAAO3sE,EAAAqW,EAAAymF,KAAMvnF,EAAAc,EAAA0+B,SAAc,OAC3B43B,MAAA9wE,EACAihG,KAAA98F,EACA+0C,SAAA,CACE55C,EAAGoa,EAASpa,EAAImD,EAAS0rB,EACzBpU,EAAGL,EAASK,EAAIlP,EAASzK,GAAA,IAWpCkjG,CAAU9oF,EAAM3P,EAAQpI,EAAQrC,EAAS+tB,EAAA,GAqK9Do1E,CAAW/oF,GALVxa,EAASI,EAAQ+4C,IAAM/4C,EAAQokD,QAAA9qC,GAE/BvV,EAAQ/D,EAAQT,KAAOS,EAAQR,OAAAM,GAGGE,EAAQ+4C,KAAM/4C,EAAQT,MAE7D,OAAIwuB,EAxJN,SAAoC3T,EAAe3P,GACjD,OAAIA,GAAc,EACT2P,EAEFA,EAAMtW,IAAI,SAAAsW,GAAQ,OAhB3B,SAAmCA,EAAY3P,GAC7C,MAAO,CACLimE,MAAOt2D,EAAKs2D,MACZswB,UAAW5mF,EAAK4mF,UAAUl9F,IACtB,SAACsW,GAAA,IAAC/X,EAAA+X,EAAAs2D,MAAO1wE,EAAAoa,EAAAymF,KAAM9yE,EAAA3T,EAAA0+B,SAAc,OAC3B43B,MAAAruE,EACAw+F,KAAA7gG,EACA84C,SAAA,CAAW55C,EAAGuL,EAAa,EAAIsjB,EAAS7uB,EAAGya,EAAGoU,EAASpU,GAAA,IAStCypF,CAAmBhpF,EAAM3P,EAAA,GAqJzC44F,CAAoBjlF,EAAara,GAEjCqa,CAAA,CCjLX,IAAMklF,GAAA,CACJC,aAAc,cACd9E,aAAc,GACd3vD,WAAY,IACZ00D,gBAAiB,KAGbC,GAAA,CAAsB,cAAe,YACrCC,GAAA,CACJC,YAAA,CAAgB,EAAG,GAAI,IACvBC,SAAA,CAAa,GAAI,KAGbC,GAAA,CACJF,YAAA,CAAgB,GAAM,IAAM,GAC5BC,SAAA,CAAa,IAETE,GAAA,CAAqB,EAAG,EAAG,GA2GjC,IAAaC,GAAA,CACXC,gBAAA,GAGWC,GAAA,CACXD,gBAAA,EACAE,cAAe,EACf/0B,eAAgB,GAChBg1B,UAAW,IA0Bb,IAAAC,GAAA,WAIE,SAAAhqF,EAAYA,EAAgB3P,IDvF9B,SAAwC2P,GACtC+B,EAC4B,iBAAjB/B,EAA2B,WAAM,uCAC5C+B,EACIumF,GAAqB1xE,QAAQ5W,IAAiB,EAC9C,WAAM,yBAAmBA,EAAA,iDCmF3BiqF,CAAwBjqF,EAAIqkF,cD1EhC,SACIrkF,EAA8B3P,GAChC0R,EAC6B,iBAAlB/B,EAAW,IAA4C,iBAAlBA,EAAW,GACvD,WAAM,gEACFA,CAAA,GAER+B,EACIomF,GAAuBnoF,EAAW,GAAI3P,GACtC,WAAM,mBAAa2P,EAAW,oCACvB3P,EAAA,MAEX0R,EACIomF,GAAuBnoF,EAAW,GAAI3P,GACtC,WAAM,kBAAY2P,EAAW,oCACtB3P,EAAA,MC4DT65F,CAAsB75F,EAAiB2P,EAAIqkF,cAE3CniG,KAAKioG,UAAYnqF,EACjB9d,KAAKknG,gBAAkB/4F,CAAA,CA0I3B,OAnHQ2P,EAAA+7E,UAAAqO,sBAAN,SACIpqF,EACA3P,GAAA,gBAAAA,IAAAA,EAAAw5F,IAAAtC,GAAA,kCAAAt/F,EAAArC,EAAA+tB,EAAAnuB,EAAAmE,EAAAuV,EAAAxZ,EAAAse,EAAA+U,EAAAnsB,EAAAL,EAAAxJ,EAAAmd,EAAA8c,EAAA/c,EAAA2Q,EAAAy5E,EAAAlrF,EAAAI,EAAA+qF,EAAA3kG,EAAA,OAAA6hG,GAAA,cAAAlrB,GAAA,OAAAA,EAAAmrB,OAAA,OAmBuB,OAjBnBx/F,EAAAsiG,GAAA,GACDV,GACAx5F,GA7DT,SAGwC2P,GAC/B,IAAA3P,EAAA2P,EAAA8pF,cAAe7hG,EAAA+X,EAAA+0D,eAAgBnvE,EAAAoa,EAAA+pF,UAEtC,GAAI15F,GAAiB,EACnB,MAAM,IAAIrM,MACN,yBAAyBqM,EAAA,mBAI/B,GAAIpI,EAAiB,GAAOA,EAAiB,EAC3C,MAAM,IAAIjE,MACN,0BAA0BiE,EAAA,mCAIhC,GAAIrC,GAAa,EACf,MAAM,IAAI5B,MAAM,qBAAqB4B,EAAA,KA6CrC4kG,CAA+Bn6F,GAEzBzK,EAAe1D,KAAKioG,UAAU9F,aAC9B1wE,EAAkBzxB,KAAKknG,gBAEvB5jG,EAAkB+iG,GAAyBvoF,GAA1CrW,EAAAnE,EAAA,GAAQ0Z,EAAA1Z,EAAA,GAETE,EAAqB8iG,GAAexoF,EAAO2T,GAA1C3P,EAAAte,EAAA+iG,QAAS1vE,EAAArzB,EAAAkjG,QAEVh8F,EACF1K,KAAKioG,UAAU1G,QAAQz/E,GADpBzX,EAAAK,EAAA43F,cAAezhG,EAAA6J,EAAA83F,QAASxkF,EAAAtT,EAAA+3F,gBAAiB3nE,EAAApwB,EAAAg4F,gBAAA,GAGjBqD,GAAA,CAC1B17F,EAAexJ,EAASmd,EAAiB8c,KAAA,OAOhC,OARR/c,EAAmBq8D,EAAAorB,OAGnB92E,EAAe3Q,EAAiB,GAChCoqF,EAAgBpqF,EAAiB,GACjCd,EAAyBc,EAAiB,GAC1CV,EAAyBU,EAAiB,MAE5B8mF,GAChBn2E,EAAcy5E,EAAelrF,EAC7BI,EAAwB3Z,EAAcqC,EAAmB6hG,cACzD7hG,EAAmB8sE,eAAgB9sE,EAAmB8hG,YAAA,OAY1D,OAfMO,EAAQhuB,EAAAorB,OAKR/hG,EAAckjG,GAChByB,EAAA,CAAQ3gG,EAAQuV,GAAQyU,EAAiBoF,EACzC9wB,EAAmB2hG,gBAEvBr9F,EAAczI,UACdf,EAAQe,UACRoc,EAAgBpc,UAChBk5B,EAAgBl5B,UAChBkgB,EAAQlgB,UAAA,GAED6B,GAAA,MAqBHqa,EAAA+7E,UAAA0O,mBAAN,SACIzqF,EACA3P,GAAA,gBAAAA,IAAAA,EAAAs5F,IAAApC,GAAA,kCAAAt/F,EAAArC,EAAA+tB,EAAAnuB,EAAAmE,EAAAuV,EAAAxZ,EAAAse,EAAA+U,EAAAnsB,EAAAL,EAAAxJ,EAAAmd,EAAA8c,EAAA/c,EAAA2Q,EAAA,OAAA42E,GAAA,cAAA6C,GAAA,OAAAA,EAAA5C,OAAA,OAgBW,OAdPx/F,EAAAsiG,GAAA,GAAyBZ,GAAmCt5F,GAI5DzK,EAAe1D,KAAKioG,UAAU9F,aAC9B1wE,EAAkBzxB,KAAKknG,gBAEvB5jG,EAAkB+iG,GAAyBvoF,GAA1CrW,EAAAnE,EAAA,GAAQ0Z,EAAA1Z,EAAA,GAETE,EAAqB8iG,GAAexoF,EAAO2T,GAA1C3P,EAAAte,EAAA+iG,QAAS1vE,EAAArzB,EAAAkjG,QAEVh8F,EACF1K,KAAKioG,UAAU1G,QAAQz/E,GADpBzX,EAAAK,EAAA43F,cAAezhG,EAAA6J,EAAA83F,QAASxkF,EAAAtT,EAAA+3F,gBAAiB3nE,EAAApwB,EAAAg4F,gBAAA,GAG7B0C,GAAiB/6F,EAAexJ,EAAS6C,IAAA,OAa5D,OAbMqa,EAAOoqF,EAAA3C,OAGP92E,EAAci4E,GAAA,CAFL5oF,GAAA,CAGHtW,EAAQuV,GAAQyU,EAAiBoF,EACzC9wB,EAAmB2hG,gBAEvBr9F,EAAczI,UACdf,EAAQe,UACRoc,EAAgBpc,UAChBk5B,EAAgBl5B,UAChBkgB,EAAQlgB,UAAA,GAED8sB,EAAY,UAIf5Q,EAAA+7E,UAAA2O,cAAN,SACI1qF,EACA3P,GAAA,OAAAk3F,GAAA,qCAAAC,GAAA,cAAAv/F,GAAA,OAAAA,EAAAw/F,OAAA,aAE4B,kBAA1Bp3F,EAAOs6F,eAAA,SACUzoG,KAAKuoG,mBAAmBzqF,EAAO3P,IAAA,OAClD,MAAO,CAAC,EAAR,CADapI,EAAAy/F,SAAA,OAGb,MAAO,CAAP,EAAOxlG,KAAKkoG,sBAAsBpqF,EAAO3P,IAAA,MAItC2P,EAAA+7E,UAAAj4F,QAAP,WACE5B,KAAKioG,UAAUrmG,SAAA,EAAAkc,CAAA,CAjJnB,GAiJmB,SAIJ4qF,GAAc5qF,GAAA,OAAAunF,GAAA,kCAAAl3F,EAAApI,EAAArC,EAAA+tB,EAAAnuB,EAAAmE,EAAAuV,EAAA,OAAAsoF,GAAA,cAAA9hG,GAAA,OAAAA,EAAA+hG,OAAA,OAI3B,GAHMp3F,EAAe2P,EAAOqkF,aACtBp8F,EAAa+X,EAAO6qF,WACpBjlG,EAAaoa,EAAO00B,WAChB,MAANo2D,EACF,MAAM,IAAI9mG,MACN,kJAMa,OADb2vB,EHlXR,SACI3T,EAAgB3P,EAAoBpI,GACtC,IAAMrC,EAAA,CAAkC,EAAK,MAAO,IAAM,MAAO,GAAM,OACjE+tB,EAAY,eAAe3T,EAAA,QAEjC,OAAmB,IAAf/X,EACK2/F,GAAqB,SAAShiG,EAAMyK,GAAA,IAAiBsjB,EAErDi0E,GAAqB,QAAQ3/F,EAAA,IAAcrC,EAAMyK,GAAA,IACpDsjB,CAAA,CGyWMo3E,CAAoB16F,EAAczK,EAAYqC,GAAA,GACjC+7F,GAAsBhkF,EAAOwiF,UAAY7uE,IAAA,OAMlE,OANMnuB,EAAaE,EAAAgiG,OACb/9F,EAAY,IAAIk7F,GAAUr/F,EAAY6K,GAEtC6O,EAAuBmpF,GACzBroF,EAAOopF,gBAAiBz/F,EAAU06F,cAAA,GAE/B,IAAI2F,GAAQrgG,EAAWuV,IAAA,KAGhC,SAAe8rF,GAAWhrF,GAAA,OAAAunF,GAAA,kCAAAl3F,EAAApI,EAAArC,EAAA+tB,EAAAnuB,EAAAmE,EAAA,OAAA69F,GAAA,cAAAtoF,GAAA,OAAAA,EAAAuoF,OAAA,OAGxB,GAFMp3F,EAAe2P,EAAOqkF,aACtBp8F,EAAa+X,EAAO6qF,WAChB,MAANC,EACF,MAAM,IAAI9mG,MACN,kJAMa,OADb4B,EHlZR,SAAmCoa,EAAgB3P,GACjD,IAAMpI,EAAY,eAAe+X,EAAA,QAEjC,OAAmB,IAAf3P,EACKw3F,GAAoB,SAAW5/F,EAE/B4/F,GAAoB,QAAQx3F,EAAA,IAAgBpI,CAAA,CG4YzCgjG,CAAmB56F,EAAcpI,GAAA,GACpB+7F,GAAsBhkF,EAAOwiF,UAAY58F,IAAA,OAIlE,OAJM+tB,EAAazU,EAAAwoF,OACbliG,EAAS,IAAIuiG,GAAOp0E,EAAYtjB,GAChC1G,EAAuB0+F,GACzBroF,EAAOopF,gBAAiB5jG,EAAO6+F,cAAA,GAC5B,IAAI2F,GAAQxkG,EAAQmE,IAAA,KAe7B,SAAsBk2B,GAAK7f,GAAA,gBAAAA,IAAAA,EAAAkpF,IAAA3B,GAAA,qCAAAC,GAAA,cAAAn3F,GAGzB,MAA4B,cAD5B2P,EArVF,SAA6BA,GAM3B,GAH2B,OAF3BA,EAASA,GAAUkpF,IAERC,eACTnpF,EAAOmpF,aAAe,eAEpBE,GAAmBzyE,QAAQ5W,EAAOmpF,cAAgB,EACpD,MAAM,IAAInlG,MACN,wBAAwBgc,EAAOmpF,aAAA,sBACXE,IAY1B,GAT8B,MAA1BrpF,EAAOopF,kBACTppF,EAAOopF,gBAAkB,KAG3BhB,GAAwBpoF,EAAOopF,iBAEJ,MAAvBppF,EAAOqkF,eACTrkF,EAAOqkF,aAAe,IAEpBiF,GAAatpF,EAAOmpF,cAAcvyE,QAAQ5W,EAAOqkF,cAAgB,EACnE,MAAM,IAAIrgG,MACN,wBAAwBgc,EAAOqkF,aAAA,sBACXiF,GAAatpF,EAAOmpF,cAAA,qBACpBnpF,EAAOmpF,aAAA,KAMjC,GAHyB,MAArBnpF,EAAO00B,aACT10B,EAAO00B,WAAa,GAElB+0D,GAAiBzpF,EAAOmpF,cAAcvyE,QAAQ5W,EAAO00B,YAAc,EACrE,MAAM,IAAI1wC,MACN,sBAAsBgc,EAAO00B,WAAA,sBACT+0D,GAAiBzpF,EAAOmpF,cAAA,qBACxBnpF,EAAOmpF,aAAA,KAMjC,GAHyB,MAArBnpF,EAAO6qF,aACT7qF,EAAO6qF,WAAa,GAElBnB,GAAkB9yE,QAAQ5W,EAAO6qF,YAAc,EACjD,MAAM,IAAI7mG,MACN,sBAAsBgc,EAAO6qF,WAAA,sBACTnB,GAAA,qBACA1pF,EAAOmpF,aAAA,KAGjC,GAA4B,gBAAxBnpF,EAAOmpF,cAA0D,KAAxBnpF,EAAOqkF,cAC1B,IAAtBrkF,EAAO00B,WACT,MAAM,IAAI1wC,MACN,2EAIN,OAAOgc,CAAA,CA8REkrF,CAAoBlrF,IAClBmpF,aAAA,GACF6B,GAAWhrF,IACe,gBAAxBA,EAAOmpF,aAAA,GACTyB,GAAc5qF,IAAA,GAEd,U","sources":["../../tfjs-core/src/backends/backend.ts","../../tfjs-core/src/util_base.ts","../../tfjs-core/src/environment.ts","../../tfjs-core/src/global_util.ts","../../tfjs-core/src/kernel_names.ts","../../tfjs-core/src/log.ts","../../tfjs-core/src/kernel_registry.ts","../../tfjs-core/src/hash_util.ts","../../tfjs-core/src/util.ts","../../tfjs-core/src/profiler.ts","../../tfjs-core/src/tensor_format.ts","../../tfjs-core/src/tensor.ts","../../tfjs-core/src/types.ts","../../tfjs-core/src/tensor_util.ts","../../tfjs-core/src/engine.ts","../../tfjs-core/src/tape.ts","../../tfjs-core/src/device_util.ts","../../tfjs-core/src/flags.ts","../../tfjs-core/src/tensor_util_env.ts","../../tfjs-core/src/ops/operation.ts","../../tfjs-core/src/ops/complex.ts","../../tfjs-core/src/ops/tensor_ops_util.ts","../../tfjs-core/src/ops/tensor.ts","../../tfjs-core/src/io/types.ts","../../tfjs-core/src/io/io_utils.ts","../../tfjs-core/src/io/router_registry.ts","../../tfjs-core/src/io/indexed_db.ts","../../tfjs-core/src/io/local_storage.ts","../../tfjs-core/src/io/model_management.ts","../../tfjs-core/src/platforms/platform_browser.ts","../../tfjs-core/src/platforms/platform_node.ts","../../tfjs-core/src/ops/buffer.ts","../../tfjs-core/src/ops/cast.ts","../../tfjs-core/src/ops/clone.ts","../../tfjs-core/src/ops/print.ts","../../tfjs-core/src/base_side_effects.ts","../../tfjs-core/src/io/browser_files.ts","../../tfjs-core/src/io/progress.ts","../../tfjs-core/src/io/weights_loader.ts","../../tfjs-core/src/io/http.ts","../../tfjs-core/src/io/passthrough.ts","../../tfjs-core/src/ops/mat_mul.ts","../../tfjs-core/src/ops/one_hot.ts","../../tfjs-core/src/globals.ts","../../tfjs-core/src/ops/imag.ts","../../tfjs-core/src/ops/neg.ts","../../tfjs-core/src/ops/real.ts","../../tfjs-core/src/ops/transpose.ts","../../tfjs-core/src/ops/confusion_matrix.ts","../../tfjs-core/src/ops/broadcast_util.ts","../../tfjs-core/src/ops/tensor3d.ts","../../tfjs-core/src/ops/browser.ts","../../tfjs-core/src/ops/gather_nd_util.ts","../../tfjs-core/src/ops/scatter_nd_util.ts","../../tfjs-core/src/ops/slice_util.ts","../../tfjs-core/src/serialization.ts","../../tfjs-core/src/test_util.ts","../../tfjs-core/src/version.ts","../../tfjs-core/src/ops/add.ts","../../tfjs-core/src/ops/floorDiv.ts","../../tfjs-core/src/ops/div.ts","../../tfjs-core/src/ops/mul.ts","../../tfjs-core/src/ops/sqrt.ts","../../tfjs-core/src/ops/square.ts","../../tfjs-core/src/ops/zeros_like.ts","../../tfjs-core/src/gradients.ts","../../tfjs-core/src/ops/scalar.ts","../../tfjs-core/src/optimizers/optimizer.ts","../../tfjs-core/src/optimizers/adadelta_optimizer.ts","../../tfjs-core/src/ops/fill.ts","../../tfjs-core/src/optimizers/adagrad_optimizer.ts","../../tfjs-core/src/ops/pow.ts","../../tfjs-core/src/ops/sub.ts","../../tfjs-core/src/optimizers/adam_optimizer.ts","../../tfjs-core/src/ops/abs.ts","../../tfjs-core/src/ops/maximum.ts","../../tfjs-core/src/optimizers/adamax_optimizer.ts","../../tfjs-core/src/optimizers/sgd_optimizer.ts","../../tfjs-core/src/optimizers/momentum_optimizer.ts","../../tfjs-core/src/optimizers/rmsprop_optimizer.ts","../../tfjs-core/src/optimizers/optimizer_constructors.ts","../../tfjs-core/src/ops/acos.ts","../../tfjs-core/src/ops/acosh.ts","../../tfjs-core/src/ops/add_n.ts","../../tfjs-core/src/ops/all.ts","../../tfjs-core/src/ops/any.ts","../../tfjs-core/src/ops/arg_max.ts","../../tfjs-core/src/ops/arg_min.ts","../../tfjs-core/src/ops/asin.ts","../../tfjs-core/src/ops/asinh.ts","../../tfjs-core/src/ops/atan.ts","../../tfjs-core/src/ops/atan2.ts","../../tfjs-core/src/ops/atanh.ts","../../tfjs-core/src/ops/conv_util.ts","../../tfjs-core/src/ops/reshape.ts","../../tfjs-core/src/ops/avg_pool.ts","../../tfjs-core/src/ops/avg_pool_3d.ts","../../tfjs-core/src/ops/concat.ts","../../tfjs-core/src/ops/sigmoid.ts","../../tfjs-core/src/ops/slice.ts","../../tfjs-core/src/ops/tanh.ts","../../tfjs-core/src/ops/basic_lstm_cell.ts","../../tfjs-core/src/ops/batch_to_space_nd.ts","../../tfjs-core/src/ops/batchnorm.ts","../../tfjs-core/src/ops/batchnorm_util.ts","../../tfjs-core/src/ops/batchnorm2d.ts","../../tfjs-core/src/ops/batchnorm3d.ts","../../tfjs-core/src/ops/batchnorm4d.ts","../../tfjs-core/src/ops/bincount.ts","../../tfjs-core/src/ops/broadcast_args.ts","../../tfjs-core/src/ops/broadcast_to.ts","../../tfjs-core/src/ops/ceil.ts","../../tfjs-core/src/ops/clip_by_value.ts","../../tfjs-core/src/ops/concat_1d.ts","../../tfjs-core/src/ops/concat_2d.ts","../../tfjs-core/src/ops/concat_3d.ts","../../tfjs-core/src/ops/concat_4d.ts","../../tfjs-core/src/ops/conv2d.ts","../../tfjs-core/src/ops/conv1d.ts","../../tfjs-core/src/ops/conv2d_backprop_input.ts","../../tfjs-core/src/ops/conv2d_transpose.ts","../../tfjs-core/src/ops/conv3d.ts","../../tfjs-core/src/ops/conv3d_backprop_input.ts","../../tfjs-core/src/ops/conv3d_transpose.ts","../../tfjs-core/src/ops/cos.ts","../../tfjs-core/src/ops/cosh.ts","../../tfjs-core/src/ops/cumprod.ts","../../tfjs-core/src/ops/cumsum.ts","../../tfjs-core/src/ops/dense_bincount.ts","../../tfjs-core/src/ops/depth_to_space.ts","../../tfjs-core/src/ops/depthwise_conv2d.ts","../../tfjs-core/src/ops/diag.ts","../../tfjs-core/src/ops/dilation2d.ts","../../tfjs-core/src/ops/equal.ts","../../tfjs-core/src/ops/where.ts","../../tfjs-core/src/ops/div_no_nan.ts","../../tfjs-core/src/ops/dot.ts","../../tfjs-core/src/ops/einsum.ts","../../tfjs-core/src/ops/elu.ts","../../tfjs-core/src/ops/erf.ts","../../tfjs-core/src/ops/axis_util.ts","../../tfjs-core/src/ops/max.ts","../../tfjs-core/src/ops/min.ts","../../tfjs-core/src/ops/sum.ts","../../tfjs-core/src/ops/norm.ts","../../tfjs-core/src/ops/euclidean_norm.ts","../../tfjs-core/src/ops/exp.ts","../../tfjs-core/src/ops/expand_dims.ts","../../tfjs-core/src/ops/expm1.ts","../../tfjs-core/src/ops/tile.ts","../../tfjs-core/src/ops/eye.ts","../../tfjs-core/src/ops/floor.ts","../../tfjs-core/src/ops/gather.ts","../../tfjs-core/src/ops/greater.ts","../../tfjs-core/src/ops/greater_equal.ts","../../tfjs-core/src/ops/is_finite.ts","../../tfjs-core/src/ops/is_inf.ts","../../tfjs-core/src/ops/is_nan.ts","../../tfjs-core/src/ops/leaky_relu.ts","../../tfjs-core/src/ops/less.ts","../../tfjs-core/src/ops/less_equal.ts","../../tfjs-core/src/ops/linspace.ts","../../tfjs-core/src/ops/local_response_normalization.ts","../../tfjs-core/src/ops/log.ts","../../tfjs-core/src/ops/log1p.ts","../../tfjs-core/src/ops/softplus.ts","../../tfjs-core/src/ops/log_sigmoid.ts","../../tfjs-core/src/ops/log_softmax.ts","../../tfjs-core/src/ops/log_sum_exp.ts","../../tfjs-core/src/ops/logical_and.ts","../../tfjs-core/src/ops/logical_not.ts","../../tfjs-core/src/ops/logical_or.ts","../../tfjs-core/src/ops/logical_xor.ts","../../tfjs-core/src/ops/search_sorted.ts","../../tfjs-core/src/ops/lower_bound.ts","../../tfjs-core/src/ops/max_pool.ts","../../tfjs-core/src/ops/max_pool_3d.ts","../../tfjs-core/src/ops/max_pool_with_argmax.ts","../../tfjs-core/src/ops/mean.ts","../../tfjs-core/src/ops/zeros.ts","../../tfjs-core/src/ops/ones.ts","../../tfjs-core/src/ops/meshgrid.ts","../../tfjs-core/src/ops/minimum.ts","../../tfjs-core/src/ops/mirror_pad.ts","../../tfjs-core/src/ops/mod.ts","../../tfjs-core/src/ops/moments.ts","../../tfjs-core/src/ops/multi_rnn_cell.ts","../../tfjs-core/src/ops/multinomial.ts","../../tfjs-core/src/ops/not_equal.ts","../../tfjs-core/src/ops/ones_like.ts","../../tfjs-core/src/ops/outer_product.ts","../../tfjs-core/src/ops/pad.ts","../../tfjs-core/src/ops/pad1d.ts","../../tfjs-core/src/ops/pad2d.ts","../../tfjs-core/src/ops/pad3d.ts","../../tfjs-core/src/ops/pad4d.ts","../../tfjs-core/src/ops/space_to_batch_nd.ts","../../tfjs-core/src/ops/pool.ts","../../tfjs-core/src/ops/prelu.ts","../../tfjs-core/src/ops/prod.ts","../../tfjs-core/src/ops/ragged_gather.ts","../../tfjs-core/src/ops/ragged_tensor_to_tensor.ts","../../tfjs-core/src/ops/rand.ts","../../tfjs-core/src/ops/rand_util.ts","../../tfjs-core/src/ops/random_gamma.ts","../../tfjs-core/src/ops/random_normal.ts","../../tfjs-core/src/ops/random_standard_normal.ts","../../tfjs-core/src/ops/random_uniform.ts","../../tfjs-core/src/ops/range.ts","../../tfjs-core/src/ops/reciprocal.ts","../../tfjs-core/src/ops/relu.ts","../../tfjs-core/src/ops/relu6.ts","../../tfjs-core/src/ops/reverse.ts","../../tfjs-core/src/ops/reverse_1d.ts","../../tfjs-core/src/ops/reverse_2d.ts","../../tfjs-core/src/ops/reverse_3d.ts","../../tfjs-core/src/ops/reverse_4d.ts","../../tfjs-core/src/ops/round.ts","../../tfjs-core/src/ops/rsqrt.ts","../../tfjs-core/src/ops/selu.ts","../../tfjs-core/src/ops/separable_conv2d.ts","../../tfjs-core/src/ops/setdiff1d_async.ts","../../tfjs-core/src/ops/sign.ts","../../tfjs-core/src/ops/sin.ts","../../tfjs-core/src/ops/sinh.ts","../../tfjs-core/src/ops/slice1d.ts","../../tfjs-core/src/ops/slice2d.ts","../../tfjs-core/src/ops/slice3d.ts","../../tfjs-core/src/ops/slice4d.ts","../../tfjs-core/src/ops/softmax.ts","../../tfjs-core/src/ops/spectral/fft.ts","../../tfjs-core/src/ops/spectral/ifft.ts","../../tfjs-core/src/ops/spectral/irfft.ts","../../tfjs-core/src/ops/split.ts","../../tfjs-core/src/ops/spectral/rfft.ts","../../tfjs-core/src/ops/squared_difference.ts","../../tfjs-core/src/ops/squeeze.ts","../../tfjs-core/src/ops/stack.ts","../../tfjs-core/src/ops/step.ts","../../tfjs-core/src/ops/strided_slice.ts","../../tfjs-core/src/ops/tan.ts","../../tfjs-core/src/ops/tensor1d.ts","../../tfjs-core/src/ops/tensor2d.ts","../../tfjs-core/src/ops/tensor4d.ts","../../tfjs-core/src/ops/tensor5d.ts","../../tfjs-core/src/ops/tensor6d.ts","../../tfjs-core/src/ops/topk.ts","../../tfjs-core/src/ops/truncated_normal.ts","../../tfjs-core/src/ops/unique.ts","../../tfjs-core/src/ops/unsorted_segment_sum.ts","../../tfjs-core/src/ops/unstack.ts","../../tfjs-core/src/ops/upper_bound.ts","../../tfjs-core/src/ops/variable.ts","../../tfjs-core/src/backends/where_impl.ts","../../tfjs-core/src/ops/where_async.ts","../../tfjs-core/src/ops/boolean_mask.ts","../../tfjs-core/src/ops/moving_average.ts","../../tfjs-core/src/ops/scatter_nd.ts","../../tfjs-core/src/ops/sparse_to_dense.ts","../../tfjs-core/src/ops/sparse_to_dense_util.ts","../../tfjs-core/src/ops/gather_nd.ts","../../tfjs-core/src/ops/dropout.ts","../../tfjs-core/src/ops/dropout_util.ts","../../tfjs-core/src/ops/signal_ops_util.ts","../../tfjs-core/src/ops/in_top_k.ts","../../tfjs-core/src/ops/conv2d_backprop_filter.ts","../../tfjs-core/src/ops/fused_util.ts","../../tfjs-core/src/ops/fused/conv2d.ts","../../tfjs-core/src/ops/depthwise_conv2d_native_backprop_filter.ts","../../tfjs-core/src/ops/depthwise_conv2d_native_backprop_input.ts","../../tfjs-core/src/ops/fused/depthwise_conv2d.ts","../../tfjs-core/src/ops/fused/mat_mul.ts","../../tfjs-core/src/ops/signal/hamming_window.ts","../../tfjs-core/src/ops/signal/hann_window.ts","../../tfjs-core/src/ops/signal/frame.ts","../../tfjs-core/src/ops/signal/stft.ts","../../tfjs-core/src/ops/image/crop_and_resize.ts","../../tfjs-core/src/ops/image/flip_left_right.ts","../../tfjs-core/src/ops/image/grayscale_to_rgb.ts","../../tfjs-core/src/ops/image/rotate_with_offset.ts","../../tfjs-core/src/ops/nonmax_util.ts","../../tfjs-core/src/ops/image/non_max_suppression.ts","../../tfjs-core/src/backends/non_max_suppression_util.ts","../../tfjs-core/src/backends/non_max_suppression_impl.ts","../../tfjs-core/src/ops/image/non_max_suppression_async.ts","../../tfjs-core/src/ops/image/non_max_suppression_with_score.ts","../../tfjs-core/src/ops/image/non_max_suppression_with_score_async.ts","../../tfjs-core/src/ops/image/non_max_suppression_padded.ts","../../tfjs-core/src/ops/image/non_max_suppression_padded_async.ts","../../tfjs-core/src/ops/image/resize_bilinear.ts","../../tfjs-core/src/ops/image/resize_nearest_neighbor.ts","../../tfjs-core/src/ops/image/threshold.ts","../../tfjs-core/src/ops/image/transform.ts","../../tfjs-core/src/ops/linalg/band_part.ts","../../tfjs-core/src/ops/linalg/gram_schmidt.ts","../../tfjs-core/src/ops/linalg/qr.ts","../../tfjs-core/src/ops/loss_ops_utils.ts","../../tfjs-core/src/ops/losses/compute_weighted_loss.ts","../../tfjs-core/src/ops/losses/absolute_difference.ts","../../tfjs-core/src/ops/losses/cosine_distance.ts","../../tfjs-core/src/ops/losses/hinge_loss.ts","../../tfjs-core/src/ops/losses/huber_loss.ts","../../tfjs-core/src/ops/losses/log_loss.ts","../../tfjs-core/src/ops/losses/mean_squared_error.ts","../../tfjs-core/src/ops/losses/sigmoid_cross_entropy.ts","../../tfjs-core/src/ops/losses/softmax_cross_entropy.ts","../../tfjs-core/src/ops/sparse/sparse_fill_empty_rows.ts","../../tfjs-core/src/ops/sparse/sparse_reshape.ts","../../tfjs-core/src/ops/sparse/sparse_segment_mean.ts","../../tfjs-core/src/ops/sparse/sparse_segment_sum.ts","../../tfjs-core/src/ops/string/string_n_grams.ts","../../tfjs-core/src/ops/string/string_split.ts","../../tfjs-core/src/ops/string/string_to_hash_bucket_fast.ts","../../tfjs-core/src/ops/ops.ts","../../tfjs-core/src/train.ts","../../tfjs-core/src/browser_util.ts","../../tfjs-core/src/ops/concat_util.ts","../../tfjs-core/src/ops/ragged_to_dense_util.ts","../../tfjs-core/src/ops/reduce_util.ts","../../tfjs-core/src/ops/rotate_util.ts","../../tfjs-core/src/ops/array_ops_util.ts","../../tfjs-core/src/ops/selu_util.ts","../../tfjs-core/src/ops/erf_util.ts","../../tfjs-core/src/backends/complex_util.ts","../../tfjs-core/src/backends/einsum_util.ts","../../tfjs-core/src/ops/split_util.ts","../../tfjs-core/src/ops/sparse/sparse_fill_empty_rows_util.ts","../../tfjs-core/src/ops/sparse/sparse_reshape_util.ts","../../tfjs-core/src/ops/sparse/sparse_segment_reduction_util.ts","../../tfjs-core/src/ops/segment_util.ts","../../tfjs-core/src/backends/backend_util.ts","../../tfjs-converter/src/data/compiled_api.ts","../../tfjs-converter/src/flags.ts","../../tfjs-converter/src/operations/custom_op/register.ts","../../tfjs-converter/src/operations/executors/utils.ts","../../tfjs-converter/src/operations/op_list/arithmetic.ts","../../tfjs-converter/src/operations/op_list/basic_math.ts","../../tfjs-converter/src/operations/op_list/control.ts","../../tfjs-converter/src/operations/op_list/convolution.ts","../../tfjs-converter/src/operations/op_list/creation.ts","../../tfjs-converter/src/operations/op_list/dynamic.ts","../../tfjs-converter/src/operations/op_list/evaluation.ts","../../tfjs-converter/src/operations/op_list/graph.ts","../../tfjs-converter/src/operations/op_list/hash_table.ts","../../tfjs-converter/src/operations/op_list/image.ts","../../tfjs-converter/src/operations/op_list/logical.ts","../../tfjs-converter/src/operations/op_list/matrices.ts","../../tfjs-converter/src/operations/op_list/normalization.ts","../../tfjs-converter/src/operations/op_list/reduction.ts","../../tfjs-converter/src/operations/op_list/slice_join.ts","../../tfjs-converter/src/operations/op_list/sparse.ts","../../tfjs-converter/src/operations/op_list/spectral.ts","../../tfjs-converter/src/operations/op_list/string.ts","../../tfjs-converter/src/operations/op_list/transformation.ts","../../tfjs-converter/src/operations/operation_mapper.ts","../../tfjs-converter/src/operations/custom_op/node_value_impl.ts","../../tfjs-converter/src/executor/tensor_utils.ts","../../tfjs-converter/src/executor/tensor_array.ts","../../tfjs-converter/src/executor/tensor_list.ts","../../tfjs-converter/src/operations/executors/control_executor.ts","../../tfjs-converter/src/operations/executors/convolution_executor.ts","../../tfjs-converter/src/operations/executors/dynamic_executor.ts","../../tfjs-converter/src/executor/hash_table.ts","../../tfjs-converter/src/operations/operation_executor.ts","../../tfjs-converter/src/operations/executors/arithmetic_executor.ts","../../tfjs-converter/src/operations/executors/basic_math_executor.ts","../../tfjs-converter/src/operations/executors/creation_executor.ts","../../tfjs-converter/src/operations/executors/evaluation_executor.ts","../../tfjs-converter/src/operations/executors/image_executor.ts","../../tfjs-converter/src/operations/executors/graph_executor.ts","../../tfjs-converter/src/operations/executors/logical_executor.ts","../../tfjs-converter/src/operations/executors/matrices_executor.ts","../../tfjs-converter/src/operations/executors/normalization_executor.ts","../../tfjs-converter/src/operations/executors/reduction_executor.ts","../../tfjs-converter/src/operations/executors/slice_join_executor.ts","../../tfjs-converter/src/operations/executors/sparse_executor.ts","../../tfjs-converter/src/operations/executors/spectral_executor.ts","../../tfjs-converter/src/operations/executors/string_executor.ts","../../tfjs-converter/src/operations/executors/transformation_executor.ts","../../tfjs-converter/src/operations/executors/hash_table_executor.ts","../../tfjs-converter/src/executor/execution_context.ts","../../tfjs-converter/src/executor/model_analysis.ts","../../tfjs-converter/src/executor/graph_executor.ts","../../tfjs-converter/src/executor/resource_manager.ts","../../tfjs-converter/src/executor/graph_model.ts","../node_modules/@tensorflow-models/posenet/src/base_model.ts","../node_modules/@tensorflow-models/posenet/src/mobilenet.ts","../node_modules/@tensorflow-models/posenet/src/multi_pose/max_heap.ts","../node_modules/@tensorflow-models/posenet/src/multi_pose/build_part_with_score_queue.ts","../node_modules/@tensorflow-models/posenet/src/keypoints.ts","../node_modules/@tensorflow-models/posenet/src/multi_pose/util.ts","../node_modules/@tensorflow-models/posenet/src/multi_pose/decode_pose.ts","../node_modules/@tensorflow-models/posenet/src/multi_pose/decode_multiple_poses.ts","../node_modules/@tensorflow-models/posenet/src/single_pose/argmax2d.ts","../node_modules/@tensorflow-models/posenet/src/single_pose/util.ts","../node_modules/@tensorflow-models/posenet/src/single_pose/decode_single_pose.ts","../node_modules/@tensorflow-models/posenet/src/checkpoints.ts","../node_modules/@tensorflow-models/posenet/src/resnet.ts","../node_modules/@tensorflow-models/posenet/src/util.ts","../node_modules/@tensorflow-models/posenet/src/posenet_model.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Backend, DataId, DataToGPUOptions, GPUData} from '../tensor';\nimport {BackendValues, DataType} from '../types';\n\nexport const EPSILON_FLOAT32 = 1e-7;\nexport const EPSILON_FLOAT16 = 1e-4;\n\n// Required information for all backends.\nexport interface BackendTimingInfo {\n  kernelMs: number|{error: string};\n  getExtraProfileInfo?(): string;  // a field for additional timing information\n                                   // e.g. packing / unpacking for WebGL backend\n}\n\nexport interface TensorStorage {\n  read(dataId: DataId): Promise<BackendValues>;\n  readSync(dataId: DataId): BackendValues;\n  disposeData(dataId: DataId, force?: boolean): boolean;\n  write(values: BackendValues, shape: number[], dtype: DataType): DataId;\n  move(\n      dataId: DataId, values: BackendValues, shape: number[], dtype: DataType,\n      refCount: number): void;\n  memory(): {unreliable: boolean;};  // Backend-specific information.\n  /** Returns number of data ids currently in the storage. */\n  numDataIds(): number;\n  refCount(dataId: DataId): number;\n}\n\n/** Convenient class for storing tensor-related data. */\nexport class DataStorage<T> {\n  private data = new WeakMap<DataId, T>();\n  private dataIdsCount = 0;\n\n  constructor(private backend: KernelBackend, private dataMover: DataMover) {}\n\n  get(dataId: DataId) {\n    if (!this.data.has(dataId)) {\n      this.dataMover.moveData(this.backend, dataId);\n    }\n    return this.data.get(dataId);\n  }\n\n  set(dataId: DataId, value: T): void {\n    this.dataIdsCount++;\n    this.data.set(dataId, value);\n  }\n\n  has(dataId: DataId): boolean {\n    return this.data.has(dataId);\n  }\n\n  delete(dataId: DataId): boolean {\n    this.dataIdsCount--;\n    return this.data.delete(dataId);\n  }\n\n  numDataIds(): number {\n    return this.dataIdsCount;\n  }\n}\n\nexport interface DataMover {\n  /**\n   * To be called by backends whenever they see a dataId that they don't own.\n   * Upon calling this method, the mover will fetch the tensor from another\n   * backend and register it with the current active backend.\n   */\n  moveData(backend: KernelBackend, dataId: DataId): void;\n}\n\nexport interface BackendTimer {\n  // check if backend timer is available\n  timerAvailable(): boolean;\n  time(f: () => void): Promise<BackendTimingInfo>;\n}\n\n/**\n * The interface that defines the kernels that should be implemented when\n * adding a new backend. New backends don't need to implement every one of the\n * methods, this can be done gradually (throw an error for unimplemented\n * methods).\n */\nexport class KernelBackend implements TensorStorage, Backend, BackendTimer {\n  refCount(dataId: DataId): number {\n    return notYetImplemented('refCount');\n  }\n  incRef(dataId: DataId): void {\n    return notYetImplemented('incRef');\n  }\n  timerAvailable(): boolean {\n    return true;\n  }\n  time(f: () => void): Promise<BackendTimingInfo> {\n    return notYetImplemented('time');\n  }\n  read(dataId: object): Promise<BackendValues> {\n    return notYetImplemented('read');\n  }\n  readSync(dataId: object): BackendValues {\n    return notYetImplemented('readSync');\n  }\n  readToGPU(dataId: object, options?: DataToGPUOptions): GPUData {\n    return notYetImplemented('readToGPU');\n  }\n  numDataIds(): number {\n    return notYetImplemented('numDataIds');\n  }\n  disposeData(dataId: object, force?: boolean): boolean {\n    return notYetImplemented('disposeData');\n  }\n  write(values: BackendValues, shape: number[], dtype: DataType): DataId {\n    return notYetImplemented('write');\n  }\n  move(\n      dataId: DataId, values: BackendValues, shape: number[], dtype: DataType,\n      refCount: number): void {\n    return notYetImplemented('move');\n  }\n  memory(): {unreliable: boolean; reasons?: string[]} {\n    return notYetImplemented('memory');\n  }\n  /** Returns the highest precision for floats in bits (e.g. 16 or 32) */\n  floatPrecision(): 16|32 {\n    return notYetImplemented('floatPrecision');\n  }\n  /** Returns the smallest representable number.  */\n  epsilon(): number {\n    return this.floatPrecision() === 32 ? EPSILON_FLOAT32 : EPSILON_FLOAT16;\n  }\n  dispose(): void {\n    return notYetImplemented('dispose');\n  }\n}\n\nfunction notYetImplemented(kernelName: string): never {\n  throw new Error(\n      `'${kernelName}' not yet implemented or not found in the registry. ` +\n      `This kernel may not be supported by the tfjs backend you have chosen`);\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, DataTypeMap, FlatVector, NumericDataType, RecursiveArray, TensorLike, TypedArray} from './types';\n\n/**\n * Shuffles the array in-place using Fisher-Yates algorithm.\n *\n * ```js\n * const a = [1, 2, 3, 4, 5];\n * tf.util.shuffle(a);\n * console.log(a);\n * ```\n *\n * @param array The array to shuffle in-place.\n *\n * @doc {heading: 'Util', namespace: 'util'}\n */\n// tslint:disable-next-line:no-any\nexport function shuffle(array: any[]|Uint32Array|Int32Array|\n                        Float32Array): void {\n  let counter = array.length;\n  let index = 0;\n  // While there are elements in the array\n  while (counter > 0) {\n    // Pick a random index\n    index = (Math.random() * counter) | 0;\n    // Decrease counter by 1\n    counter--;\n    // And swap the last element with it\n    swap(array, counter, index);\n  }\n}\n\n/**\n * Shuffles two arrays in-place the same way using Fisher-Yates algorithm.\n *\n * ```js\n * const a = [1,2,3,4,5];\n * const b = [11,22,33,44,55];\n * tf.util.shuffleCombo(a, b);\n * console.log(a, b);\n * ```\n *\n * @param array The first array to shuffle in-place.\n * @param array2 The second array to shuffle in-place with the same permutation\n *     as the first array.\n *\n * @doc {heading: 'Util', namespace: 'util'}\n */\nexport function shuffleCombo(\n    // tslint:disable-next-line:no-any\n    array: any[]|Uint32Array|Int32Array|Float32Array,\n    // tslint:disable-next-line:no-any\n    array2: any[]|Uint32Array|Int32Array|Float32Array): void {\n  if (array.length !== array2.length) {\n    throw new Error(\n        `Array sizes must match to be shuffled together ` +\n        `First array length was ${array.length}` +\n        `Second array length was ${array2.length}`);\n  }\n  let counter = array.length;\n  let index = 0;\n  // While there are elements in the array\n  while (counter > 0) {\n    // Pick a random index\n    index = (Math.random() * counter) | 0;\n    // Decrease counter by 1\n    counter--;\n    // And swap the last element of each array with it\n    swap(array, counter, index);\n    swap(array2, counter, index);\n  }\n}\n\n/** Clamps a value to a specified range. */\nexport function clamp(min: number, x: number, max: number): number {\n  return Math.max(min, Math.min(x, max));\n}\n\nexport function nearestLargerEven(val: number): number {\n  return val % 2 === 0 ? val : val + 1;\n}\n\nexport function swap<T>(\n    object: {[index: number]: T}, left: number, right: number) {\n  const temp = object[left];\n  object[left] = object[right];\n  object[right] = temp;\n}\n\nexport function sum(arr: number[]): number {\n  let sum = 0;\n  for (let i = 0; i < arr.length; i++) {\n    sum += arr[i];\n  }\n  return sum;\n}\n\n/**\n * Returns a sample from a uniform [a, b) distribution.\n *\n * @param a The minimum support (inclusive).\n * @param b The maximum support (exclusive).\n * @return A pseudorandom number on the half-open interval [a,b).\n */\nexport function randUniform(a: number, b: number) {\n  const r = Math.random();\n  return (b * r) + (1 - r) * a;\n}\n\n/** Returns the squared Euclidean distance between two vectors. */\nexport function distSquared(a: FlatVector, b: FlatVector): number {\n  let result = 0;\n  for (let i = 0; i < a.length; i++) {\n    const diff = Number(a[i]) - Number(b[i]);\n    result += diff * diff;\n  }\n  return result;\n}\n\n/**\n * Asserts that the expression is true. Otherwise throws an error with the\n * provided message.\n *\n * ```js\n * const x = 2;\n * tf.util.assert(x === 2, 'x is not 2');\n * ```\n *\n * @param expr The expression to assert (as a boolean).\n * @param msg A function that returns the message to report when throwing an\n *     error. We use a function for performance reasons.\n *\n * @doc {heading: 'Util', namespace: 'util'}\n */\nexport function assert(expr: boolean, msg: () => string) {\n  if (!expr) {\n    throw new Error(typeof msg === 'string' ? msg : msg());\n  }\n}\n\nexport function assertShapesMatch(\n    shapeA: number[], shapeB: number[], errorMessagePrefix = ''): void {\n  assert(\n      arraysEqual(shapeA, shapeB),\n      () => errorMessagePrefix + ` Shapes ${shapeA} and ${shapeB} must match`);\n}\n\nexport function assertNonNull(a: TensorLike): void {\n  assert(\n      a != null,\n      () => `The input to the tensor constructor must be a non-null value.`);\n}\n\n// NOTE: We explicitly type out what T extends instead of any so that\n// util.flatten on a nested array of number doesn't try to infer T as a\n// number[][], causing us to explicitly type util.flatten<number>().\n/**\n *  Flattens an arbitrarily nested array.\n *\n * ```js\n * const a = [[1, 2], [3, 4], [5, [6, [7]]]];\n * const flat = tf.util.flatten(a);\n * console.log(flat);\n * ```\n *\n *  @param arr The nested array to flatten.\n *  @param result The destination array which holds the elements.\n *  @param skipTypedArray If true, avoids flattening the typed arrays. Defaults\n *      to false.\n *\n * @doc {heading: 'Util', namespace: 'util'}\n */\nexport function\nflatten<T extends number|boolean|string|Promise<number>|TypedArray>(\n    arr: T|RecursiveArray<T>, result: T[] = [], skipTypedArray = false): T[] {\n  if (result == null) {\n    result = [];\n  }\n  if (Array.isArray(arr) || isTypedArray(arr) && !skipTypedArray) {\n    for (let i = 0; i < arr.length; ++i) {\n      flatten(arr[i], result, skipTypedArray);\n    }\n  } else {\n    result.push(arr as T);\n  }\n  return result;\n}\n\n/**\n * Returns the size (number of elements) of the tensor given its shape.\n *\n * ```js\n * const shape = [3, 4, 2];\n * const size = tf.util.sizeFromShape(shape);\n * console.log(size);\n * ```\n *\n * @doc {heading: 'Util', namespace: 'util'}\n */\nexport function sizeFromShape(shape: number[]): number {\n  if (shape.length === 0) {\n    // Scalar.\n    return 1;\n  }\n  let size = shape[0];\n  for (let i = 1; i < shape.length; i++) {\n    size *= shape[i];\n  }\n  return size;\n}\n\nexport function isScalarShape(shape: number[]): boolean {\n  return shape.length === 0;\n}\n\nexport function arraysEqual(n1: FlatVector, n2: FlatVector) {\n  if (n1 === n2) {\n    return true;\n  }\n  if (n1 == null || n2 == null) {\n    return false;\n  }\n\n  if (n1.length !== n2.length) {\n    return false;\n  }\n  for (let i = 0; i < n1.length; i++) {\n    if (n1[i] !== n2[i]) {\n      return false;\n    }\n  }\n  return true;\n}\n\nexport function isInt(a: number): boolean {\n  return a % 1 === 0;\n}\n\nexport function tanh(x: number): number {\n  // tslint:disable-next-line:no-any\n  if ((Math as any).tanh != null) {\n    // tslint:disable-next-line:no-any\n    return (Math as any).tanh(x);\n  }\n  if (x === Infinity) {\n    return 1;\n  } else if (x === -Infinity) {\n    return -1;\n  } else {\n    const e2x = Math.exp(2 * x);\n    return (e2x - 1) / (e2x + 1);\n  }\n}\n\nexport function sizeToSquarishShape(size: number): [number, number] {\n  const width = Math.ceil(Math.sqrt(size));\n  return [width, Math.ceil(size / width)];\n}\n\n/**\n * Creates a new array with randomized indices to a given quantity.\n *\n * ```js\n * const randomTen = tf.util.createShuffledIndices(10);\n * console.log(randomTen);\n * ```\n *\n * @param number Quantity of how many shuffled indices to create.\n *\n * @doc {heading: 'Util', namespace: 'util'}\n */\nexport function createShuffledIndices(n: number): Uint32Array {\n  const shuffledIndices = new Uint32Array(n);\n  for (let i = 0; i < n; ++i) {\n    shuffledIndices[i] = i;\n  }\n  shuffle(shuffledIndices);\n  return shuffledIndices;\n}\n\nexport function rightPad(a: string, size: number): string {\n  if (size <= a.length) {\n    return a;\n  }\n  return a + ' '.repeat(size - a.length);\n}\n\nexport function repeatedTry(\n    checkFn: () => boolean, delayFn = (counter: number) => 0,\n    maxCounter?: number,\n    scheduleFn: (functionRef: Function, delay: number) => void =\n        setTimeout): Promise<void> {\n  return new Promise<void>((resolve, reject) => {\n    let tryCount = 0;\n\n    const tryFn = () => {\n      if (checkFn()) {\n        resolve();\n        return;\n      }\n\n      tryCount++;\n\n      const nextBackoff = delayFn(tryCount);\n\n      if (maxCounter != null && tryCount >= maxCounter) {\n        reject();\n        return;\n      }\n      scheduleFn(tryFn, nextBackoff);\n    };\n\n    tryFn();\n  });\n}\n\n/**\n * Given the full size of the array and a shape that may contain -1 as the\n * implicit dimension, returns the inferred shape where -1 is replaced.\n * E.g. For shape=[2, -1, 3] and size=24, it will return [2, 4, 3].\n *\n * @param shape The shape, which may contain -1 in some dimension.\n * @param size The full size (number of elements) of the array.\n * @return The inferred shape where -1 is replaced with the inferred size.\n */\nexport function inferFromImplicitShape(\n    shape: number[], size: number): number[] {\n  let shapeProd = 1;\n  let implicitIdx = -1;\n\n  for (let i = 0; i < shape.length; ++i) {\n    if (shape[i] >= 0) {\n      shapeProd *= shape[i];\n    } else if (shape[i] === -1) {\n      if (implicitIdx !== -1) {\n        throw Error(\n            `Shapes can only have 1 implicit size. ` +\n            `Found -1 at dim ${implicitIdx} and dim ${i}`);\n      }\n      implicitIdx = i;\n    } else if (shape[i] < 0) {\n      throw Error(`Shapes can not be < 0. Found ${shape[i]} at dim ${i}`);\n    }\n  }\n\n  if (implicitIdx === -1) {\n    if (size > 0 && size !== shapeProd) {\n      throw Error(`Size(${size}) must match the product of shape ${shape}`);\n    }\n    return shape;\n  }\n\n  if (shapeProd === 0) {\n    throw Error(\n        `Cannot infer the missing size in [${shape}] when ` +\n        `there are 0 elements`);\n  }\n  if (size % shapeProd !== 0) {\n    throw Error(\n        `The implicit shape can't be a fractional number. ` +\n        `Got ${size} / ${shapeProd}`);\n  }\n\n  const newShape = shape.slice();\n  newShape[implicitIdx] = size / shapeProd;\n  return newShape;\n}\n\nexport function parseAxisParam(\n    axis: number|number[], shape: number[]): number[] {\n  const rank = shape.length;\n\n  // Normalize input\n  axis = axis == null ? shape.map((s, i) => i) : [].concat(axis);\n\n  // Check for valid range\n  assert(\n      axis.every(ax => ax >= -rank && ax < rank),\n      () =>\n          `All values in axis param must be in range [-${rank}, ${rank}) but ` +\n          `got axis ${axis}`);\n\n  // Check for only integers\n  assert(\n      axis.every(ax => isInt(ax)),\n      () => `All values in axis param must be integers but ` +\n          `got axis ${axis}`);\n\n  // Handle negative axis.\n  return axis.map(a => a < 0 ? rank + a : a);\n}\n\n/** Reduces the shape by removing all dimensions of shape 1. */\nexport function squeezeShape(shape: number[], axis?: number[]):\n    {newShape: number[], keptDims: number[]} {\n  const newShape: number[] = [];\n  const keptDims: number[] = [];\n  const isEmptyArray = axis != null && Array.isArray(axis) && axis.length === 0;\n  const axes = (axis == null || isEmptyArray) ?\n      null :\n      parseAxisParam(axis, shape).sort();\n  let j = 0;\n  for (let i = 0; i < shape.length; ++i) {\n    if (axes != null) {\n      if (axes[j] === i && shape[i] !== 1) {\n        throw new Error(\n            `Can't squeeze axis ${i} since its dim '${shape[i]}' is not 1`);\n      }\n      if ((axes[j] == null || axes[j] > i) && shape[i] === 1) {\n        newShape.push(shape[i]);\n        keptDims.push(i);\n      }\n      if (axes[j] <= i) {\n        j++;\n      }\n    }\n    if (shape[i] !== 1) {\n      newShape.push(shape[i]);\n      keptDims.push(i);\n    }\n  }\n  return {newShape, keptDims};\n}\n\nexport function getTypedArrayFromDType<D extends NumericDataType>(\n    dtype: D, size: number): DataTypeMap[D] {\n  let values = null;\n  if (dtype == null || dtype === 'float32') {\n    values = new Float32Array(size);\n  } else if (dtype === 'int32') {\n    values = new Int32Array(size);\n  } else if (dtype === 'bool') {\n    values = new Uint8Array(size);\n  } else {\n    throw new Error(`Unknown data type ${dtype}`);\n  }\n  return values as DataTypeMap[D];\n}\n\nexport function getArrayFromDType<D extends DataType>(\n    dtype: D, size: number): DataTypeMap[D] {\n  let values = null;\n  if (dtype == null || dtype === 'float32') {\n    values = new Float32Array(size);\n  } else if (dtype === 'int32') {\n    values = new Int32Array(size);\n  } else if (dtype === 'bool') {\n    values = new Uint8Array(size);\n  } else if (dtype === 'string') {\n    values = new Array<'string'>(size);\n  } else {\n    throw new Error(`Unknown data type ${dtype}`);\n  }\n  return values as DataTypeMap[D];\n}\n\nexport function checkConversionForErrors<D extends DataType>(\n    vals: DataTypeMap[D]|number[], dtype: D): void {\n  for (let i = 0; i < vals.length; i++) {\n    const num = vals[i] as number;\n    if (isNaN(num) || !isFinite(num)) {\n      throw Error(`A tensor of type ${dtype} being uploaded contains ${num}.`);\n    }\n  }\n}\n\n/** Returns true if the dtype is valid. */\nexport function isValidDtype(dtype: DataType): boolean {\n  return dtype === 'bool' || dtype === 'complex64' || dtype === 'float32' ||\n      dtype === 'int32' || dtype === 'string';\n}\n\n/**\n * Returns true if the new type can't encode the old type without loss of\n * precision.\n */\nexport function hasEncodingLoss(oldType: DataType, newType: DataType): boolean {\n  if (newType === 'complex64') {\n    return false;\n  }\n  if (newType === 'float32' && oldType !== 'complex64') {\n    return false;\n  }\n  if (newType === 'int32' && oldType !== 'float32' && oldType !== 'complex64') {\n    return false;\n  }\n  if (newType === 'bool' && oldType === 'bool') {\n    return false;\n  }\n  return true;\n}\n\nexport function isTypedArray(a: {}): a is Float32Array|Int32Array|Uint8Array|\n    Uint8ClampedArray {\n  return a instanceof Float32Array || a instanceof Int32Array ||\n      a instanceof Uint8Array || a instanceof Uint8ClampedArray;\n}\n\nexport function bytesPerElement(dtype: DataType): number {\n  if (dtype === 'float32' || dtype === 'int32') {\n    return 4;\n  } else if (dtype === 'complex64') {\n    return 8;\n  } else if (dtype === 'bool') {\n    return 1;\n  } else {\n    throw new Error(`Unknown dtype ${dtype}`);\n  }\n}\n\n/**\n * Returns the approximate number of bytes allocated in the string array - 2\n * bytes per character. Computing the exact bytes for a native string in JS\n * is not possible since it depends on the encoding of the html page that\n * serves the website.\n */\nexport function bytesFromStringArray(arr: Uint8Array[]): number {\n  if (arr == null) {\n    return 0;\n  }\n  let bytes = 0;\n  arr.forEach(x => bytes += x.length);\n  return bytes;\n}\n\n/** Returns true if the value is a string. */\nexport function isString(value: {}): value is string {\n  return typeof value === 'string' || value instanceof String;\n}\n\nexport function isBoolean(value: {}): boolean {\n  return typeof value === 'boolean';\n}\n\nexport function isNumber(value: {}): boolean {\n  return typeof value === 'number';\n}\n\nexport function inferDtype(values: TensorLike): DataType {\n  if (Array.isArray(values)) {\n    return inferDtype(values[0]);\n  }\n  if (values instanceof Float32Array) {\n    return 'float32';\n  } else if (\n      values instanceof Int32Array || values instanceof Uint8Array ||\n      values instanceof Uint8ClampedArray) {\n    return 'int32';\n  } else if (isNumber(values)) {\n    return 'float32';\n  } else if (isString(values)) {\n    return 'string';\n  } else if (isBoolean(values)) {\n    return 'bool';\n  }\n  return 'float32';\n}\n\nexport function isFunction(f: Function) {\n  return !!(f && f.constructor && f.call && f.apply);\n}\n\nexport function nearestDivisor(size: number, start: number): number {\n  for (let i = start; i < size; ++i) {\n    if (size % i === 0) {\n      return i;\n    }\n  }\n  return size;\n}\n\nexport function computeStrides(shape: number[]): number[] {\n  const rank = shape.length;\n  if (rank < 2) {\n    return [];\n  }\n\n  // Last dimension has implicit stride of 1, thus having D-1 (instead of D)\n  // strides.\n  const strides = new Array(rank - 1);\n  strides[rank - 2] = shape[rank - 1];\n  for (let i = rank - 3; i >= 0; --i) {\n    strides[i] = strides[i + 1] * shape[i + 1];\n  }\n  return strides;\n}\n\nfunction createNestedArray(\n    offset: number, shape: number[], a: TypedArray, isComplex = false) {\n  const ret = new Array();\n  if (shape.length === 1) {\n    const d = shape[0] * (isComplex ? 2 : 1);\n    for (let i = 0; i < d; i++) {\n      ret[i] = a[offset + i];\n    }\n  } else {\n    const d = shape[0];\n    const rest = shape.slice(1);\n    const len = rest.reduce((acc, c) => acc * c) * (isComplex ? 2 : 1);\n    for (let i = 0; i < d; i++) {\n      ret[i] = createNestedArray(offset + i * len, rest, a, isComplex);\n    }\n  }\n  return ret;\n}\n\n// Provide a nested array of TypedArray in given shape.\nexport function toNestedArray(\n    shape: number[], a: TypedArray, isComplex = false) {\n  if (shape.length === 0) {\n    // Scalar type should return a single number.\n    return a[0];\n  }\n  const size = shape.reduce((acc, c) => acc * c) * (isComplex ? 2 : 1);\n  if (size === 0) {\n    // A tensor with shape zero should be turned into empty list.\n    return [];\n  }\n  if (size !== a.length) {\n    throw new Error(`[${shape}] does not match the input size ${a.length}${\n        isComplex ? ' for a complex tensor' : ''}.`);\n  }\n\n  return createNestedArray(0, shape, a, isComplex);\n}\n\nexport function makeOnesTypedArray<D extends DataType>(\n    size: number, dtype: D): DataTypeMap[D] {\n  const array = makeZerosTypedArray(size, dtype);\n  for (let i = 0; i < array.length; i++) {\n    array[i] = 1;\n  }\n  return array;\n}\n\nexport function makeZerosTypedArray<D extends DataType>(\n    size: number, dtype: D): DataTypeMap[D] {\n  if (dtype == null || dtype === 'float32' || dtype === 'complex64') {\n    return new Float32Array(size) as DataTypeMap[D];\n  } else if (dtype === 'int32') {\n    return new Int32Array(size) as DataTypeMap[D];\n  } else if (dtype === 'bool') {\n    return new Uint8Array(size) as DataTypeMap[D];\n  } else {\n    throw new Error(`Unknown data type ${dtype}`);\n  }\n}\n\n/**\n * Make nested `TypedArray` filled with zeros.\n * @param shape The shape information for the nested array.\n * @param dtype dtype of the array element.\n */\nexport function makeZerosNestedTypedArray<D extends DataType>(\n    shape: number[], dtype: D) {\n  const size = shape.reduce((prev, curr) => prev * curr, 1);\n  if (dtype == null || dtype === 'float32') {\n    return toNestedArray(shape, new Float32Array(size));\n  } else if (dtype === 'int32') {\n    return toNestedArray(shape, new Int32Array(size));\n  } else if (dtype === 'bool') {\n    return toNestedArray(shape, new Uint8Array(size));\n  } else {\n    throw new Error(`Unknown data type ${dtype}`);\n  }\n}\n\nexport function assertNonNegativeIntegerDimensions(shape: number[]) {\n  shape.forEach(dimSize => {\n    assert(\n        Number.isInteger(dimSize) && dimSize >= 0,\n        () =>\n            `Tensor must have a shape comprised of positive integers but got ` +\n            `shape [${shape}].`);\n  });\n}\n\n/**\n * Computes flat index for a given location (multidimentionsal index) in a\n * Tensor/multidimensional array.\n *\n * @param locs Location in the tensor.\n * @param rank Rank of the tensor.\n * @param strides Tensor strides.\n */\nexport function locToIndex(\n    locs: number[], rank: number, strides: number[]): number {\n  if (rank === 0) {\n    return 0;\n  } else if (rank === 1) {\n    return locs[0];\n  }\n  let index = locs[locs.length - 1];\n  for (let i = 0; i < locs.length - 1; ++i) {\n    index += strides[i] * locs[i];\n  }\n  return index;\n}\n\n/**\n * Computes the location (multidimensional index) in a\n * tensor/multidimentional array for a given flat index.\n *\n * @param index Index in flat array.\n * @param rank Rank of tensor.\n * @param strides Strides of tensor.\n */\nexport function indexToLoc(\n    index: number, rank: number, strides: number[]): number[] {\n  if (rank === 0) {\n    return [];\n  } else if (rank === 1) {\n    return [index];\n  }\n  const locs: number[] = new Array(rank);\n  for (let i = 0; i < locs.length - 1; ++i) {\n    locs[i] = Math.floor(index / strides[i]);\n    index -= locs[i] * strides[i];\n  }\n  locs[locs.length - 1] = index;\n  return locs;\n}\n\n/**\n * This method asserts whether an object is a Promise instance.\n * @param object\n */\n// tslint:disable-next-line: no-any\nexport function isPromise(object: any): object is Promise<unknown> {\n  //  We chose to not use 'obj instanceOf Promise' for two reasons:\n  //  1. It only reliably works for es6 Promise, not other Promise\n  //  implementations.\n  //  2. It doesn't work with framework that uses zone.js. zone.js monkey\n  //  patch the async calls, so it is possible the obj (patched) is\n  //  comparing to a pre-patched Promise.\n  return object && object.then && typeof object.then === 'function';\n}\n","/**\n * @license\n * Copyright 2017 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Platform} from './platforms/platform';\nimport {isPromise} from './util_base';\n\n// Expects flags from URL in the format ?tfjsflags=FLAG1:1,FLAG2:true.\nconst TENSORFLOWJS_FLAGS_PREFIX = 'tfjsflags';\n\ntype FlagValue = number|boolean;\ntype FlagEvaluationFn = (() => FlagValue)|(() => Promise<FlagValue>);\nexport type Flags = {\n  [featureName: string]: FlagValue\n};\nexport type FlagRegistryEntry = {\n  evaluationFn: FlagEvaluationFn;\n  setHook?: (value: FlagValue) => void;\n};\n\n/**\n * The environment contains evaluated flags as well as the registered platform.\n * This is always used as a global singleton and can be retrieved with\n * `tf.env()`.\n *\n * @doc {heading: 'Environment'}\n */\nexport class Environment {\n  private flags: Flags = {};\n  private flagRegistry: {[flagName: string]: FlagRegistryEntry} = {};\n\n  private urlFlags: Flags = {};\n\n  platformName: string;\n  platform: Platform;\n\n  // Jasmine spies on this in 'environment_test.ts'\n  getQueryParams = getQueryParams;\n\n  // tslint:disable-next-line: no-any\n  constructor(public global: any) {\n    this.populateURLFlags();\n  }\n\n  setPlatform(platformName: string, platform: Platform) {\n    if (this.platform != null) {\n      if (!(env().getBool('IS_TEST') || env().getBool('PROD'))) {\n        console.warn(\n            `Platform ${this.platformName} has already been set. ` +\n            `Overwriting the platform with ${platformName}.`);\n      }\n    }\n    this.platformName = platformName;\n    this.platform = platform;\n  }\n\n  registerFlag(\n      flagName: string, evaluationFn: FlagEvaluationFn,\n      setHook?: (value: FlagValue) => void) {\n    this.flagRegistry[flagName] = {evaluationFn, setHook};\n\n    // Override the flag value from the URL. This has to happen here because\n    // the environment is initialized before flags get registered.\n    if (this.urlFlags[flagName] != null) {\n      const flagValue = this.urlFlags[flagName];\n      if (!(env().getBool('IS_TEST') || env().getBool('PROD'))) {\n        console.warn(\n            `Setting feature override from URL ${flagName}: ${flagValue}.`);\n      }\n      this.set(flagName, flagValue);\n    }\n  }\n\n  async getAsync(flagName: string): Promise<FlagValue> {\n    if (flagName in this.flags) {\n      return this.flags[flagName];\n    }\n\n    this.flags[flagName] = await this.evaluateFlag(flagName);\n    return this.flags[flagName];\n  }\n\n  get(flagName: string): FlagValue {\n    if (flagName in this.flags) {\n      return this.flags[flagName];\n    }\n\n    const flagValue = this.evaluateFlag(flagName);\n    if (isPromise(flagValue)) {\n      throw new Error(\n          `Flag ${flagName} cannot be synchronously evaluated. ` +\n          `Please use getAsync() instead.`);\n    }\n\n    this.flags[flagName] = flagValue;\n    return this.flags[flagName];\n  }\n\n  getNumber(flagName: string): number {\n    return this.get(flagName) as number;\n  }\n\n  getBool(flagName: string): boolean {\n    return this.get(flagName) as boolean;\n  }\n\n  getFlags(): Flags {\n    return this.flags;\n  }\n  // For backwards compatibility.\n  get features(): Flags {\n    return this.flags;\n  }\n\n  set(flagName: string, value: FlagValue): void {\n    if (this.flagRegistry[flagName] == null) {\n      throw new Error(\n          `Cannot set flag ${flagName} as it has not been registered.`);\n    }\n    this.flags[flagName] = value;\n    if (this.flagRegistry[flagName].setHook != null) {\n      this.flagRegistry[flagName].setHook(value);\n    }\n  }\n\n  private evaluateFlag(flagName: string): FlagValue|Promise<FlagValue> {\n    if (this.flagRegistry[flagName] == null) {\n      throw new Error(\n          `Cannot evaluate flag '${flagName}': no evaluation function found.`);\n    }\n    return this.flagRegistry[flagName].evaluationFn();\n  }\n\n  setFlags(flags: Flags) {\n    this.flags = Object.assign({}, flags);\n  }\n\n  reset() {\n    this.flags = {};\n    this.urlFlags = {};\n    this.populateURLFlags();\n  }\n\n  private populateURLFlags(): void {\n    if (typeof this.global === 'undefined' ||\n        typeof this.global.location === 'undefined' ||\n        typeof this.global.location.search === 'undefined') {\n      return;\n    }\n\n    const urlParams = this.getQueryParams(this.global.location.search);\n    if (TENSORFLOWJS_FLAGS_PREFIX in urlParams) {\n      const keyValues = urlParams[TENSORFLOWJS_FLAGS_PREFIX].split(',');\n      keyValues.forEach(keyValue => {\n        const [key, value] = keyValue.split(':') as [string, string];\n        this.urlFlags[key] = parseValue(key, value);\n      });\n    }\n  }\n}\n\nexport function getQueryParams(queryString: string): {[key: string]: string} {\n  const params = {};\n  queryString.replace(/[?&]([^=?&]+)(?:=([^&]*))?/g, (s, ...t) => {\n    decodeParam(params, t[0], t[1]);\n    return t.join('=');\n  });\n  return params;\n}\n\nfunction decodeParam(\n    params: {[key: string]: string}, name: string, value?: string) {\n  params[decodeURIComponent(name)] = decodeURIComponent(value || '');\n}\n\nfunction parseValue(flagName: string, value: string): FlagValue {\n  value = value.toLowerCase();\n  if (value === 'true' || value === 'false') {\n    return value === 'true';\n  } else if (`${+ value}` === value) {\n    return +value;\n  }\n  throw new Error(\n      `Could not parse value flag value ${value} for flag ${flagName}.`);\n}\n\n/**\n * Returns the current environment (a global singleton).\n *\n * The environment object contains the evaluated feature values as well as the\n * active platform.\n *\n * @doc {heading: 'Environment'}\n */\nexport function env() {\n  return ENV;\n}\n\nexport let ENV: Environment = null;\nexport function setEnvironmentGlobal(environment: Environment) {\n  ENV = environment;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n// Note that the identifier globalNameSpace is scoped to this module, but will\n// always resolve to the same global object regardless of how the module is\n// resolved.\n// tslint:disable-next-line:no-any\nlet globalNameSpace: {_tfGlobals: Map<string, any>};\n// tslint:disable-next-line:no-any\nexport function getGlobalNamespace(): {_tfGlobals: Map<string, any>} {\n  if (globalNameSpace == null) {\n    // tslint:disable-next-line:no-any\n    let ns: any;\n    if (typeof (window) !== 'undefined') {\n      ns = window;\n    } else if (typeof (global) !== 'undefined') {\n      ns = global;\n    } else if (typeof (process) !== 'undefined') {\n      ns = process;\n    } else if (typeof (self) !== 'undefined') {\n      ns = self;\n    } else {\n      throw new Error('Could not find a global object');\n    }\n    globalNameSpace = ns;\n  }\n  return globalNameSpace;\n}\n\n// tslint:disable-next-line:no-any\nfunction getGlobalMap(): Map<string, any> {\n  const ns = getGlobalNamespace();\n  if (ns._tfGlobals == null) {\n    ns._tfGlobals = new Map();\n  }\n  return ns._tfGlobals;\n}\n\n/**\n * Returns a globally accessible 'singleton' object.\n *\n * @param key the name of the object\n * @param init a function to initialize to initialize this object\n *             the first time it is fetched.\n */\nexport function getGlobal<T>(key: string, init: () => T): T {\n  const globalMap = getGlobalMap();\n  if (globalMap.has(key)) {\n    return globalMap.get(key);\n  } else {\n    const singleton = init();\n    globalMap.set(key, singleton);\n    return globalMap.get(key);\n  }\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n// Allow UpperCamelCase variable names\n// tslint:disable: variable-name\n// Unfortunately just enabling PascalCase per file (tslint:enable:\n// allow-pascal-case) doesn't work.\nimport {NamedTensorInfoMap, TensorInfo} from './kernel_registry';\nimport {ExplicitPadding} from './ops/conv_util';\nimport {Activation} from './ops/fused_types';\nimport {DataType, PixelData} from './types';\n\nexport const Abs = 'Abs';\nexport type AbsInputs = UnaryInputs;\n\nexport const Acos = 'Acos';\nexport type AcosInputs = UnaryInputs;\n\nexport const Acosh = 'Acosh';\nexport type AcoshInputs = UnaryInputs;\n\nexport const Add = 'Add';\nexport type AddInputs = BinaryInputs;\n\nexport const AddN = 'AddN';\nexport type AddNInputs = TensorInfo[];\n\nexport const All = 'All';\nexport type AllInputs = Pick<NamedTensorInfoMap, 'x'>;\nexport interface AllAttrs {\n  axis: number|number[];\n  keepDims: boolean;\n}\n\nexport const Any = 'Any';\nexport type AnyInputs = Pick<NamedTensorInfoMap, 'x'>;\nexport interface AnyAttrs {\n  axis: number|number[];\n  keepDims: boolean;\n}\n\nexport const ArgMax = 'ArgMax';\nexport type ArgMaxInputs = Pick<NamedTensorInfoMap, 'x'>;\nexport interface ArgMaxAttrs {\n  axis: number;\n}\n\nexport const ArgMin = 'ArgMin';\nexport type ArgMinInputs = Pick<NamedTensorInfoMap, 'x'>;\nexport interface ArgMinAttrs {\n  axis: number;\n}\n\nexport const Asin = 'Asin';\nexport type AsinInputs = UnaryInputs;\n\nexport const Asinh = 'Asinh';\nexport type AsinhInputs = UnaryInputs;\n\nexport const Atan = 'Atan';\nexport type AtanInputs = UnaryInputs;\n\nexport const Atanh = 'Atanh';\nexport type AtanhInputs = UnaryInputs;\n\nexport const Atan2 = 'Atan2';\nexport type Atan2Inputs = BinaryInputs;\n\nexport const AvgPool = 'AvgPool';\nexport type AvgPoolInputs = Pick<NamedTensorInfoMap, 'x'>;\nexport interface AvgPoolAttrs {\n  filterSize: [number, number]|number;\n  strides: [number, number]|number;\n  pad: 'valid'|'same'|number|ExplicitPadding;\n  dimRoundingMode?: 'floor'|'round'|'ceil';\n}\n\nexport const AvgPoolGrad = 'AvgPoolGrad';\nexport type AvgPoolGradInputs = Pick<NamedTensorInfoMap, 'dy'|'input'>;\nexport interface AvgPoolGradAttrs {\n  filterSize: [number, number]|number;\n  strides: [number, number]|number;\n  pad: 'valid'|'same'|number|ExplicitPadding;\n}\n\nexport const AvgPool3D = 'AvgPool3D';\nexport type AvgPool3DInputs = Pick<NamedTensorInfoMap, 'x'>;\nexport interface AvgPool3DAttrs {\n  filterSize: [number, number, number]|number;\n  strides: [number, number, number]|number;\n  pad: 'valid'|'same'|number;\n  dimRoundingMode?: 'floor'|'round'|'ceil';\n  dataFormat: 'NDHWC'|'NCDHW';\n}\n\nexport const AvgPool3DGrad = 'AvgPool3DGrad';\nexport type AvgPool3DGradInputs = Pick<NamedTensorInfoMap, 'dy'|'input'>;\nexport interface AvgPool3DGradAttrs {\n  filterSize: [number, number, number]|number;\n  strides: [number, number, number]|number;\n  pad: 'valid'|'same'|number;\n  dimRoundingMode?: 'floor'|'round'|'ceil';\n}\n\nexport const BatchMatMul = 'BatchMatMul';\nexport type BatchMatMulInputs = Pick<NamedTensorInfoMap, 'a'|'b'>;\nexport interface BatchMatMulAttrs {\n  transposeA: boolean;\n  transposeB: boolean;\n}\n\nexport const BatchToSpaceND = 'BatchToSpaceND';\nexport type BatchToSpaceNDInputs = Pick<NamedTensorInfoMap, 'x'>;\nexport interface BatchToSpaceNDAttrs {\n  blockShape: number[];\n  crops: number[][];\n}\n\nexport type BinaryInputs = Pick<NamedTensorInfoMap, 'a'|'b'>;\n\nexport const Bincount = 'Bincount';\nexport type BincountInputs = Pick<NamedTensorInfoMap, 'x'|'weights'>;\nexport interface BincountAttrs {\n  size: number;\n}\n\nexport const BroadcastTo = 'BroadcastTo';\nexport type BroadcastToInputs = Pick<NamedTensorInfoMap, 'x'>;\nexport interface BroadCastToAttrs {\n  shape: number[];\n  inputShape: number[];  // for gradient\n}\n\nexport const BroadcastArgs = 'BroadcastArgs';\nexport type BroadcastArgsInputs = Pick<NamedTensorInfoMap, 's0'|'s1'>;\n\nexport const Cast = 'Cast';\nexport type CastInputs = UnaryInputs;\nexport interface CastAttrs {\n  dtype: DataType;\n}\n\nexport const Ceil = 'Ceil';\nexport type CeilInputs = UnaryInputs;\n\nexport const ClipByValue = 'ClipByValue';\nexport type ClipByValueInputs = UnaryInputs;\nexport interface ClipByValueAttrs {\n  clipValueMin: number;\n  clipValueMax: number;\n}\n\nexport const Complex = 'Complex';\nexport type ComplexInputs = Pick<NamedTensorInfoMap, 'real'|'imag'>;\n\nexport const ComplexAbs = 'ComplexAbs';\nexport type ComplexAbsInputs = UnaryInputs;\n\nexport const Concat = 'Concat';\nexport type ConcatInputs = TensorInfo[];\nexport interface ConcatAttrs {\n  axis: number;\n}\n\nexport const Conv2D = 'Conv2D';\nexport type Conv2DInputs = Pick<NamedTensorInfoMap, 'x'|'filter'>;\nexport interface Conv2DAttrs {\n  strides: [number, number]|number;\n  pad: 'valid'|'same'|number|ExplicitPadding;\n  dataFormat: 'NHWC'|'NCHW';\n  dilations: [number, number]|number;\n  dimRoundingMode?: 'floor'|'round'|'ceil';\n}\n\nexport const Conv2DBackpropFilter = 'Conv2DBackpropFilter';\nexport type Conv2DBackpropFilterInputs = Pick<NamedTensorInfoMap, 'x'|'dy'>;\nexport interface Conv2DBackpropFilterAttrs {\n  strides: [number, number]|number;\n  pad: 'valid'|'same'|number|ExplicitPadding;\n  dataFormat: 'NHWC'|'NCHW';\n  dimRoundingMode?: 'floor'|'round'|'ceil';\n  filterShape: [number, number, number, number];\n}\n\nexport const Conv2DBackpropInput = 'Conv2DBackpropInput';\nexport type Conv2DBackpropInputInputs = Pick<NamedTensorInfoMap, 'dy'|'filter'>;\nexport interface Conv2DBackpropInputAttrs {\n  strides: [number, number]|number;\n  pad: 'valid'|'same'|number|ExplicitPadding;\n  dataFormat: 'NHWC'|'NCHW';\n  dimRoundingMode?: 'floor'|'round'|'ceil';\n  inputShape: [number, number, number, number];\n}\n\nexport const Conv3D = 'Conv3D';\nexport type Conv3DInputs = Pick<NamedTensorInfoMap, 'x'|'filter'>;\nexport interface Conv3DAttrs {\n  strides: [number, number, number]|number;\n  pad: 'valid'|'same';\n  dataFormat: 'NDHWC'|'NCDHW';\n  dilations: [number, number, number]|number;\n}\n\nexport const Conv3DBackpropFilterV2 = 'Conv3DBackpropFilterV2';\nexport type Conv3DBackpropFilterV2Inputs = Pick<NamedTensorInfoMap, 'x'|'dy'>;\n\nexport interface Conv3DBackpropFilterV2Attrs {\n  strides: [number, number, number]|number;\n  pad: 'valid'|'same';\n  filterShape: [number, number, number, number, number];\n}\n\nexport const Conv3DBackpropInputV2 = 'Conv3DBackpropInputV2';\nexport type Conv3DBackpropInputV2Inputs =\n    Pick<NamedTensorInfoMap, 'dy'|'filter'>;\nexport interface Conv3DBackpropInputV2Attrs {\n  strides: [number, number, number]|number;\n  pad: 'valid'|'same';\n  inputShape: [number, number, number, number, number];\n}\n\nexport const Cos = 'Cos';\nexport type CosInputs = UnaryInputs;\n\nexport const Cosh = 'Cosh';\nexport type CoshInputs = UnaryInputs;\n\nexport const Cumprod = 'Cumprod';\nexport type CumprodInputs = Pick<NamedTensorInfoMap, 'x'>;\nexport interface CumprodAttrs {\n  axis: number;\n  exclusive: boolean;\n  reverse: boolean;\n}\n\nexport const Cumsum = 'Cumsum';\nexport type CumsumInputs = Pick<NamedTensorInfoMap, 'x'>;\nexport interface CumsumAttrs {\n  axis: number;\n  exclusive: boolean;\n  reverse: boolean;\n}\n\nexport const CropAndResize = 'CropAndResize';\nexport type CropAndResizeInputs =\n    Pick<NamedTensorInfoMap, 'image'|'boxes'|'boxInd'>;\nexport interface CropAndResizeAttrs {\n  cropSize: [number, number];\n  method: 'bilinear'|'nearest';\n  extrapolationValue: number;\n}\n\nexport const DenseBincount = 'DenseBincount';\nexport type DenseBincountInputs = Pick<NamedTensorInfoMap, 'x'|'weights'>;\nexport interface DenseBincountAttrs {\n  size: number;\n  binaryOutput?: boolean;\n}\n\nexport const DepthToSpace = 'DepthToSpace';\nexport type DepthToSpaceInputs = Pick<NamedTensorInfoMap, 'x'>;\nexport interface DepthToSpaceAttrs {\n  blockSize: number;\n  dataFormat: 'NHWC'|'NCHW';\n}\n\nexport const DepthwiseConv2dNative = 'DepthwiseConv2dNative';\nexport type DepthwiseConv2dNativeInputs =\n    Pick<NamedTensorInfoMap, 'x'|'filter'>;\nexport interface DepthwiseConv2dNativeAttrs {\n  strides: [number, number]|number;\n  pad: 'valid'|'same'|number|ExplicitPadding;\n  dataFormat: 'NHWC'|'NCHW';\n  dilations: [number, number]|number;\n  dimRoundingMode?: 'floor'|'round'|'ceil';\n}\n\nexport const DepthwiseConv2dNativeBackpropFilter =\n    'DepthwiseConv2dNativeBackpropFilter';\nexport type DepthwiseConv2dNativeBackpropFilterInputs =\n    Pick<NamedTensorInfoMap, 'x'|'dy'>;\nexport interface DepthwiseConv2dNativeBackpropFilterAttrs {\n  strides: [number, number]|number;\n  dilations: [number, number]|number;\n  pad: 'valid'|'same'|number|ExplicitPadding;\n  dimRoundingMode?: 'floor'|'round'|'ceil';\n  filterShape: [number, number, number, number];\n}\n\nexport const DepthwiseConv2dNativeBackpropInput =\n    'DepthwiseConv2dNativeBackpropInput';\nexport type DepthwiseConv2dNativeBackpropInputInputs =\n    Pick<NamedTensorInfoMap, 'dy'|'filter'>;\nexport interface DepthwiseConv2dNativeBackpropInputAttrs {\n  strides: [number, number]|number;\n  dilations: [number, number]|number;\n  pad: 'valid'|'same'|number|ExplicitPadding;\n  dimRoundingMode?: 'floor'|'round'|'ceil';\n  inputShape: [number, number, number, number];\n}\n\nexport const Diag = 'Diag';\nexport type DiagInputs = Pick<NamedTensorInfoMap, 'x'>;\n\nexport const Dilation2D = 'Dilation2D';\nexport type Dilation2DInputs = Pick<NamedTensorInfoMap, 'x'|'filter'>;\nexport interface Dilation2DAttrs {\n  strides: [number, number]|number;\n  pad: 'valid'|'same'|number;\n  dilations: [number, number]|number;\n}\n\nexport const Dilation2DBackpropInput = 'Dilation2DBackpropInput';\nexport type Dilation2DBackpropInputInputs =\n    Pick<NamedTensorInfoMap, 'x'|'filter'|'dy'>;\n\nexport const Dilation2DBackpropFilter = 'Dilation2DBackpropFilter';\nexport type Dilation2DBackpropFilterInputs =\n    Pick<NamedTensorInfoMap, 'x'|'filter'|'dy'>;\n\nexport const RealDiv = 'RealDiv';\nexport type RealDivInputs = BinaryInputs;\n\nexport const Einsum = 'Einsum';\nexport type EinsumInputs = TensorInfo[];\nexport interface EinsumAttrs {\n  equation: string;\n}\n\nexport const Elu = 'Elu';\nexport type EluInputs = Pick<NamedTensorInfoMap, 'x'>;\n\nexport const EluGrad = 'EluGrad';\nexport type EluGradInputs = Pick<NamedTensorInfoMap, 'dy'|'y'>;\n\nexport const Erf = 'Erf';\nexport type ErfInputs = UnaryInputs;\n\nexport const Equal = 'Equal';\nexport type EqualInputs = BinaryInputs;\n\nexport const Exp = 'Exp';\nexport type ExpInputs = UnaryInputs;\n\nexport const ExpandDims = 'ExpandDims';\nexport type ExpandDimsInputs = Pick<NamedTensorInfoMap, 'input'>;\nexport interface ExpandDimsAttrs {\n  dim: number;\n}\n\nexport const Expm1 = 'Expm1';\nexport type Expm1Inputs = UnaryInputs;\n\nexport const FFT = 'FFT';\nexport type FFTInputs = Pick<NamedTensorInfoMap, 'input'>;\n\nexport const Fill = 'Fill';\nexport interface FillAttrs {\n  shape: number[];\n  value: number|string;\n  dtype: DataType;\n}\n\nexport const FlipLeftRight = 'FlipLeftRight';\nexport type FlipLeftRightInputs = Pick<NamedTensorInfoMap, 'image'>;\n\nexport const Floor = 'Floor';\nexport type FloorInputs = UnaryInputs;\n\nexport const FloorDiv = 'FloorDiv';\nexport type FloorDivInputs = BinaryInputs;\n\nexport const FusedBatchNorm = 'FusedBatchNorm';\nexport type FusedBatchNormInputs =\n    Pick<NamedTensorInfoMap, 'x'|'scale'|'offset'|'mean'|'variance'>;\nexport interface FusedBatchNormAttrs {\n  varianceEpsilon: number;\n}\n\nexport const GatherV2 = 'GatherV2';\nexport type GatherV2Inputs = Pick<NamedTensorInfoMap, 'x'|'indices'>;\nexport interface GatherV2Attrs {\n  axis: number;\n  batchDims: number;\n}\n\nexport const GatherNd = 'GatherNd';\nexport type GatherNdInputs = Pick<NamedTensorInfoMap, 'params'|'indices'>;\n\nexport const Greater = 'Greater';\nexport type GreaterInputs = BinaryInputs;\n\nexport const GreaterEqual = 'GreaterEqual';\nexport type GreaterEqualInputs = BinaryInputs;\n\nexport const Identity = 'Identity';\nexport type IdentityInputs = Pick<NamedTensorInfoMap, 'x'>;\n\nexport const IFFT = 'IFFT';\nexport type IFFTInputs = Pick<NamedTensorInfoMap, 'input'>;\n\nexport const Imag = 'Imag';\nexport type ImagInputs = Pick<NamedTensorInfoMap, 'input'>;\n\nexport const IsFinite = 'IsFinite';\nexport type IsFiniteInputs = UnaryInputs;\n\nexport const IsInf = 'IsInf';\nexport type IsInfInputs = UnaryInputs;\n\nexport const IsNan = 'IsNan';\nexport type IsNanInputs = UnaryInputs;\n\nexport const LeakyRelu = 'LeakyRelu';\nexport type LeakyReluInputs = Pick<NamedTensorInfoMap, 'x'>;\nexport interface LeakyReluAttrs {\n  alpha: number;\n}\n\nexport const Less = 'Less';\nexport type LessInputs = BinaryInputs;\n\nexport const LessEqual = 'LessEqual';\nexport type LessEqualInputs = BinaryInputs;\n\nexport const LinSpace = 'LinSpace';\nexport interface LinSpaceAttrs {\n  start: number;\n  stop: number;\n  num: number;\n}\nexport const Log = 'Log';\nexport type LogInputs = UnaryInputs;\n\nexport const Log1p = 'Log1p';\nexport type Log1pInputs = UnaryInputs;\n\nexport const LogicalAnd = 'LogicalAnd';\nexport type LogicalAndInputs = BinaryInputs;\n\nexport const LogicalNot = 'LogicalNot';\nexport type LogicalNotInputs = Pick<NamedTensorInfoMap, 'x'>;\n\nexport const LogicalOr = 'LogicalOr';\nexport type LogicalOrInputs = BinaryInputs;\n\nexport const LogicalXor = 'LogicalXor';\nexport type LogicalXorInputs = BinaryInputs;\n\nexport const LogSoftmax = 'LogSoftmax';\nexport type LogSoftmaxInputs = Pick<NamedTensorInfoMap, 'logits'>;\nexport interface LogSoftmaxAttrs {\n  axis: number;\n}\n\nexport const LowerBound = 'LowerBound';\nexport type LowerBoundInputs =\n    Pick<NamedTensorInfoMap, 'sortedSequence'|'values'>;\n\nexport const LRN = 'LRN';\nexport type LRNInputs = Pick<NamedTensorInfoMap, 'x'>;\nexport interface LRNAttrs {\n  depthRadius: number;\n  bias: number;\n  alpha: number;\n  beta: number;\n}\n\nexport const LRNGrad = 'LRNGrad';\nexport type LRNGradInputs = Pick<NamedTensorInfoMap, 'x'|'y'|'dy'>;\nexport interface LRNGradAttrs {\n  depthRadius: number;\n  bias: number;\n  alpha: number;\n  beta: number;\n}\n\nexport const Max = 'Max';\nexport type MaxInputs = Pick<NamedTensorInfoMap, 'x'>;\nexport interface MaxAttrs {\n  reductionIndices: number|number[];\n  keepDims: boolean;\n}\n\nexport const Maximum = 'Maximum';\nexport type MaximumInputs = BinaryInputs;\n\nexport const MaxPool = 'MaxPool';\nexport type MaxPoolInputs = Pick<NamedTensorInfoMap, 'x'>;\nexport interface MaxPoolAttrs {\n  filterSize: [number, number]|number;\n  strides: [number, number]|number;\n  pad: 'valid'|'same'|number|ExplicitPadding;\n  dimRoundingMode?: 'floor'|'round'|'ceil';\n}\n\nexport const MaxPoolGrad = 'MaxPoolGrad';\nexport type MaxPoolGradInputs = Pick<NamedTensorInfoMap, 'dy'|'input'|'output'>;\nexport interface MaxPoolGradAttrs {\n  filterSize: [number, number]|number;\n  strides: [number, number]|number;\n  pad: 'valid'|'same'|number|ExplicitPadding;\n  dimRoundingMode?: 'floor'|'round'|'ceil';\n}\n\nexport const MaxPool3D = 'MaxPool3D';\nexport type MaxPool3DInputs = Pick<NamedTensorInfoMap, 'x'>;\nexport interface MaxPool3DAttrs {\n  filterSize: [number, number, number]|number;\n  strides: [number, number, number]|number;\n  pad: 'valid'|'same'|number;\n  dataFormat: 'NDHWC'|'NCDHW';\n  dimRoundingMode?: 'floor'|'round'|'ceil';\n}\n\nexport const MaxPool3DGrad = 'MaxPool3DGrad';\nexport type MaxPool3DGradInputs =\n    Pick<NamedTensorInfoMap, 'dy'|'input'|'output'>;\nexport interface MaxPool3DGradAttrs {\n  filterSize: [number, number, number]|number;\n  strides: [number, number, number]|number;\n  pad: 'valid'|'same'|number;\n  dimRoundingMode?: 'floor'|'round'|'ceil';\n}\n\nexport const MaxPoolWithArgmax = 'MaxPoolWithArgmax';\nexport type MaxPoolWithArgmaxInputs = Pick<NamedTensorInfoMap, 'x'>;\nexport interface MaxPoolWithArgmaxAttrs {\n  filterSize: [number, number]|number;\n  strides: [number, number]|number;\n  pad: 'valid'|'same'|number;\n  includeBatchInIndex: boolean;\n}\n\nexport const Mean = 'Mean';\nexport type MeanInputs = Pick<NamedTensorInfoMap, 'x'>;\nexport interface MeanAttrs {\n  axis: number|number[];\n  keepDims: boolean;\n}\n\nexport const Min = 'Min';\nexport type MinInputs = Pick<NamedTensorInfoMap, 'x'>;\nexport interface MinAttrs {\n  axis: number|number[];\n  keepDims: boolean;\n}\n\nexport const Minimum = 'Minimum';\nexport type MinimumInputs = BinaryInputs;\n\nexport const MirrorPad = 'MirrorPad';\nexport type MirrorPadInputs = Pick<NamedTensorInfoMap, 'x'>;\nexport interface MirrorPadAttrs {\n  paddings: Array<[number, number]>;\n  mode: 'reflect'|'symmetric';\n}\n\nexport const Mod = 'Mod';\nexport type ModInputs = BinaryInputs;\n\nexport const Multinomial = 'Multinomial';\nexport type MultinomialInputs = Pick<NamedTensorInfoMap, 'logits'>;\nexport interface MultinomialAttrs {\n  numSamples: number;\n  seed: number;\n  normalized: boolean;\n}\n\nexport const Multiply = 'Multiply';\nexport type MultiplyInputs = BinaryInputs;\n\nexport const Neg = 'Neg';\nexport type NegInputs = UnaryInputs;\n\nexport const NotEqual = 'NotEqual';\nexport type NotEqualInputs = BinaryInputs;\n\nexport const NonMaxSuppressionV3 = 'NonMaxSuppressionV3';\nexport type NonMaxSuppressionV3Inputs =\n    Pick<NamedTensorInfoMap, 'boxes'|'scores'>;\nexport interface NonMaxSuppressionV3Attrs {\n  maxOutputSize: number;\n  iouThreshold: number;\n  scoreThreshold: number;\n}\n\nexport const NonMaxSuppressionV4 = 'NonMaxSuppressionV4';\nexport type NonMaxSuppressionV4Inputs =\n    Pick<NamedTensorInfoMap, 'boxes'|'scores'>;\nexport interface NonMaxSuppressionV4Attrs {\n  maxOutputSize: number;\n  iouThreshold: number;\n  scoreThreshold: number;\n  padToMaxOutputSize: boolean;\n}\n\nexport const NonMaxSuppressionV5 = 'NonMaxSuppressionV5';\nexport type NonMaxSuppressionV5Inputs =\n    Pick<NamedTensorInfoMap, 'boxes'|'scores'>;\nexport interface NonMaxSuppressionV5Attrs {\n  maxOutputSize: number;\n  iouThreshold: number;\n  scoreThreshold: number;\n  softNmsSigma: number;\n}\n\nexport const OnesLike = 'OnesLike';\nexport type OnesLikeInputs = UnaryInputs;\n\nexport const OneHot = 'OneHot';\nexport type OneHotInputs = Pick<NamedTensorInfoMap, 'indices'>;\nexport interface OneHotAttrs {\n  depth: number;\n  onValue: number;\n  offValue: number;\n  dtype: DataType;\n}\n\nexport const Pack = 'Pack';\nexport type PackInputs = TensorInfo[];\nexport interface PackAttrs {\n  axis: number;\n}\n\nexport const PadV2 = 'PadV2';\nexport type PadV2Inputs = Pick<NamedTensorInfoMap, 'x'>;\nexport interface PadV2Attrs {\n  paddings: Array<[number, number]>;\n  constantValue: number;\n}\n\nexport const Pool = 'Pool';\nexport type PoolInputs = Pick<NamedTensorInfoMap, 'input'>;\n\nexport const Pow = 'Pow';\nexport type PowInputs = BinaryInputs;\n\nexport const Prelu = 'Prelu';\nexport type PreluInputs = Pick<NamedTensorInfoMap, 'x'|'alpha'>;\n\nexport const Prod = 'Prod';\nexport type ProdInputs = Pick<NamedTensorInfoMap, 'x'>;\nexport interface ProdAttrs {\n  axis: number|number[];\n  keepDims: boolean;\n}\n\nexport const RaggedGather = 'RaggedGather';\nexport type RaggedGatherInputs = {\n  paramsNestedSplits: TensorInfo[]\n}&Pick<NamedTensorInfoMap, 'paramsDenseValues'|'indices'>;\nexport interface RaggedGatherAttrs {\n  outputRaggedRank: number;\n}\n\nexport const RaggedTensorToTensor = 'RaggedTensorToTensor';\nexport type RaggedTensorToTensorInputs =\n    Pick<NamedTensorInfoMap, 'shape'|'values'|'defaultValue'>&\n    {rowPartitionTensors: TensorInfo[]};\nexport interface RaggedTensorToTensorAttrs {\n  rowPartitionTypes: string[];\n}\n\nexport const Range = 'Range';\nexport interface RangeAttrs {\n  start: number;\n  stop: number;\n  step: number;\n  dtype: 'float32'|'int32';\n}\n\nexport const Real = 'Real';\nexport type RealInputs = Pick<NamedTensorInfoMap, 'input'>;\n\nexport const Reciprocal = 'Reciprocal';\nexport type ReciprocalInputs = UnaryInputs;\n\nexport const Relu = 'Relu';\nexport type ReluInputs = Pick<NamedTensorInfoMap, 'x'>;\n\nexport const Reshape = 'Reshape';\nexport type ReshapeInputs = Pick<NamedTensorInfoMap, 'x'>;\nexport interface ReshapeAttrs {\n  shape: number[];\n}\n\nexport const ResizeNearestNeighbor = 'ResizeNearestNeighbor';\nexport type ResizeNearestNeighborInputs = Pick<NamedTensorInfoMap, 'images'>;\nexport interface ResizeNearestNeighborAttrs {\n  alignCorners: boolean;\n  halfPixelCenters: boolean;\n  size: [number, number];\n}\n\nexport const ResizeNearestNeighborGrad = 'ResizeNearestNeighborGrad';\nexport type ResizeNearestNeighborGradInputs =\n    Pick<NamedTensorInfoMap, 'images'|'dy'>;\nexport type ResizeNearestNeighborGradAttrs = ResizeNearestNeighborAttrs;\n\nexport const ResizeBilinear = 'ResizeBilinear';\nexport type ResizeBilinearInputs = Pick<NamedTensorInfoMap, 'images'>;\nexport interface ResizeBilinearAttrs {\n  alignCorners: boolean;\n  halfPixelCenters: boolean;\n  size: [number, number];\n}\n\nexport const ResizeBilinearGrad = 'ResizeBilinearGrad';\nexport type ResizeBilinearGradInputs = Pick<NamedTensorInfoMap, 'images'|'dy'>;\nexport type ResizeBilinearGradAttrs = ResizeBilinearAttrs;\n\nexport const Relu6 = 'Relu6';\nexport type Relu6Inputs = Pick<NamedTensorInfoMap, 'x'>;\n\nexport const Reverse = 'Reverse';\nexport type ReverseInputs = Pick<NamedTensorInfoMap, 'x'>;\nexport interface ReverseAttrs {\n  dims: number|number[];\n}\n\nexport const Round = 'Round';\nexport type RoundInputs = UnaryInputs;\n\nexport const Rsqrt = 'Rsqrt';\nexport type RsqrtInputs = UnaryInputs;\n\nexport const ScatterNd = 'ScatterNd';\nexport type ScatterNdInputs = Pick<NamedTensorInfoMap, 'indices'|'updates'>;\nexport interface ScatterNdAttrs {\n  shape: number[];\n}\n\nexport const SearchSorted = 'SearchSorted';\nexport type SearchSortedInputs =\n    Pick<NamedTensorInfoMap, 'sortedSequence'|'values'>;\nexport interface SearchSortedAttrs {\n  side: 'left'|'right';\n}\n\nexport const Select = 'Select';\nexport type SelectInputs = Pick<NamedTensorInfoMap, 'condition'|'t'|'e'>;\n\nexport const Selu = 'Selu';\nexport type SeluInputs = Pick<NamedTensorInfoMap, 'x'>;\n\nexport const Slice = 'Slice';\nexport type SliceInputs = Pick<NamedTensorInfoMap, 'x'>;\nexport interface SliceAttrs {\n  begin: number|number[];\n  size: number|number[];\n}\nexport const Sin = 'Sin';\nexport type SinInputs = UnaryInputs;\n\nexport const Sinh = 'Sinh';\nexport type SinhInputs = UnaryInputs;\n\nexport const Sign = 'Sign';\nexport type SignInputs = UnaryInputs;\n\nexport const Sigmoid = 'Sigmoid';\nexport type SigmoidInputs = UnaryInputs;\n\nexport const Softplus = 'Softplus';\nexport type SoftplusInputs = UnaryInputs;\n\nexport const Sqrt = 'Sqrt';\nexport type SqrtInputs = UnaryInputs;\n\nexport const Sum = 'Sum';\nexport type SumInputs = Pick<NamedTensorInfoMap, 'x'>;\nexport interface SumAttrs {\n  axis: number|number[];\n  keepDims: boolean;\n}\n\nexport const SpaceToBatchND = 'SpaceToBatchND';\nexport type SpaceToBatchNDInputs = Pick<NamedTensorInfoMap, 'x'>;\nexport interface SpaceToBatchNDAttrs {\n  blockShape: number[];\n  paddings: number[][];\n}\n\nexport const SplitV = 'SplitV';\nexport type SplitVInputs = Pick<NamedTensorInfoMap, 'x'>;\nexport interface SplitVAttrs {\n  numOrSizeSplits: number[]|number;\n  axis: number;\n}\n\nexport const Softmax = 'Softmax';\nexport type SoftmaxInputs = Pick<NamedTensorInfoMap, 'logits'>;\nexport interface SoftmaxAttrs {\n  dim: number;\n}\n\nexport const SparseFillEmptyRows = 'SparseFillEmptyRows';\nexport type SparseFillEmptyRowsInputs =\n    Pick<NamedTensorInfoMap, 'indices'|'values'|'denseShape'|'defaultValue'>;\n\nexport const SparseReshape = 'SparseReshape';\nexport type SparseReshapeInputs =\n    Pick<NamedTensorInfoMap, 'inputIndices'|'inputShape'|'newShape'>;\n\nexport const SparseSegmentMean = 'SparseSegmentMean';\nexport type SparseSegmentMeanInputs =\n    Pick<NamedTensorInfoMap, 'data'|'indices'|'segmentIds'>;\n\nexport const SparseSegmentSum = 'SparseSegmentSum';\nexport type SparseSegmentSumInputs =\n    Pick<NamedTensorInfoMap, 'data'|'indices'|'segmentIds'>;\n\nexport const SparseToDense = 'SparseToDense';\nexport type SparseToDenseInputs =\n    Pick<NamedTensorInfoMap, 'sparseIndices'|'sparseValues'|'defaultValue'>;\nexport interface SparseToDenseAttrs {\n  outputShape: number[];\n}\n\nexport const SquaredDifference = 'SquaredDifference';\nexport type SquaredDifferenceInputs = BinaryInputs;\n\nexport const Square = 'Square';\nexport type SquareInputs = Pick<NamedTensorInfoMap, 'x'>;\n\nexport const StridedSlice = 'StridedSlice';\nexport type StridedSliceInputs = Pick<NamedTensorInfoMap, 'x'>;\nexport interface StridedSliceAttrs {\n  begin: number[];\n  end: number[];\n  strides: number[];\n  beginMask: number;\n  endMask: number;\n  ellipsisMask: number;\n  newAxisMask: number;\n  shrinkAxisMask: number;\n}\n\nexport const StringNGrams = 'StringNGrams';\nexport type StringNGramsInputs = Pick<NamedTensorInfoMap, 'data'|'dataSplits'>;\nexport interface StringNGramsAttrs {\n  separator: string;\n  nGramWidths: number[];\n  leftPad: string;\n  rightPad: string;\n  padWidth: number;\n  preserveShortSequences: boolean;\n}\n\nexport const StringSplit = 'StringSplit';\nexport type StringSplitInputs = Pick<NamedTensorInfoMap, 'input'|'delimiter'>;\nexport interface StringSplitAttrs {\n  skipEmpty: boolean;\n}\n\nexport const StringToHashBucketFast = 'StringToHashBucketFast';\nexport type StringToHashBucketFastInputs = Pick<NamedTensorInfoMap, 'input'>;\nexport interface StringToHashBucketFastAttrs {\n  numBuckets: number;\n}\n\nexport const Sub = 'Sub';\nexport type SubInputs = BinaryInputs;\n\nexport const Tan = 'Tan';\nexport type TanInputs = UnaryInputs;\n\nexport const Tanh = 'Tanh';\nexport type TanhInputs = UnaryInputs;\n\nexport const Tile = 'Tile';\nexport type TileInputs = Pick<NamedTensorInfoMap, 'x'>;\nexport interface TileAttrs {\n  reps: number[];\n}\n\nexport const TopK = 'TopK';\nexport type TopKInputs = Pick<NamedTensorInfoMap, 'x'>;\nexport interface TopKAttrs {\n  k: number;\n  sorted: boolean;\n}\n\nexport const Transform = 'Transform';\nexport type TransformInputs = Pick<NamedTensorInfoMap, 'image'|'transforms'>;\nexport interface TransformAttrs {\n  interpolation: 'nearest'|'bilinear';\n  fillMode: 'constant'|'reflect'|'wrap'|'nearest';\n  fillValue: number;\n  outputShape?: [number, number];\n}\n\nexport const Transpose = 'Transpose';\nexport type TransposeInputs = Pick<NamedTensorInfoMap, 'x'>;\nexport interface TransposeAttrs {\n  perm: number[];\n}\n\nexport const Unique = 'Unique';\nexport type UniqueInputs = Pick<NamedTensorInfoMap, 'x'>;\nexport interface UniqueAttrs {\n  axis: number;\n}\n\nexport type UnaryInputs = Pick<NamedTensorInfoMap, 'x'>;\n\nexport const Unpack = 'Unpack';\nexport type UnpackInputs = Pick<NamedTensorInfoMap, 'value'>;\nexport interface UnpackAttrs {\n  axis: number;\n}\n\nexport const UnsortedSegmentSum = 'UnsortedSegmentSum';\nexport type UnsortedSegmentSumInputs =\n    Pick<NamedTensorInfoMap, 'x'|'segmentIds'>;\nexport interface UnsortedSegmentSumAttrs {\n  numSegments: number;\n}\n\nexport const UpperBound = 'UpperBound';\nexport type UpperBoundInputs =\n    Pick<NamedTensorInfoMap, 'sortedSequence'|'values'>;\n\nexport const ZerosLike = 'ZerosLike';\nexport type ZerosLikeInputs = UnaryInputs;\n\n/**\n * TensorFlow.js-only kernels\n */\nexport const Step = 'Step';\nexport type StepInputs = UnaryInputs;\nexport interface StepAttrs {\n  alpha: number;\n}\n\nexport const FromPixels = 'FromPixels';\nexport interface FromPixelsInputs {\n  pixels: PixelData|ImageData|HTMLImageElement|HTMLCanvasElement|\n      HTMLVideoElement|ImageBitmap;\n}\nexport interface FromPixelsAttrs {\n  numChannels: number;\n}\n\nexport const RotateWithOffset = 'RotateWithOffset';\nexport type RotateWithOffsetInputs = Pick<NamedTensorInfoMap, 'image'>;\nexport interface RotateWithOffsetAttrs {\n  radians: number;\n  fillValue: number|[number, number, number];\n  center: number|[number, number];\n}\n\nexport const _FusedMatMul = '_FusedMatMul';\n// tslint:disable-next-line: class-name\nexport interface _FusedMatMulInputs extends NamedTensorInfoMap {\n  a: TensorInfo;\n  b: TensorInfo;\n  bias?: TensorInfo;\n  preluActivationWeights?: TensorInfo;\n}\n// tslint:disable-next-line: class-name\nexport interface _FusedMatMulAttrs {\n  transposeA: boolean;\n  transposeB: boolean;\n  activation: Activation;\n  leakyreluAlpha?: number;\n}\n\nexport const FusedConv2D = 'FusedConv2D';\nexport interface FusedConv2DInputs extends NamedTensorInfoMap {\n  x: TensorInfo;\n  filter: TensorInfo;\n  bias?: TensorInfo;\n  preluActivationWeights?: TensorInfo;\n}\nexport interface FusedConv2DAttrs {\n  strides: [number, number]|number;\n  pad: 'valid'|'same'|number|ExplicitPadding;\n  dataFormat: 'NHWC'|'NCHW';\n  dilations: [number, number]|number;\n  dimRoundingMode: 'floor'|'round'|'ceil';\n  activation: Activation;\n  leakyreluAlpha?: number;\n}\n\nexport const FusedDepthwiseConv2D = 'FusedDepthwiseConv2D';\nexport interface FusedDepthwiseConv2DInputs extends NamedTensorInfoMap {\n  x: TensorInfo;\n  filter: TensorInfo;\n  bias?: TensorInfo;\n  preluActivationWeights?: TensorInfo;\n}\nexport interface FusedDepthwiseConv2DAttrs {\n  strides: [number, number]|number;\n  pad: 'valid'|'same'|number|ExplicitPadding;\n  dataFormat: 'NHWC'|'NCHW';\n  dilations: [number, number]|number;\n  dimRoundingMode: 'floor'|'round'|'ceil';\n  activation: Activation;\n  leakyreluAlpha?: number;\n}\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {env} from './environment';\n\nexport function warn(...msg: Array<{}>): void {\n  if (!(env().getBool('IS_TEST') || env().getBool('PROD'))) {\n    console.warn(...msg);\n  }\n}\n\nexport function log(...msg: Array<{}>): void {\n  if (!(env().getBool('IS_TEST') || env().getBool('PROD'))) {\n    console.log(...msg);\n  }\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {env} from './environment';\nimport {getGlobal} from './global_util';\nimport * as log from './log';\nimport {NamedGradientMap} from './tape';\nimport {Tensor} from './tensor';\nimport {DataType, RecursiveArray} from './types';\n\nconst kernelRegistry =\n    getGlobal('kernelRegistry', () => new Map<string, KernelConfig>());\nconst gradRegistry =\n    getGlobal('gradRegistry', () => new Map<string, GradConfig>());\n\nexport type DataId = object;\n\ntype AttributeValue =\n    number|number[]|boolean|boolean[]|string|string[]|NamedAttrMap;\n\n/** These are extra non-tensor/primitive params passed to kernel functions. */\nexport type Attribute = AttributeValue|RecursiveArray<AttributeValue>;\n\n/** Specifies the code to run when executing a kernel. */\nexport type KernelFunc = (params: {\n  inputs: NamedTensorInfoMap,\n  backend: {},\n  attrs?: NamedAttrMap,\n}) => TensorInfo|TensorInfo[];\n\n/** The function to run when computing a gradient during backprop. */\nexport type GradFunc =\n    (dy: Tensor|Tensor[], saved: Tensor[], attrs: NamedAttrMap) =>\n        NamedGradientMap;\n\n/** Function that gets called after the backend initializes. */\nexport type KernelSetupFunc = (backend: {}) => void;\n/** Function that gets called right before the backend is disposed. */\nexport type KernelDisposeFunc = KernelSetupFunc;\n\n/** Config object for registering a kernel in the global registry. */\nexport interface KernelConfig {\n  kernelName: string;\n  backendName: string;\n  kernelFunc: KernelFunc;\n  setupFunc?: KernelSetupFunc;\n  disposeFunc?: KernelDisposeFunc;\n}\n\n/** Config object for registering a gradient in the global registry. */\nexport interface GradConfig {\n  kernelName: string;\n  inputsToSave?: string[];\n  // When saveAllInputs is true, all inputs will be saved. Only use this flag\n  // if inputs is an array of Tensors.\n  saveAllInputs?: boolean;\n  outputsToSave?: boolean[];\n  gradFunc: GradFunc;\n}\n\n/** Holds metadata for a given tensor. */\nexport interface TensorInfo {\n  dataId: DataId;\n  shape: number[];\n  dtype: DataType;\n}\n\nexport interface NamedTensorInfoMap {\n  [name: string]: TensorInfo|undefined;\n}\n\nexport interface NamedAttrMap {\n  [name: string]: Attribute;\n}\n\n/**\n * Returns the kernel function (code) associated with the provided names.\n *\n * @param kernelName The official name of the kernel.\n * @param backendName The official name of the backend.\n */\nexport function getKernel(\n    kernelName: string, backendName: string): KernelConfig {\n  const key = makeKey(kernelName, backendName);\n  return kernelRegistry.get(key);\n}\n\n/**\n * Returns the registered gradient info associated with the provided kernel.\n * @param kernelName The official TF kernel name.\n */\nexport function getGradient(kernelName: string): GradConfig {\n  return gradRegistry.get(kernelName);\n}\n\nexport function getKernelsForBackend(backendName: string): KernelConfig[] {\n  const it = kernelRegistry.entries();\n  const result: KernelConfig[] = [];\n\n  while (true) {\n    const {done, value} = it.next();\n    if (done) {\n      break;\n    }\n    const [key, config] = value;\n    const [backend, ] = key.split('_');\n    if (backend === backendName) {\n      result.push(config);\n    }\n  }\n  return result;\n}\n\n/**\n * Registers the function (forward pass) for the kernel in a global registry.\n *\n * @param config A config object with the following properties:\n * - `kernelName` The official name of the kernel.\n * - `backendName` The official name of the backend.\n * - `kernelFunc` The function to run during the forward pass of the kernel.\n * - `setupFunc` Optional. Gets called once, after the backend initializes.\n * - `disposeFunc` Optional. Gets called once, right before the backend is\n * disposed.\n */\nexport function registerKernel(config: KernelConfig) {\n  const {kernelName, backendName} = config;\n  const key = makeKey(kernelName, backendName);\n  if (kernelRegistry.has(key)) {\n    log.warn(\n        `The kernel '${kernelName}' for backend ` +\n        `'${backendName}' is already registered`);\n  }\n  kernelRegistry.set(key, config);\n}\n\n/**\n * Registers a gradient function for a given kernel in the global registry,\n * to be used during the back-propagation of that kernel.\n *\n * @param config An object with the following properties:\n * - `kernelName` The name of the kernel that the gradient function is for.\n * - `gradFunc` The function to run during back-propagation.\n */\nexport function registerGradient(config: GradConfig) {\n  const {kernelName} = config;\n\n  if (gradRegistry.has(kernelName)) {\n    // TODO (yassogba) after 3.0 assess whether we need to keep this gated\n    // to debug mode.\n    if (env().getBool('DEBUG')) {\n      log.warn(`Overriding the gradient for '${kernelName}'`);\n    }\n  }\n  gradRegistry.set(kernelName, config);\n}\n\n/**\n * Removes the kernel function from the registry.\n *\n * @param kernelName The official name of the kernel.\n * @param backendName The official name of the backend.\n *\n */\nexport function unregisterKernel(\n    kernelName: string, backendName: string): void {\n  const key = makeKey(kernelName, backendName);\n  if (!kernelRegistry.has(key)) {\n    throw new Error(\n        `The kernel '${kernelName}' for backend ` +\n        `'${backendName}' is not registered`);\n  }\n  kernelRegistry.delete(key);\n}\n\n/** Removes the registered gradient from the global registry. */\nexport function unregisterGradient(kernelName: string): void {\n  if (!gradRegistry.has(kernelName)) {\n    throw new Error(\n        `The gradient '${kernelName}' for backend is not registered`);\n  }\n  gradRegistry.delete(kernelName);\n}\n\n/**\n * Finds kernels that have already been registered to a backend and re-registers\n * them for a new backend. Useful for registering custom backends.\n * @param registeredBackendName Already registered backend.\n * @param newBackendName New backend.\n */\nexport function copyRegisteredKernels(\n    registeredBackendName: string, newBackendName: string): void {\n  const kernels = getKernelsForBackend(registeredBackendName);\n  kernels.forEach(kernelConfig => {\n    const newKernelConfig =\n        Object.assign({}, kernelConfig, {backendName: newBackendName});\n    registerKernel(newKernelConfig);\n  });\n}\n\nfunction makeKey(kernelName: string, backendName: string) {\n  return `${backendName}_${kernelName}`;\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n// Workaround for allowing cjs module to be included in bundle created by\n// rollup.\nimport * as LongExports from 'long';\n// tslint:disable-next-line\nconst Long: LongExports.LongConstructor =\n    // tslint:disable-next-line\n    (LongExports as any).default || LongExports;\n\nexport function hexToLong(hex: string): Long {\n  return Long.fromString(hex, true, 16);\n}\n\n// Some primes between 2^63 and 2^64 for various uses.\n// Hex 0xc3a5c85c97cb3127\nconst k0: Long = hexToLong('c3a5c85c97cb3127');\n// Hex 0xb492b66fbe98f273\nconst k1: Long = hexToLong('b492b66fbe98f273');\n// Hex 0x9ae16a3b2f90404f\nconst k2: Long = hexToLong('9ae16a3b2f90404f');\n\nfunction shiftMix(val: Long): Long {\n  return val.xor(val.shru(47));\n}\n\nfunction fetch(s: Uint8Array, offset: number, numBytes: number): Long {\n  const bytes = s.slice(offset, offset + numBytes);\n  return Long.fromBytes(Array.from(bytes), true, true);\n}\n\nfunction fetch64(s: Uint8Array, offset: number): Long {\n  return fetch(s, offset, 8);\n}\n\nfunction fetch32(s: Uint8Array, offset: number): Long {\n  return fetch(s, offset, 4);\n}\n\nfunction rotate64(val: Long, shift: number): Long {\n  // Avoid shifting by 64: doing so yields an undefined result.\n  return shift === 0 ? val : val.shru(shift).or(val.shl(64 - shift));\n}\n\nfunction hashLen16(u: Long, v: Long, mul = hexToLong('9ddfea08eb382d69')) {\n  // Murmur-inspired hashing.\n  let a = u.xor(v).mul(mul);\n  a = a.xor(a.shru(47));\n  let b = v.xor(a).mul(mul);\n  b = b.xor(b.shru(47));\n  b = b.mul(mul);\n  return b;\n}\n\n// Return a 16-byte hash for 48 bytes.  Quick and dirty.\n// Callers do best to use \"random-looking\" values for a and b.\nfunction weakHashLen32WithSeeds(\n    w: Long, x: Long, y: Long, z: Long, a: Long, b: Long) {\n  a = a.add(w);\n  b = rotate64(b.add(a).add(z), 21);\n  const c = a;\n  a = a.add(x);\n  a = a.add(y);\n  b = b.add(rotate64(a, 44));\n  return [a.add(z), b.add(c)];\n}\n\nfunction weakHashLen32WithSeedsStr(\n    s: Uint8Array, offset: number, a: Long, b: Long) {\n  return weakHashLen32WithSeeds(\n      fetch64(s, offset), fetch64(s, offset + 8), fetch64(s, offset + 16),\n      fetch64(s, offset + 24), a, b);\n}\n\nfunction hashLen0to16(s: Uint8Array, len = s.length): Long {\n  if (len >= 8) {\n    const mul = k2.add(len * 2);\n    const a = fetch64(s, 0).add(k2);\n    const b = fetch64(s, len - 8);\n    const c = rotate64(b, 37).mul(mul).add(a);\n    const d = rotate64(a, 25).add(b).mul(mul);\n    return hashLen16(c, d, mul);\n  }\n  if (len >= 4) {\n    const mul = k2.add(len * 2);\n    const a = fetch32(s, 0);\n    return hashLen16(a.shl(3).add(len), fetch32(s, len - 4), mul);\n  }\n  if (len > 0) {\n    const a = s[0];\n    const b = s[len >> 1];\n    const c = s[len - 1];\n    const y = a + (b << 8);\n    const z = len + (c << 2);\n    return shiftMix(k2.mul(y).xor(k0.mul(z))).mul(k2);\n  }\n  return k2;\n}\n\nfunction hashLen17to32(s: Uint8Array, len = s.length): Long {\n  const mul = k2.add(len * 2);\n  const a = fetch64(s, 0).mul(k1);\n  const b = fetch64(s, 8);\n  const c = fetch64(s, len - 8).mul(mul);\n  const d = fetch64(s, len - 16).mul(k2);\n  return hashLen16(\n      rotate64(a.add(b), 43).add(rotate64(c, 30)).add(d),\n      a.add(rotate64(b.add(k2), 18)).add(c), mul);\n}\n\nfunction hashLen33to64(s: Uint8Array, len = s.length): Long {\n  const mul = k2.add(len * 2);\n  const a = fetch64(s, 0).mul(k2);\n  const b = fetch64(s, 8);\n  const c = fetch64(s, len - 8).mul(mul);\n  const d = fetch64(s, len - 16).mul(k2);\n  const y = rotate64(a.add(b), 43).add(rotate64(c, 30)).add(d);\n  const z = hashLen16(y, a.add(rotate64(b.add(k2), 18)).add(c), mul);\n  const e = fetch64(s, 16).mul(mul);\n  const f = fetch64(s, 24);\n  const g = y.add(fetch64(s, len - 32)).mul(mul);\n  const h = z.add(fetch64(s, len - 24)).mul(mul);\n  return hashLen16(\n      rotate64(e.add(f), 43).add(rotate64(g, 30)).add(h),\n      e.add(rotate64(f.add(a), 18)).add(g), mul);\n}\n\nexport function fingerPrint64(s: Uint8Array, len = s.length): Long {\n  const seed: Long = Long.fromNumber(81, true);\n  if (len <= 32) {\n    if (len <= 16) {\n      return hashLen0to16(s, len);\n    } else {\n      return hashLen17to32(s, len);\n    }\n  } else if (len <= 64) {\n    return hashLen33to64(s, len);\n  }\n\n  // For strings over 64 bytes we loop.  Internal state consists of\n  // 56 bytes: v, w, x, y, and z.\n  let x = seed;\n  let y = seed.mul(k1).add(113);\n\n  let z = shiftMix(y.mul(k2).add(113)).mul(k2);\n  let v = [Long.UZERO, Long.UZERO];\n  let w = [Long.UZERO, Long.UZERO];\n  x = x.mul(k2).add(fetch64(s, 0));\n\n  let offset = 0;\n  // Set end so that after the loop we have 1 to 64 bytes left to process.\n  const end = ((len - 1) >> 6) * 64;\n  const last64 = end + ((len - 1) & 63) - 63;\n\n  do {\n    x = rotate64(x.add(y).add(v[0]).add(fetch64(s, offset + 8)), 37).mul(k1);\n    y = rotate64(y.add(v[1]).add(fetch64(s, offset + 48)), 42).mul(k1);\n    x = x.xor(w[1]);\n    y = y.add(v[0]).add(fetch64(s, offset + 40));\n    z = rotate64(z.add(w[0]), 33).mul(k1);\n    v = weakHashLen32WithSeedsStr(s, offset, v[1].mul(k1), x.add(w[0]));\n    w = weakHashLen32WithSeedsStr(\n        s, offset + 32, z.add(w[1]), y.add(fetch64(s, offset + 16)));\n\n    [z, x] = [x, z];\n    offset += 64;\n  } while (offset !== end);\n  const mul = k1.add(z.and(0xff).shl(1));\n  // Point to the last 64 bytes of input.\n  offset = last64;\n\n  w[0] = w[0].add((len - 1) & 63);\n  v[0] = v[0].add(w[0]);\n  w[0] = w[0].add(v[0]);\n\n  x = rotate64(x.add(y).add(v[0]).add(fetch64(s, offset + 8)), 37).mul(mul);\n  y = rotate64(y.add(v[1]).add(fetch64(s, offset + 48)), 42).mul(mul);\n  x = x.xor(w[1].mul(9));\n  y = y.add(v[0].mul(9).add(fetch64(s, offset + 40)));\n  z = rotate64(z.add(w[0]), 33).mul(mul);\n  v = weakHashLen32WithSeedsStr(s, offset, v[1].mul(mul), x.add(w[0]));\n  w = weakHashLen32WithSeedsStr(\n      s, offset + 32, z.add(w[1]), y.add(fetch64(s, offset + 16)));\n\n  [z, x] = [x, z];\n\n  return hashLen16(\n      hashLen16(v[0], w[0], mul).add(shiftMix(y).mul(k0)).add(z),\n      hashLen16(v[1], w[1], mul).add(x), mul);\n}\n","/**\n * @license\n * Copyright 2017 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {env} from './environment';\nimport {BackendValues, DataType, TensorLike, TypedArray} from './types';\nimport * as base from './util_base';\nexport * from './util_base';\nexport * from './hash_util';\n\n/**\n * Create typed array for scalar value. Used for storing in `DataStorage`.\n */\nexport function createScalarValue(\n    value: DataType, dtype: DataType): BackendValues {\n  if (dtype === 'string') {\n    return encodeString(value);\n  }\n\n  return toTypedArray([value], dtype);\n}\n\nfunction noConversionNeeded(a: TensorLike, dtype: DataType): boolean {\n  return (a instanceof Float32Array && dtype === 'float32') ||\n      (a instanceof Int32Array && dtype === 'int32') ||\n      (a instanceof Uint8Array && dtype === 'bool');\n}\n\nexport function toTypedArray(a: TensorLike, dtype: DataType): TypedArray {\n  if (dtype === 'string') {\n    throw new Error('Cannot convert a string[] to a TypedArray');\n  }\n  if (Array.isArray(a)) {\n    a = base.flatten(a);\n  }\n\n  if (env().getBool('DEBUG')) {\n    base.checkConversionForErrors(a as number[], dtype);\n  }\n  if (noConversionNeeded(a, dtype)) {\n    return a as TypedArray;\n  }\n  if (dtype == null || dtype === 'float32' || dtype === 'complex64') {\n    return new Float32Array(a as number[]);\n  } else if (dtype === 'int32') {\n    return new Int32Array(a as number[]);\n  } else if (dtype === 'bool') {\n    const bool = new Uint8Array((a as number[]).length);\n    for (let i = 0; i < bool.length; ++i) {\n      if (Math.round((a as number[])[i]) !== 0) {\n        bool[i] = 1;\n      }\n    }\n    return bool;\n  } else {\n    throw new Error(`Unknown data type ${dtype}`);\n  }\n}\n\n/**\n * Returns the current high-resolution time in milliseconds relative to an\n * arbitrary time in the past. It works across different platforms (node.js,\n * browsers).\n *\n * ```js\n * console.log(tf.util.now());\n * ```\n *\n * @doc {heading: 'Util', namespace: 'util'}\n */\nexport function now(): number {\n  return env().platform.now();\n}\n\n/**\n * Returns a platform-specific implementation of\n * [`fetch`](https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API).\n *\n * If `fetch` is defined on the global object (`window`, `process`, etc.),\n * `tf.util.fetch` returns that function.\n *\n * If not, `tf.util.fetch` returns a platform-specific solution.\n *\n * ```js\n * const resource = await tf.util.fetch('https://unpkg.com/@tensorflow/tfjs');\n * // handle response\n * ```\n *\n * @doc {heading: 'Util'}\n */\nexport function fetch(\n    path: string, requestInits?: RequestInit): Promise<Response> {\n  return env().platform.fetch(path, requestInits);\n}\n\n/**\n * Encodes the provided string into bytes using the provided encoding scheme.\n *\n * @param s The string to encode.\n * @param encoding The encoding scheme. Defaults to utf-8.\n *\n * @doc {heading: 'Util'}\n */\nexport function encodeString(s: string, encoding = 'utf-8'): Uint8Array {\n  encoding = encoding || 'utf-8';\n  return env().platform.encode(s, encoding);\n}\n\n/**\n * Decodes the provided bytes into a string using the provided encoding scheme.\n * @param bytes The bytes to decode.\n *\n * @param encoding The encoding scheme. Defaults to utf-8.\n *\n * @doc {heading: 'Util'}\n */\nexport function decodeString(bytes: Uint8Array, encoding = 'utf-8'): string {\n  encoding = encoding || 'utf-8';\n  return env().platform.decode(bytes, encoding);\n}\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {BackendTimer, BackendTimingInfo} from './backends/backend';\nimport {env} from './environment';\nimport {Tensor} from './tensor';\nimport {NamedTensorMap} from './tensor_types';\nimport {DataType, DataTypeMap, TypedArray} from './types';\nimport * as util from './util';\n\nexport type KernelProfile = {\n  kernelName: string,\n  outputs: Tensor[],\n  inputs: NamedTensorMap,\n  timeMs: Promise<number|{error: string}>,\n  extraInfo: Promise<string>\n};\n\nexport class Profiler {\n  constructor(private backendTimer: BackendTimer, private logger?: Logger) {\n    if (logger == null) {\n      this.logger = new Logger();\n    }\n  }\n\n  profileKernel(kernelName: string, inputs: NamedTensorMap, f: () => Tensor[]):\n      KernelProfile {\n    let outputs: Tensor[];\n    const holdResultWrapperFn = () => {\n      outputs = f();\n    };\n    let timer: Promise<BackendTimingInfo>;\n    const start = util.now();\n    if (this.backendTimer.timerAvailable()) {\n      timer = this.backendTimer.time(holdResultWrapperFn);\n    } else {\n      holdResultWrapperFn();\n      for (const output of outputs) {\n        output.dataSync();\n      }\n      timer = Promise.resolve({kernelMs: util.now() - start});\n    }\n    if (env().getBool('CHECK_COMPUTATION_FOR_ERRORS')) {\n      for (let i = 0; i < outputs.length; i++) {\n        const output = outputs[i];\n        // Dangling promise here because we don't want to propagate up\n        // asynchronicity.\n        output.data().then(tensorVals => {\n          checkComputationForErrors(tensorVals, output.dtype, kernelName);\n        });\n      }\n    }\n\n    const kernelProfile = {\n      kernelName,\n      outputs,\n      inputs,\n      timeMs: timer.then(timing => timing.kernelMs),\n      extraInfo: timer.then(\n          timing => timing.getExtraProfileInfo != null ?\n              timing.getExtraProfileInfo() :\n              '')\n    };\n    return kernelProfile;\n  }\n\n  logKernelProfile(kernelProfile: KernelProfile): void {\n    const {kernelName, outputs, timeMs, inputs, extraInfo} = kernelProfile;\n\n    outputs.forEach(result => {\n      Promise.all([result.data(), timeMs, extraInfo]).then(valueContainer => {\n        this.logger.logKernelProfile(\n            kernelName, result, valueContainer[0], valueContainer[1], inputs,\n            valueContainer[2]);\n      });\n    });\n  }\n}\n\nexport function checkComputationForErrors<D extends DataType>(\n    vals: DataTypeMap[D], dtype: D, kernelName: string): boolean {\n  if (dtype !== 'float32') {\n    // Only floating point computations will generate NaN values\n    return false;\n  }\n  for (let i = 0; i < vals.length; i++) {\n    const num = vals[i] as number;\n    if (isNaN(num) || !isFinite(num)) {\n      // Throwing custom exception so behavior is testable.\n      console.warn(`Found ${num} in the result of '${kernelName}'`);\n      return true;\n    }\n  }\n  return false;\n}\n\nexport class Logger {\n  logKernelProfile(\n      name: string, result: Tensor, vals: TypedArray,\n      timeMs: number|{error: string}, inputs: NamedTensorMap,\n      extraInfo?: string) {\n    const time = typeof timeMs === 'number' ? util.rightPad(`${timeMs}ms`, 9) :\n                                              timeMs['error'];\n    const paddedName = util.rightPad(name, 25);\n    const rank = result.rank;\n    const size = result.size;\n    const shape = util.rightPad(result.shape.toString(), 14);\n    let inputShapesDescription = '';\n\n    for (const name in inputs) {\n      const input = inputs[name];\n      if (input != null) {\n        // The input might be a non-tensor (e.g HTMLImageElement), in which case\n        // we claim the output shape as input shape.\n        const inputShape = input.shape || result.shape;\n        const inputRank = inputShape.length;\n        inputShapesDescription +=\n            `${name}: ${inputRank}D ${inputRank > 0 ? inputShape : ''} `;\n      }\n    }\n\n    console.log(\n        `%c${paddedName}\\t%c${time}\\t%c${rank}D ${shape}\\t%c${size}\\t%c${\n            inputShapesDescription}\\t%c${extraInfo}`,\n        'font-weight:bold', 'color:red', 'color:blue', 'color: orange',\n        'color: green', 'color: steelblue');\n  }\n}\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, TypedArray} from './types';\nimport {computeStrides, isString, rightPad, sizeFromShape} from './util';\n\n// Maximum number of values before we decide to show ellipsis.\nconst FORMAT_LIMIT_NUM_VALS = 20;\n// Number of first and last values to show when displaying a, b,...,y, z.\nconst FORMAT_NUM_FIRST_LAST_VALS = 3;\n// Number of significant digits to show.\nconst FORMAT_NUM_SIG_DIGITS = 7;\n\nexport function tensorToString(\n    vals: TypedArray|string[], shape: number[], dtype: DataType,\n    verbose: boolean) {\n  const strides = computeStrides(shape);\n  const padPerCol = computeMaxSizePerColumn(vals, shape, dtype, strides);\n  const rank = shape.length;\n  const valsLines = subTensorToString(vals, shape, dtype, strides, padPerCol);\n  const lines = ['Tensor'];\n  if (verbose) {\n    lines.push(`  dtype: ${dtype}`);\n    lines.push(`  rank: ${rank}`);\n    lines.push(`  shape: [${shape}]`);\n    lines.push(`  values:`);\n  }\n  lines.push(valsLines.map(l => '    ' + l).join('\\n'));\n  return lines.join('\\n');\n}\n\nfunction computeMaxSizePerColumn(\n    vals: TypedArray|string[], shape: number[], dtype: DataType,\n    strides: number[]): number[] {\n  const n = sizeFromShape(shape);\n  const numCols = strides[strides.length - 1];\n  const padPerCol = new Array(numCols).fill(0);\n  const rank = shape.length;\n  const valuesOrTuples =\n      dtype === 'complex64' ? createComplexTuples(vals) : vals;\n\n  if (rank > 1) {\n    for (let row = 0; row < n / numCols; row++) {\n      const offset = row * numCols;\n      for (let j = 0; j < numCols; j++) {\n        padPerCol[j] = Math.max(\n            padPerCol[j],\n            valToString(valuesOrTuples[offset + j], 0, dtype).length);\n      }\n    }\n  }\n  return padPerCol;\n}\n\nfunction valToString(\n    val: number|string|[number, number], pad: number, dtype: DataType) {\n  let valStr: string;\n  if (Array.isArray(val)) {\n    valStr = `${parseFloat(val[0].toFixed(FORMAT_NUM_SIG_DIGITS))} + ` +\n        `${parseFloat(val[1].toFixed(FORMAT_NUM_SIG_DIGITS))}j`;\n  } else if (isString(val)) {\n    valStr = `'${val}'`;\n  } else if (dtype === 'bool') {\n    valStr = boolNumToString(val);\n  } else {\n    valStr = parseFloat(val.toFixed(FORMAT_NUM_SIG_DIGITS)).toString();\n  }\n\n  return rightPad(valStr, pad);\n}\n\nfunction boolNumToString(v: number): string {\n  return v === 0 ? 'false' : 'true';\n}\n\nfunction subTensorToString(\n    vals: TypedArray|string[], shape: number[], dtype: DataType,\n    strides: number[], padPerCol: number[], isLast = true): string[] {\n  const storagePerElement = dtype === 'complex64' ? 2 : 1;\n\n  const size = shape[0];\n  const rank = shape.length;\n  if (rank === 0) {\n    if (dtype === 'complex64') {\n      const complexTuple = createComplexTuples(vals);\n      return [valToString(complexTuple[0], 0, dtype)];\n    }\n    if (dtype === 'bool') {\n      return [boolNumToString(vals[0] as number)];\n    }\n    return [vals[0].toString()];\n  }\n\n  if (rank === 1) {\n    if (size > FORMAT_LIMIT_NUM_VALS) {\n      const firstValsSize = FORMAT_NUM_FIRST_LAST_VALS * storagePerElement;\n\n      let firstVals = Array.from<number|string|[number, number]>(\n          vals.slice(0, firstValsSize));\n      let lastVals = Array.from<number|string|[number, number]>(vals.slice(\n          (size - FORMAT_NUM_FIRST_LAST_VALS) * storagePerElement,\n          size * storagePerElement));\n      if (dtype === 'complex64') {\n        firstVals = createComplexTuples(firstVals);\n        lastVals = createComplexTuples(lastVals);\n      }\n      return [\n        '[' +\n        firstVals.map((x, i) => valToString(x, padPerCol[i], dtype))\n            .join(', ') +\n        ', ..., ' +\n        lastVals\n            .map(\n                (x, i) => valToString(\n                    x, padPerCol[size - FORMAT_NUM_FIRST_LAST_VALS + i], dtype))\n            .join(', ') +\n        ']'\n      ];\n    }\n    const displayVals: Array<number|string|[number, number]> =\n        dtype === 'complex64' ? createComplexTuples(vals) :\n                                Array.from<number|string>(vals);\n\n    return [\n      '[' +\n      displayVals.map((x, i) => valToString(x, padPerCol[i], dtype))\n          .join(', ') +\n      ']'\n    ];\n  }\n\n  // The array is rank 2 or more.\n  const subshape = shape.slice(1);\n  const substrides = strides.slice(1);\n  const stride = strides[0] * storagePerElement;\n  const lines: string[] = [];\n  if (size > FORMAT_LIMIT_NUM_VALS) {\n    for (let i = 0; i < FORMAT_NUM_FIRST_LAST_VALS; i++) {\n      const start = i * stride;\n      const end = start + stride;\n      lines.push(...subTensorToString(\n          vals.slice(start, end), subshape, dtype, substrides, padPerCol,\n          false /* isLast */));\n    }\n    lines.push('...');\n    for (let i = size - FORMAT_NUM_FIRST_LAST_VALS; i < size; i++) {\n      const start = i * stride;\n      const end = start + stride;\n      lines.push(...subTensorToString(\n          vals.slice(start, end), subshape, dtype, substrides, padPerCol,\n          i === size - 1 /* isLast */));\n    }\n  } else {\n    for (let i = 0; i < size; i++) {\n      const start = i * stride;\n      const end = start + stride;\n      lines.push(...subTensorToString(\n          vals.slice(start, end), subshape, dtype, substrides, padPerCol,\n          i === size - 1 /* isLast */));\n    }\n  }\n  const sep = rank === 2 ? ',' : '';\n  lines[0] = '[' + lines[0] + sep;\n  for (let i = 1; i < lines.length - 1; i++) {\n    lines[i] = ' ' + lines[i] + sep;\n  }\n  let newLineSep = ',\\n';\n  for (let i = 2; i < rank; i++) {\n    newLineSep += '\\n';\n  }\n  lines[lines.length - 1] =\n      ' ' + lines[lines.length - 1] + ']' + (isLast ? '' : newLineSep);\n  return lines;\n}\n\nfunction createComplexTuples(vals: Array<{}>|\n                             TypedArray): Array<[number, number]> {\n  const complexTuples: Array<[number, number]> = [];\n  for (let i = 0; i < vals.length; i += 2) {\n    complexTuples.push([vals[i], vals[i + 1]] as [number, number]);\n  }\n  return complexTuples;\n}\n","/**\n * @license\n * Copyright 2017 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n// Workaround for: https://github.com/bazelbuild/rules_nodejs/issues/1265\n/// <reference types=\"@webgpu/types/dist\" />\n\nimport {getGlobal} from './global_util';\nimport {tensorToString} from './tensor_format';\nimport {ArrayMap, BackendValues, DataType, DataTypeMap, DataValues, NumericDataType, Rank, ShapeMap, SingleValueMap, TypedArray} from './types';\nimport * as util from './util';\nimport {computeStrides, toNestedArray} from './util';\n\nexport interface TensorData<D extends DataType> {\n  dataId?: DataId;\n  values?: DataTypeMap[D];\n}\n\n// This interface mimics KernelBackend (in backend.ts), which would create a\n// circular dependency if imported.\nexport interface Backend {}\n\n/**\n * A mutable object, similar to `tf.Tensor`, that allows users to set values\n * at locations before converting to an immutable `tf.Tensor`.\n *\n * See `tf.buffer` for creating a tensor buffer.\n *\n * @doc {heading: 'Tensors', subheading: 'Classes'}\n */\nexport class TensorBuffer<R extends Rank, D extends DataType = 'float32'> {\n  size: number;\n  shape: ShapeMap[R];\n  strides: number[];\n  values: DataTypeMap[D];\n\n  constructor(shape: ShapeMap[R], public dtype: D, values?: DataTypeMap[D]) {\n    this.shape = shape.slice() as ShapeMap[R];\n    this.size = util.sizeFromShape(shape);\n\n    if (values != null) {\n      const n = values.length;\n      util.assert(\n          n === this.size,\n          () => `Length of values '${n}' does not match the size ` +\n              `inferred by the shape '${this.size}'.`);\n    }\n    if (dtype === 'complex64') {\n      throw new Error(\n          `complex64 dtype TensorBuffers are not supported. Please create ` +\n          `a TensorBuffer for the real and imaginary parts separately and ` +\n          `call tf.complex(real, imag).`);\n    }\n    this.values = values || util.getArrayFromDType(dtype, this.size);\n    this.strides = computeStrides(shape);\n  }\n\n  /**\n   * Sets a value in the buffer at a given location.\n   *\n   * @param value The value to set.\n   * @param locs  The location indices.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Creation'}\n   */\n  set(value: SingleValueMap[D], ...locs: number[]): void {\n    if (locs.length === 0) {\n      locs = [0];\n    }\n    util.assert(\n        locs.length === this.rank,\n        () => `The number of provided coordinates (${locs.length}) must ` +\n            `match the rank (${this.rank})`);\n\n    const index = this.locToIndex(locs);\n    this.values[index] = value as number;\n  }\n\n  /**\n   * Returns the value in the buffer at the provided location.\n   *\n   * @param locs The location indices.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Creation'}\n   */\n  get(...locs: number[]): SingleValueMap[D] {\n    if (locs.length === 0) {\n      locs = [0];\n    }\n    let i = 0;\n    for (const loc of locs) {\n      if (loc < 0 || loc >= this.shape[i]) {\n        const msg = `Requested out of range element at ${locs}. ` +\n            `  Buffer shape=${this.shape}`;\n        throw new Error(msg);\n      }\n      i++;\n    }\n    let index = locs[locs.length - 1];\n    for (let i = 0; i < locs.length - 1; ++i) {\n      index += this.strides[i] * locs[i];\n    }\n    return this.values[index] as SingleValueMap[D];\n  }\n\n  locToIndex(locs: number[]): number {\n    if (this.rank === 0) {\n      return 0;\n    } else if (this.rank === 1) {\n      return locs[0];\n    }\n    let index = locs[locs.length - 1];\n    for (let i = 0; i < locs.length - 1; ++i) {\n      index += this.strides[i] * locs[i];\n    }\n    return index;\n  }\n\n  indexToLoc(index: number): number[] {\n    if (this.rank === 0) {\n      return [];\n    } else if (this.rank === 1) {\n      return [index];\n    }\n    const locs: number[] = new Array(this.shape.length);\n    for (let i = 0; i < locs.length - 1; ++i) {\n      locs[i] = Math.floor(index / this.strides[i]);\n      index -= locs[i] * this.strides[i];\n    }\n    locs[locs.length - 1] = index;\n    return locs;\n  }\n\n  get rank() {\n    return this.shape.length;\n  }\n\n  /**\n   * Creates an immutable `tf.Tensor` object from the buffer.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Creation'}\n   */\n  toTensor(): Tensor<R> {\n    return trackerFn().makeTensor(this.values, this.shape, this.dtype) as\n        Tensor<R>;\n  }\n}\n\nexport interface DataToGPUWebGLOption {\n  customTexShape?: [number, number];\n}\n\nexport type DataToGPUOptions = DataToGPUWebGLOption;\n\nexport interface GPUData {\n  tensorRef: Tensor;\n  texture?: WebGLTexture;\n  buffer?: GPUBuffer;\n  texShape?: [number, number];\n  bufSize?: number;\n}\n\nexport interface TensorTracker {\n  makeTensor(\n      values: DataValues, shape: number[], dtype: DataType,\n      backend?: Backend): Tensor;\n  makeVariable(\n      initialValue: Tensor, trainable?: boolean, name?: string,\n      dtype?: DataType): Variable;\n  incRef(a: Tensor, backend: Backend): void;\n  disposeTensor(t: Tensor): void;\n  disposeVariable(v: Variable): void;\n  read(dataId: DataId): Promise<BackendValues>;\n  readSync(dataId: DataId): BackendValues;\n  readToGPU(dataId: DataId, options?: DataToGPUOptions): GPUData;\n}\n\n/**\n * The Tensor class calls into this handler to delegate chaining operations.\n */\nexport interface OpHandler {\n  cast<T extends Tensor>(x: T, dtype: DataType): T;\n  buffer<R extends Rank, D extends DataType>(\n      shape: ShapeMap[R], dtype: D,\n      values?: DataTypeMap[D]): TensorBuffer<R, D>;\n  print<T extends Tensor>(x: T, verbose: boolean): void;\n  clone<T extends Tensor>(x: T): T;\n  // TODO(yassogba) bring reshape back?\n}\n\n// For tracking tensor creation and disposal.\nlet trackerFn: () => TensorTracker = null;\n// Used by chaining methods to call into ops.\nlet opHandler: OpHandler = null;\n// Used to warn about deprecated methods.\nlet deprecationWarningFn: (msg: string) => void = null;\n// This here so that we can use this method on dev branches and keep the\n// functionality at master.\n// tslint:disable-next-line:no-unused-expression\n[deprecationWarningFn];\n\n/**\n * An external consumer can register itself as the tensor tracker. This way\n * the Tensor class can notify the tracker for every tensor created and\n * disposed.\n */\nexport function setTensorTracker(fn: () => TensorTracker) {\n  trackerFn = fn;\n}\n\n/**\n * An external consumer can register itself as the op handler. This way the\n * Tensor class can have chaining methods that call into ops via the op\n * handler.\n */\nexport function setOpHandler(handler: OpHandler) {\n  opHandler = handler;\n}\n\n/**\n * Sets the deprecation warning function to be used by this file. This way the\n * Tensor class can be a leaf but still use the environment.\n */\nexport function setDeprecationWarningFn(fn: (msg: string) => void) {\n  deprecationWarningFn = fn;\n}\n\n/**\n * We wrap data id since we use weak map to avoid memory leaks.\n * Since we have our own memory management, we have a reference counter\n * mapping a tensor to its data, so there is always a pointer (even if that\n * data is otherwise garbage collectable).\n * See https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/\n * Global_Objects/WeakMap\n */\nexport type DataId = object;  // object instead of {} to force non-primitive.\n\n// Declare this namespace to make Tensor class augmentation work in google3.\nexport declare namespace Tensor {}\n/**\n * A `tf.Tensor` object represents an immutable, multidimensional array of\n * numbers that has a shape and a data type.\n *\n * For performance reasons, functions that create tensors do not necessarily\n * perform a copy of the data passed to them (e.g. if the data is passed as a\n * `Float32Array`), and changes to the data will change the tensor. This is not\n * a feature and is not supported. To avoid this behavior, use the tensor before\n * changing the input data or create a copy with `copy = tf.add(yourTensor, 0)`.\n *\n * See `tf.tensor` for details on how to create a `tf.Tensor`.\n *\n * @doc {heading: 'Tensors', subheading: 'Classes'}\n */\nexport class Tensor<R extends Rank = Rank> {\n  /** Unique id of this tensor. */\n  readonly id: number;\n  /**\n   * Id of the bucket holding the data for this tensor. Multiple arrays can\n   * point to the same bucket (e.g. when calling array.reshape()).\n   */\n  dataId: DataId;\n  /** The shape of the tensor. */\n  readonly shape: ShapeMap[R];\n  /** Number of elements in the tensor. */\n  readonly size: number;\n  /** The data type for the array. */\n  readonly dtype: DataType;\n  /** The rank type for the array (see `Rank` enum). */\n  readonly rankType: R;\n\n  /** Whether this tensor has been globally kept. */\n  kept = false;\n  /** The id of the scope this tensor is being tracked in. */\n  scopeId: number;\n\n  /**\n   * Number of elements to skip in each dimension when indexing. See\n   * https://docs.scipy.org/doc/numpy/reference/generated/\\\n   * numpy.ndarray.strides.html\n   */\n  readonly strides: number[];\n\n  constructor(shape: ShapeMap[R], dtype: DataType, dataId: DataId, id: number) {\n    this.shape = shape.slice() as ShapeMap[R];\n    this.dtype = dtype || 'float32';\n    this.size = util.sizeFromShape(shape);\n    this.strides = computeStrides(shape);\n    this.dataId = dataId;\n    this.id = id;\n    this.rankType = (this.rank < 5 ? this.rank.toString() : 'higher') as R;\n  }\n\n  get rank(): number {\n    return this.shape.length;\n  }\n\n  /**\n   * Returns a promise of `tf.TensorBuffer` that holds the underlying data.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n  async buffer<D extends DataType = 'float32'>(): Promise<TensorBuffer<R, D>> {\n    const vals = await this.data<D>();\n    return opHandler.buffer(this.shape, this.dtype as D, vals);\n  }\n\n  /**\n   * Returns a `tf.TensorBuffer` that holds the underlying data.\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n  bufferSync<D extends DataType = 'float32'>(): TensorBuffer<R, D> {\n    return opHandler.buffer(this.shape, this.dtype as D, this.dataSync());\n  }\n\n  /**\n   * Returns the tensor data as a nested array. The transfer of data is done\n   * asynchronously.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n  async array(): Promise<ArrayMap[R]> {\n    const vals = await this.data();\n    return toNestedArray(this.shape, vals, this.dtype === 'complex64') as\n        ArrayMap[R];\n  }\n\n  /**\n   * Returns the tensor data as a nested array. The transfer of data is done\n   * synchronously.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n  arraySync(): ArrayMap[R] {\n    return toNestedArray(\n               this.shape, this.dataSync(), this.dtype === 'complex64') as\n        ArrayMap[R];\n  }\n\n  /**\n   * Asynchronously downloads the values from the `tf.Tensor`. Returns a\n   * promise of `TypedArray` that resolves when the computation has finished.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n  async data<D extends DataType = NumericDataType>(): Promise<DataTypeMap[D]> {\n    this.throwIfDisposed();\n    const data = trackerFn().read(this.dataId);\n    if (this.dtype === 'string') {\n      const bytes = await data as Uint8Array[];\n      try {\n        return bytes.map(b => util.decodeString(b)) as DataTypeMap[D];\n      } catch {\n        throw new Error(\n            'Failed to decode the string bytes into utf-8. ' +\n            'To get the original bytes, call tensor.bytes().');\n      }\n    }\n    return data as Promise<DataTypeMap[D]>;\n  }\n\n  /**\n   * Copy the tensor's data to a new GPU resource. Comparing to the `dataSync()`\n   * and `data()`, this method prevents data from being downloaded to CPU.\n   *\n   * For WebGL backend, the data will be stored on a densely packed texture.\n   * This means that the texture will use the RGBA channels to store value.\n   *\n   * For WebGPU backend, the data will be stored on a buffer. There is no\n   * parameter, so can not use a user-defined size to create the buffer.\n   *\n   * @param options:\n   *     For WebGL,\n   *         - customTexShape: Optional. If set, will use the user defined\n   *     texture shape to create the texture.\n   *\n   * @returns For WebGL backend, a GPUData contains the new texture and\n   *     its information.\n   *     {\n   *        tensorRef: The tensor that is associated with this texture,\n   *        texture: WebGLTexture,\n   *        texShape: [number, number] // [height, width]\n   *     }\n   *\n   *     For WebGPU backend, a GPUData contains the new buffer and\n   *     its information.\n   *     {\n   *        tensorRef: The tensor that is associated with this buffer,\n   *        buffer: GPUBuffer,\n   *        bufSize: number\n   *     }\n   *\n   *     Remember to dispose the GPUData after it is used by\n   *     `res.tensorRef.dispose()`.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n  dataToGPU(options?: DataToGPUOptions): GPUData {\n    this.throwIfDisposed();\n    return trackerFn().readToGPU(this.dataId, options);\n  }\n\n  /**\n   * Synchronously downloads the values from the `tf.Tensor`. This blocks the\n   * UI thread until the values are ready, which can cause performance issues.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n  dataSync<D extends DataType = NumericDataType>(): DataTypeMap[D] {\n    this.throwIfDisposed();\n    const data = trackerFn().readSync(this.dataId);\n    if (this.dtype === 'string') {\n      try {\n        return (data as Uint8Array[]).map(b => util.decodeString(b)) as\n            DataTypeMap[D];\n      } catch {\n        throw new Error(\n            'Failed to decode the string bytes into utf-8. ' +\n            'To get the original bytes, call tensor.bytes().');\n      }\n    }\n    return data as DataTypeMap[D];\n  }\n\n  /** Returns the underlying bytes of the tensor's data. */\n  async bytes(): Promise<Uint8Array[]|Uint8Array> {\n    this.throwIfDisposed();\n    const data = await trackerFn().read(this.dataId);\n    if (this.dtype === 'string') {\n      return data as Uint8Array[];\n    } else {\n      return new Uint8Array((data as TypedArray).buffer);\n    }\n  }\n\n  /**\n   * Disposes `tf.Tensor` from memory.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n  dispose(): void {\n    if (this.isDisposed) {\n      return;\n    }\n    trackerFn().disposeTensor(this);\n    this.isDisposedInternal = true;\n  }\n\n  protected isDisposedInternal = false;\n  get isDisposed(): boolean {\n    return this.isDisposedInternal;\n  }\n\n  throwIfDisposed() {\n    if (this.isDisposed) {\n      throw new Error(`Tensor is disposed.`);\n    }\n  }\n\n  /**\n   * Prints the `tf.Tensor`. See `tf.print` for details.\n   *\n   * @param verbose Whether to print verbose information about the tensor,\n   *    including dtype and size.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n  print(verbose = false): void {\n    return opHandler.print(this, verbose);\n  }\n\n  /**\n   * Returns a copy of the tensor. See `tf.clone` for details.\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n  clone<T extends Tensor>(this: T): T {\n    this.throwIfDisposed();\n    return opHandler.clone(this);\n  }\n\n  /**\n   * Returns a human-readable description of the tensor. Useful for logging.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n  toString(verbose = false): string {\n    const vals = this.dataSync();\n    return tensorToString(vals, this.shape, this.dtype, verbose);\n  }\n\n  cast<T extends this>(dtype: DataType): T {\n    this.throwIfDisposed();\n    return opHandler.cast(this as T, dtype);\n  }\n  variable(trainable = true, name?: string, dtype?: DataType): Variable<R> {\n    this.throwIfDisposed();\n    return trackerFn().makeVariable(this, trainable, name, dtype) as\n        Variable<R>;\n  }\n}\n\nObject.defineProperty(Tensor, Symbol.hasInstance, {\n  value: (instance: Tensor) => {\n    // Implementation note: we should use properties of the object that will be\n    // defined before the constructor body has finished executing (methods).\n    // This is because when this code is transpiled by babel, babel will call\n    // classCallCheck before the constructor body is run.\n    // See https://github.com/tensorflow/tfjs/issues/3384 for backstory.\n    return !!instance && instance.data != null && instance.dataSync != null &&\n        instance.throwIfDisposed != null;\n  }\n});\n\nexport function getGlobalTensorClass() {\n  // Use getGlobal so that we can augment the Tensor class across package\n  // boundaries becase the node resolution alg may result in different modules\n  // being returned for this file depending on the path they are loaded from.\n  return getGlobal('Tensor', () => {\n    return Tensor;\n  });\n}\n\n// Global side effect. Cache global reference to Tensor class\ngetGlobalTensorClass();\n\nexport interface NumericTensor<R extends Rank = Rank> extends Tensor<R> {\n  dtype: NumericDataType;\n  dataSync<D extends DataType = NumericDataType>(): DataTypeMap[D];\n  data<D extends DataType = NumericDataType>(): Promise<DataTypeMap[D]>;\n  dataToGPU(options?: DataToGPUOptions): GPUData;\n}\n\nexport interface StringTensor<R extends Rank = Rank> extends Tensor<R> {\n  dtype: 'string';\n  dataSync<D extends DataType = 'string'>(): DataTypeMap[D];\n  data<D extends DataType = 'string'>(): Promise<DataTypeMap[D]>;\n}\n\n/** @doclink Tensor */\nexport type Scalar = Tensor<Rank.R0>;\n/** @doclink Tensor */\nexport type Tensor1D = Tensor<Rank.R1>;\n/** @doclink Tensor */\nexport type Tensor2D = Tensor<Rank.R2>;\n/** @doclink Tensor */\nexport type Tensor3D = Tensor<Rank.R3>;\n/** @doclink Tensor */\nexport type Tensor4D = Tensor<Rank.R4>;\n/** @doclink Tensor */\nexport type Tensor5D = Tensor<Rank.R5>;\n/** @doclink Tensor */\nexport type Tensor6D = Tensor<Rank.R6>;\n\n/**\n * A mutable `tf.Tensor`, useful for persisting state, e.g. for training.\n *\n * @doc {heading: 'Tensors', subheading: 'Classes'}\n */\nexport class Variable<R extends Rank = Rank> extends Tensor<R> {\n  name: string;\n\n  constructor(\n      initialValue: Tensor<R>, public trainable: boolean, name: string,\n      tensorId: number) {\n    super(\n        initialValue.shape, initialValue.dtype, initialValue.dataId, tensorId);\n    this.name = name;\n  }\n\n  /**\n   * Assign a new `tf.Tensor` to this variable. The new `tf.Tensor` must have\n   * the same shape and dtype as the old `tf.Tensor`.\n   *\n   * @param newValue New tensor to be assigned to this variable.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n  assign(newValue: Tensor<R>): void {\n    if (newValue.dtype !== this.dtype) {\n      throw new Error(\n          `dtype of the new value (${newValue.dtype}) and ` +\n          `previous value (${this.dtype}) must match`);\n    }\n    if (!util.arraysEqual(newValue.shape, this.shape)) {\n      throw new Error(\n          `shape of the new value (${newValue.shape}) and ` +\n          `previous value (${this.shape}) must match`);\n    }\n    trackerFn().disposeTensor(this);\n    this.dataId = newValue.dataId;\n    trackerFn().incRef(this, null /* backend */);\n  }\n\n  dispose(): void {\n    trackerFn().disposeVariable(this);\n    this.isDisposedInternal = true;\n  }\n}\n\nObject.defineProperty(Variable, Symbol.hasInstance, {\n  value: (instance: Variable) => {\n    return instance instanceof Tensor && instance.assign != null &&\n        instance.assign instanceof Function;\n  }\n});\n","/**\n * @license\n * Copyright 2017 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n/** @docalias number[] */\nexport interface ShapeMap {\n  R0: number[];\n  R1: [number];\n  R2: [number, number];\n  R3: [number, number, number];\n  R4: [number, number, number, number];\n  R5: [number, number, number, number, number];\n  R6: [number, number, number, number, number, number];\n}\n\n/** @docalias number[] */\nexport interface ArrayMap {\n  R0: number;\n  R1: number[];\n  R2: number[][];\n  R3: number[][][];\n  R4: number[][][][];\n  R5: number[][][][][];\n  R6: number[][][][][][];\n}\n\nexport interface DataTypeMap {\n  float32: Float32Array;\n  int32: Int32Array;\n  bool: Uint8Array;\n  complex64: Float32Array;\n  string: string[];\n}\n\nexport interface SingleValueMap {\n  bool: boolean;\n  int32: number;\n  float32: number;\n  complex64: number;\n  string: string;\n}\n\n/** @docalias 'float32'|'int32'|'bool'|'complex64'|'string' */\nexport type DataType = keyof DataTypeMap;\nexport type NumericDataType = 'float32'|'int32'|'bool'|'complex64';\nexport type TypedArray = Float32Array|Int32Array|Uint8Array;\n/** Tensor data used in tensor creation and user-facing API. */\nexport type DataValues = DataTypeMap[DataType];\n/** The underlying tensor data that gets stored in a backend. */\nexport type BackendValues = Float32Array|Int32Array|Uint8Array|Uint8Array[];\n\nexport enum Rank {\n  R0 = 'R0',\n  R1 = 'R1',\n  R2 = 'R2',\n  R3 = 'R3',\n  R4 = 'R4',\n  R5 = 'R5',\n  R6 = 'R6'\n}\n\nexport type FlatVector = boolean[]|number[]|TypedArray;\nexport type RegularArray<T> =\n    T[]|T[][]|T[][][]|T[][][][]|T[][][][][]|T[][][][][][];\n\n// tslint:disable-next-line:no-any\nexport interface RecursiveArray<T extends any> {\n  [index: number]: T|RecursiveArray<T>;\n}\n\n// Looks for upcasting types. Used, for example, in operations with mixed dtype\n// inputs.\nenum UpcastInt32AndMap {\n  'float32' = 'float32',\n  'int32' = 'int32',\n  'bool' = 'int32',\n  'complex64' = 'complex64'\n}\n\nenum UpcastBoolAndMap {\n  'float32' = 'float32',\n  'int32' = 'int32',\n  'bool' = 'bool',\n  'complex64' = 'complex64'\n}\n\nenum UpcastFloat32AndMap {\n  'float32' = 'float32',\n  'int32' = 'float32',\n  'bool' = 'float32',\n  'complex64' = 'complex64'\n}\n\nenum UpcastComplex64AndMap {\n  'float32' = 'complex64',\n  'int32' = 'complex64',\n  'bool' = 'complex64',\n  'complex64' = 'complex64'\n}\n\nconst upcastTypeMap = {\n  'float32': UpcastFloat32AndMap,\n  'int32': UpcastInt32AndMap,\n  'bool': UpcastBoolAndMap,\n  'complex64': UpcastComplex64AndMap\n};\n\nexport function upcastType(typeA: DataType, typeB: DataType): DataType {\n  if (typeA === 'string' || typeB === 'string') {\n    if (typeA === 'string' && typeB === 'string') {\n      return 'string';\n    }\n    throw new Error(`Can not upcast ${typeA} with ${typeB}`);\n  }\n  return upcastTypeMap[typeA][typeB];\n}\n\n/** Returns the output type after summation. */\nexport function sumOutType(type: DataType): DataType {\n  return upcastType(type, 'int32');\n}\n\n/** @docalias TypedArray|Array */\nexport type TensorLike =\n    TypedArray|number|boolean|string|RecursiveArray<number|number[]|TypedArray>|\n    RecursiveArray<boolean>|RecursiveArray<string>|Uint8Array[];\nexport type ScalarLike = number|boolean|string|Uint8Array;\n/** @docalias TypedArray|Array */\nexport type TensorLike1D = TypedArray|number[]|boolean[]|string[]|Uint8Array[];\n/** @docalias TypedArray|Array */\nexport type TensorLike2D = TypedArray|number[]|number[][]|boolean[]|boolean[][]|\n    string[]|string[][]|Uint8Array[]|Uint8Array[][];\n/** @docalias TypedArray|Array */\nexport type TensorLike3D = TypedArray|number[]|number[][][]|boolean[]|\n    boolean[][][]|string[]|string[][][]|Uint8Array[]|Uint8Array[][][];\n/** @docalias TypedArray|Array */\nexport type TensorLike4D = TypedArray|number[]|number[][][][]|boolean[]|\n    boolean[][][][]|string[]|string[][][][]|Uint8Array[]|Uint8Array[][][][];\n/** @docalias TypedArray|Array */\nexport type TensorLike5D =\n    TypedArray|number[]|number[][][][][]|boolean[]|boolean[][][][][]|string[]|\n    string[][][][][]|Uint8Array[]|Uint8Array[][][][][];\n/** @docalias TypedArray|Array */\nexport type TensorLike6D =\n    TypedArray|number[]|number[][][][][][]|boolean[]|boolean[][][][][][]|\n    string[]|string[][][][][][]|Uint8Array[]|Uint8Array[][][][][];\n\n/** Type for representing image data in Uint8Array type. */\nexport interface PixelData {\n  width: number;\n  height: number;\n  data: Uint8Array;\n}\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor} from './tensor';\nimport {TensorContainer, TensorContainerArray} from './tensor_types';\nimport {upcastType} from './types';\nimport {assert} from './util';\n\nexport function makeTypesMatch<T extends Tensor>(a: T, b: T): [T, T] {\n  if (a.dtype === b.dtype) {\n    return [a, b];\n  }\n  const dtype = upcastType(a.dtype, b.dtype);\n  return [a.cast(dtype), b.cast(dtype)];\n}\n\nexport function assertTypesMatch(a: Tensor, b: Tensor): void {\n  assert(\n      a.dtype === b.dtype,\n      () => `The dtypes of the first(${a.dtype}) and` +\n          ` second(${b.dtype}) input must match`);\n}\n\nexport function isTensorInList(tensor: Tensor, tensorList: Tensor[]): boolean {\n  return tensorList.some(x => x.id === tensor.id);\n}\n\n/**\n * Extracts any `Tensor`s found within the provided object.\n *\n * @param container an object that may be a `Tensor` or may directly contain\n *   `Tensor`s, such as a `Tensor[]` or `{key: Tensor, ...}`. In general it\n *   is safe to pass any object here, except that `Promise`s are not\n *   supported.\n * @returns An array of `Tensors` found within the passed object. If the\n *   argument is simply a `Tensor', a list containing that `Tensor` is\n *   returned. If the object is not a `Tensor` or does not\n *   contain `Tensors`, an empty list is returned.\n */\nexport function getTensorsInContainer(result: TensorContainer): Tensor[] {\n  const list: Tensor[] = [];\n  const seen = new Set<{}|void>();\n  walkTensorContainer(result, list, seen);\n  return list;\n}\n\nfunction walkTensorContainer(\n    container: TensorContainer, list: Tensor[], seen: Set<{}|void>): void {\n  if (container == null) {\n    return;\n  }\n  if (container instanceof Tensor) {\n    list.push(container);\n    return;\n  }\n  if (!isIterable(container)) {\n    return;\n  }\n  // Iteration over keys works also for arrays.\n  const iterable = container as TensorContainerArray;\n  for (const k in iterable) {\n    const val = iterable[k];\n    if (!seen.has(val)) {\n      seen.add(val);\n      walkTensorContainer(val, list, seen);\n    }\n  }\n}\n\n// tslint:disable-next-line:no-any\nfunction isIterable(obj: any): boolean {\n  return Array.isArray(obj) || typeof obj === 'object';\n}\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {BackendTimingInfo, DataMover, KernelBackend} from './backends/backend';\nimport {Environment, setEnvironmentGlobal} from './environment';\nimport {getGlobalNamespace} from './global_util';\nimport {Add, Cast, Identity} from './kernel_names';\nimport {getGradient, getKernel, getKernelsForBackend, GradFunc, NamedAttrMap, TensorInfo} from './kernel_registry';\nimport * as log from './log';\nimport {KernelProfile, Profiler} from './profiler';\nimport {backpropagateGradients, getFilteredNodesXToY, TapeNode} from './tape';\nimport {DataId, DataToGPUOptions, GPUData, setTensorTracker, Tensor, TensorTracker, Variable} from './tensor';\nimport {GradSaveFunc, NamedTensorMap, NamedVariableMap, TensorContainer} from './tensor_types';\nimport {getTensorsInContainer} from './tensor_util';\nimport {BackendValues, DataType, DataValues} from './types';\nimport * as util from './util';\nimport {bytesFromStringArray, makeOnesTypedArray, now, sizeFromShape} from './util';\n\n/**\n * A function that computes an output. The save function is for saving tensors\n * computed in the forward pass, that we need in the backward pass.\n */\nexport type ForwardFunc<T> = (backend: KernelBackend, save?: GradSaveFunc) => T;\n\n/**\n * @docalias (a: Tensor, b: Tensor,..., save?: Function) => {\n *   value: Tensor,\n *   gradFunc: (dy: Tensor, saved?: NamedTensorMap) => Tensor | Tensor[]\n * }\n */\nexport type CustomGradientFunc<T extends Tensor> =\n    (...inputs: Array<Tensor|GradSaveFunc>) => {\n      value: T;\n      gradFunc: (dy: T, saved: Tensor[]) => Tensor | Tensor[];\n    };\n\nexport type MemoryInfo = {\n  numTensors: number; numDataBuffers: number; numBytes: number;\n  unreliable?: boolean; reasons: string[];\n};\n\ntype KernelInfo = {\n  name: string; bytesAdded: number; totalBytesSnapshot: number;\n  tensorsAdded: number;\n  totalTensorsSnapshot: number;\n  inputShapes: number[][];\n  outputShapes: number[][];\n  kernelTimeMs: number | {error: string} | Promise<number|{error: string}>;\n  extraInfo: string | Promise<string>;\n};\n\nexport type ProfileInfo = {\n  newBytes: number; newTensors: number; peakBytes: number;\n  kernels: KernelInfo[];\n  result: TensorContainer;\n  kernelNames: string[];\n};\n\nexport interface TimingInfo extends BackendTimingInfo {\n  wallMs: number;\n}\n\n/** @docalias Function */\nexport type ScopeFn<T extends TensorContainer> = () => T;\n\ninterface ScopeState {\n  track: Tensor[];\n  name: string;\n  id: number;\n}\n\ninterface RegisteredKernelInvocation<I extends NamedTensorMap> {\n  kernelName: string;\n  inputs: I;\n  attrs?: NamedAttrMap;\n}\n\ninterface CustomGradKernelInvocation<T extends Tensor|Tensor[],\n                                               I extends NamedTensorMap> {\n  forwardFunc: ForwardFunc<T>;\n  backwardsFunc: (dy: T, saved: Tensor[]) => {\n    [P in keyof I]: () => I[P]\n  };\n  inputs: I;\n  attrs?: NamedAttrMap;\n}\n\nfunction isRegisteredKernelInvocation<T extends Tensor|Tensor[],\n                                                I extends NamedTensorMap>(\n    kernelInvocation: RegisteredKernelInvocation<I>|\n    CustomGradKernelInvocation<T, I>):\n    kernelInvocation is RegisteredKernelInvocation<I> {\n  return (kernelInvocation as RegisteredKernelInvocation<I>).kernelName != null;\n}\n\nclass EngineState {\n  // Public since optimizers will use it.\n  registeredVariables: NamedVariableMap = {};\n\n  nextTapeNodeId = 0;\n  numBytes = 0;\n  numTensors = 0;\n  numStringTensors = 0;\n  numDataBuffers = 0;\n\n  activeTape: TapeNode[];\n  // Number of nested tf.grad() statements when computing higher-order\n  // gradients. E.g. `1` for first-order gradients and `2` for second-order\n  // gradients. Used to track if the tape should be removed after a backprop.\n  gradientDepth = 0;\n  // Number of nested kernel calls. When kernel depth is greater than 1, we turn\n  // off the tape.\n  kernelDepth = 0;\n\n  // Keep Tensors that parallel the tapes.\n  activeScope: ScopeState;\n  scopeStack: ScopeState[] = [];\n  /**\n   * Keeps track of the number of data moves during a kernel execution. We\n   * maintain a stack since kernels can call other kernels, recursively.\n   */\n  numDataMovesStack: number[] = [];\n  nextScopeId = 0;\n\n  tensorInfo = new WeakMap<DataId, {\n    backend: KernelBackend,\n    bytes: number,\n    dtype: DataType,\n    shape: number[]\n  }>();\n\n  profiling = false;\n  activeProfile: ProfileInfo = {\n    newBytes: 0,\n    newTensors: 0,\n    peakBytes: 0,\n    kernels: [],\n    result: null,\n    get kernelNames():\n        string[] {\n          return Array.from(new Set(this.kernels.map(k => k.name)));\n        }\n  };\n\n  dispose() {\n    for (const variableName in this.registeredVariables) {\n      this.registeredVariables[variableName].dispose();\n    }\n  }\n}\n\nexport class Engine implements TensorTracker, DataMover {\n  state: EngineState;\n  backendName: string;\n  registry: {[id: string]: KernelBackend} = {};\n  registryFactory: {\n    [id: string]: {\n      factory: () => KernelBackend | Promise<KernelBackend>,\n      priority: number\n    }\n  } = {};\n\n  private profiler: Profiler;\n  private backendInstance: KernelBackend;\n  private pendingBackendInit: Promise<boolean>;\n  private pendingBackendInitId = 0;\n\n  constructor(public ENV: Environment) {\n    this.state = new EngineState();\n  }\n\n  async ready(): Promise<void> {\n    if (this.pendingBackendInit != null) {\n      return this.pendingBackendInit.then(() => {});\n    }\n    if (this.backendInstance != null) {\n      return;\n    }\n    const sortedBackends = this.getSortedBackends();\n\n    for (let i = 0; i < sortedBackends.length; i++) {\n      const backendName = sortedBackends[i];\n      const success = await this.initializeBackend(backendName).success;\n      if (success) {\n        await this.setBackend(backendName);\n        return;\n      }\n    }\n\n    throw new Error(\n        `Could not initialize any backends, all backend initializations ` +\n        `failed.`);\n  }\n\n  get backend(): KernelBackend {\n    if (this.pendingBackendInit != null) {\n      throw new Error(\n          `Backend '${this.backendName}' has not yet been initialized. Make ` +\n          `sure to await tf.ready() or await tf.setBackend() before calling ` +\n          `other methods`);\n    }\n    if (this.backendInstance == null) {\n      const {name, asyncInit} = this.initializeBackendsAndReturnBest();\n      if (asyncInit) {\n        throw new Error(\n            `The highest priority backend '${name}' has not yet been ` +\n            `initialized. Make sure to await tf.ready() or ` +\n            `await tf.setBackend() before calling other methods`);\n      }\n      this.setBackend(name);\n    }\n    return this.backendInstance;\n  }\n\n  backendNames(): string[] {\n    return Object.keys(this.registryFactory);\n  }\n\n  findBackend(backendName: string): KernelBackend {\n    if (!(backendName in this.registry)) {\n      // If the backend hasn't been initialized but we have a registry entry for\n      // it, initialize it and return it.\n      if (backendName in this.registryFactory) {\n        const {asyncInit} = this.initializeBackend(backendName);\n        if (asyncInit) {\n          // Backend is not ready yet.\n          return null;\n        }\n      } else {\n        return null;\n      }\n    }\n    return this.registry[backendName];\n  }\n\n  findBackendFactory(backendName: string):\n      () => KernelBackend | Promise<KernelBackend> {\n    if (!(backendName in this.registryFactory)) {\n      return null;\n    }\n    return this.registryFactory[backendName].factory;\n  }\n\n  registerBackend(\n      backendName: string,\n      factory: () => KernelBackend | Promise<KernelBackend>,\n      priority = 1): boolean {\n    if (backendName in this.registryFactory) {\n      log.warn(\n          `${backendName} backend was already registered. ` +\n          `Reusing existing backend factory.`);\n      return false;\n    }\n    this.registryFactory[backendName] = {factory, priority};\n    return true;\n  }\n\n  async setBackend(backendName: string): Promise<boolean> {\n    if (this.registryFactory[backendName] == null) {\n      throw new Error(`Backend name '${backendName}' not found in registry`);\n    }\n    this.backendName = backendName;\n    if (this.registry[backendName] == null) {\n      this.backendInstance = null;\n      const {success, asyncInit} = this.initializeBackend(backendName);\n      const result = asyncInit ? await success : success;\n      if (!result) {\n        return false;\n      }\n    }\n    this.backendInstance = this.registry[backendName];\n    this.setupRegisteredKernels();\n    // Reset the profiler.\n    this.profiler = new Profiler(this.backendInstance);\n\n    return true;\n  }\n\n  private setupRegisteredKernels(): void {\n    const kernels = getKernelsForBackend(this.backendName);\n    kernels.forEach(kernel => {\n      if (kernel.setupFunc != null) {\n        kernel.setupFunc(this.backendInstance);\n      }\n    });\n  }\n\n  private disposeRegisteredKernels(backendName: string): void {\n    const kernels = getKernelsForBackend(backendName);\n    kernels.forEach(kernel => {\n      if (kernel.disposeFunc != null) {\n        kernel.disposeFunc(this.registry[backendName]);\n      }\n    });\n  }\n\n  /**\n   * Initializes a backend by looking up the backend name in the factory\n   * registry and calling the factory method. Returns a boolean representing\n   * whether the initialization of the backend suceeded. Throws an error if\n   * there is no backend in the factory registry.\n   */\n  private initializeBackend(backendName: string):\n      {success: boolean|Promise<boolean>, asyncInit: boolean} {\n    const registryFactoryEntry = this.registryFactory[backendName];\n    if (registryFactoryEntry == null) {\n      throw new Error(\n          `Cannot initialize backend ${backendName}, no registration found.`);\n    }\n\n    try {\n      const backend = registryFactoryEntry.factory();\n      /* Test if the factory returns a promise.\n      Done in a more liberal way than\n      previous 'Promise.resolve(backend)===backend'\n      as we needed to account for custom Promise\n      implementations (e.g. Angular) */\n      if (backend && !(backend instanceof KernelBackend) &&\n          typeof backend.then === 'function') {\n        const promiseId = ++this.pendingBackendInitId;\n        const success =\n            backend\n                .then(backendInstance => {\n                  // Outdated promise. Another backend was set in the meantime.\n                  if (promiseId < this.pendingBackendInitId) {\n                    return false;\n                  }\n                  this.registry[backendName] = backendInstance;\n                  this.pendingBackendInit = null;\n                  return true;\n                })\n                .catch(err => {\n                  // Outdated promise. Another backend was set in the meantime.\n                  if (promiseId < this.pendingBackendInitId) {\n                    return false;\n                  }\n                  this.pendingBackendInit = null;\n                  log.warn(`Initialization of backend ${backendName} failed`);\n                  log.warn(err.stack || err.message);\n                  return false;\n                });\n        this.pendingBackendInit = success;\n        return {success, asyncInit: true};\n      } else {\n        this.registry[backendName] = backend as KernelBackend;\n        return {success: true, asyncInit: false};\n      }\n    } catch (err) {\n      log.warn(`Initialization of backend ${backendName} failed`);\n      log.warn(err.stack || err.message);\n      return {success: false, asyncInit: false};\n    }\n  }\n\n  removeBackend(backendName: string): void {\n    if (!(backendName in this.registryFactory)) {\n      throw new Error(`${backendName} backend not found in registry`);\n    }\n    if (this.backendName === backendName && this.pendingBackendInit != null) {\n      // There is a pending promise of the backend we want to remove. Make it\n      // obsolete.\n      this.pendingBackendInitId++;\n    }\n\n    if (backendName in this.registry) {\n      this.disposeRegisteredKernels(backendName);\n      this.registry[backendName].dispose();\n      delete this.registry[backendName];\n    }\n\n    delete this.registryFactory[backendName];\n\n    // Unset the backend if it is active.\n    if (this.backendName === backendName) {\n      this.pendingBackendInit = null;\n      this.backendName = null;\n      this.backendInstance = null;\n    }\n  }\n\n  private getSortedBackends(): string[] {\n    if (Object.keys(this.registryFactory).length === 0) {\n      throw new Error('No backend found in registry.');\n    }\n    return Object.keys(this.registryFactory).sort((a: string, b: string) => {\n      // Highest priority comes first.\n      return this.registryFactory[b].priority -\n          this.registryFactory[a].priority;\n    });\n  }\n\n  private initializeBackendsAndReturnBest():\n      {name: string, asyncInit: boolean} {\n    const sortedBackends = this.getSortedBackends();\n\n    for (let i = 0; i < sortedBackends.length; i++) {\n      const backendName = sortedBackends[i];\n      const {success, asyncInit} = this.initializeBackend(backendName);\n      if (asyncInit || success) {\n        return {name: backendName, asyncInit};\n      }\n    }\n    throw new Error(\n        `Could not initialize any backends, all backend initializations ` +\n        `failed.`);\n  }\n\n  moveData(backend: KernelBackend, dataId: DataId) {\n    const info = this.state.tensorInfo.get(dataId);\n    const srcBackend = info.backend;\n    const values = this.readSync(dataId);\n    const refCount = srcBackend.refCount(dataId);\n    // Delete the tensor from the old backend and move it to the new\n    // backend.\n    srcBackend.disposeData(dataId, true);\n    info.backend = backend;\n    backend.move(dataId, values, info.shape, info.dtype, refCount);\n    if (this.shouldCheckForMemLeaks()) {\n      // Track the number of moves during a kernel execution to correctly\n      // detect memory leaks.\n      this.state.numDataMovesStack[this.state.numDataMovesStack.length - 1]++;\n    }\n  }\n\n  tidy<T extends TensorContainer>(nameOrFn: string|ScopeFn<T>, fn?: ScopeFn<T>):\n      T {\n    let name: string = null;\n    if (fn == null) {\n      // Called with only 1 argument.\n      if (typeof nameOrFn !== 'function') {\n        throw new Error('Please provide a function to tidy()');\n      }\n      fn = nameOrFn;\n    } else {\n      // Called with 2 arguments.\n      if (typeof nameOrFn !== 'string' && !(nameOrFn instanceof String)) {\n        throw new Error(\n            'When calling with two arguments, the first argument ' +\n            'to tidy() must be a string');\n      }\n      if (typeof fn !== 'function') {\n        throw new Error(\n            'When calling with two arguments, the 2nd argument ' +\n            'to tidy() must be a function');\n      }\n      name = nameOrFn as string;\n      // TODO(nsthorat,smilkov): Do operation logging and performance\n      // profiling.\n    }\n    let result: T;\n    return this.scopedRun(\n        () => this.startScope(name), () => this.endScope(result), () => {\n          result = fn();\n          if (result instanceof Promise) {\n            console.error('Cannot return a Promise inside of tidy.');\n          }\n          return result;\n        });\n  }\n\n  private scopedRun<T>(start: () => void, end: () => void, f: () => T): T {\n    start();\n    try {\n      const res = f();\n      end();\n      return res;\n    } catch (ex) {\n      end();\n      throw ex;\n    }\n  }\n\n  private static nextTensorId = 0;\n  private nextTensorId(): number {\n    return Engine.nextTensorId++;\n  }\n\n  private static nextVariableId = 0;\n  private nextVariableId(): number {\n    return Engine.nextVariableId++;\n  }\n\n  /**\n   * This method is called instead of the public-facing tensor.clone() when\n   * saving a tensor for backwards pass. It makes sure to add the clone\n   * operation to the tape regardless of being called inside a kernel\n   * execution.\n   */\n  private clone(x: Tensor): Tensor {\n    const y: Tensor = ENGINE.runKernel(Identity, {x} as {} as NamedTensorMap);\n    const inputs = {x};\n    const grad = (dy: Tensor) => ({\n      x: () => {\n        const dtype = 'float32';\n        const gradInputs = {x: dy};\n        const attrs = {dtype};\n\n        return ENGINE.runKernel(\n                   Cast, gradInputs as {} as NamedTensorMap,\n                   // tslint:disable-next-line: no-unnecessary-type-assertion\n                   attrs as {} as NamedAttrMap) as Tensor;\n      }\n    });\n    const saved: Tensor[] = [];\n    this.addTapeNode(this.state.activeScope.name, inputs, [y], grad, saved, {});\n    return y;\n  }\n\n  /**\n   * Execute a kernel with the given name and return the output tensor.\n   *\n   * @param kernelName The name of the kernel to execute.\n   * @param inputs A map of input names to tensors.\n   * @param attrs A map of attribute names to their values. An attribute is a\n   *     primitive (non-tensor) input to the kernel.\n   * @param inputsToSave A list of tensors, inputs to save for the backprop\n   *     computation.\n   * @param outputsToSave A list of booleans, specifying which output to save\n   *     for the backprop computation. These are booleans since the output\n   * tensors are not visible to the user.\n   */\n  runKernel<T extends Tensor|Tensor[]>(\n      kernelName: string, inputs: NamedTensorMap, attrs?: NamedAttrMap): T {\n    if (this.backendName == null) {\n      // backend has not been initialized yet (backend initialization is lazy\n      // can be deferred until an op/ kernel is run).\n      // The below getter has side effects that will try to initialize the\n      // backend and set properties like this.backendName\n      // tslint:disable-next-line: no-unused-expression\n      this.backend;\n    }\n    const hasKernel = getKernel(kernelName, this.backendName) != null;\n    if (!hasKernel) {\n      throw new Error(`Kernel '${kernelName}' not registered for backend '${\n          this.backendName}'`);\n    }\n    return this.runKernelFunc({kernelName, inputs, attrs});\n  }\n\n  private shouldCheckForMemLeaks(): boolean {\n    return this.ENV.getBool('IS_TEST');\n  }\n\n  private checkKernelForMemLeak(\n      kernelName: string, numDataIdsBefore: number,\n      outInfos: TensorInfo[]): void {\n    const numDataIdsAfter = this.backend.numDataIds();\n\n    // Count the number of data ids associated with the result of the kernel.\n    let numOutputDataIds = 0;\n    outInfos.forEach(info => {\n      // Complex numbers allocate 3 data ids, one for 'real', one for\n      // 'imaginary', and one for the container that holds the former two.\n      numOutputDataIds += (info.dtype === 'complex64' ? 3 : 1);\n    });\n\n    // Account for the number of moves during kernel execution. A \"data move\"\n    // can happen in the middle of a kernel execution, placing a new (key,value)\n    // pair in the data storage. Since data moves have net zero effect (we\n    // always remove the data from the old backend), we have to cancel them out\n    // when detecting memory leaks.\n    const numMoves =\n        this.state.numDataMovesStack[this.state.numDataMovesStack.length - 1];\n    const dataIdsLeaked =\n        numDataIdsAfter - numDataIdsBefore - numOutputDataIds - numMoves;\n    if (dataIdsLeaked > 0) {\n      throw new Error(\n          `Backend '${this.backendName}' has an internal memory leak ` +\n          `(${dataIdsLeaked} data ids) after running '${kernelName}'`);\n    }\n  }\n\n  /**\n   * Internal helper method to execute a kernel Func\n   *\n   * Use `runKernel` to execute kernels from outside of engine.\n   */\n  private runKernelFunc<T extends Tensor|Tensor[], I extends NamedTensorMap>(\n      kernelParams: RegisteredKernelInvocation<I>|\n      CustomGradKernelInvocation<T, I>): T {\n    let outputs: Tensor[];\n    let saved: Tensor[] = [];\n    const isTapeOn = this.isTapeOn();\n\n    const startingBytecount = this.state.numBytes;\n    const startingNumTensors = this.state.numTensors;\n\n    if (this.shouldCheckForMemLeaks()) {\n      this.state.numDataMovesStack.push(0);\n    }\n\n    let kernelFunc: () => Tensor[];\n    if (this.backendName == null) {\n      // backend has not been initialized yet (backend initialization is lazy\n      // can be deferred until an op/ kernel is run).\n      // The below getter has side effects that will try to initialize the\n      // backend and set properties like this.backendName\n      // tslint:disable-next-line: no-unused-expression\n      this.backend;\n    }\n\n    let out: TensorInfo|TensorInfo[];\n\n    const kernelOrScopeName = isRegisteredKernelInvocation(kernelParams) ?\n        kernelParams.kernelName :\n        this.state.activeScope != null ? this.state.activeScope.name : '';\n\n    // Create the kernelFunc from either a registered kernel OR passed in\n    // forward/backward functions (used by custom grad). In this context a\n    // kernelFunc wraps a kernel implementation with some bookkeeping.\n\n    if (isRegisteredKernelInvocation(kernelParams)) {\n      const {kernelName, inputs, attrs} = kernelParams;\n      if (this.backendName == null) {\n        // backend has not been initialized yet (backend initialization is lazy\n        // can be deferred until an op/ kernel is run).\n        // The below getter has side effects that will try to initialize the\n        // backend and set properties like this.backendName\n        // tslint:disable-next-line: no-unused-expression\n        this.backend;\n      }\n      const kernel = getKernel(kernelName, this.backendName);\n      util.assert(\n          kernel != null,\n          () => `Cannot find registered kernel '${kernelName}' for backend '${\n              this.backendName}'`);\n\n      kernelFunc = () => {\n        const numDataIdsBefore = this.backend.numDataIds();\n        out = kernel.kernelFunc({inputs, attrs, backend: this.backend});\n        const outInfos = Array.isArray(out) ? out : [out];\n        if (this.shouldCheckForMemLeaks()) {\n          this.checkKernelForMemLeak(kernelName, numDataIdsBefore, outInfos);\n        }\n\n        const outTensors = outInfos.map((outInfo: TensorInfo|Tensor) => {\n          // todo (yassogba) remove this option (Tensor) when node backend\n          // methods have been modularized and they all return tensorInfo.\n          // TensorInfos do not have a rank attribute.\n          if ((outInfo as Tensor).rank != null) {\n            return outInfo as Tensor;\n          }\n          return this.makeTensorFromTensorInfo(outInfo);\n        });\n\n        // Save any required inputs and outputs.\n\n        // Do not save unless we are recording to the tape. Otherwise it would\n        // cause a mem leak since there would be no backprop for these tensors\n        // (which would otherwise dispose them).\n        if (isTapeOn) {\n          const tensorsToSave =\n              this.getTensorsForGradient(kernelName, inputs, outTensors);\n          saved = this.saveTensorsForBackwardMode(tensorsToSave);\n        }\n        return outTensors;\n      };\n    } else {\n      const {forwardFunc} = kernelParams;\n      // Running a customGrad op.\n      const saveFunc: GradSaveFunc = (tensors) => {\n        // Do not save unless we are recording to the tape. Otherwise it would\n        // cause a mem leak since we would never run backprop, which disposes\n        // the kept tensors.\n        if (!isTapeOn) {\n          return;\n        }\n        saved = tensors.map(tensor => this.keep(this.clone(tensor)));\n      };\n\n      kernelFunc = () => {\n        const numDataIdsBefore = this.backend.numDataIds();\n        out = this.tidy(() => forwardFunc(this.backend, saveFunc));\n        const outs = (Array.isArray(out) ? out : [out]) as Tensor[];\n        if (this.shouldCheckForMemLeaks()) {\n          // Scope name is used to print a more helpful error message if needed.\n          this.checkKernelForMemLeak(kernelOrScopeName, numDataIdsBefore, outs);\n        }\n        return outs;\n      };\n    }\n\n    //\n    // Run the kernelFunc. Optionally profiling it.\n    //\n    const {inputs, attrs} = kernelParams;\n    const backwardsFunc = isRegisteredKernelInvocation(kernelParams) ?\n        null :\n        kernelParams.backwardsFunc;\n\n    let kernelProfile: KernelProfile;\n    this.scopedRun(\n        // Stop recording to a tape when running a kernel.\n        () => this.state.kernelDepth++, () => this.state.kernelDepth--, () => {\n          if (!this.ENV.getBool('DEBUG') && !this.state.profiling) {\n            outputs = kernelFunc();\n          } else {\n            kernelProfile = this.profiler.profileKernel(\n                kernelOrScopeName, inputs, () => kernelFunc());\n            if (this.ENV.getBool('DEBUG')) {\n              this.profiler.logKernelProfile(kernelProfile);\n            }\n            outputs = kernelProfile.outputs;\n          }\n        });\n\n    if (isTapeOn) {\n      this.addTapeNode(\n          kernelOrScopeName, inputs, outputs, backwardsFunc, saved, attrs);\n    }\n\n    if (this.state.profiling) {\n      this.state.activeProfile.kernels.push({\n        name: kernelOrScopeName,\n        bytesAdded: this.state.numBytes - startingBytecount,\n        totalBytesSnapshot: this.state.numBytes,\n        tensorsAdded: this.state.numTensors - startingNumTensors,\n        totalTensorsSnapshot: this.state.numTensors,\n        inputShapes: Object.keys(inputs).map(\n            key => inputs[key] != null ? inputs[key].shape : null),\n        outputShapes: outputs.map(item => item.shape),\n        kernelTimeMs: kernelProfile.timeMs,\n        extraInfo: kernelProfile.extraInfo\n      });\n    }\n    return (Array.isArray(out) ? outputs : outputs[0]) as T;\n  }\n\n  /**\n   * Saves tensors used in forward mode for use in backward mode.\n   *\n   * @param tensors the list of tensors to save.\n   */\n  private saveTensorsForBackwardMode(tensors: Tensor[]): Tensor[] {\n    const saved = tensors.map(tensor => this.keep(this.clone(tensor)));\n    return saved;\n  }\n\n  /**\n   * Returns a list of tensors to save for a given gradient calculation.\n   *\n   * @param kernelName name of kernel to look up gradient for.\n   * @param inputs a map of input tensors.\n   * @param outputs an array of output tensors from forward mode of kernel.\n   */\n  private getTensorsForGradient(\n      kernelName: string, inputs: NamedTensorMap,\n      outputs: Tensor[]): Tensor[]|null {\n    const gradConfig = getGradient(kernelName);\n    if (gradConfig != null) {\n      const inputsToSave: string[] = gradConfig.inputsToSave || [];\n      const outputsToSave: boolean[] = gradConfig.outputsToSave || [];\n\n      // If saveAllInputs is true, all inputs will be saved. Otherwise, inputs\n      // specified in inputsToSave will be saved.\n      let inputTensorsToSave: Tensor[];\n      if (gradConfig.saveAllInputs) {\n        util.assert(\n            Array.isArray(inputs),\n            () => 'saveAllInputs is true, expected inputs to be an array.');\n\n        inputTensorsToSave = Object.keys(inputs).map((key) => inputs[key]);\n      } else {\n        inputTensorsToSave = inputsToSave.map((inputName) => inputs[inputName]);\n      }\n\n      const outputTensorsToSave: Tensor[] =\n          outputs.filter((_, i) => outputsToSave[i]);\n\n      return inputTensorsToSave.concat(outputTensorsToSave);\n    }\n    // We return an empty list rather than throw an error because the kernel we\n    // are looking up may not actually be relevant to backproping through the\n    // overall function\n    //\n    // See 'does not error if irrelevant (pruned) ops are missing grads' test\n    // in gradients_test.ts for an example.\n    return [];\n  }\n\n  /**\n   * Internal method used by public APIs for tensor creation. Makes a new\n   * tensor with the provided shape, dtype and values. It always\n   * creates a new data id and writes the values to the underlying backend.\n   */\n  makeTensor(\n      values: DataValues, shape: number[], dtype: DataType,\n      backend?: KernelBackend): Tensor {\n    if (values == null) {\n      throw new Error('Values passed to engine.makeTensor() are null');\n    }\n    dtype = dtype || 'float32';\n    backend = backend || this.backend;\n    let backendVals = values as BackendValues;\n    if (dtype === 'string' && util.isString(values[0])) {\n      backendVals = (values as string[]).map(d => util.encodeString(d));\n    }\n    const dataId = backend.write(backendVals, shape, dtype);\n    const t = new Tensor(shape, dtype, dataId, this.nextTensorId());\n    this.trackTensor(t, backend);\n\n    // Count bytes for string tensors.\n    if (dtype === 'string') {\n      const info = this.state.tensorInfo.get(dataId);\n      const newBytes = bytesFromStringArray(backendVals as Uint8Array[]);\n      this.state.numBytes += newBytes - info.bytes;\n      info.bytes = newBytes;\n    }\n    return t;\n  }\n\n  /**\n   * Internal method used by backends. Makes a new tensor\n   * that is a wrapper around an existing data id. It doesn't create\n   * a new data id, only increments the ref count used in memory tracking.\n   * @deprecated\n   */\n  makeTensorFromDataId(\n    dataId: DataId, shape: number[], dtype: DataType,\n    backend?: KernelBackend): Tensor {\n    dtype = dtype || 'float32';\n    const tensorInfo: TensorInfo = {dataId, shape, dtype};\n    return this.makeTensorFromTensorInfo(tensorInfo, backend);\n  }\n\n  /**\n   * Internal method used by backends. Makes a new tensor that is a wrapper\n   * around an existing data id in TensorInfo. It doesn't create a new data id,\n   * only increments the ref count used in memory tracking.\n   */\n  makeTensorFromTensorInfo(tensorInfo: TensorInfo, backend?: KernelBackend):\n      Tensor {\n    const {dataId, shape, dtype} = tensorInfo;\n    const t = new Tensor(shape, dtype, dataId, this.nextTensorId());\n    this.trackTensor(t, backend);\n    return t;\n  }\n\n  makeVariable(\n      initialValue: Tensor, trainable = true, name?: string,\n      dtype?: DataType): Variable {\n    name = name || this.nextVariableId().toString();\n    if (dtype != null && dtype !== initialValue.dtype) {\n      initialValue = initialValue.cast(dtype);\n    }\n    const v = new Variable(initialValue, trainable, name, this.nextTensorId());\n    if (this.state.registeredVariables[v.name] != null) {\n      throw new Error(`Variable with name ${v.name} was already registered`);\n    }\n    this.state.registeredVariables[v.name] = v;\n    this.incRef(v, this.backend);\n    return v;\n  }\n\n  trackTensor(a: Tensor, backend: KernelBackend): void {\n    this.state.numTensors++;\n    if (a.dtype === 'string') {\n      this.state.numStringTensors++;\n    }\n    // Bytes for complex numbers are counted by their components. Bytes for\n    // string tensors are counted when writing values.\n    let bytes = 0;\n    if (a.dtype !== 'complex64' && a.dtype !== 'string') {\n      bytes = a.size * util.bytesPerElement(a.dtype);\n    }\n    this.state.numBytes += bytes;\n\n    if (!this.state.tensorInfo.has(a.dataId)) {\n      this.state.numDataBuffers++;\n      this.state.tensorInfo.set(a.dataId, {\n        backend: backend || this.backend,\n        dtype: a.dtype,\n        shape: a.shape,\n        bytes\n      });\n    }\n\n    if (!(a instanceof Variable)) {\n      this.track(a);\n    }\n  }\n\n  // Track the tensor by dataId and increase the refCount for the dataId in the\n  // backend.\n  // TODO(pyu10055): This is currently used by makeVariable method, to increase\n  // refCount on the backend for the dataId. It can potentially be replaced with\n  // Identity op indead of calling backend directly.\n  incRef(a: Tensor, backend: KernelBackend): void {\n    this.trackTensor(a, backend);\n    this.backend.incRef(a.dataId);\n  }\n\n  removeDataId(dataId: DataId, backend: KernelBackend) {\n    if (this.state.tensorInfo.has(dataId) &&\n        this.state.tensorInfo.get(dataId).backend === backend) {\n      this.state.tensorInfo.delete(dataId);\n      this.state.numDataBuffers--;\n    }\n  }\n  disposeTensor(a: Tensor): void {\n    if (!this.state.tensorInfo.has(a.dataId)) {\n      return;\n    }\n    const info = this.state.tensorInfo.get(a.dataId);\n\n    this.state.numTensors--;\n    if (a.dtype === 'string') {\n      this.state.numStringTensors--;\n      this.state.numBytes -= info.bytes;\n    }\n    // Don't count bytes for complex numbers as they are counted by their\n    // components.\n    if (a.dtype !== 'complex64' && a.dtype !== 'string') {\n      const bytes = a.size * util.bytesPerElement(a.dtype);\n      this.state.numBytes -= bytes;\n    }\n\n    // Remove the reference to dataId if backend dispose the data successfully\n    if (info.backend.disposeData(a.dataId)) {\n      this.removeDataId(a.dataId, info.backend);\n    }\n\n    // TODO(nsthorat): Construct an error and save the stack trace for\n    // debugging when in debug mode. Creating a stack trace is too expensive\n    // to do unconditionally.\n  }\n\n  disposeVariables(): void {\n    for (const varName in this.state.registeredVariables) {\n      const v = this.state.registeredVariables[varName];\n      this.disposeVariable(v);\n    }\n  }\n\n  disposeVariable(v: Variable): void {\n    this.disposeTensor(v);\n    if (this.state.registeredVariables[v.name] != null) {\n      delete this.state.registeredVariables[v.name];\n    }\n  }\n\n  memory(): MemoryInfo {\n    const info = this.backend.memory() as MemoryInfo;\n    info.numTensors = this.state.numTensors;\n    info.numDataBuffers = this.state.numDataBuffers;\n    info.numBytes = this.state.numBytes;\n    if (this.state.numStringTensors > 0) {\n      info.unreliable = true;\n      if (info.reasons == null) {\n        info.reasons = [];\n      }\n      info.reasons.push(\n          'Memory usage by string tensors is approximate ' +\n          '(2 bytes per character)');\n    }\n    return info;\n  }\n\n  async profile(query: () => (TensorContainer | Promise<TensorContainer>)):\n      Promise<ProfileInfo> {\n    this.state.profiling = true;\n\n    const startBytes = this.state.numBytes;\n    const startNumTensors = this.state.numTensors;\n\n    this.state.activeProfile.kernels = [];\n    this.state.activeProfile.result = await query();\n\n    this.state.profiling = false;\n\n    this.state.activeProfile.peakBytes = Math.max(\n        ...this.state.activeProfile.kernels.map(d => d.totalBytesSnapshot));\n    this.state.activeProfile.newBytes = this.state.numBytes - startBytes;\n    this.state.activeProfile.newTensors =\n        this.state.numTensors - startNumTensors;\n    for (const kernel of this.state.activeProfile.kernels) {\n      kernel.kernelTimeMs = await kernel.kernelTimeMs;\n      kernel.extraInfo = await kernel.extraInfo;\n    }\n    return this.state.activeProfile;\n  }\n\n  isTapeOn(): boolean {\n    return this.state.gradientDepth > 0 && this.state.kernelDepth === 0;\n  }\n\n  private addTapeNode(\n      kernelName: string, inputs: NamedTensorMap, outputs: Tensor[],\n      gradientsFunc: GradFunc, saved: Tensor[], attrs: NamedAttrMap): void {\n    const tapeNode: TapeNode =\n        {id: this.state.nextTapeNodeId++, kernelName, inputs, outputs, saved};\n\n    const gradConfig = getGradient(kernelName);\n    if (gradConfig != null) {\n      gradientsFunc = gradConfig.gradFunc;\n    }\n    if (gradientsFunc != null) {\n      tapeNode.gradient = (dys: Tensor[]) => {\n        // TODO(smilkov): To optimize back-prop, pass dys that are not used in\n        // the backprop graph to the user as null instead of zeros\n        dys = dys.map((dy, i) => {\n          if (dy == null) {\n            const output = outputs[i];\n            const vals = util.makeZerosTypedArray(output.size, output.dtype);\n            return this.makeTensor(vals, output.shape, output.dtype);\n          }\n          return dy;\n        });\n        // Grad functions of ops with single outputs expect a dy, while ops\n        // with multiple outputs expect dys (array of dy).\n        return gradientsFunc(dys.length > 1 ? dys : dys[0], saved, attrs);\n      };\n    }\n    this.state.activeTape.push(tapeNode);\n  }\n\n  keep<T extends Tensor>(result: T): T {\n    result.kept = true;\n    return result;\n  }\n\n  private startTape() {\n    if (this.state.gradientDepth === 0) {\n      this.state.activeTape = [];\n    }\n    this.state.gradientDepth++;\n  }\n\n  private endTape() {\n    this.state.gradientDepth--;\n  }\n\n  /**\n   * Start a scope. Use this with endScope() to achieve the same functionality\n   * as scope() without the need for a function closure.\n   */\n  startScope(name?: string) {\n    const scopeInfo: ScopeState = {\n      track: [],\n      name: 'unnamed scope',\n      id: this.state.nextScopeId++\n    };\n    if (name) {\n      scopeInfo.name = name;\n    }\n    this.state.scopeStack.push(scopeInfo);\n    this.state.activeScope = scopeInfo;\n  }\n\n  /**\n   * End a scope. Use this with startScope() to achieve the same functionality\n   * as scope() without the need for a function closure.\n   */\n  endScope(result?: TensorContainer) {\n    const tensorsToTrackInParent = getTensorsInContainer(result);\n    const tensorsToTrackInParentSet =\n        new Set(tensorsToTrackInParent.map(t => t.id));\n\n    // Dispose the arrays tracked in this scope.\n    for (let i = 0; i < this.state.activeScope.track.length; i++) {\n      const tensor = this.state.activeScope.track[i];\n      if (!tensor.kept && !tensorsToTrackInParentSet.has(tensor.id)) {\n        tensor.dispose();\n      }\n    }\n\n    const oldScope = this.state.scopeStack.pop();\n    this.state.activeScope = this.state.scopeStack.length === 0 ?\n        null :\n        this.state.scopeStack[this.state.scopeStack.length - 1];\n\n    // Track the current result in the parent scope.\n    tensorsToTrackInParent.forEach(tensor => {\n      // Only track the tensor if was allocated in the inner scope and is not\n      // globally kept.\n      if (!tensor.kept && tensor.scopeId === oldScope.id) {\n        this.track(tensor);\n      }\n    });\n  }\n\n  /**\n   * Returns gradients of `f` with respect to each of the `xs`. The gradients\n   * returned are of the same length as `xs`, but some might be null if `f`\n   * was not a function of that `x`. It also takes optional dy to multiply the\n   * gradient, which defaults to `1`.\n   */\n  gradients<T extends Tensor>(\n      f: () => T, xs: Tensor[], dy?: T,\n      allowNoGradients = false): {value: T, grads: Tensor[]} {\n    util.assert(\n        xs.length > 0, () => 'gradients() received an empty list of xs.');\n    if (dy != null && dy.dtype !== 'float32') {\n      throw new Error(`dy must have 'float32' dtype, but has '${dy.dtype}'`);\n    }\n\n    const y = this.scopedRun(\n        () => this.startTape(), () => this.endTape(),\n        () => this.tidy('forward', f));\n\n    util.assert(\n        y instanceof Tensor,\n        () => 'The result y returned by f() must be a tensor.');\n    // Filter out the nodes that don't connect x => y.\n    const filteredTape = getFilteredNodesXToY(this.state.activeTape, xs, y);\n    if (!allowNoGradients && filteredTape.length === 0 && xs.length > 0) {\n      throw new Error(\n          'Cannot compute gradient of y=f(x) with respect to x. Make sure ' +\n          'that the f you passed encloses all operations that lead from x ' +\n          'to y.');\n    }\n\n    return this.tidy('backward', () => {\n      const accumulatedGradientMap: {[tensorId: number]: Tensor} = {};\n      accumulatedGradientMap[y.id] = (dy == null) ? ones(y.shape) : dy;\n\n      // Backprop gradients through the filtered nodes.\n      backpropagateGradients(\n          accumulatedGradientMap, filteredTape,\n          // Pass the tidy function to avoid circular dep with `tape.ts`.\n          f => this.tidy(f as ScopeFn<Tensor>),\n          // Pass an add function to avoide a circular dep with `tape.ts`.\n          add);\n      const grads = xs.map(x => accumulatedGradientMap[x.id]);\n\n      if (this.state.gradientDepth === 0) {\n        // This means that we are not computing higher-order gradients\n        // and can clean up the tape.\n        this.state.activeTape.forEach(node => {\n          for (const tensor of node.saved) {\n            tensor.dispose();\n          }\n        });\n        this.state.activeTape = null;\n      }\n      return {value: y, grads};\n    });\n  }\n\n  customGrad<T extends Tensor>(f: CustomGradientFunc<T>):\n      (...args: Array<Tensor|GradSaveFunc>) => T {\n    util.assert(\n        util.isFunction(f),\n        () => 'The f passed in customGrad(f) must be a function.');\n    return (...inputs: Tensor[]): T => {\n      util.assert(\n          inputs.every(t => t instanceof Tensor),\n          () => 'The args passed in customGrad(f)(x1, x2,...) must all be ' +\n              'tensors');\n\n      let res: {\n        value: T,\n        gradFunc: (dy: T, saved: Tensor[]) => Tensor | Tensor[],\n      };\n      const inputMap: NamedTensorMap = {};\n      inputs.forEach((input, i) => {\n        inputMap[i] = input;\n      });\n\n      const forwardFunc: ForwardFunc<T> = (_, save) => {\n        res = f(...[...inputs, save]);\n        util.assert(\n            res.value instanceof Tensor,\n            () => 'The function f passed in customGrad(f) must return an ' +\n                'object where `obj.value` is a tensor');\n        util.assert(\n            util.isFunction(res.gradFunc),\n            () => 'The function f passed in customGrad(f) must return an ' +\n                'object where `obj.gradFunc` is a function.');\n        return res.value;\n      };\n\n      const backwardsFunc = (dy: T, saved: Tensor[]) => {\n        const gradRes = res.gradFunc(dy, saved);\n        const grads: Tensor[] = Array.isArray(gradRes) ? gradRes : [gradRes];\n        util.assert(\n            grads.length === inputs.length,\n            () => 'The function f passed in customGrad(f) must return an ' +\n                'object where `obj.gradFunc` is a function that returns ' +\n                'the same number of tensors as inputs passed to f(...).');\n        util.assert(\n            grads.every(t => t instanceof Tensor),\n            () => 'The function f passed in customGrad(f) must return an ' +\n                'object where `obj.gradFunc` is a function that returns ' +\n                'a list of only tensors.');\n        const gradMap: {[key: string]: () => Tensor} = {};\n        grads.forEach((grad, i) => {\n          gradMap[i] = () => grad;\n        });\n        return gradMap;\n      };\n\n      return this.runKernelFunc({\n        forwardFunc,\n        backwardsFunc,\n        inputs: inputMap,\n      });\n    };\n  }\n\n  readSync(dataId: DataId): BackendValues {\n    // Route the read to the correct backend.\n    const info = this.state.tensorInfo.get(dataId);\n    return info.backend.readSync(dataId);\n  }\n  read(dataId: DataId): Promise<BackendValues> {\n    // Route the read to the correct backend.\n    const info = this.state.tensorInfo.get(dataId);\n    return info.backend.read(dataId);\n  }\n\n  readToGPU(dataId: DataId, options?: DataToGPUOptions): GPUData {\n    // Route the read to the correct backend.\n    const info = this.state.tensorInfo.get(dataId);\n    return info.backend.readToGPU(dataId, options);\n  }\n\n  async time(query: () => void): Promise<TimingInfo> {\n    const start = now();\n    const timingInfo = await this.backend.time(query) as TimingInfo;\n    timingInfo.wallMs = now() - start;\n    return timingInfo;\n  }\n\n  /**\n   * Tracks a Tensor in the current scope to be automatically cleaned up\n   * when the current scope ends, and returns the value.\n   *\n   * @param result The Tensor to track in the current scope.\n   */\n  private track<T extends Tensor>(result: T): T {\n    if (this.state.activeScope != null) {\n      result.scopeId = this.state.activeScope.id;\n      this.state.activeScope.track.push(result);\n    }\n\n    return result;\n  }\n\n  get registeredVariables(): NamedVariableMap {\n    return this.state.registeredVariables;\n  }\n\n  /**\n   * Resets the engine state. Removes all backends but does not remove\n   * registered backend factories.\n   */\n  reset(): void {\n    // Make any pending promise obsolete.\n    this.pendingBackendInitId++;\n\n    this.state.dispose();\n    this.ENV.reset();\n    this.state = new EngineState();\n\n    for (const backendName in this.registry) {\n      this.disposeRegisteredKernels(backendName);\n      this.registry[backendName].dispose();\n      delete this.registry[backendName];\n    }\n    this.backendName = null;\n    this.backendInstance = null;\n    this.pendingBackendInit = null;\n  }\n}\n\nfunction ones(shape: number[]): Tensor {\n  const values = makeOnesTypedArray(sizeFromShape(shape), 'float32');\n  return ENGINE.makeTensor(values, shape, 'float32');\n}\n\nexport function getOrMakeEngine(): Engine {\n  const ns = getGlobalNamespace() as {} as {_tfengine: Engine};\n  if (ns._tfengine == null) {\n    const environment = new Environment(ns);\n    ns._tfengine = new Engine(environment);\n  }\n  setEnvironmentGlobal(ns._tfengine.ENV);\n\n  // Tell the current tensor interface that the global engine is responsible\n  // for tracking.\n  setTensorTracker(() => ns._tfengine);\n  return ns._tfengine;\n}\n\nexport const ENGINE = getOrMakeEngine();\n\n/**\n * A implementation of the add op for use within engine and tape.\n *\n * This allows us to avoid a circular dependency between add.ts and engine.\n * It is exported to be available in tape tests.\n */\nexport function add(a: Tensor, b: Tensor): Tensor {\n  // We duplicate Add here to avoid a circular dependency with add.ts.\n  const inputs = {a, b};\n  return ENGINE.runKernel(Add, inputs as {} as NamedTensorMap);\n}\n","/**\n * @license\n * Copyright 2017 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor} from './tensor';\nimport {NamedTensorMap} from './tensor_types';\nimport * as util from './util';\n\nexport interface TapeNode {\n  id: number;\n  kernelName: string;\n  outputs: Tensor[];\n  inputs: NamedTensorMap;\n  // Optional params, defined only for ops with gradient impl.\n  gradient?: (dys: Tensor[]) => NamedGradientMap;\n  saved?: Tensor[];\n}\n\nexport type NamedGradientMap = {\n  [inputName: string]: () => Tensor;\n};\n\n/**\n * Computes a list of TapeNodes that connect x to y, filtering everything else\n * out and preserving the order of the original tape elements.\n *\n * @param tape The tape elements to filter.\n * @param xs The input Tensors.\n * @param y The output Tensor.\n */\nexport function getFilteredNodesXToY(\n    tape: TapeNode[], xs: Tensor[], y: Tensor): TapeNode[] {\n  // Forward pass to compute all the nodes and Tensors that are transitively a\n  // function of x.\n  const tensorsFromX: {[tensorId: number]: boolean} = {};\n  const nodesFromX: {[nodeId: number]: boolean} = {};\n  for (let i = 0; i < xs.length; i++) {\n    tensorsFromX[xs[i].id] = true;\n  }\n\n  for (let i = 0; i < tape.length; i++) {\n    const node = tape[i];\n    const nodeInputs = node.inputs;\n    for (const inputName in nodeInputs) {\n      const input = nodeInputs[inputName];\n\n      let anyInputFromX = false;\n      for (let j = 0; j < xs.length; j++) {\n        if (tensorsFromX[input.id]) {\n          node.outputs.forEach(output => tensorsFromX[output.id] = true);\n          anyInputFromX = true;\n          nodesFromX[node.id] = true;\n          break;\n        }\n      }\n\n      if (anyInputFromX) {\n        break;\n      }\n    }\n  }\n\n  // Backward pass to find all of the nodes and Tensors that lead to y.\n  const tensorsLeadToY: {[tensorId: number]: boolean} = {};\n  tensorsLeadToY[y.id] = true;\n  const nodesToY: {[nodeId: number]: boolean} = {};\n\n  for (let i = tape.length - 1; i >= 0; i--) {\n    const node = tape[i];\n    const nodeInputs = node.inputs;\n\n    // If any of the outputs lead to y, mark all of the inputs as leading to y.\n    for (let j = 0; j < node.outputs.length; j++) {\n      if (tensorsLeadToY[node.outputs[j].id]) {\n        for (const inputName in nodeInputs) {\n          tensorsLeadToY[nodeInputs[inputName].id] = true;\n          nodesToY[node.id] = true;\n        }\n        break;\n      }\n    }\n  }\n\n  // Return the paths that come from x and lead to y.\n  const filteredTape: TapeNode[] = [];\n  for (let i = 0; i < tape.length; i++) {\n    const node = tape[i];\n\n    if (nodesFromX[node.id] && nodesToY[node.id]) {\n      // Prune the inputs from the node that aren't a function of x.\n      const prunedInputs: {[inputName: string]: Tensor} = {};\n      for (const inputName in node.inputs) {\n        const nodeInput = node.inputs[inputName];\n        if (tensorsFromX[nodeInput.id]) {\n          prunedInputs[inputName] = nodeInput;\n        }\n      }\n\n      // Copy the node and overwrite inputsAndArgs to the pruned version.\n      const prunedNode = Object.assign({}, node);\n      prunedNode.inputs = prunedInputs;\n      prunedNode.outputs = node.outputs;\n\n      filteredTape.push(prunedNode);\n    }\n  }\n\n  return filteredTape;\n}\n\n/**\n * Backpropagate gradients through the filtered TapeNodes.\n *\n * @param tensorAccumulatedGradientMap A map of Tensor to its gradient. This map\n * is mutated by this method.\n * @param filteredTape The filtered TapeNodes to backprop through.\n */\nexport function backpropagateGradients(\n    tensorAccumulatedGradientMap: {[tensorId: number]: Tensor},\n    filteredTape: TapeNode[], tidy: (f: Function) => Tensor,\n    add: (a: Tensor, b: Tensor) => Tensor) {\n  // Walk the tape backward and keep a map of Tensor to its gradient.\n  for (let i = filteredTape.length - 1; i >= 0; i--) {\n    const node = filteredTape[i];\n\n    const dys: Tensor[] = [];\n    node.outputs.forEach(o => {\n      const gradTensor = tensorAccumulatedGradientMap[o.id];\n      if (gradTensor != null) {\n        dys.push(gradTensor);\n      } else {\n        // This particular output is not in the back-propagation subgraph, so it\n        // does not affect the final output, thus we put null for its dy.\n        dys.push(null);\n      }\n    });\n\n    if (node.gradient == null) {\n      throw new Error(\n          `Cannot compute gradient: gradient function not found ` +\n          `for ${node.kernelName}.`);\n    }\n\n    // Backprop dy through this node and accumulate gradients over the inputs.\n    const inputGradients = node.gradient(dys);\n\n    for (const inputName in node.inputs) {\n      if (!(inputName in inputGradients)) {\n        throw new Error(\n            `Cannot backprop through input ${inputName}. ` +\n            `Available gradients found: ${Object.keys(inputGradients)}.`);\n      }\n\n      // Call the gradient function.\n      const dx = tidy(() => inputGradients[inputName]());\n      if (dx.dtype !== 'float32') {\n        throw new Error(\n            `Error in gradient for op ${\n                node.kernelName}. The gradient of input ` +\n            `${inputName} must have 'float32' dtype, but has '${dx.dtype}'`);\n      }\n      const x = node.inputs[inputName];\n      if (!util.arraysEqual(dx.shape, x.shape)) {\n        throw new Error(\n            `Error in gradient for op ${\n                node.kernelName}. The gradient of input ` +\n            `'${inputName}' has shape '${dx.shape}', which does not match ` +\n            `the shape of the input '${x.shape}'`);\n      }\n\n      if (tensorAccumulatedGradientMap[x.id] == null) {\n        tensorAccumulatedGradientMap[x.id] = dx;\n      } else {\n        const curGradient = tensorAccumulatedGradientMap[x.id];\n        tensorAccumulatedGradientMap[x.id] = add(curGradient, dx);\n        curGradient.dispose();\n      }\n    }\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n// tslint:disable-next-line:no-any\nfunction _isNavigatorDefined(): boolean {\n  return typeof navigator !== 'undefined' && navigator != null;\n}\n\nlet isMobileMockValue: boolean|undefined;\n\nexport function mockIsMobile(value: boolean|undefined) {\n  isMobileMockValue = value;\n}\n\nexport function isMobile(nav?: Navigator): boolean {\n  if (isMobileMockValue !== undefined) {\n    return isMobileMockValue;\n  }\n  if (nav || _isNavigatorDefined()) {\n    if (!nav) {\n      nav = navigator;\n    }\n    if (nav.product === 'ReactNative') {\n      return true;\n    }\n\n    const a = nav.userAgent || nav.vendor ||\n        // tslint:disable-next-line:no-any\n        (typeof window !== 'undefined' ? (window as any).opera : '');\n    // Use `navigator.userAgentData.mobile` as fallback.\n    if (!a) {\n      // tslint:disable-next-line:no-any\n      const navAny = nav as any;\n      return navAny.userAgentData && navAny.userAgentData.mobile;\n    }\n    // tslint:disable-next-line:max-line-length\n    return /(android|bb\\d+|meego).+mobile|avantgo|bada\\/|blackberry|blazer|compal|elaine|fennec|hiptop|iemobile|ip(hone|od)|iris|kindle|lge |maemo|midp|mmp|mobile.+firefox|netfront|opera m(ob|in)i|palm( os)?|phone|p(ixi|re)\\/|plucker|pocket|psp|series(4|6)0|symbian|treo|up\\.(browser|link)|vodafone|wap|windows ce|xda|xiino/i\n               .test(a) ||\n        // tslint:disable-next-line:max-line-length\n        /1207|6310|6590|3gso|4thp|50[1-6]i|770s|802s|a wa|abac|ac(er|oo|s\\-)|ai(ko|rn)|al(av|ca|co)|amoi|an(ex|ny|yw)|aptu|ar(ch|go)|as(te|us)|attw|au(di|\\-m|r |s )|avan|be(ck|ll|nq)|bi(lb|rd)|bl(ac|az)|br(e|v)w|bumb|bw\\-(n|u)|c55\\/|capi|ccwa|cdm\\-|cell|chtm|cldc|cmd\\-|co(mp|nd)|craw|da(it|ll|ng)|dbte|dc\\-s|devi|dica|dmob|do(c|p)o|ds(12|\\-d)|el(49|ai)|em(l2|ul)|er(ic|k0)|esl8|ez([4-7]0|os|wa|ze)|fetc|fly(\\-|_)|g1 u|g560|gene|gf\\-5|g\\-mo|go(\\.w|od)|gr(ad|un)|haie|hcit|hd\\-(m|p|t)|hei\\-|hi(pt|ta)|hp( i|ip)|hs\\-c|ht(c(\\-| |_|a|g|p|s|t)|tp)|hu(aw|tc)|i\\-(20|go|ma)|i230|iac( |\\-|\\/)|ibro|idea|ig01|ikom|im1k|inno|ipaq|iris|ja(t|v)a|jbro|jemu|jigs|kddi|keji|kgt( |\\/)|klon|kpt |kwc\\-|kyo(c|k)|le(no|xi)|lg( g|\\/(k|l|u)|50|54|\\-[a-w])|libw|lynx|m1\\-w|m3ga|m50\\/|ma(te|ui|xo)|mc(01|21|ca)|m\\-cr|me(rc|ri)|mi(o8|oa|ts)|mmef|mo(01|02|bi|de|do|t(\\-| |o|v)|zz)|mt(50|p1|v )|mwbp|mywa|n10[0-2]|n20[2-3]|n30(0|2)|n50(0|2|5)|n7(0(0|1)|10)|ne((c|m)\\-|on|tf|wf|wg|wt)|nok(6|i)|nzph|o2im|op(ti|wv)|oran|owg1|p800|pan(a|d|t)|pdxg|pg(13|\\-([1-8]|c))|phil|pire|pl(ay|uc)|pn\\-2|po(ck|rt|se)|prox|psio|pt\\-g|qa\\-a|qc(07|12|21|32|60|\\-[2-7]|i\\-)|qtek|r380|r600|raks|rim9|ro(ve|zo)|s55\\/|sa(ge|ma|mm|ms|ny|va)|sc(01|h\\-|oo|p\\-)|sdk\\/|se(c(\\-|0|1)|47|mc|nd|ri)|sgh\\-|shar|sie(\\-|m)|sk\\-0|sl(45|id)|sm(al|ar|b3|it|t5)|so(ft|ny)|sp(01|h\\-|v\\-|v )|sy(01|mb)|t2(18|50)|t6(00|10|18)|ta(gt|lk)|tcl\\-|tdg\\-|tel(i|m)|tim\\-|t\\-mo|to(pl|sh)|ts(70|m\\-|m3|m5)|tx\\-9|up(\\.b|g1|si)|utst|v400|v750|veri|vi(rg|te)|vk(40|5[0-3]|\\-v)|vm40|voda|vulc|vx(52|53|60|61|70|80|81|83|85|98)|w3c(\\-| )|webc|whit|wi(g |nc|nw)|wmlb|wonu|x700|yas\\-|your|zeto|zte\\-/i\n            .test(a.substr(0, 4));\n  }\n  return false;\n}\n\nexport function isBrowser(): boolean {\n  return (typeof window !== 'undefined' && window.document != null) ||\n      //@ts-ignore\n      (typeof WorkerGlobalScope !== 'undefined');\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport './engine';\n\nimport * as device_util from './device_util';\nimport {env} from './environment';\n\nconst ENV = env();\n\n/**\n * This file contains environment-related flag registrations.\n */\n\n/** Whether to enable debug mode. */\nENV.registerFlag('DEBUG', () => false, debugValue => {\n  if (debugValue) {\n    console.warn(\n        'Debugging mode is ON. The output of every math call will ' +\n        'be downloaded to CPU and checked for NaNs. ' +\n        'This significantly impacts performance.');\n  }\n});\n\n/** Whether we are in a browser (as versus, say, node.js) environment. */\nENV.registerFlag('IS_BROWSER', () => device_util.isBrowser());\n\n/** Whether we are in a browser (as versus, say, node.js) environment. */\nENV.registerFlag(\n    'IS_NODE',\n    () => (typeof process !== 'undefined') &&\n        (typeof process.versions !== 'undefined') &&\n        (typeof process.versions.node !== 'undefined'));\n\n/** Whether this browser is Chrome. */\nENV.registerFlag(\n    'IS_CHROME',\n    () => typeof navigator !== 'undefined' && navigator != null &&\n        navigator.userAgent != null && /Chrome/.test(navigator.userAgent) &&\n        /Google Inc/.test(navigator.vendor));\n\n/**\n * True when the environment is \"production\" where we disable safety checks\n * to gain performance.\n */\nENV.registerFlag('PROD', () => false);\n\n/**\n * Whether to do sanity checks when inferring a shape from user-provided\n * values, used when creating a new tensor.\n */\nENV.registerFlag(\n    'TENSORLIKE_CHECK_SHAPE_CONSISTENCY', () => ENV.getBool('DEBUG'));\n\n/** Whether deprecation warnings are enabled. */\nENV.registerFlag('DEPRECATION_WARNINGS_ENABLED', () => true);\n\n/** True if running unit tests. */\nENV.registerFlag('IS_TEST', () => false);\n\n/** Whether to check computation result for errors. */\nENV.registerFlag('CHECK_COMPUTATION_FOR_ERRORS', () => true);\n\n/** Whether the backend needs to wrap input to imageBitmap. */\nENV.registerFlag('WRAP_TO_IMAGEBITMAP', () => false);\n\n/** Experimental flag, whether enter compile only phase. */\nENV.registerFlag('ENGINE_COMPILE_ONLY', () => false);\n\n/** Whether to enable canvas2d willReadFrequently for GPU backends */\nENV.registerFlag('CANVAS2D_WILL_READ_FREQUENTLY_FOR_GPU', () => false);\n\n/** Whether to use setTimeoutCustom */\nENV.registerFlag('USE_SETTIMEOUTCUSTOM', () => false);\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from './engine';\nimport {env} from './environment';\nimport {Tensor} from './tensor';\nimport {DataType, TensorLike} from './types';\nimport {assert, flatten, inferDtype, isTypedArray, toTypedArray} from './util';\n\nexport function inferShape(val: TensorLike, dtype?: DataType): number[] {\n  let firstElem: typeof val = val;\n\n  if (isTypedArray(val)) {\n    return dtype === 'string' ? [] : [val.length];\n  }\n  if (!Array.isArray(val)) {\n    return [];  // Scalar.\n  }\n  const shape: number[] = [];\n\n  while (Array.isArray(firstElem) ||\n         isTypedArray(firstElem) && dtype !== 'string') {\n    shape.push(firstElem.length);\n    firstElem = firstElem[0];\n  }\n  if (Array.isArray(val) &&\n      env().getBool('TENSORLIKE_CHECK_SHAPE_CONSISTENCY')) {\n    deepAssertShapeConsistency(val, shape, []);\n  }\n\n  return shape;\n}\n\nfunction deepAssertShapeConsistency(\n    val: TensorLike, shape: number[], indices: number[]) {\n  indices = indices || [];\n  if (!(Array.isArray(val)) && !isTypedArray(val)) {\n    assert(\n        shape.length === 0,\n        () => `Element arr[${indices.join('][')}] is a primitive, ` +\n            `but should be an array/TypedArray of ${shape[0]} elements`);\n    return;\n  }\n  assert(\n      shape.length > 0,\n      () => `Element arr[${indices.join('][')}] should be a primitive, ` +\n          `but is an array of ${val.length} elements`);\n  assert(\n      val.length === shape[0],\n      () => `Element arr[${indices.join('][')}] should have ${shape[0]} ` +\n          `elements, but has ${val.length} elements`);\n  const subShape = shape.slice(1);\n  for (let i = 0; i < val.length; ++i) {\n    deepAssertShapeConsistency(val[i], subShape, indices.concat(i));\n  }\n}\n\nfunction assertDtype(\n    expectedDtype: DataType|'numeric'|'string_or_numeric',\n    actualDType: DataType, argName: string, functionName: string) {\n  if (expectedDtype === 'string_or_numeric') {\n    return;\n  }\n  if (expectedDtype == null) {\n    throw new Error(`Expected dtype cannot be null.`);\n  }\n  if (expectedDtype !== 'numeric' && expectedDtype !== actualDType ||\n      expectedDtype === 'numeric' && actualDType === 'string') {\n    throw new Error(\n        `Argument '${argName}' passed to '${functionName}' must ` +\n        `be ${expectedDtype} tensor, but got ${actualDType} tensor`);\n  }\n}\n\nexport function convertToTensor<T extends Tensor>(\n    x: T|TensorLike, argName: string, functionName: string,\n    parseAsDtype: DataType|'numeric'|'string_or_numeric' = 'numeric'): T {\n  if (x instanceof Tensor) {\n    assertDtype(parseAsDtype, x.dtype, argName, functionName);\n    return x;\n  }\n  let inferredDtype = inferDtype(x);\n  // If the user expects a bool/int/float, use that info to update the\n  // inferredDtype when it is not a string.\n  if (inferredDtype !== 'string' &&\n      ['bool', 'int32', 'float32'].indexOf(parseAsDtype) >= 0) {\n    inferredDtype = parseAsDtype as DataType;\n  }\n  assertDtype(parseAsDtype, inferredDtype, argName, functionName);\n\n  if ((x == null) ||\n      (!isTypedArray(x) && !Array.isArray(x) && typeof x !== 'number' &&\n       typeof x !== 'boolean' && typeof x !== 'string')) {\n    const type = x == null ? 'null' : (x as {}).constructor.name;\n    throw new Error(\n        `Argument '${argName}' passed to '${functionName}' must be a ` +\n        `Tensor or TensorLike, but got '${type}'`);\n  }\n  const inferredShape = inferShape(x, inferredDtype);\n  if (!isTypedArray(x) && !Array.isArray(x)) {\n    x = [x] as number[];\n  }\n  const skipTypedArray = true;\n  const values = inferredDtype !== 'string' ?\n      toTypedArray(x, inferredDtype as DataType) :\n      flatten(x as string[], [], skipTypedArray) as string[];\n  return ENGINE.makeTensor(values, inferredShape, inferredDtype) as T;\n}\n\nexport function convertToTensorArray<T extends Tensor>(\n    arg: Array<T|TensorLike>, argName: string, functionName: string,\n    parseAsDtype: DataType|'numeric'|'string_or_numeric' = 'numeric'): T[] {\n  if (!Array.isArray(arg)) {\n    throw new Error(\n        `Argument ${argName} passed to ${functionName} must be a ` +\n        '`Tensor[]` or `TensorLike[]`');\n  }\n  const tensors = arg as T[];\n  return tensors.map(\n      (t, i) =>\n          convertToTensor(t, `${argName}[${i}]`, functionName, parseAsDtype));\n}\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {ENGINE} from '../engine';\nimport {isPromise} from '../util';\n\nexport const OP_SCOPE_SUFFIX = '__op';\n\n/**\n * Used for wrapping functions that perform math operations on\n * Tensors. The function will be wrapped in a named scope that cleans all\n * memory usage after the function is done.\n */\nexport function op<T extends Function>(f: {[name: string]: T}): T {\n  const keys = Object.keys(f);\n  if (keys.length !== 1) {\n    throw new Error(\n        `Please provide an object with a single key ` +\n        `(operation name) mapping to a function. Got an object with ` +\n        `${keys.length} keys.`);\n  }\n\n  let opName = keys[0];\n  const fn = f[opName];\n\n  // Strip the underscore from the end of the function name.\n  if (opName.endsWith('_')) {\n    opName = opName.substring(0, opName.length - 1);\n  }\n\n  // add an __op suffix to distinguish ops from kernels in tf.profile\n  opName = opName + OP_SCOPE_SUFFIX;\n\n  // tslint:disable-next-line:no-any\n  const f2 = (...args: any[]) => {\n    ENGINE.startScope(opName);\n    try {\n      const result = fn(...args);\n      if (isPromise(result)) {\n        console.error('Cannot return a Promise inside of tidy.');\n      }\n      ENGINE.endScope(result);\n      return result;\n    } catch (ex) {\n      ENGINE.endScope(null);\n      throw ex;\n    }\n  };\n  Object.defineProperty(f2, 'name', {value: opName, configurable: true});\n\n  // tslint:disable-next-line:no-any\n  return f2 as any as T;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {ENGINE} from '../engine';\nimport {Complex, ComplexInputs} from '../kernel_names';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\nimport * as util from '../util';\n\nimport {op} from './operation';\n\n/**\n * Converts two real numbers to a complex number.\n *\n * Given a tensor `real` representing the real part of a complex number, and a\n * tensor `imag` representing the imaginary part of a complex number, this\n * operation returns complex numbers elementwise of the form [r0, i0, r1, i1],\n * where r represents the real part and i represents the imag part.\n *\n * The input tensors real and imag must have the same shape.\n *\n * ```js\n * const real = tf.tensor1d([2.25, 3.25]);\n * const imag = tf.tensor1d([4.75, 5.75]);\n * const complex = tf.complex(real, imag);\n *\n * complex.print();\n * ```\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nfunction complex_<T extends Tensor>(real: T|TensorLike, imag: T|TensorLike): T {\n  const $real = convertToTensor(real, 'real', 'complex');\n  const $imag = convertToTensor(imag, 'imag', 'complex');\n  util.assertShapesMatch(\n      $real.shape, $imag.shape,\n      `real and imag shapes, ${$real.shape} and ${$imag.shape}, ` +\n          `must match in call to tf.complex().`);\n\n  const inputs: ComplexInputs = {real: $real, imag: $imag};\n  return ENGINE.runKernel(Complex, inputs as {} as NamedTensorMap);\n}\n\nexport const complex = op({complex_});\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {Tensor} from '../tensor';\nimport {TensorLike, TypedArray} from '../types';\nimport {DataType} from '../types';\nimport {assert, assertNonNegativeIntegerDimensions, flatten, inferDtype, isTypedArray, sizeFromShape, toTypedArray} from '../util';\n\n/** This is shared code across all tensor creation methods. */\nexport function makeTensor(\n    values: TensorLike, shape: number[], inferredShape: number[],\n    dtype?: DataType): Tensor {\n  if (dtype == null) {\n    dtype = inferDtype(values);\n  }\n  if (dtype === 'complex64') {\n    throw new Error(\n        `Cannot construct a complex64 tensor directly. ` +\n        `Please use tf.complex(real, imag).`);\n  }\n  if (!isTypedArray(values) && !Array.isArray(values) &&\n      typeof values !== 'number' && typeof values !== 'boolean' &&\n      typeof values !== 'string') {\n    throw new Error(\n        'values passed to tensor(values) must be a number/boolean/string or ' +\n        'an array of numbers/booleans/strings, or a TypedArray');\n  }\n  if (shape != null) {\n    assertNonNegativeIntegerDimensions(shape);\n\n    const providedSize = sizeFromShape(shape);\n    const inferredSize = sizeFromShape(inferredShape);\n    assert(\n        providedSize === inferredSize,\n        () =>\n            `Based on the provided shape, [${shape}], the tensor should have ` +\n            `${providedSize} values but has ${inferredSize}`);\n\n    for (let i = 0; i < inferredShape.length; ++i) {\n      const inferred = inferredShape[i];\n      const flatDimsDontMatch = i === inferredShape.length - 1 ?\n          inferred !== sizeFromShape(shape.slice(i)) :\n          true;\n      assert(\n          inferredShape[i] === shape[i] || !flatDimsDontMatch,\n          () => `Error creating a new Tensor. Inferred shape ` +\n              `(${inferredShape}) does not match the provided ` +\n              `shape (${shape}). `);\n    }\n  }\n\n  if (!isTypedArray(values) && !Array.isArray(values)) {\n    values = [values] as number[];\n  }\n\n  shape = shape || inferredShape;\n  values = dtype !== 'string' ?\n      toTypedArray(values, dtype) :\n      flatten(values as string[], [], true) as string[];\n  return ENGINE.makeTensor(values as TypedArray, shape, dtype);\n}\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor} from '../tensor';\nimport {inferShape} from '../tensor_util_env';\nimport {TensorLike} from '../types';\nimport {DataType, Rank, ShapeMap} from '../types';\n\nimport {makeTensor} from './tensor_ops_util';\n\n/**\n * Creates a `tf.Tensor` with the provided values, shape and dtype.\n *\n * ```js\n * // Pass an array of values to create a vector.\n * tf.tensor([1, 2, 3, 4]).print();\n * ```\n *\n * ```js\n * // Pass a nested array of values to make a matrix or a higher\n * // dimensional tensor.\n * tf.tensor([[1, 2], [3, 4]]).print();\n * ```\n *\n * ```js\n * // Pass a flat array and specify a shape yourself.\n * tf.tensor([1, 2, 3, 4], [2, 2]).print();\n * ```\n *\n * @param values The values of the tensor. Can be nested array of numbers,\n *     or a flat array, or a `TypedArray`. If the values are strings,\n *     they will be encoded as utf-8 and kept as `Uint8Array[]`.\n * @param shape The shape of the tensor. Optional. If not provided,\n *   it is inferred from `values`.\n * @param dtype The data type.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nexport function tensor<R extends Rank>(\n    values: TensorLike, shape?: ShapeMap[R], dtype?: DataType): Tensor<R> {\n  const inferredShape = inferShape(values, dtype);\n  return makeTensor(values, shape, inferredShape, dtype) as Tensor<R>;\n}\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n/* Type definitions for exporting and importing of models. */\n\n/**\n * A map from Tensor dtype to number of bytes per element of the Tensor.\n */\nexport const DTYPE_VALUE_SIZE_MAP: {[dtype: string]: number} = {\n  'float32': 4,\n  'float16': 2,\n  'int32': 4,\n  'uint16': 2,\n  'uint8': 1,\n  'bool': 1,\n  'complex64': 8\n};\n\n/**\n * A weight manifest.\n *\n * The weight manifest consists of an ordered list of weight-manifest groups.\n * Each weight-manifest group (\"group\" for short hereafter) consists of a\n * number of weight values stored in a number of paths.\n * See the documentation of `WeightManifestGroupConfig` below for more details.\n */\nexport declare type WeightsManifestConfig = WeightsManifestGroupConfig[];\n\n/**\n * A weight-manifest group.\n *\n * Consists of an ordered list of weight values encoded in binary format,\n * stored in an ordered list of paths.\n */\nexport declare interface WeightsManifestGroupConfig {\n  /**\n   * An ordered list of paths.\n   *\n   * Paths are intentionally abstract in order to be general. For example, they\n   * can be relative URL paths or relative paths on the file system.\n   */\n  paths: string[];\n\n  /**\n   * Specifications of the weights stored in the paths.\n   */\n  weights: WeightsManifestEntry[];\n}\n\n/**\n * Group to which the weight belongs.\n *\n * - 'optimizer': Weight from a stateful optimizer.\n */\nexport type WeightGroup = 'model'|'optimizer';\n\n/**\n * An entry in the weight manifest.\n *\n * The entry contains specification of a weight.\n */\nexport declare interface WeightsManifestEntry {\n  /**\n   * Name of the weight, e.g., 'Dense_1/bias'\n   */\n  name: string;\n\n  /**\n   * Shape of the weight.\n   */\n  shape: number[];\n\n  /**\n   * Data type of the weight.\n   */\n  dtype: 'float32'|'int32'|'bool'|'string'|'complex64';\n\n  /**\n   * Type of the weight.\n   *\n   * Optional.\n   *\n   * The value 'optimizer' indicates the weight belongs to an optimizer\n   * (i.e., used only during model training and not during inference).\n   */\n  group?: WeightGroup;\n\n  /**\n   * Information for dequantization of the weight.\n   */\n  quantization?: {\n    scale?: number,  // The scaling constant to multiply by.\n    min?: number,    // The (possibly nudged) minimum weight to add.\n       dtype: 'uint16'|'uint8'|'float16'  // The dtype of the quantized weights.\n  };\n}\n\n/**\n * Options for saving a model.\n * @innamespace io\n */\nexport interface SaveConfig {\n  /**\n   * Whether to save only the trainable weights of the model, ignoring the\n   * non-trainable ones.\n   */\n  trainableOnly?: boolean;\n\n  /**\n   * Whether the optimizer will be saved (if exists).\n   *\n   * Default: `false`.\n   */\n  includeOptimizer?: boolean;\n}\n\n/**\n * Result of a saving operation.\n */\nexport interface SaveResult {\n  /**\n   * Information about the model artifacts saved.\n   */\n  modelArtifactsInfo: ModelArtifactsInfo;\n\n  /**\n   * HTTP responses from the server that handled the model-saving request (if\n   * any). This is applicable only to server-based saving routes.\n   */\n  responses?: Response[];\n\n  /**\n   * Error messages and related data (if any).\n   */\n  errors?: Array<{}|string>;\n}\n\nexport declare interface ModelArtifactsInfo {\n  /**\n   * Timestamp for when the model is saved.\n   */\n  dateSaved: Date;\n\n  /**\n   * TODO (cais,yassogba) consider removing GraphDef as GraphDefs now\n   * come in a JSON format and none of our IOHandlers support a non json\n   * format. We could conder replacing this with 'Binary' if we want to\n   * allow future handlers to save to non json formats (though they will\n   * probably want more information than 'Binary').\n   * Type of the model topology\n   *\n   * Type of the model topology\n   *\n   * Possible values:\n   *   - JSON: JSON config (human-readable, e.g., Keras JSON).\n   *   - GraphDef: TensorFlow\n   *     [GraphDef](https://www.tensorflow.org/extend/tool_developers/#graphdef)\n   *     protocol buffer (binary).\n   */\n  modelTopologyType: 'JSON'|'GraphDef';\n\n  /**\n   * Size of model topology (Keras JSON or GraphDef), in bytes.\n   */\n  modelTopologyBytes?: number;\n\n  /**\n   * Size of weight specification or manifest, in bytes.\n   */\n  weightSpecsBytes?: number;\n\n  /**\n   * Size of weight value data, in bytes.\n   */\n  weightDataBytes?: number;\n}\n\n/** Model training configuration. */\nexport declare interface TrainingConfig {\n  // TODO(cais): Tighten the typing once keras spec is available to tfjs-core.\n  // See\n  // tslint:disable-next-line:max-line-length\n  // https://github.com/tensorflow/tfjs-layers/blob/master/src/keras_format/training_config.ts\n  /** Optimizer used for the model training. */\n  optimizer_config: {};\n\n  // TODO(cais): Tighten the typing once keras spec is available to tfjs-core.\n  /** Loss function(s) for the model's output(s). */\n  loss: string|string[]|{[key: string]: string};\n\n  // TODO(cais): Tighten the typing once keras spec is available to tfjs-core.\n  /** Metric function(s) for the model's output(s). */\n  metrics?: string[]|{[key: string]: string};\n\n  // TODO(cais): Tighten the typing once keras spec is available to tfjs-core.\n  weighted_metrics?: string[];\n\n  // TODO(cais): Tighten the typing once keras spec is available to tfjs-core.\n  sample_weight_mode?: string;\n\n  loss_weights?: number[]|{[key: string]: number};\n}\n\n/**\n * The serialized artifacts of a model, including topology and weights.\n *\n * The `modelTopology`, `trainingConfig`, `weightSpecs` and `weightData` fields\n * of this interface are optional, in order to support topology- or weights-only\n * saving and loading.\n *\n * Note this interface is used internally in IOHandlers.  For the file format\n * written to disk as `model.json`, see `ModelJSON`.\n */\nexport declare interface ModelArtifacts {\n  /**\n   * Model topology.\n   *\n   * For Keras-style `tf.Model`s, this is a JSON object.\n   * For TensorFlow-style models (e.g., `SavedModel`), this is the JSON\n   * encoding of the `GraphDef` protocol buffer.\n   */\n  modelTopology?: {}|ArrayBuffer;\n\n  /**\n   * Serialized configuration for the model's training.\n   */\n  trainingConfig?: TrainingConfig;\n\n  /**\n   * Weight specifications.\n   *\n   * This corresponds to the weightsData below.\n   */\n  weightSpecs?: WeightsManifestEntry[];\n\n  /**\n   * Binary buffer for all weight values concatenated in the order specified\n   * by `weightSpecs`.\n   */\n  weightData?: ArrayBuffer;\n\n  /**\n   * Hard-coded format name for models saved from TensorFlow.js or converted\n   * by TensorFlow.js Converter.\n   */\n  format?: string;\n\n  /**\n   * What library is responsible for originally generating this artifact.\n   *\n   * Used for debugging purposes. E.g., 'TensorFlow.js v1.0.0'.\n   */\n  generatedBy?: string;\n\n  /**\n   * What library or tool is responsible for converting the original model\n   * to this format, applicable only if the model is output by a converter.\n   *\n   * Used for debugging purposes.  E.g., 'TensorFlow.js Converter v1.0.0'.\n   *\n   * A value of `null` means the model artifacts are generated without any\n   * conversion process (e.g., saved directly from a TensorFlow.js\n   * `tf.LayersModel` instance.)\n   */\n  convertedBy?: string|null;\n\n  /**\n   * Inputs and outputs signature for saved model.\n   */\n  signature?: {};\n\n  /**\n   * User-defined metadata about the model.\n   */\n  userDefinedMetadata?: {[key: string]: {}};\n\n  /**\n   * Initializer for the model.\n   */\n  modelInitializer?: {};\n}\n\n/**\n * The on-disk format of the `model.json` file.\n *\n * TF.js 1.0 always populates the optional fields when writing model.json.\n * Prior versions did not provide those fields.\n */\nexport declare interface ModelJSON {\n  /**\n   * Model topology.\n   *\n   * For Keras-style `tf.Model`s, this is a JSON object.\n   * For TensorFlow-style models (e.g., `SavedModel`), this is the JSON\n   * encoding of the `GraphDef` protocol buffer.\n   */\n  modelTopology: {};\n\n  /** Model training configuration. */\n  trainingConfig?: TrainingConfig;\n\n  /**\n   * Weights manifest.\n   *\n   * The weights manifest consists of an ordered list of weight-manifest\n   * groups. Each weight-manifest group consists of a number of weight values\n   * stored in a number of paths. See the documentation of\n   * `WeightsManifestConfig` for more details.\n   */\n  weightsManifest: WeightsManifestConfig;\n\n  /**\n   * Hard-coded format name for models saved from TensorFlow.js or converted\n   * by TensorFlow.js Converter.\n   */\n  format?: string;\n\n  /**\n   * What library is responsible for originally generating this artifact.\n   *\n   * Used for debugging purposes. E.g., 'TensorFlow.js v1.0.0'.\n   */\n  generatedBy?: string;\n\n  /**\n   * What library or tool is responsible for converting the original model\n   * to this format, applicable only if the model is output by a converter.\n   *\n   * Used for debugging purposes.  E.g., 'TensorFlow.js Converter v1.0.0'.\n   *\n   * A value of `null` means the model artifacts are generated without any\n   * conversion process (e.g., saved directly from a TensorFlow.js\n   * `tf.LayersModel` instance.)\n   */\n  convertedBy?: string|null;\n\n  /**\n   * Inputs and outputs signature for saved model.\n   */\n  signature?: {};\n\n  /**\n   * User-defined metadata about the model.\n   */\n  userDefinedMetadata?: {[key: string]: {}};\n\n  /**\n   * Initializer for the model.\n   */\n  modelInitializer?: {};\n}\n\n/**\n * Type definition for handlers of loading operations.\n */\nexport type LoadHandler = () => Promise<ModelArtifacts>;\n\n/**\n * Type definition for handlers of saving operations.\n */\nexport type SaveHandler = (modelArtifact: ModelArtifacts) =>\n    Promise<SaveResult>;\n\n/**\n * Interface for a model import/export handler.\n *\n * The `save` and `load` handlers are both optional, in order to allow handlers\n * that support only saving or loading.\n */\n// tslint:disable-next-line:interface-name\nexport interface IOHandler {\n  save?: SaveHandler;\n  load?: LoadHandler;\n}\n\n/**\n * Type definition for handlers of synchronous loading operations.\n */\nexport type LoadHandlerSync = () => ModelArtifacts;\n\n/**\n * Type definition for handlers of synchronous saving operations.\n */\nexport type SaveHandlerSync = (modelArtifact: ModelArtifacts) => SaveResult;\n\n/**\n * Interface for a synchronous model import/export handler.\n *\n * The `save` and `load` handlers are both optional, in order to allow handlers\n * that support only saving or loading.\n */\n// tslint:disable-next-line:interface-name\nexport type IOHandlerSync = {\n  save?: SaveHandlerSync;\n  load?: LoadHandlerSync;\n};\n\n/**\n * An interface for the manager of a model store.\n *\n * A model store is defined as a storage medium on which multiple models can\n * be stored. Each stored model has a unique `path` as its identifier.\n * A `ModelStoreManager` for the store allows actions including\n *\n * - Listing the models stored in the store.\n * - Deleting a model from the store.\n */\nexport interface ModelStoreManager {\n  /**\n   * List all models in the model store.\n   *\n   * @returns A dictionary mapping paths of existing models to their\n   *   model artifacts info. Model artifacts info include type of the model's\n   *   topology, byte sizes of the topology, weights, etc.\n   */\n  listModels(): Promise<{[path: string]: ModelArtifactsInfo}>;\n\n  /**\n   * Remove a model specified by `path`.\n   *\n   * @param path\n   * @returns ModelArtifactsInfo of the deleted model (if and only if deletion\n   *   is successful).\n   * @throws Error if deletion fails, e.g., if no model exists at `path`.\n   */\n  removeModel(path: string): Promise<ModelArtifactsInfo>;\n}\n\n/**\n * Callback for the progress of a long-running action such as an HTTP\n * request for a large binary object.\n *\n * `fraction` should be a number in the [0, 1] interval, indicating how\n * much of the action has completed.\n */\nexport type OnProgressCallback = (fraction: number) => void;\n\n/** @innamespace io */\nexport interface LoadOptions {\n  /**\n   * RequestInit (options) for HTTP requests.\n   *\n   * For detailed information on the supported fields, see\n   * [https://developer.mozilla.org/en-US/docs/Web/API/Request/Request](\n   *     https://developer.mozilla.org/en-US/docs/Web/API/Request/Request)\n   */\n  requestInit?: RequestInit;\n\n  /**\n   * Progress callback.\n   */\n  onProgress?: OnProgressCallback;\n\n  /**\n   * A function used to override the `window.fetch` function.\n   */\n  fetchFunc?: Function;\n\n  /**\n   * Strict loading model: whether extraneous weights or missing\n   * weights should trigger an `Error`.\n   *\n   * If `true`, require that the provided weights exactly match those\n   * required by the layers. `false` means that both extra weights\n   * and missing weights will be silently ignored.\n   *\n   * Default: `true`.\n   */\n  strict?: boolean;\n\n  /**\n   * Path prefix for weight files, by default this is calculated from the\n   * path of the model JSON file.\n   *\n   * For instance, if the path to the model JSON file is\n   * `http://localhost/foo/model.json`, then the default path prefix will be\n   * `http://localhost/foo/`. If a weight file has the path value\n   * `group1-shard1of2` in the weight manifest, then the weight file will be\n   * loaded from `http://localhost/foo/group1-shard1of2` by default. However,\n   * if you provide a `weightPathPrefix` value of\n   * `http://localhost/foo/alt-weights`, then the weight file will be loaded\n   * from the path `http://localhost/foo/alt-weights/group1-shard1of2` instead.\n   */\n  weightPathPrefix?: string;\n\n  /**\n   * Whether the module or model is to be loaded from TF Hub.\n   *\n   * Setting this to `true` allows passing a TF-Hub module URL, omitting the\n   * standard model file name and the query parameters.\n   *\n   * Default: `false`.\n   */\n  fromTFHub?: boolean;\n\n  /**\n   * An async function to convert weight file name to URL. The weight file\n   * names are stored in model.json's weightsManifest.paths field. By default we\n   * consider weight files are colocated with the model.json file. For example:\n   *     model.json URL: https://www.google.com/models/1/model.json\n   *     group1-shard1of1.bin url:\n   *        https://www.google.com/models/1/group1-shard1of1.bin\n   *\n   * With this func you can convert the weight file name to any URL.\n   */\n  weightUrlConverter?: (weightFileName: string) => Promise<string>;\n}\n\n/**\n * Additional options for Platform.fetch\n */\nexport interface RequestDetails {\n  /**\n   * Is this request for a binary file (as opposed to a json file)\n   */\n  isBinary?: boolean;\n}\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {complex} from '../ops/complex';\nimport {tensor} from '../ops/tensor';\nimport {NamedTensor, NamedTensorMap} from '../tensor_types';\nimport {TypedArray} from '../types';\nimport {sizeFromShape} from '../util';\n\nimport {DTYPE_VALUE_SIZE_MAP, ModelArtifacts, ModelArtifactsInfo, ModelJSON, WeightGroup, WeightsManifestConfig, WeightsManifestEntry} from './types';\n\n/** Number of bytes reserved for the length of the string. (32bit integer). */\nconst NUM_BYTES_STRING_LENGTH = 4;\n\n/**\n * Encode a map from names to weight values as an ArrayBuffer, along with an\n * `Array` of `WeightsManifestEntry` as specification of the encoded weights.\n *\n * This function does not perform sharding.\n *\n * This function is the reverse of `decodeWeights`.\n *\n * @param tensors A map (\"dict\") from names to tensors.\n * @param group Group to which the weights belong (optional).\n * @returns A `Promise` of\n *   - A flat `ArrayBuffer` with all the binary values of the `Tensor`s\n *     concatenated.\n *   - An `Array` of `WeightManifestEntry`s, carrying information including\n *     tensor names, `dtype`s and shapes.\n * @throws Error: on unsupported tensor `dtype`.\n */\nexport async function encodeWeights(\n    tensors: NamedTensorMap|NamedTensor[], group?: WeightGroup):\n    Promise<{data: ArrayBuffer, specs: WeightsManifestEntry[]}> {\n  // TODO(adarob, cais): Support quantization.\n  const specs: WeightsManifestEntry[] = [];\n  const dataPromises: Array<Promise<TypedArray>> = [];\n\n  const names: string[] = Array.isArray(tensors) ?\n      tensors.map(tensor => tensor.name) :\n      Object.keys(tensors);\n\n  for (let i = 0; i < names.length; ++i) {\n    const name = names[i];\n    const t = Array.isArray(tensors) ? tensors[i].tensor : tensors[name];\n    if (t.dtype !== 'float32' && t.dtype !== 'int32' && t.dtype !== 'bool' &&\n        t.dtype !== 'string' && t.dtype !== 'complex64') {\n      throw new Error(`Unsupported dtype in weight '${name}': ${t.dtype}`);\n    }\n    const spec: WeightsManifestEntry = {name, shape: t.shape, dtype: t.dtype};\n    if (t.dtype === 'string') {\n      const utf8bytes = new Promise<TypedArray>(async resolve => {\n        const vals = await t.bytes() as Uint8Array[];\n        const totalNumBytes = vals.reduce((p, c) => p + c.length, 0) +\n            NUM_BYTES_STRING_LENGTH * vals.length;\n        const bytes = new Uint8Array(totalNumBytes);\n        let offset = 0;\n        for (let i = 0; i < vals.length; i++) {\n          const val = vals[i];\n          const bytesOfLength =\n              new Uint8Array(new Uint32Array([val.length]).buffer);\n          bytes.set(bytesOfLength, offset);\n          offset += NUM_BYTES_STRING_LENGTH;\n          bytes.set(val, offset);\n          offset += val.length;\n        }\n        resolve(bytes);\n      });\n      dataPromises.push(utf8bytes);\n    } else {\n      dataPromises.push(t.data());\n    }\n    if (group != null) {\n      spec.group = group;\n    }\n    specs.push(spec);\n  }\n\n  const tensorValues = await Promise.all(dataPromises);\n  return {data: concatenateTypedArrays(tensorValues), specs};\n}\n\n/**\n * Decode flat ArrayBuffer as weights.\n *\n * This function does not handle sharding.\n *\n * This function is the reverse of `encodeWeights`.\n *\n * @param buffer A flat ArrayBuffer carrying the binary values of the tensors\n *   concatenated in the order specified in `specs`.\n * @param specs Specifications of the names, dtypes and shapes of the tensors\n *   whose value are encoded by `buffer`.\n * @return A map from tensor name to tensor value, with the names corresponding\n *   to names in `specs`.\n * @throws Error, if any of the tensors has unsupported dtype.\n */\nexport function decodeWeights(\n    buffer: ArrayBuffer, specs: WeightsManifestEntry[]): NamedTensorMap {\n  // TODO(adarob, cais): Support quantization.\n  const out: NamedTensorMap = {};\n  let float16Decode: (buffer: Uint16Array) => Float32Array | undefined;\n  let offset = 0;\n  for (const spec of specs) {\n    const name = spec.name;\n    const dtype = spec.dtype;\n    const shape = spec.shape;\n    const size = sizeFromShape(shape);\n    let values: TypedArray|string[]|Uint8Array[];\n\n    if ('quantization' in spec) {\n      const quantization = spec.quantization;\n      if (quantization.dtype === 'uint8' || quantization.dtype === 'uint16') {\n        if (!('min' in quantization && 'scale' in quantization)) {\n          throw new Error(\n              `Weight ${spec.name} with quantization ${quantization.dtype} ` +\n              `doesn't have corresponding metadata min and scale.`);\n        }\n      } else if (quantization.dtype === 'float16') {\n        if (dtype !== 'float32') {\n          throw new Error(\n              `Weight ${spec.name} is quantized with ${quantization.dtype} ` +\n              `which only supports weights of type float32 not ${dtype}.`);\n        }\n      } else {\n        throw new Error(\n            `Weight ${spec.name} has unknown ` +\n            `quantization dtype ${quantization.dtype}. ` +\n            `Supported quantization dtypes are: ` +\n            `'uint8', 'uint16', and 'float16'.`);\n      }\n      const quantizationSizeFactor = DTYPE_VALUE_SIZE_MAP[quantization.dtype];\n      const byteBuffer =\n          buffer.slice(offset, offset + size * quantizationSizeFactor);\n      const quantizedArray = (quantization.dtype === 'uint8') ?\n          new Uint8Array(byteBuffer) :\n          new Uint16Array(byteBuffer);\n      if (dtype === 'float32') {\n        if (quantization.dtype === 'uint8' || quantization.dtype === 'uint16') {\n          values = new Float32Array(quantizedArray.length);\n          for (let i = 0; i < quantizedArray.length; i++) {\n            const v = quantizedArray[i];\n            values[i] = v * quantization.scale + quantization.min;\n          }\n        } else if (quantization.dtype === 'float16') {\n          if (float16Decode === undefined) {\n            float16Decode = getFloat16Decoder();\n          }\n          values = float16Decode(quantizedArray as Uint16Array);\n        } else {\n          throw new Error(\n              `Unsupported quantization type ${quantization.dtype} ` +\n              `for weight type float32.`);\n        }\n      } else if (dtype === 'int32') {\n        if (quantization.dtype !== 'uint8' && quantization.dtype !== 'uint16') {\n          throw new Error(\n              `Unsupported quantization type ${quantization.dtype} ` +\n              `for weight type int32.`);\n        }\n        values = new Int32Array(quantizedArray.length);\n        for (let i = 0; i < quantizedArray.length; i++) {\n          const v = quantizedArray[i];\n          values[i] = Math.round(v * quantization.scale + quantization.min);\n        }\n      } else {\n        throw new Error(`Unsupported dtype in weight '${name}': ${dtype}`);\n      }\n      offset += size * quantizationSizeFactor;\n    } else if (dtype === 'string') {\n      const size = sizeFromShape(spec.shape);\n      values = [];\n      for (let i = 0; i < size; i++) {\n        const byteLength = new Uint32Array(\n            buffer.slice(offset, offset + NUM_BYTES_STRING_LENGTH))[0];\n        offset += NUM_BYTES_STRING_LENGTH;\n        const bytes = new Uint8Array(buffer.slice(offset, offset + byteLength));\n        (values as Uint8Array[]).push(bytes);\n        offset += byteLength;\n      }\n    } else {\n      const dtypeFactor = DTYPE_VALUE_SIZE_MAP[dtype];\n      const byteBuffer = buffer.slice(offset, offset + size * dtypeFactor);\n\n      if (dtype === 'float32') {\n        values = new Float32Array(byteBuffer);\n      } else if (dtype === 'int32') {\n        values = new Int32Array(byteBuffer);\n      } else if (dtype === 'bool') {\n        values = new Uint8Array(byteBuffer);\n      } else if (dtype === 'complex64') {\n        values = new Float32Array(byteBuffer);\n        const real = new Float32Array(values.length / 2);\n        const image = new Float32Array(values.length / 2);\n        for (let i = 0; i < real.length; i++) {\n          real[i] = values[i * 2];\n          image[i] = values[i * 2 + 1];\n        }\n        const realTensor = tensor(real, shape, 'float32');\n        const imageTensor = tensor(image, shape, 'float32');\n        out[name] = complex(realTensor, imageTensor);\n        realTensor.dispose();\n        imageTensor.dispose();\n      } else {\n        throw new Error(`Unsupported dtype in weight '${name}': ${dtype}`);\n      }\n      offset += size * dtypeFactor;\n    }\n    if (dtype !== 'complex64') {\n      out[name] = tensor(values, shape, dtype);\n    }\n  }\n  return out;\n}\n\n/**\n * Concatenate TypedArrays into an ArrayBuffer.\n */\nexport function concatenateTypedArrays(xs: TypedArray[]): ArrayBuffer {\n  // TODO(adarob, cais): Support quantization.\n  if (xs === null) {\n    throw new Error(`Invalid input value: ${JSON.stringify(xs)}`);\n  }\n\n  let totalByteLength = 0;\n\n  // `normalizedXs` is here for this reason: a `TypedArray`'s `buffer'\n  // can have a different byte length from that of the `TypedArray` itself,\n  // for example, when the `TypedArray` is created from an offset in an\n  // `ArrayBuffer`. `normliazedXs` holds `TypedArray`s whose `buffer`s match\n  // the `TypedArray` in byte length. If an element of `xs` does not show\n  // this property, a new `TypedArray` that satisfy this property will be\n  // constructed and pushed into `normalizedXs`.\n  const normalizedXs: TypedArray[] = [];\n  xs.forEach((x: TypedArray) => {\n    totalByteLength += x.byteLength;\n    // tslint:disable:no-any\n    normalizedXs.push(\n        x.byteLength === x.buffer.byteLength ? x :\n                                               new (x.constructor as any)(x));\n    if (!(x as any instanceof Float32Array || x as any instanceof Int32Array ||\n          x as any instanceof Uint8Array)) {\n      throw new Error(`Unsupported TypedArray subtype: ${x.constructor.name}`);\n    }\n    // tslint:enable:no-any\n  });\n\n  const y = new Uint8Array(totalByteLength);\n  let offset = 0;\n  normalizedXs.forEach((x: TypedArray) => {\n    y.set(new Uint8Array(x.buffer), offset);\n    offset += x.byteLength;\n  });\n\n  return y.buffer;\n}\n\n// Use Buffer on Node.js instead of Blob/atob/btoa\nconst useNodeBuffer = typeof Buffer !== 'undefined' &&\n    (typeof Blob === 'undefined' || typeof atob === 'undefined' ||\n     typeof btoa === 'undefined');\n\n/**\n * Calculate the byte length of a JavaScript string.\n *\n * Note that a JavaScript string can contain wide characters, therefore the\n * length of the string is not necessarily equal to the byte length.\n *\n * @param str Input string.\n * @returns Byte length.\n */\nexport function stringByteLength(str: string): number {\n  if (useNodeBuffer) {\n    return Buffer.byteLength(str);\n  }\n  return new Blob([str]).size;\n}\n\n/**\n * Encode an ArrayBuffer as a base64 encoded string.\n *\n * @param buffer `ArrayBuffer` to be converted.\n * @returns A string that base64-encodes `buffer`.\n */\nexport function arrayBufferToBase64String(buffer: ArrayBuffer): string {\n  if (useNodeBuffer) {\n    return Buffer.from(buffer).toString('base64');\n  }\n  const buf = new Uint8Array(buffer);\n  let s = '';\n  for (let i = 0, l = buf.length; i < l; i++) {\n    s += String.fromCharCode(buf[i]);\n  }\n  return btoa(s);\n}\n\n/**\n * Decode a base64 string as an ArrayBuffer.\n *\n * @param str Base64 string.\n * @returns Decoded `ArrayBuffer`.\n */\nexport function base64StringToArrayBuffer(str: string): ArrayBuffer {\n  if (useNodeBuffer) {\n    const buf = Buffer.from(str, 'base64');\n    return buf.buffer.slice(buf.byteOffset, buf.byteOffset + buf.byteLength);\n  }\n  const s = atob(str);\n  const buffer = new Uint8Array(s.length);\n  for (let i = 0; i < s.length; ++i) {\n    buffer.set([s.charCodeAt(i)], i);\n  }\n  return buffer.buffer;\n}\n\n/**\n * Concatenate a number of ArrayBuffers into one.\n *\n * @param buffers A number of array buffers to concatenate.\n * @returns Result of concatenating `buffers` in order.\n */\nexport function concatenateArrayBuffers(buffers: ArrayBuffer[]): ArrayBuffer {\n  if (buffers.length === 1) {\n    return buffers[0];\n  }\n\n  let totalByteLength = 0;\n  buffers.forEach((buffer: ArrayBuffer) => {\n    totalByteLength += buffer.byteLength;\n  });\n\n  const temp = new Uint8Array(totalByteLength);\n  let offset = 0;\n  buffers.forEach((buffer: ArrayBuffer) => {\n    temp.set(new Uint8Array(buffer), offset);\n    offset += buffer.byteLength;\n  });\n  return temp.buffer;\n}\n\n/**\n * Get the basename of a path.\n *\n * Behaves in a way analogous to Linux's basename command.\n *\n * @param path\n */\nexport function basename(path: string): string {\n  const SEPARATOR = '/';\n  path = path.trim();\n  while (path.endsWith(SEPARATOR)) {\n    path = path.slice(0, path.length - 1);\n  }\n  const items = path.split(SEPARATOR);\n  return items[items.length - 1];\n}\n\n/**\n * Create `ModelJSON` from `ModelArtifacts`.\n *\n * @param artifacts Model artifacts, describing the model and its weights.\n * @param manifest Weight manifest, describing where the weights of the\n *     `ModelArtifacts` are stored, and some metadata about them.\n * @returns Object representing the `model.json` file describing the model\n *     artifacts and weights\n */\nexport function getModelJSONForModelArtifacts(\n    artifacts: ModelArtifacts, manifest: WeightsManifestConfig): ModelJSON {\n  const result: ModelJSON = {\n    modelTopology: artifacts.modelTopology,\n    format: artifacts.format,\n    generatedBy: artifacts.generatedBy,\n    convertedBy: artifacts.convertedBy,\n    weightsManifest: manifest\n  };\n  if (artifacts.signature != null) {\n    result.signature = artifacts.signature;\n  }\n  if (artifacts.userDefinedMetadata != null) {\n    result.userDefinedMetadata = artifacts.userDefinedMetadata;\n  }\n  if (artifacts.modelInitializer != null) {\n    result.modelInitializer = artifacts.modelInitializer;\n  }\n  if (artifacts.trainingConfig != null) {\n    result.trainingConfig = artifacts.trainingConfig;\n  }\n  return result;\n}\n\n/**\n * Create `ModelArtifacts` from a JSON file and weights.\n *\n * @param modelJSON Object containing the parsed JSON of `model.json`\n * @param weightSpecs The list of WeightsManifestEntry for the model. Must be\n *     passed if the modelJSON has a weightsManifest.\n * @param weightData An ArrayBuffer of weight data for the model corresponding\n *     to the weights in weightSpecs. Must be passed if the modelJSON has a\n *     weightsManifest.\n * @returns A Promise of the `ModelArtifacts`, as described by the JSON file.\n */\nexport function getModelArtifactsForJSONSync(\n    modelJSON: ModelJSON, weightSpecs?: WeightsManifestEntry[],\n    weightData?: ArrayBuffer): ModelArtifacts {\n\n  const modelArtifacts: ModelArtifacts = {\n    modelTopology: modelJSON.modelTopology,\n    format: modelJSON.format,\n    generatedBy: modelJSON.generatedBy,\n    convertedBy: modelJSON.convertedBy\n  };\n\n  if (modelJSON.trainingConfig != null) {\n    modelArtifacts.trainingConfig = modelJSON.trainingConfig;\n  }\n  if (modelJSON.weightsManifest != null) {\n    if (!weightSpecs) {\n      throw new Error('modelJSON has weightsManifest but weightSpecs is null');\n    }\n    if (!weightData) {\n      throw new Error('modelJSON has weightsManifest but weightData is null');\n    }\n    modelArtifacts.weightSpecs = weightSpecs;\n    modelArtifacts.weightData = weightData;\n  }\n  if (modelJSON.signature != null) {\n    modelArtifacts.signature = modelJSON.signature;\n  }\n  if (modelJSON.userDefinedMetadata != null) {\n    modelArtifacts.userDefinedMetadata = modelJSON.userDefinedMetadata;\n  }\n  if (modelJSON.modelInitializer != null) {\n    modelArtifacts.modelInitializer = modelJSON.modelInitializer;\n  }\n\n  return modelArtifacts;\n}\n\n/**\n * Create `ModelArtifacts` from a JSON file.\n *\n * @param modelJSON Object containing the parsed JSON of `model.json`\n * @param loadWeights Function that takes the JSON file's weights manifest,\n *     reads weights from the listed path(s), and returns a Promise of the\n *     weight manifest entries along with the weights data.\n * @returns A Promise of the `ModelArtifacts`, as described by the JSON file.\n */\nexport async function getModelArtifactsForJSON(\n    modelJSON: ModelJSON,\n    loadWeights: (weightsManifest: WeightsManifestConfig) => Promise<[\n      /* weightSpecs */ WeightsManifestEntry[], /* weightData */ ArrayBuffer\n    ]>): Promise<ModelArtifacts> {\n  let weightSpecs: WeightsManifestEntry[] | undefined;\n  let weightData: ArrayBuffer | undefined;\n\n  if (modelJSON.weightsManifest != null) {\n    [weightSpecs, weightData] = await loadWeights(modelJSON.weightsManifest);\n  }\n\n  return getModelArtifactsForJSONSync(modelJSON, weightSpecs, weightData);\n}\n\n/**\n * Populate ModelArtifactsInfo fields for a model with JSON topology.\n * @param modelArtifacts\n * @returns A ModelArtifactsInfo object.\n */\nexport function getModelArtifactsInfoForJSON(modelArtifacts: ModelArtifacts):\n    ModelArtifactsInfo {\n  if (modelArtifacts.modelTopology instanceof ArrayBuffer) {\n    throw new Error('Expected JSON model topology, received ArrayBuffer.');\n  }\n\n  return {\n    dateSaved: new Date(),\n    modelTopologyType: 'JSON',\n    modelTopologyBytes: modelArtifacts.modelTopology == null ?\n        0 :\n        stringByteLength(JSON.stringify(modelArtifacts.modelTopology)),\n    weightSpecsBytes: modelArtifacts.weightSpecs == null ?\n        0 :\n        stringByteLength(JSON.stringify(modelArtifacts.weightSpecs)),\n    weightDataBytes: modelArtifacts.weightData == null ?\n        0 :\n        modelArtifacts.weightData.byteLength,\n  };\n}\n\n/**\n * Concatenate the weights stored in a WeightsManifestConfig into a list of\n * WeightsManifestEntry\n *\n * @param weightsManifest The WeightsManifestConfig to extract weights from.\n * @returns A list of WeightsManifestEntry of the weights in the weightsManifest\n */\nexport function getWeightSpecs(weightsManifest: WeightsManifestConfig):\n    WeightsManifestEntry[] {\n  const weightSpecs: WeightsManifestEntry[] = [];\n  for (const entry of weightsManifest) {\n    weightSpecs.push(...entry.weights);\n  }\n  return weightSpecs;\n}\n\n/**\n * Computes mantisa table for casting Float16 to Float32\n * See http://www.fox-toolkit.org/ftp/fasthalffloatconversion.pdf\n *\n * @returns Uint32Array, 2048 mantissa lookup values.\n */\nfunction computeFloat16MantisaTable(): Uint32Array {\n  const convertMantissa = (i: number): number => {\n    let m = i << 13;\n    let e = 0;\n\n    while ((m & 0x00800000) === 0) {\n      e -= 0x00800000;\n      m <<= 1;\n    }\n    m &= ~0x00800000;\n    e += 0x38800000;\n\n    return m | e;\n  };\n\n  const mantisaTable = new Uint32Array(2048);\n\n  mantisaTable[0] = 0;\n  for (let i = 1; i < 1024; i++) {\n    mantisaTable[i] = convertMantissa(i);\n  }\n  for (let i = 1024; i < 2048; i++) {\n    mantisaTable[i] = 0x38000000 + ((i - 1024) << 13);\n  }\n\n  return mantisaTable;\n}\n\n/**\n * Computes exponent table for casting Float16 to Float32\n * See http://www.fox-toolkit.org/ftp/fasthalffloatconversion.pdf\n *\n * @returns Uint32Array, 64 exponent lookup values.\n */\nfunction computeFloat16ExponentTable(): Uint32Array {\n  const exponentTable = new Uint32Array(64);\n\n  exponentTable[0] = 0;\n  exponentTable[31] = 0x47800000;\n  exponentTable[32] = 0x80000000;\n  exponentTable[63] = 0xc7800000;\n  for (let i = 1; i < 31; i++) {\n    exponentTable[i] = i << 23;\n  }\n  for (let i = 33; i < 63; i++) {\n    exponentTable[i] = 0x80000000 + ((i - 32) << 23);\n  }\n\n  return exponentTable;\n}\n\n/**\n * Computes offset table for casting Float16 to Float32\n * See http://www.fox-toolkit.org/ftp/fasthalffloatconversion.pdf\n *\n * @returns Uint32Array, 6d offset values.\n */\nfunction computeFloat16OffsetTable(): Uint32Array {\n  const offsetTable = new Uint32Array(64);\n\n  for (let i = 0; i < 64; i++) {\n    offsetTable[i] = 1024;\n  }\n  offsetTable[0] = offsetTable[32] = 0;\n\n  return offsetTable;\n}\n\n/**\n * Retrieve a Float16 decoder which will decode a ByteArray of Float16 values\n * to a Float32Array.\n *\n * @returns Function (buffer: Uint16Array) => Float32Array which decodes\n *          the Uint16Array of Float16 bytes to a Float32Array.\n */\nexport function getFloat16Decoder(): (buffer: Uint16Array) => Float32Array {\n  // Algorithm is based off of\n  // http://www.fox-toolkit.org/ftp/fasthalffloatconversion.pdf\n\n  // Cache lookup tables\n  const mantisaTable = computeFloat16MantisaTable();\n  const exponentTable = computeFloat16ExponentTable();\n  const offsetTable = computeFloat16OffsetTable();\n\n  return (quantizedArray: Uint16Array) => {\n    const buffer = new ArrayBuffer(4 * quantizedArray.length);\n    const bufferUint32View = new Uint32Array(buffer);\n    for (let index = 0; index < quantizedArray.length; index++) {\n      const float16Bits = quantizedArray[index];\n      const float32Bits =\n          mantisaTable[offsetTable[float16Bits >> 10] + (float16Bits & 0x3ff)] +\n          exponentTable[float16Bits >> 10];\n      bufferUint32View[index] = float32Bits;\n    }\n    return new Float32Array(buffer);\n  };\n}\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {IOHandler, LoadOptions} from './types';\n\nexport type IORouter = (url: string|string[], loadOptions?: LoadOptions) =>\n    IOHandler;\n\nexport class IORouterRegistry {\n  // Singleton instance.\n  private static instance: IORouterRegistry;\n\n  private saveRouters: IORouter[];\n  private loadRouters: IORouter[];\n\n  private constructor() {\n    this.saveRouters = [];\n    this.loadRouters = [];\n  }\n\n  private static getInstance(): IORouterRegistry {\n    if (IORouterRegistry.instance == null) {\n      IORouterRegistry.instance = new IORouterRegistry();\n    }\n    return IORouterRegistry.instance;\n  }\n\n  /**\n   * Register a save-handler router.\n   *\n   * @param saveRouter A function that maps a URL-like string onto an instance\n   * of `IOHandler` with the `save` method defined or `null`.\n   */\n  static registerSaveRouter(saveRouter: IORouter) {\n    IORouterRegistry.getInstance().saveRouters.push(saveRouter);\n  }\n\n  /**\n   * Register a load-handler router.\n   *\n   * @param loadRouter A function that maps a URL-like string onto an instance\n   * of `IOHandler` with the `load` method defined or `null`.\n   */\n  static registerLoadRouter(loadRouter: IORouter) {\n    IORouterRegistry.getInstance().loadRouters.push(loadRouter);\n  }\n\n  /**\n   * Look up IOHandler for saving, given a URL-like string.\n   *\n   * @param url\n   * @returns If only one match is found, an instance of IOHandler with the\n   * `save` method defined. If no match is found, `null`.\n   * @throws Error, if more than one match is found.\n   */\n  static getSaveHandlers(url: string|string[]): IOHandler[] {\n    return IORouterRegistry.getHandlers(url, 'save');\n  }\n\n  /**\n   * Look up IOHandler for loading, given a URL-like string.\n   *\n   * @param url\n   * @param loadOptions Optional, custom load options.\n   * @returns All valid handlers for `url`, given the currently registered\n   *   handler routers.\n   */\n  static getLoadHandlers(url: string|string[], loadOptions?: LoadOptions):\n      IOHandler[] {\n    return IORouterRegistry.getHandlers(url, 'load', loadOptions);\n  }\n\n  private static getHandlers(\n      url: string|string[], handlerType: 'save'|'load',\n      loadOptions?: LoadOptions): IOHandler[] {\n    const validHandlers: IOHandler[] = [];\n    const routers = handlerType === 'load' ?\n        IORouterRegistry.getInstance().loadRouters :\n        IORouterRegistry.getInstance().saveRouters;\n    routers.forEach(router => {\n      const handler = router(url, loadOptions);\n      if (handler !== null) {\n        validHandlers.push(handler);\n      }\n    });\n    return validHandlers;\n  }\n}\n\nexport const registerSaveRouter = (loudRouter: IORouter) =>\n    IORouterRegistry.registerSaveRouter(loudRouter);\nexport const registerLoadRouter = (loudRouter: IORouter) =>\n    IORouterRegistry.registerLoadRouter(loudRouter);\nexport const getSaveHandlers = (url: string|string[]) =>\n    IORouterRegistry.getSaveHandlers(url);\nexport const getLoadHandlers =\n    (url: string|string[], loadOptions?: LoadOptions) =>\n        IORouterRegistry.getLoadHandlers(url, loadOptions);\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport '../flags';\n\nimport {env} from '../environment';\n\nimport {getModelArtifactsInfoForJSON} from './io_utils';\nimport {IORouter, IORouterRegistry} from './router_registry';\nimport {IOHandler, ModelArtifacts, ModelArtifactsInfo, ModelStoreManager, SaveResult} from './types';\n\nconst DATABASE_NAME = 'tensorflowjs';\nconst DATABASE_VERSION = 1;\n\n// Model data and ModelArtifactsInfo (metadata) are stored in two separate\n// stores for efficient access of the list of stored models and their metadata.\n// 1. The object store for model data: topology, weights and weight manifests.\nconst MODEL_STORE_NAME = 'models_store';\n// 2. The object store for ModelArtifactsInfo, including meta-information such\n//    as the type of topology (JSON vs binary), byte size of the topology, byte\n//    size of the weights, etc.\nconst INFO_STORE_NAME = 'model_info_store';\n\n/**\n * Delete the entire database for tensorflow.js, including the models store.\n */\nexport async function deleteDatabase(): Promise<void> {\n  const idbFactory = getIndexedDBFactory();\n\n  return new Promise<void>((resolve, reject) => {\n    const deleteRequest = idbFactory.deleteDatabase(DATABASE_NAME);\n    deleteRequest.onsuccess = () => resolve();\n    deleteRequest.onerror = error => reject(error);\n  });\n}\n\nfunction getIndexedDBFactory(): IDBFactory {\n  if (!env().getBool('IS_BROWSER')) {\n    // TODO(cais): Add more info about what IOHandler subtypes are available.\n    //   Maybe point to a doc page on the web and/or automatically determine\n    //   the available IOHandlers and print them in the error message.\n    throw new Error(\n        'Failed to obtain IndexedDB factory because the current environment' +\n        'is not a web browser.');\n  }\n  // tslint:disable-next-line:no-any\n  const theWindow: any = typeof window === 'undefined' ? self : window;\n  const factory = theWindow.indexedDB || theWindow.mozIndexedDB ||\n      theWindow.webkitIndexedDB || theWindow.msIndexedDB ||\n      theWindow.shimIndexedDB;\n  if (factory == null) {\n    throw new Error(\n        'The current browser does not appear to support IndexedDB.');\n  }\n  return factory;\n}\n\nfunction setUpDatabase(openRequest: IDBRequest) {\n  const db = openRequest.result as IDBDatabase;\n  db.createObjectStore(MODEL_STORE_NAME, {keyPath: 'modelPath'});\n  db.createObjectStore(INFO_STORE_NAME, {keyPath: 'modelPath'});\n}\n\n/**\n * IOHandler subclass: Browser IndexedDB.\n *\n * See the doc string of `browserIndexedDB` for more details.\n */\nexport class BrowserIndexedDB implements IOHandler {\n  protected readonly indexedDB: IDBFactory;\n  protected readonly modelPath: string;\n\n  static readonly URL_SCHEME = 'indexeddb://';\n\n  constructor(modelPath: string) {\n    this.indexedDB = getIndexedDBFactory();\n\n    if (modelPath == null || !modelPath) {\n      throw new Error(\n          'For IndexedDB, modelPath must not be null, undefined or empty.');\n    }\n    this.modelPath = modelPath;\n  }\n\n  async save(modelArtifacts: ModelArtifacts): Promise<SaveResult> {\n    // TODO(cais): Support saving GraphDef models.\n    if (modelArtifacts.modelTopology instanceof ArrayBuffer) {\n      throw new Error(\n          'BrowserLocalStorage.save() does not support saving model topology ' +\n          'in binary formats yet.');\n    }\n\n    return this.databaseAction(this.modelPath, modelArtifacts) as\n        Promise<SaveResult>;\n  }\n\n  async load(): Promise<ModelArtifacts> {\n    return this.databaseAction(this.modelPath) as Promise<ModelArtifacts>;\n  }\n\n  /**\n   * Perform database action to put model artifacts into or read model artifacts\n   * from IndexedDB object store.\n   *\n   * Whether the action is put or get depends on whether `modelArtifacts` is\n   * specified. If it is specified, the action will be put; otherwise the action\n   * will be get.\n   *\n   * @param modelPath A unique string path for the model.\n   * @param modelArtifacts If specified, it will be the model artifacts to be\n   *   stored in IndexedDB.\n   * @returns A `Promise` of `SaveResult`, if the action is put, or a `Promise`\n   *   of `ModelArtifacts`, if the action is get.\n   */\n  private databaseAction(modelPath: string, modelArtifacts?: ModelArtifacts):\n      Promise<ModelArtifacts|SaveResult> {\n    return new Promise<ModelArtifacts|SaveResult>((resolve, reject) => {\n      const openRequest = this.indexedDB.open(DATABASE_NAME, DATABASE_VERSION);\n      openRequest.onupgradeneeded = () => setUpDatabase(openRequest);\n\n      openRequest.onsuccess = () => {\n        const db = openRequest.result;\n\n        if (modelArtifacts == null) {\n          // Read model out from object store.\n          const modelTx = db.transaction(MODEL_STORE_NAME, 'readonly');\n          const modelStore = modelTx.objectStore(MODEL_STORE_NAME);\n          const getRequest = modelStore.get(this.modelPath);\n          getRequest.onsuccess = () => {\n            if (getRequest.result == null) {\n              db.close();\n              return reject(new Error(\n                  `Cannot find model with path '${this.modelPath}' ` +\n                  `in IndexedDB.`));\n            } else {\n              resolve(getRequest.result.modelArtifacts);\n            }\n          };\n          getRequest.onerror = error => {\n            db.close();\n            return reject(getRequest.error);\n          };\n          modelTx.oncomplete = () => db.close();\n        } else {\n          // Put model into object store.\n          const modelArtifactsInfo: ModelArtifactsInfo =\n              getModelArtifactsInfoForJSON(modelArtifacts);\n          // First, put ModelArtifactsInfo into info store.\n          const infoTx = db.transaction(INFO_STORE_NAME, 'readwrite');\n          let infoStore = infoTx.objectStore(INFO_STORE_NAME);\n          const putInfoRequest =\n              infoStore.put({modelPath: this.modelPath, modelArtifactsInfo});\n          let modelTx: IDBTransaction;\n          putInfoRequest.onsuccess = () => {\n            // Second, put model data into model store.\n            modelTx = db.transaction(MODEL_STORE_NAME, 'readwrite');\n            const modelStore = modelTx.objectStore(MODEL_STORE_NAME);\n            const putModelRequest = modelStore.put({\n              modelPath: this.modelPath,\n              modelArtifacts,\n              modelArtifactsInfo\n            });\n            putModelRequest.onsuccess = () => resolve({modelArtifactsInfo});\n            putModelRequest.onerror = error => {\n              // If the put-model request fails, roll back the info entry as\n              // well.\n              infoStore = infoTx.objectStore(INFO_STORE_NAME);\n              const deleteInfoRequest = infoStore.delete(this.modelPath);\n              deleteInfoRequest.onsuccess = () => {\n                db.close();\n                return reject(putModelRequest.error);\n              };\n              deleteInfoRequest.onerror = error => {\n                db.close();\n                return reject(putModelRequest.error);\n              };\n            };\n          };\n          putInfoRequest.onerror = error => {\n            db.close();\n            return reject(putInfoRequest.error);\n          };\n          infoTx.oncomplete = () => {\n            if (modelTx == null) {\n              db.close();\n            } else {\n              modelTx.oncomplete = () => db.close();\n            }\n          };\n        }\n      };\n      openRequest.onerror = error => reject(openRequest.error);\n    });\n  }\n}\n\nexport const indexedDBRouter: IORouter = (url: string|string[]) => {\n  if (!env().getBool('IS_BROWSER')) {\n    return null;\n  } else {\n    if (!Array.isArray(url) && url.startsWith(BrowserIndexedDB.URL_SCHEME)) {\n      return browserIndexedDB(url.slice(BrowserIndexedDB.URL_SCHEME.length));\n    } else {\n      return null;\n    }\n  }\n};\nIORouterRegistry.registerSaveRouter(indexedDBRouter);\nIORouterRegistry.registerLoadRouter(indexedDBRouter);\n\n/**\n * Creates a browser IndexedDB IOHandler for saving and loading models.\n *\n * ```js\n * const model = tf.sequential();\n * model.add(\n *     tf.layers.dense({units: 1, inputShape: [100], activation: 'sigmoid'}));\n *\n * const saveResult = await model.save('indexeddb://MyModel'));\n * console.log(saveResult);\n * ```\n *\n * @param modelPath A unique identifier for the model to be saved. Must be a\n *   non-empty string.\n * @returns An instance of `BrowserIndexedDB` (sublcass of `IOHandler`),\n *   which can be used with, e.g., `tf.Model.save`.\n */\nexport function browserIndexedDB(modelPath: string): IOHandler {\n  return new BrowserIndexedDB(modelPath);\n}\n\nfunction maybeStripScheme(key: string) {\n  return key.startsWith(BrowserIndexedDB.URL_SCHEME) ?\n      key.slice(BrowserIndexedDB.URL_SCHEME.length) :\n      key;\n}\n\nexport class BrowserIndexedDBManager implements ModelStoreManager {\n  private indexedDB: IDBFactory;\n\n  constructor() {\n    this.indexedDB = getIndexedDBFactory();\n  }\n\n  async listModels(): Promise<{[path: string]: ModelArtifactsInfo}> {\n    return new Promise<{[path: string]: ModelArtifactsInfo}>(\n        (resolve, reject) => {\n          const openRequest =\n              this.indexedDB.open(DATABASE_NAME, DATABASE_VERSION);\n          openRequest.onupgradeneeded = () => setUpDatabase(openRequest);\n\n          openRequest.onsuccess = () => {\n            const db = openRequest.result;\n            const tx = db.transaction(INFO_STORE_NAME, 'readonly');\n            const store = tx.objectStore(INFO_STORE_NAME);\n            // tslint:disable:max-line-length\n            // Need to cast `store` as `any` here because TypeScript's DOM\n            // library does not have the `getAll()` method even though the\n            // method is supported in the latest version of most mainstream\n            // browsers:\n            // https://developer.mozilla.org/en-US/docs/Web/API/IDBObjectStore/getAll\n            // tslint:enable:max-line-length\n            // tslint:disable-next-line:no-any\n            const getAllInfoRequest = (store as any).getAll() as IDBRequest;\n            getAllInfoRequest.onsuccess = () => {\n              const out: {[path: string]: ModelArtifactsInfo} = {};\n              for (const item of getAllInfoRequest.result) {\n                out[item.modelPath] = item.modelArtifactsInfo;\n              }\n              resolve(out);\n            };\n            getAllInfoRequest.onerror = error => {\n              db.close();\n              return reject(getAllInfoRequest.error);\n            };\n            tx.oncomplete = () => db.close();\n          };\n          openRequest.onerror = error => reject(openRequest.error);\n        });\n  }\n\n  async removeModel(path: string): Promise<ModelArtifactsInfo> {\n    path = maybeStripScheme(path);\n    return new Promise<ModelArtifactsInfo>((resolve, reject) => {\n      const openRequest = this.indexedDB.open(DATABASE_NAME, DATABASE_VERSION);\n      openRequest.onupgradeneeded = () => setUpDatabase(openRequest);\n\n      openRequest.onsuccess = () => {\n        const db = openRequest.result;\n        const infoTx = db.transaction(INFO_STORE_NAME, 'readwrite');\n        const infoStore = infoTx.objectStore(INFO_STORE_NAME);\n\n        const getInfoRequest = infoStore.get(path);\n        let modelTx: IDBTransaction;\n        getInfoRequest.onsuccess = () => {\n          if (getInfoRequest.result == null) {\n            db.close();\n            return reject(new Error(\n                `Cannot find model with path '${path}' ` +\n                `in IndexedDB.`));\n          } else {\n            // First, delete the entry in the info store.\n            const deleteInfoRequest = infoStore.delete(path);\n            const deleteModelData = () => {\n              // Second, delete the entry in the model store.\n              modelTx = db.transaction(MODEL_STORE_NAME, 'readwrite');\n              const modelStore = modelTx.objectStore(MODEL_STORE_NAME);\n              const deleteModelRequest = modelStore.delete(path);\n              deleteModelRequest.onsuccess = () =>\n                  resolve(getInfoRequest.result.modelArtifactsInfo);\n              deleteModelRequest.onerror = error =>\n                  reject(getInfoRequest.error);\n            };\n            // Proceed with deleting model data regardless of whether deletion\n            // of info data succeeds or not.\n            deleteInfoRequest.onsuccess = deleteModelData;\n            deleteInfoRequest.onerror = error => {\n              deleteModelData();\n              db.close();\n              return reject(getInfoRequest.error);\n            };\n          }\n        };\n        getInfoRequest.onerror = error => {\n          db.close();\n          return reject(getInfoRequest.error);\n        };\n\n        infoTx.oncomplete = () => {\n          if (modelTx == null) {\n            db.close();\n          } else {\n            modelTx.oncomplete = () => db.close();\n          }\n        };\n      };\n      openRequest.onerror = error => reject(openRequest.error);\n    });\n  }\n}\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport '../flags';\nimport {env} from '../environment';\n\nimport {assert} from '../util';\nimport {arrayBufferToBase64String, base64StringToArrayBuffer, getModelArtifactsInfoForJSON} from './io_utils';\nimport {IORouter, IORouterRegistry} from './router_registry';\nimport {IOHandler, ModelArtifacts, ModelArtifactsInfo, ModelJSON, ModelStoreManager, SaveResult} from './types';\n\nconst PATH_SEPARATOR = '/';\nconst PATH_PREFIX = 'tensorflowjs_models';\nconst INFO_SUFFIX = 'info';\nconst MODEL_TOPOLOGY_SUFFIX = 'model_topology';\nconst WEIGHT_SPECS_SUFFIX = 'weight_specs';\nconst WEIGHT_DATA_SUFFIX = 'weight_data';\nconst MODEL_METADATA_SUFFIX = 'model_metadata';\n\n/**\n * Purge all tensorflow.js-saved model artifacts from local storage.\n *\n * @returns Paths of the models purged.\n */\nexport function purgeLocalStorageArtifacts(): string[] {\n  if (!env().getBool('IS_BROWSER') || typeof window === 'undefined' ||\n      typeof window.localStorage === 'undefined') {\n    throw new Error(\n        'purgeLocalStorageModels() cannot proceed because local storage is ' +\n        'unavailable in the current environment.');\n  }\n  const LS = window.localStorage;\n  const purgedModelPaths: string[] = [];\n  for (let i = 0; i < LS.length; ++i) {\n    const key = LS.key(i);\n    const prefix = PATH_PREFIX + PATH_SEPARATOR;\n    if (key.startsWith(prefix) && key.length > prefix.length) {\n      LS.removeItem(key);\n      const modelName = getModelPathFromKey(key);\n      if (purgedModelPaths.indexOf(modelName) === -1) {\n        purgedModelPaths.push(modelName);\n      }\n    }\n  }\n  return purgedModelPaths;\n}\n\ntype LocalStorageKeys = {\n  /** Key of the localStorage entry storing `ModelArtifactsInfo`. */\n  info: string,\n  /**\n   * Key of the localStorage entry storing the 'modelTopology' key of\n   * `model.json`\n   */\n  topology: string,\n  /**\n   * Key of the localStorage entry storing the `weightsManifest.weights` entries\n   * of `model.json`\n   */\n  weightSpecs: string,\n  /** Key of the localStorage entry storing the weight data in Base64 */\n  weightData: string,\n  /**\n   * Key of the localStorage entry storing the remaining fields of `model.json`\n   * @see {@link ModelMetadata}\n   */\n  modelMetadata: string,\n};\n\ntype ModelMetadata = Omit<ModelJSON, 'modelTopology'|'weightsManifest'>;\n\nfunction getModelKeys(path: string): LocalStorageKeys {\n  return {\n    info: [PATH_PREFIX, path, INFO_SUFFIX].join(PATH_SEPARATOR),\n    topology: [PATH_PREFIX, path, MODEL_TOPOLOGY_SUFFIX].join(PATH_SEPARATOR),\n    weightSpecs: [PATH_PREFIX, path, WEIGHT_SPECS_SUFFIX].join(PATH_SEPARATOR),\n    weightData: [PATH_PREFIX, path, WEIGHT_DATA_SUFFIX].join(PATH_SEPARATOR),\n    modelMetadata:\n        [PATH_PREFIX, path, MODEL_METADATA_SUFFIX].join(PATH_SEPARATOR)\n  };\n}\n\nfunction removeItems(keys: LocalStorageKeys): void {\n  for (const key of Object.values(keys)) {\n    window.localStorage.removeItem(key);\n  }\n}\n\n/**\n * Get model path from a local-storage key.\n *\n * E.g., 'tensorflowjs_models/my/model/1/info' --> 'my/model/1'\n *\n * @param key\n */\nfunction getModelPathFromKey(key: string) {\n  const items = key.split(PATH_SEPARATOR);\n  if (items.length < 3) {\n    throw new Error(`Invalid key format: ${key}`);\n  }\n  return items.slice(1, items.length - 1).join(PATH_SEPARATOR);\n}\n\nfunction maybeStripScheme(key: string) {\n  return key.startsWith(BrowserLocalStorage.URL_SCHEME) ?\n      key.slice(BrowserLocalStorage.URL_SCHEME.length) :\n      key;\n}\n\n/**\n * IOHandler subclass: Browser Local Storage.\n *\n * See the doc string to `browserLocalStorage` for more details.\n */\nexport class BrowserLocalStorage implements IOHandler {\n  protected readonly LS: Storage;\n  protected readonly modelPath: string;\n  protected readonly keys: LocalStorageKeys;\n\n  static readonly URL_SCHEME = 'localstorage://';\n\n  constructor(modelPath: string) {\n    if (!env().getBool('IS_BROWSER') || typeof window === 'undefined' ||\n        typeof window.localStorage === 'undefined') {\n      // TODO(cais): Add more info about what IOHandler subtypes are\n      // available.\n      //   Maybe point to a doc page on the web and/or automatically determine\n      //   the available IOHandlers and print them in the error message.\n      throw new Error(\n          'The current environment does not support local storage.');\n    }\n    this.LS = window.localStorage;\n\n    if (modelPath == null || !modelPath) {\n      throw new Error(\n          'For local storage, modelPath must not be null, undefined or empty.');\n    }\n    this.modelPath = modelPath;\n    this.keys = getModelKeys(this.modelPath);\n  }\n\n  /**\n   * Save model artifacts to browser local storage.\n   *\n   * See the documentation to `browserLocalStorage` for details on the saved\n   * artifacts.\n   *\n   * @param modelArtifacts The model artifacts to be stored.\n   * @returns An instance of SaveResult.\n   */\n  async save(modelArtifacts: ModelArtifacts): Promise<SaveResult> {\n    if (modelArtifacts.modelTopology instanceof ArrayBuffer) {\n      throw new Error(\n          'BrowserLocalStorage.save() does not support saving model topology ' +\n          'in binary formats yet.');\n    } else {\n      const topology = JSON.stringify(modelArtifacts.modelTopology);\n      const weightSpecs = JSON.stringify(modelArtifacts.weightSpecs);\n\n      const modelArtifactsInfo: ModelArtifactsInfo =\n          getModelArtifactsInfoForJSON(modelArtifacts);\n\n      try {\n        this.LS.setItem(this.keys.info, JSON.stringify(modelArtifactsInfo));\n        this.LS.setItem(this.keys.topology, topology);\n        this.LS.setItem(this.keys.weightSpecs, weightSpecs);\n        this.LS.setItem(\n            this.keys.weightData,\n            arrayBufferToBase64String(modelArtifacts.weightData));\n\n        // Note that JSON.stringify doesn't write out keys that have undefined\n        // values, so for some keys, we set undefined instead of a null-ish\n        // value.\n        const metadata: Required<ModelMetadata> = {\n          format: modelArtifacts.format,\n          generatedBy: modelArtifacts.generatedBy,\n          convertedBy: modelArtifacts.convertedBy,\n          signature: modelArtifacts.signature != null ?\n              modelArtifacts.signature :\n              undefined,\n          userDefinedMetadata: modelArtifacts.userDefinedMetadata != null ?\n              modelArtifacts.userDefinedMetadata :\n              undefined,\n          modelInitializer: modelArtifacts.modelInitializer != null ?\n              modelArtifacts.modelInitializer :\n              undefined,\n          trainingConfig: modelArtifacts.trainingConfig != null ?\n              modelArtifacts.trainingConfig :\n              undefined\n        };\n        this.LS.setItem(this.keys.modelMetadata, JSON.stringify(metadata));\n\n        return {modelArtifactsInfo};\n      } catch (err) {\n        // If saving failed, clean up all items saved so far.\n        removeItems(this.keys);\n\n        throw new Error(\n            `Failed to save model '${this.modelPath}' to local storage: ` +\n            `size quota being exceeded is a possible cause of this failure: ` +\n            `modelTopologyBytes=${modelArtifactsInfo.modelTopologyBytes}, ` +\n            `weightSpecsBytes=${modelArtifactsInfo.weightSpecsBytes}, ` +\n            `weightDataBytes=${modelArtifactsInfo.weightDataBytes}.`);\n      }\n    }\n  }\n\n  /**\n   * Load a model from local storage.\n   *\n   * See the documentation to `browserLocalStorage` for details on the saved\n   * artifacts.\n   *\n   * @returns The loaded model (if loading succeeds).\n   */\n  async load(): Promise<ModelArtifacts> {\n    const info =\n        JSON.parse(this.LS.getItem(this.keys.info)) as ModelArtifactsInfo;\n    if (info == null) {\n      throw new Error(\n          `In local storage, there is no model with name '${this.modelPath}'`);\n    }\n\n    if (info.modelTopologyType !== 'JSON') {\n      throw new Error(\n          'BrowserLocalStorage does not support loading non-JSON model ' +\n          'topology yet.');\n    }\n\n    const out: ModelArtifacts = {};\n\n    // Load topology.\n    const topology = JSON.parse(this.LS.getItem(this.keys.topology));\n    if (topology == null) {\n      throw new Error(\n          `In local storage, the topology of model '${this.modelPath}' ` +\n          `is missing.`);\n    }\n    out.modelTopology = topology;\n\n    // Load weight specs.\n    const weightSpecs = JSON.parse(this.LS.getItem(this.keys.weightSpecs));\n    if (weightSpecs == null) {\n      throw new Error(\n          `In local storage, the weight specs of model '${this.modelPath}' ` +\n          `are missing.`);\n    }\n    out.weightSpecs = weightSpecs;\n\n    // Load meta-data fields.\n    const metadataString = this.LS.getItem(this.keys.modelMetadata);\n    if (metadataString != null) {\n      const metadata = JSON.parse(metadataString) as ModelMetadata;\n      out.format = metadata.format;\n      out.generatedBy = metadata.generatedBy;\n      out.convertedBy = metadata.convertedBy;\n      if (metadata.signature != null) {\n        out.signature = metadata.signature;\n      }\n      if (metadata.userDefinedMetadata != null) {\n        out.userDefinedMetadata = metadata.userDefinedMetadata;\n      }\n      if (metadata.modelInitializer != null) {\n        out.modelInitializer = metadata.modelInitializer;\n      }\n      if (metadata.trainingConfig != null) {\n        out.trainingConfig = metadata.trainingConfig;\n      }\n    }\n\n    // Load weight data.\n    const weightDataBase64 = this.LS.getItem(this.keys.weightData);\n    if (weightDataBase64 == null) {\n      throw new Error(\n          `In local storage, the binary weight values of model ` +\n          `'${this.modelPath}' are missing.`);\n    }\n    out.weightData = base64StringToArrayBuffer(weightDataBase64);\n\n    return out;\n  }\n}\n\nexport const localStorageRouter: IORouter = (url: string|string[]) => {\n  if (!env().getBool('IS_BROWSER')) {\n    return null;\n  } else {\n    if (!Array.isArray(url) && url.startsWith(BrowserLocalStorage.URL_SCHEME)) {\n      return browserLocalStorage(\n          url.slice(BrowserLocalStorage.URL_SCHEME.length));\n    } else {\n      return null;\n    }\n  }\n};\nIORouterRegistry.registerSaveRouter(localStorageRouter);\nIORouterRegistry.registerLoadRouter(localStorageRouter);\n\n/**\n * Factory function for local storage IOHandler.\n *\n * This `IOHandler` supports both `save` and `load`.\n *\n * For each model's saved artifacts, four items are saved to local storage.\n *   - `${PATH_SEPARATOR}/${modelPath}/info`: Contains meta-info about the\n *     model, such as date saved, type of the topology, size in bytes, etc.\n *   - `${PATH_SEPARATOR}/${modelPath}/topology`: Model topology. For Keras-\n *     style models, this is a stringized JSON.\n *   - `${PATH_SEPARATOR}/${modelPath}/weight_specs`: Weight specs of the\n *     model, can be used to decode the saved binary weight values (see\n *     item below).\n *   - `${PATH_SEPARATOR}/${modelPath}/weight_data`: Concatenated binary\n *     weight values, stored as a base64-encoded string.\n *\n * Saving may throw an `Error` if the total size of the artifacts exceed the\n * browser-specific quota.\n *\n * @param modelPath A unique identifier for the model to be saved. Must be a\n *   non-empty string.\n * @returns An instance of `IOHandler`, which can be used with, e.g.,\n *   `tf.Model.save`.\n */\nexport function browserLocalStorage(modelPath: string): IOHandler {\n  return new BrowserLocalStorage(modelPath);\n}\n\nexport class BrowserLocalStorageManager implements ModelStoreManager {\n  private readonly LS: Storage;\n\n  constructor() {\n    assert(\n        env().getBool('IS_BROWSER'),\n        () => 'Current environment is not a web browser');\n    assert(\n        typeof window === 'undefined' ||\n            typeof window.localStorage !== 'undefined',\n        () => 'Current browser does not appear to support localStorage');\n    this.LS = window.localStorage;\n  }\n\n  async listModels(): Promise<{[path: string]: ModelArtifactsInfo}> {\n    const out: {[path: string]: ModelArtifactsInfo} = {};\n    const prefix = PATH_PREFIX + PATH_SEPARATOR;\n    const suffix = PATH_SEPARATOR + INFO_SUFFIX;\n    for (let i = 0; i < this.LS.length; ++i) {\n      const key = this.LS.key(i);\n      if (key.startsWith(prefix) && key.endsWith(suffix)) {\n        const modelPath = getModelPathFromKey(key);\n        out[modelPath] = JSON.parse(this.LS.getItem(key)) as ModelArtifactsInfo;\n      }\n    }\n    return out;\n  }\n\n  async removeModel(path: string): Promise<ModelArtifactsInfo> {\n    path = maybeStripScheme(path);\n    const keys = getModelKeys(path);\n    if (this.LS.getItem(keys.info) == null) {\n      throw new Error(`Cannot find model at path '${path}'`);\n    }\n    const info = JSON.parse(this.LS.getItem(keys.info)) as ModelArtifactsInfo;\n    removeItems(keys);\n    return info;\n  }\n}\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n/**\n * Classes and functions for model management across multiple storage mediums.\n *\n * Supported client actions:\n * - Listing models on all registered storage mediums.\n * - Remove model by URL from any registered storage mediums, by using URL\n *   string.\n * - Moving or copying model from one path to another in the same medium or from\n *   one medium to another, by using URL strings.\n */\n\nimport {assert} from '../util';\n\nimport {IORouterRegistry} from './router_registry';\nimport {ModelArtifactsInfo, ModelStoreManager} from './types';\n\nconst URL_SCHEME_SUFFIX = '://';\n\nexport class ModelStoreManagerRegistry {\n  // Singleton instance.\n  private static instance: ModelStoreManagerRegistry;\n\n  private managers: {[scheme: string]: ModelStoreManager};\n\n  private constructor() {\n    this.managers = {};\n  }\n\n  private static getInstance(): ModelStoreManagerRegistry {\n    if (ModelStoreManagerRegistry.instance == null) {\n      ModelStoreManagerRegistry.instance = new ModelStoreManagerRegistry();\n    }\n    return ModelStoreManagerRegistry.instance;\n  }\n\n  /**\n   * Register a save-handler router.\n   *\n   * @param saveRouter A function that maps a URL-like string onto an instance\n   * of `IOHandler` with the `save` method defined or `null`.\n   */\n  static registerManager(scheme: string, manager: ModelStoreManager) {\n    assert(scheme != null, () => 'scheme must not be undefined or null.');\n    if (scheme.endsWith(URL_SCHEME_SUFFIX)) {\n      scheme = scheme.slice(0, scheme.indexOf(URL_SCHEME_SUFFIX));\n    }\n    assert(scheme.length > 0, () => 'scheme must not be an empty string.');\n    const registry = ModelStoreManagerRegistry.getInstance();\n    assert(\n        registry.managers[scheme] == null,\n        () => `A model store manager is already registered for scheme '${\n            scheme}'.`);\n    registry.managers[scheme] = manager;\n  }\n\n  static getManager(scheme: string): ModelStoreManager {\n    const manager = ModelStoreManagerRegistry.getInstance().managers[scheme];\n    if (manager == null) {\n      throw new Error(`Cannot find model manager for scheme '${scheme}'`);\n    }\n    return manager;\n  }\n\n  static getSchemes(): string[] {\n    return Object.keys(ModelStoreManagerRegistry.getInstance().managers);\n  }\n}\n\n/**\n * Helper method for parsing a URL string into a scheme and a path.\n *\n * @param url E.g., 'localstorage://my-model'\n * @returns A dictionary with two fields: scheme and path.\n *   Scheme: e.g., 'localstorage' in the example above.\n *   Path: e.g., 'my-model' in the example above.\n */\nfunction parseURL(url: string): {scheme: string, path: string} {\n  if (url.indexOf(URL_SCHEME_SUFFIX) === -1) {\n    throw new Error(\n        `The url string provided does not contain a scheme. ` +\n        `Supported schemes are: ` +\n        `${ModelStoreManagerRegistry.getSchemes().join(',')}`);\n  }\n  return {\n    scheme: url.split(URL_SCHEME_SUFFIX)[0],\n    path: url.split(URL_SCHEME_SUFFIX)[1],\n  };\n}\n\nasync function cloneModelInternal(\n    sourceURL: string, destURL: string,\n    deleteSource = false): Promise<ModelArtifactsInfo> {\n  assert(\n      sourceURL !== destURL,\n      () => `Old path and new path are the same: '${sourceURL}'`);\n\n  const loadHandlers = IORouterRegistry.getLoadHandlers(sourceURL);\n  assert(\n      loadHandlers.length > 0,\n      () => `Copying failed because no load handler is found for source URL ${\n          sourceURL}.`);\n  assert(\n      loadHandlers.length < 2,\n      () => `Copying failed because more than one (${loadHandlers.length}) ` +\n          `load handlers for source URL ${sourceURL}.`);\n  const loadHandler = loadHandlers[0];\n\n  const saveHandlers = IORouterRegistry.getSaveHandlers(destURL);\n  assert(\n      saveHandlers.length > 0,\n      () => `Copying failed because no save handler is found for destination ` +\n          `URL ${destURL}.`);\n  assert(\n      saveHandlers.length < 2,\n      () => `Copying failed because more than one (${loadHandlers.length}) ` +\n          `save handlers for destination URL ${destURL}.`);\n  const saveHandler = saveHandlers[0];\n\n  const sourceScheme = parseURL(sourceURL).scheme;\n  const sourcePath = parseURL(sourceURL).path;\n  const sameMedium = sourceScheme === parseURL(sourceURL).scheme;\n\n  const modelArtifacts = await loadHandler.load();\n\n  // If moving within the same storage medium, remove the old model as soon as\n  // the loading is done. Without doing this, it is possible that the combined\n  // size of the two models will cause the cloning to fail.\n  if (deleteSource && sameMedium) {\n    await ModelStoreManagerRegistry.getManager(sourceScheme)\n        .removeModel(sourcePath);\n  }\n\n  const saveResult = await saveHandler.save(modelArtifacts);\n\n  // If moving between mediums, the deletion is done after the save succeeds.\n  // This guards against the case in which saving to the destination medium\n  // fails.\n  if (deleteSource && !sameMedium) {\n    await ModelStoreManagerRegistry.getManager(sourceScheme)\n        .removeModel(sourcePath);\n  }\n\n  return saveResult.modelArtifactsInfo;\n}\n\n/**\n * List all models stored in registered storage mediums.\n *\n * For a web browser environment, the registered mediums are Local Storage and\n * IndexedDB.\n *\n * ```js\n * // First create and save a model.\n * const model = tf.sequential();\n * model.add(tf.layers.dense(\n *     {units: 1, inputShape: [10], activation: 'sigmoid'}));\n * await model.save('localstorage://demo/management/model1');\n *\n * // Then list existing models.\n * console.log(JSON.stringify(await tf.io.listModels()));\n *\n * // Delete the model.\n * await tf.io.removeModel('localstorage://demo/management/model1');\n *\n * // List models again.\n * console.log(JSON.stringify(await tf.io.listModels()));\n * ```\n *\n * @returns A `Promise` of a dictionary mapping URLs of existing models to\n * their model artifacts info. URLs include medium-specific schemes, e.g.,\n *   'indexeddb://my/model/1'. Model artifacts info include type of the\n * model's topology, byte sizes of the topology, weights, etc.\n *\n * @doc {\n *   heading: 'Models',\n *   subheading: 'Management',\n *   namespace: 'io',\n *   ignoreCI: true\n * }\n */\nasync function listModels(): Promise<{[url: string]: ModelArtifactsInfo}> {\n  const schemes = ModelStoreManagerRegistry.getSchemes();\n  const out: {[url: string]: ModelArtifactsInfo} = {};\n  for (const scheme of schemes) {\n    const schemeOut =\n        await ModelStoreManagerRegistry.getManager(scheme).listModels();\n    for (const path in schemeOut) {\n      const url = scheme + URL_SCHEME_SUFFIX + path;\n      out[url] = schemeOut[path];\n    }\n  }\n  return out;\n}\n\n/**\n * Remove a model specified by URL from a registered storage medium.\n *\n * ```js\n * // First create and save a model.\n * const model = tf.sequential();\n * model.add(tf.layers.dense(\n *     {units: 1, inputShape: [10], activation: 'sigmoid'}));\n * await model.save('localstorage://demo/management/model1');\n *\n * // Then list existing models.\n * console.log(JSON.stringify(await tf.io.listModels()));\n *\n * // Delete the model.\n * await tf.io.removeModel('localstorage://demo/management/model1');\n *\n * // List models again.\n * console.log(JSON.stringify(await tf.io.listModels()));\n * ```\n *\n * @param url A URL to a stored model, with a scheme prefix, e.g.,\n *   'localstorage://my-model-1', 'indexeddb://my/model/2'.\n * @returns ModelArtifactsInfo of the deleted model (if and only if deletion\n *   is successful).\n * @throws Error if deletion fails, e.g., if no model exists at `path`.\n *\n * @doc {\n *   heading: 'Models',\n *   subheading: 'Management',\n *   namespace: 'io',\n *   ignoreCI: true\n * }\n */\nasync function removeModel(url: string): Promise<ModelArtifactsInfo> {\n  const schemeAndPath = parseURL(url);\n  const manager = ModelStoreManagerRegistry.getManager(schemeAndPath.scheme);\n  return manager.removeModel(schemeAndPath.path);\n}\n\n/**\n * Copy a model from one URL to another.\n *\n * This function supports:\n *\n * 1. Copying within a storage medium, e.g.,\n *    `tf.io.copyModel('localstorage://model-1', 'localstorage://model-2')`\n * 2. Copying between two storage mediums, e.g.,\n *    `tf.io.copyModel('localstorage://model-1', 'indexeddb://model-1')`\n *\n * ```js\n * // First create and save a model.\n * const model = tf.sequential();\n * model.add(tf.layers.dense(\n *     {units: 1, inputShape: [10], activation: 'sigmoid'}));\n * await model.save('localstorage://demo/management/model1');\n *\n * // Then list existing models.\n * console.log(JSON.stringify(await tf.io.listModels()));\n *\n * // Copy the model, from Local Storage to IndexedDB.\n * await tf.io.copyModel(\n *     'localstorage://demo/management/model1',\n *     'indexeddb://demo/management/model1');\n *\n * // List models again.\n * console.log(JSON.stringify(await tf.io.listModels()));\n *\n * // Remove both models.\n * await tf.io.removeModel('localstorage://demo/management/model1');\n * await tf.io.removeModel('indexeddb://demo/management/model1');\n * ```\n *\n * @param sourceURL Source URL of copying.\n * @param destURL Destination URL of copying.\n * @returns ModelArtifactsInfo of the copied model (if and only if copying\n *   is successful).\n * @throws Error if copying fails, e.g., if no model exists at `sourceURL`, or\n *   if `oldPath` and `newPath` are identical.\n *\n * @doc {\n *   heading: 'Models',\n *   subheading: 'Management',\n *   namespace: 'io',\n *   ignoreCI: true\n * }\n */\nasync function copyModel(\n    sourceURL: string, destURL: string): Promise<ModelArtifactsInfo> {\n  const deleteSource = false;\n  return cloneModelInternal(sourceURL, destURL, deleteSource);\n}\n\n/**\n * Move a model from one URL to another.\n *\n * This function supports:\n *\n * 1. Moving within a storage medium, e.g.,\n *    `tf.io.moveModel('localstorage://model-1', 'localstorage://model-2')`\n * 2. Moving between two storage mediums, e.g.,\n *    `tf.io.moveModel('localstorage://model-1', 'indexeddb://model-1')`\n *\n * ```js\n * // First create and save a model.\n * const model = tf.sequential();\n * model.add(tf.layers.dense(\n *     {units: 1, inputShape: [10], activation: 'sigmoid'}));\n * await model.save('localstorage://demo/management/model1');\n *\n * // Then list existing models.\n * console.log(JSON.stringify(await tf.io.listModels()));\n *\n * // Move the model, from Local Storage to IndexedDB.\n * await tf.io.moveModel(\n *     'localstorage://demo/management/model1',\n *     'indexeddb://demo/management/model1');\n *\n * // List models again.\n * console.log(JSON.stringify(await tf.io.listModels()));\n *\n * // Remove the moved model.\n * await tf.io.removeModel('indexeddb://demo/management/model1');\n * ```\n *\n * @param sourceURL Source URL of moving.\n * @param destURL Destination URL of moving.\n * @returns ModelArtifactsInfo of the copied model (if and only if copying\n *   is successful).\n * @throws Error if moving fails, e.g., if no model exists at `sourceURL`, or\n *   if `oldPath` and `newPath` are identical.\n *\n * @doc {\n *   heading: 'Models',\n *   subheading: 'Management',\n *   namespace: 'io',\n *   ignoreCI: true\n * }\n */\nasync function moveModel(\n    sourceURL: string, destURL: string): Promise<ModelArtifactsInfo> {\n  const deleteSource = true;\n  return cloneModelInternal(sourceURL, destURL, deleteSource);\n}\n\nexport {moveModel, copyModel, removeModel, listModels};\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport '../flags';\n\nimport {env} from '../environment';\nimport {BrowserIndexedDB, BrowserIndexedDBManager} from '../io/indexed_db';\nimport {BrowserLocalStorage, BrowserLocalStorageManager} from '../io/local_storage';\nimport {ModelStoreManagerRegistry} from '../io/model_management';\n\nimport {Platform} from './platform';\n\nexport class PlatformBrowser implements Platform {\n  // According to the spec, the built-in encoder can do only UTF-8 encoding.\n  // https://developer.mozilla.org/en-US/docs/Web/API/TextEncoder/TextEncoder\n  private textEncoder: TextEncoder;\n\n  // For setTimeoutCustom\n  private messageName = 'setTimeoutCustom';\n  private functionRefs: Function[] = [];\n  private handledMessageCount = 0;\n  private hasEventListener = false;\n\n  fetch(path: string, init?: RequestInit): Promise<Response> {\n    return fetch(path, init);\n  }\n\n  now(): number {\n    return performance.now();\n  }\n\n  encode(text: string, encoding: string): Uint8Array {\n    if (encoding !== 'utf-8' && encoding !== 'utf8') {\n      throw new Error(\n          `Browser's encoder only supports utf-8, but got ${encoding}`);\n    }\n    if (this.textEncoder == null) {\n      this.textEncoder = new TextEncoder();\n    }\n    return this.textEncoder.encode(text);\n  }\n  decode(bytes: Uint8Array, encoding: string): string {\n    return new TextDecoder(encoding).decode(bytes);\n  }\n\n  // If the setTimeout nesting level is greater than 5 and timeout is less\n  // than 4ms, timeout will be clamped to 4ms, which hurts the perf.\n  // Interleaving window.postMessage and setTimeout will trick the browser and\n  // avoid the clamp.\n  setTimeoutCustom(functionRef: Function, delay: number): void {\n    if (!window || !env().getBool('USE_SETTIMEOUTCUSTOM')) {\n      setTimeout(functionRef, delay);\n      return;\n    }\n\n    this.functionRefs.push(functionRef);\n    setTimeout(() => {\n      window.postMessage(\n          {name: this.messageName, index: this.functionRefs.length - 1}, '*');\n    }, delay);\n\n    if (!this.hasEventListener) {\n      this.hasEventListener = true;\n      window.addEventListener('message', (event: MessageEvent) => {\n        if (event.source === window && event.data.name === this.messageName) {\n          event.stopPropagation();\n          const functionRef = this.functionRefs[event.data.index];\n          functionRef();\n          this.handledMessageCount++;\n          if (this.handledMessageCount === this.functionRefs.length) {\n            this.functionRefs = [];\n            this.handledMessageCount = 0;\n          }\n        }\n      }, true);\n    }\n  }\n}\n\nif (env().get('IS_BROWSER')) {\n  env().setPlatform('browser', new PlatformBrowser());\n\n  // Register LocalStorage IOHandler\n  try {\n    ModelStoreManagerRegistry.registerManager(\n        BrowserLocalStorage.URL_SCHEME, new BrowserLocalStorageManager());\n  } catch (err) {\n  }\n\n  // Register IndexedDB IOHandler\n  try {\n    ModelStoreManagerRegistry.registerManager(\n        BrowserIndexedDB.URL_SCHEME, new BrowserIndexedDBManager());\n  } catch (err) {\n  }\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {env} from '../environment';\nimport {Platform} from './platform';\n\n// We are wrapping this within an object so it can be stubbed by Jasmine.\nexport const getNodeFetch = {\n  // tslint:disable-next-line:no-require-imports\n  importFetch: () => require('node-fetch')\n};\n\ntype FetchFn = (url: string, init?: RequestInit) => Promise<Response>;\nlet systemFetch: FetchFn;\n// These getters and setters are for testing so we don't export a mutable\n// variable.\nexport function resetSystemFetch() {\n  systemFetch = null;\n}\nexport function setSystemFetch(fetchFn: FetchFn) {\n  systemFetch = fetchFn;\n}\nexport function getSystemFetch(): FetchFn {\n  return systemFetch;\n}\n\nexport class PlatformNode implements Platform {\n  private textEncoder: TextEncoder;\n  // tslint:disable-next-line:no-any\n  util: any;\n\n  constructor() {\n    // tslint:disable-next-line:no-require-imports\n    this.util = require('util');\n    // According to the spec, the built-in encoder can do only UTF-8 encoding.\n    // https://developer.mozilla.org/en-US/docs/Web/API/TextEncoder/TextEncoder\n    this.textEncoder = new this.util.TextEncoder();\n  }\n\n  fetch(path: string, requestInits?: RequestInit): Promise<Response> {\n    if (env().global.fetch != null) {\n      return env().global.fetch(path, requestInits);\n    }\n\n    if (systemFetch == null) {\n      systemFetch = getNodeFetch.importFetch();\n    }\n    return systemFetch(path, requestInits);\n  }\n\n  now(): number {\n    const time = process.hrtime();\n    return time[0] * 1000 + time[1] / 1000000;\n  }\n\n  encode(text: string, encoding: string): Uint8Array {\n    if (encoding !== 'utf-8' && encoding !== 'utf8') {\n      throw new Error(\n          `Node built-in encoder only supports utf-8, but got ${encoding}`);\n    }\n    return this.textEncoder.encode(text);\n  }\n  decode(bytes: Uint8Array, encoding: string): string {\n    if (bytes.length === 0) {\n      return '';\n    }\n    return new this.util.TextDecoder(encoding).decode(bytes);\n  }\n}\n\nif (env().get('IS_NODE') && !env().get('IS_BROWSER')) {\n  env().setPlatform('node', new PlatformNode());\n}\n","/**\n * @license\n * Copyright 2020 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {TensorBuffer} from '../tensor';\nimport {DataType, DataTypeMap, Rank, ShapeMap} from '../types';\nimport * as util from '../util';\n\n/**\n * Creates an empty `tf.TensorBuffer` with the specified `shape` and `dtype`.\n *\n * The values are stored in CPU as `TypedArray`. Fill the buffer using\n * `buffer.set()`, or by modifying directly `buffer.values`.\n *\n * When done, call `buffer.toTensor()` to get an immutable `tf.Tensor` with\n * those values.\n *\n * ```js\n * // Create a buffer and set values at particular indices.\n * const buffer = tf.buffer([2, 2]);\n * buffer.set(3, 0, 0);\n * buffer.set(5, 1, 0);\n *\n * // Convert the buffer back to a tensor.\n * buffer.toTensor().print();\n * ```\n *\n * @param shape An array of integers defining the output tensor shape.\n * @param dtype The dtype of the buffer. Defaults to 'float32'.\n * @param values The values of the buffer as `TypedArray`. Defaults to\n * zeros.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nexport function buffer<R extends Rank, D extends DataType = 'float32'>(\n    shape: ShapeMap[R], dtype: D = 'float32' as D,\n    values?: DataTypeMap[D]): TensorBuffer<R, D> {\n  dtype = dtype || 'float32' as D;\n  util.assertNonNegativeIntegerDimensions(shape);\n  return new TensorBuffer<R, D>(shape, dtype, values);\n}\n","/**\n * @license\n * Copyright 2020 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {ENGINE} from '../engine';\nimport {Cast, CastAttrs, CastInputs} from '../kernel_names';\nimport {NamedAttrMap} from '../kernel_registry';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {DataType, TensorLike} from '../types';\nimport * as util from '../util';\n\nimport {op} from './operation';\n\n/**\n * Casts a `tf.Tensor` to a new dtype.\n *\n * ```js\n * const x = tf.tensor1d([1.5, 2.5, 3]);\n * tf.cast(x, 'int32').print();\n * ```\n * @param x The input tensor to be casted.\n * @param dtype The dtype to cast the input tensor to.\n *\n * @doc {heading: 'Tensors', subheading: 'Transformations'}\n */\nfunction cast_<T extends Tensor>(x: T|TensorLike, dtype: DataType): T {\n  const $x = convertToTensor(x, 'x', 'cast');\n\n  // Sanity checks.\n  if (!util.isValidDtype(dtype)) {\n    throw new Error(`Failed to cast to unknown dtype ${dtype}`);\n  }\n  if (dtype === 'string' && $x.dtype !== 'string' ||\n      dtype !== 'string' && $x.dtype === 'string') {\n    throw new Error('Only strings can be casted to strings');\n  }\n\n  const inputs: CastInputs = {x: $x};\n  const attrs: CastAttrs = {dtype};\n\n  return ENGINE.runKernel(\n      Cast, inputs as {} as NamedTensorMap, attrs as {} as NamedAttrMap);\n}\n\nexport const cast = op({cast_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {Identity, IdentityInputs} from '../kernel_names';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {op} from './operation';\n\n/**\n * Creates a new tensor with the same values and shape as the specified\n * tensor.\n *\n * ```js\n * const x = tf.tensor([1, 2]);\n *\n * x.clone().print();\n * ```\n *\n * @param x The tensor to clone.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nfunction clone_<T extends Tensor>(x: T|TensorLike): T {\n  const $x = convertToTensor(x, 'x', 'clone', 'string_or_numeric');\n  const inputs: IdentityInputs = {x: $x};\n\n  // Note this op is called tf.identity in python. Hence the kernel name used\n  // here.\n  return ENGINE.runKernel(Identity, inputs as {} as NamedTensorMap);\n}\n\nexport const clone = op({clone_});\n","/**\n * @license\n * Copyright 2020 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor} from '../tensor';\n\n/**\n * Prints information about the `tf.Tensor` including its data.\n *\n * ```js\n * const verbose = true;\n * tf.tensor2d([1, 2, 3, 4], [2, 2]).print(verbose);\n * ```\n * @param x The tensor to be printed.\n * @param verbose Whether to print verbose information about the ` Tensor`,\n * including dtype and size.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nexport function print<T extends Tensor>(x: T, verbose = false): void {\n  console.log(x.toString(verbose));\n}\n","/**\n * @license\n * Copyright 2020 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n// Required side effectful code for tfjs-core\n\n// Set up Engine and ENV\nimport {getOrMakeEngine} from './engine';\ngetOrMakeEngine();\n\n// Register backend-agnostic flags.\nimport './flags';\n// Register platforms\nimport './platforms/platform_browser';\nimport './platforms/platform_node';\n\n// Set up OpHandler\nimport {buffer} from './ops/buffer';\nimport {cast} from './ops/cast';\nimport {clone} from './ops/clone';\nimport {print} from './ops/print';\nimport {OpHandler, setOpHandler} from './tensor';\nconst opHandler: OpHandler = {\n  buffer,\n  cast,\n  clone,\n  print\n};\nsetOpHandler(opHandler);\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n/**\n * IOHandlers related to files, such as browser-triggered file downloads,\n * user-selected files in browser.\n */\n\nimport '../flags';\nimport {env} from '../environment';\n\nimport {basename, concatenateArrayBuffers, getModelArtifactsForJSON, getModelArtifactsInfoForJSON, getModelJSONForModelArtifacts} from './io_utils';\nimport {IORouter, IORouterRegistry} from './router_registry';\nimport {IOHandler, ModelArtifacts, ModelJSON, SaveResult, WeightsManifestConfig, WeightsManifestEntry} from './types';\n\nconst DEFAULT_FILE_NAME_PREFIX = 'model';\nconst DEFAULT_JSON_EXTENSION_NAME = '.json';\nconst DEFAULT_WEIGHT_DATA_EXTENSION_NAME = '.weights.bin';\n\nfunction defer<T>(f: () => T): Promise<T> {\n  return new Promise(resolve => setTimeout(resolve)).then(f);\n}\n\nexport class BrowserDownloads implements IOHandler {\n  private readonly modelJsonFileName: string;\n  private readonly weightDataFileName: string;\n  private readonly modelJsonAnchor: HTMLAnchorElement;\n  private readonly weightDataAnchor: HTMLAnchorElement;\n\n  static readonly URL_SCHEME = 'downloads://';\n\n  constructor(fileNamePrefix?: string) {\n    if (!env().getBool('IS_BROWSER')) {\n      // TODO(cais): Provide info on what IOHandlers are available under the\n      //   current environment.\n      throw new Error(\n          'browserDownloads() cannot proceed because the current environment ' +\n          'is not a browser.');\n    }\n\n    if (fileNamePrefix.startsWith(BrowserDownloads.URL_SCHEME)) {\n      fileNamePrefix = fileNamePrefix.slice(BrowserDownloads.URL_SCHEME.length);\n    }\n    if (fileNamePrefix == null || fileNamePrefix.length === 0) {\n      fileNamePrefix = DEFAULT_FILE_NAME_PREFIX;\n    }\n\n    this.modelJsonFileName = fileNamePrefix + DEFAULT_JSON_EXTENSION_NAME;\n    this.weightDataFileName =\n        fileNamePrefix + DEFAULT_WEIGHT_DATA_EXTENSION_NAME;\n  }\n\n  async save(modelArtifacts: ModelArtifacts): Promise<SaveResult> {\n    if (typeof (document) === 'undefined') {\n      throw new Error(\n          'Browser downloads are not supported in ' +\n          'this environment since `document` is not present');\n    }\n    const weightsURL = window.URL.createObjectURL(new Blob(\n        [modelArtifacts.weightData], {type: 'application/octet-stream'}));\n\n    if (modelArtifacts.modelTopology instanceof ArrayBuffer) {\n      throw new Error(\n          'BrowserDownloads.save() does not support saving model topology ' +\n          'in binary formats yet.');\n    } else {\n      const weightsManifest: WeightsManifestConfig = [{\n        paths: ['./' + this.weightDataFileName],\n        weights: modelArtifacts.weightSpecs\n      }];\n      const modelJSON: ModelJSON =\n          getModelJSONForModelArtifacts(modelArtifacts, weightsManifest);\n\n      const modelJsonURL = window.URL.createObjectURL(\n          new Blob([JSON.stringify(modelJSON)], {type: 'application/json'}));\n\n      // If anchor elements are not provided, create them without attaching them\n      // to parents, so that the downloaded file names can be controlled.\n      const jsonAnchor = this.modelJsonAnchor == null ?\n          document.createElement('a') :\n          this.modelJsonAnchor;\n      jsonAnchor.download = this.modelJsonFileName;\n      jsonAnchor.href = modelJsonURL;\n      // Trigger downloads by evoking a click event on the download anchors.\n      // When multiple downloads are started synchronously, Firefox will only\n      // save the last one.\n      await defer(() => jsonAnchor.dispatchEvent(new MouseEvent('click')));\n\n      if (modelArtifacts.weightData != null) {\n        const weightDataAnchor = this.weightDataAnchor == null ?\n            document.createElement('a') :\n            this.weightDataAnchor;\n        weightDataAnchor.download = this.weightDataFileName;\n        weightDataAnchor.href = weightsURL;\n        await defer(\n            () => weightDataAnchor.dispatchEvent(new MouseEvent('click')));\n      }\n\n      return {modelArtifactsInfo: getModelArtifactsInfoForJSON(modelArtifacts)};\n    }\n  }\n}\n\nclass BrowserFiles implements IOHandler {\n  private readonly jsonFile: File;\n  private readonly weightsFiles: File[];\n\n  constructor(files: File[]) {\n    if (files == null || files.length < 1) {\n      throw new Error(\n          `When calling browserFiles, at least 1 file is required, ` +\n          `but received ${files}`);\n    }\n    this.jsonFile = files[0];\n    this.weightsFiles = files.slice(1);\n  }\n\n  async load(): Promise<ModelArtifacts> {\n    return new Promise((resolve, reject) => {\n      const jsonReader = new FileReader();\n      jsonReader.onload = (event: Event) => {\n        // tslint:disable-next-line:no-any\n        const modelJSON = JSON.parse((event.target as any).result) as ModelJSON;\n\n        const modelTopology = modelJSON.modelTopology;\n        if (modelTopology == null) {\n          reject(new Error(`modelTopology field is missing from file ${\n              this.jsonFile.name}`));\n          return;\n        }\n\n        const weightsManifest = modelJSON.weightsManifest;\n        if (weightsManifest == null) {\n          reject(new Error(`weightManifest field is missing from file ${\n              this.jsonFile.name}`));\n          return;\n        }\n\n        if (this.weightsFiles.length === 0) {\n          resolve({modelTopology});\n          return;\n        }\n\n        const modelArtifactsPromise = getModelArtifactsForJSON(\n            modelJSON, (weightsManifest) => this.loadWeights(weightsManifest));\n        resolve(modelArtifactsPromise);\n      };\n\n      jsonReader.onerror = error => reject(\n          `Failed to read model topology and weights manifest JSON ` +\n          `from file '${this.jsonFile.name}'. BrowserFiles supports loading ` +\n          `Keras-style tf.Model artifacts only.`);\n      jsonReader.readAsText(this.jsonFile);\n    });\n  }\n\n  private loadWeights(weightsManifest: WeightsManifestConfig): Promise<[\n    /* weightSpecs */ WeightsManifestEntry[], /* weightData */ ArrayBuffer\n  ]> {\n    const weightSpecs: WeightsManifestEntry[] = [];\n    const paths: string[] = [];\n    for (const entry of weightsManifest) {\n      weightSpecs.push(...entry.weights);\n      paths.push(...entry.paths);\n    }\n\n    const pathToFile: {[path: string]: File} =\n        this.checkManifestAndWeightFiles(weightsManifest);\n\n    const promises: Array<Promise<ArrayBuffer>> =\n        paths.map(path => this.loadWeightsFile(path, pathToFile[path]));\n\n    return Promise.all(promises).then(\n        buffers => [weightSpecs, concatenateArrayBuffers(buffers)]);\n  }\n\n  private loadWeightsFile(path: string, file: File): Promise<ArrayBuffer> {\n    return new Promise((resolve, reject) => {\n      const weightFileReader = new FileReader();\n      weightFileReader.onload = (event: Event) => {\n        // tslint:disable-next-line:no-any\n        const weightData = (event.target as any).result as ArrayBuffer;\n        resolve(weightData);\n      };\n      weightFileReader.onerror = error =>\n          reject(`Failed to weights data from file of path '${path}'.`);\n      weightFileReader.readAsArrayBuffer(file);\n    });\n  }\n\n  /**\n   * Check the compatibility between weights manifest and weight files.\n   */\n  private checkManifestAndWeightFiles(manifest: WeightsManifestConfig):\n      {[path: string]: File} {\n    const basenames: string[] = [];\n    const fileNames = this.weightsFiles.map(file => basename(file.name));\n    const pathToFile: {[path: string]: File} = {};\n    for (const group of manifest) {\n      group.paths.forEach(path => {\n        const pathBasename = basename(path);\n        if (basenames.indexOf(pathBasename) !== -1) {\n          throw new Error(\n              `Duplicate file basename found in weights manifest: ` +\n              `'${pathBasename}'`);\n        }\n        basenames.push(pathBasename);\n        if (fileNames.indexOf(pathBasename) === -1) {\n          throw new Error(\n              `Weight file with basename '${pathBasename}' is not provided.`);\n        } else {\n          pathToFile[path] = this.weightsFiles[fileNames.indexOf(pathBasename)];\n        }\n      });\n    }\n\n    if (basenames.length !== this.weightsFiles.length) {\n      throw new Error(\n          `Mismatch in the number of files in weights manifest ` +\n          `(${basenames.length}) and the number of weight files provided ` +\n          `(${this.weightsFiles.length}).`);\n    }\n    return pathToFile;\n  }\n}\n\nexport const browserDownloadsRouter: IORouter = (url: string|string[]) => {\n  if (!env().getBool('IS_BROWSER')) {\n    return null;\n  } else {\n    if (!Array.isArray(url) && url.startsWith(BrowserDownloads.URL_SCHEME)) {\n      return browserDownloads(url.slice(BrowserDownloads.URL_SCHEME.length));\n    } else {\n      return null;\n    }\n  }\n};\nIORouterRegistry.registerSaveRouter(browserDownloadsRouter);\n\n/**\n * Creates an IOHandler that triggers file downloads from the browser.\n *\n * The returned `IOHandler` instance can be used as model exporting methods such\n * as `tf.Model.save` and supports only saving.\n *\n * ```js\n * const model = tf.sequential();\n * model.add(tf.layers.dense(\n *     {units: 1, inputShape: [10], activation: 'sigmoid'}));\n * const saveResult = await model.save('downloads://mymodel');\n * // This will trigger downloading of two files:\n * //   'mymodel.json' and 'mymodel.weights.bin'.\n * console.log(saveResult);\n * ```\n *\n * @param fileNamePrefix Prefix name of the files to be downloaded. For use with\n *   `tf.Model`, `fileNamePrefix` should follow either of the following two\n *   formats:\n *   1. `null` or `undefined`, in which case the default file\n *      names will be used:\n *      - 'model.json' for the JSON file containing the model topology and\n *        weights manifest.\n *      - 'model.weights.bin' for the binary file containing the binary weight\n *        values.\n *   2. A single string or an Array of a single string, as the file name prefix.\n *      For example, if `'foo'` is provided, the downloaded JSON\n *      file and binary weights file will be named 'foo.json' and\n *      'foo.weights.bin', respectively.\n * @param config Additional configuration for triggering downloads.\n * @returns An instance of `BrowserDownloads` `IOHandler`.\n *\n * @doc {\n *   heading: 'Models',\n *   subheading: 'Loading',\n *   namespace: 'io',\n *   ignoreCI: true\n * }\n */\nexport function browserDownloads(fileNamePrefix = 'model'): IOHandler {\n  return new BrowserDownloads(fileNamePrefix);\n}\n\n/**\n * Creates an IOHandler that loads model artifacts from user-selected files.\n *\n * This method can be used for loading from files such as user-selected files\n * in the browser.\n * When used in conjunction with `tf.loadLayersModel`, an instance of\n * `tf.LayersModel` (Keras-style) can be constructed from the loaded artifacts.\n *\n * ```js\n * // Note: This code snippet won't run properly without the actual file input\n * //   elements in the HTML DOM.\n *\n * // Suppose there are two HTML file input (`<input type=\"file\" ...>`)\n * // elements.\n * const uploadJSONInput = document.getElementById('upload-json');\n * const uploadWeightsInput = document.getElementById('upload-weights');\n * const model = await tf.loadLayersModel(tf.io.browserFiles(\n *     [uploadJSONInput.files[0], uploadWeightsInput.files[0]]));\n * ```\n *\n * @param files `File`s to load from. Currently, this function supports only\n *   loading from files that contain Keras-style models (i.e., `tf.Model`s), for\n *   which an `Array` of `File`s is expected (in that order):\n *   - A JSON file containing the model topology and weight manifest.\n *   - Optionally, one or more binary files containing the binary weights.\n *     These files must have names that match the paths in the `weightsManifest`\n *     contained by the aforementioned JSON file, or errors will be thrown\n *     during loading. These weights files have the same format as the ones\n *     generated by `tensorflowjs_converter` that comes with the `tensorflowjs`\n *     Python PIP package. If no weights files are provided, only the model\n *     topology will be loaded from the JSON file above.\n * @returns An instance of `Files` `IOHandler`.\n *\n * @doc {\n *   heading: 'Models',\n *   subheading: 'Loading',\n *   namespace: 'io',\n *   ignoreCI: true\n * }\n */\nexport function browserFiles(files: File[]): IOHandler {\n  return new BrowserFiles(files);\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {assert} from '../util';\n\nimport {OnProgressCallback} from './types';\n\n/**\n * Monitor Promise.all progress, fire onProgress callback function.\n *\n * @param promises Promise list going to be monitored\n * @param onProgress Callback function. Fired when a promise resolved.\n * @param startFraction Optional fraction start. Default to 0.\n * @param endFraction Optional fraction end. Default to 1.\n */\nexport function monitorPromisesProgress(\n    promises: Array<Promise<{}|void>>, onProgress: OnProgressCallback,\n    startFraction?: number, endFraction?: number) {\n  checkPromises(promises);\n  startFraction = startFraction == null ? 0 : startFraction;\n  endFraction = endFraction == null ? 1 : endFraction;\n  checkFraction(startFraction, endFraction);\n  let resolvedPromise = 0;\n\n  const registerMonitor = (promise: Promise<{}>) => {\n    promise.then(value => {\n      const fraction = startFraction +\n          ++resolvedPromise / promises.length * (endFraction - startFraction);\n      // pass fraction as parameter to callback function.\n      onProgress(fraction);\n      return value;\n    });\n    return promise;\n  };\n\n  function checkPromises(promises: Array<Promise<{}|void>>): void {\n    assert(\n        promises != null && Array.isArray(promises) && promises.length > 0,\n        () => 'promises must be a none empty array');\n  }\n\n  function checkFraction(startFraction: number, endFraction: number): void {\n    assert(\n        startFraction >= 0 && startFraction <= 1,\n        () => `Progress fraction must be in range [0, 1], but ` +\n            `got startFraction ${startFraction}`);\n    assert(\n        endFraction >= 0 && endFraction <= 1,\n        () => `Progress fraction must be in range [0, 1], but ` +\n            `got endFraction ${endFraction}`);\n    assert(\n        endFraction >= startFraction,\n        () => `startFraction must be no more than endFraction, but ` +\n            `got startFraction ${startFraction} and endFraction ` +\n            `${endFraction}`);\n  }\n\n  return Promise.all(promises.map(registerMonitor));\n}\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {env} from '../environment';\n\nimport {NamedTensorMap} from '../tensor_types';\nimport * as util from '../util';\nimport {decodeWeights} from './io_utils';\nimport {monitorPromisesProgress} from './progress';\nimport {DTYPE_VALUE_SIZE_MAP, LoadOptions, WeightsManifestConfig, WeightsManifestEntry} from './types';\n\n/**\n * Reads binary weights data from a number of URLs.\n *\n * @param fetchURLs URLs to send the HTTP requests at, using `fetch` calls.\n * @param requestOptions RequestInit (options) for the HTTP requests.\n * @param fetchFunc Optional overriding value for the `window.fetch` function.\n * @param onProgress Optional, progress callback function, fired periodically\n *   before the load is completed.\n * @returns A `Promise` of an Array of `ArrayBuffer`. The Array has the same\n *   length as `fetchURLs`.\n */\nexport async function loadWeightsAsArrayBuffer(\n    fetchURLs: string[], loadOptions?: LoadOptions): Promise<ArrayBuffer[]> {\n  if (loadOptions == null) {\n    loadOptions = {};\n  }\n\n  const fetchFunc = loadOptions.fetchFunc == null ? env().platform.fetch :\n                                                    loadOptions.fetchFunc;\n\n  // Create the requests for all of the weights in parallel.\n  const requests = fetchURLs.map(\n      fetchURL =>\n          fetchFunc(fetchURL, loadOptions.requestInit, {isBinary: true}));\n\n  const fetchStartFraction = 0;\n  const fetchEndFraction = 0.5;\n\n  const responses = loadOptions.onProgress == null ?\n      await Promise.all(requests) :\n      await monitorPromisesProgress(\n          requests, loadOptions.onProgress, fetchStartFraction,\n          fetchEndFraction);\n\n  const bufferPromises = responses.map(response => response.arrayBuffer());\n\n  const bufferStartFraction = 0.5;\n  const bufferEndFraction = 1;\n\n  const buffers = loadOptions.onProgress == null ?\n      await Promise.all(bufferPromises) :\n      await monitorPromisesProgress(\n          bufferPromises, loadOptions.onProgress, bufferStartFraction,\n          bufferEndFraction);\n  return buffers;\n}\n\n/**\n * Reads a weights manifest JSON configuration, fetches the weights and\n * returns them as `Tensor`s.\n *\n * @param manifest The weights manifest JSON.\n * @param filePathPrefix The path prefix for filenames given in the manifest.\n *     Defaults to the empty string.\n * @param weightNames The names of the weights to be fetched.\n */\nexport async function loadWeights(\n    manifest: WeightsManifestConfig, filePathPrefix = '',\n    weightNames?: string[],\n    requestInit?: RequestInit): Promise<NamedTensorMap> {\n  // TODO(nsthorat): Groups are currently fetched atomically. If you need a\n  // single weight from a group, the whole group will be fetched. At a future\n  // date, we should support fetching only the individual shards within a\n  // group that are needed to reconstruct the requested weight.\n  // TODO(cais): Use `decodeWeights` for implementation.\n\n  const fetchWeights = (fetchUrls: string[]) =>\n      loadWeightsAsArrayBuffer(fetchUrls, {requestInit});\n  const loadWeights = weightsLoaderFactory(fetchWeights);\n\n  return loadWeights(manifest, filePathPrefix, weightNames);\n}\n\n/**\n * Creates a function, which reads a weights manifest JSON configuration,\n * fetches the weight files using the specified function and returns them as\n * `Tensor`s.\n *\n * ```js\n * // example for creating a nodejs weight loader, which reads the weight files\n * // from disk using fs.readFileSync\n *\n * import * as fs from 'fs'\n *\n * const fetchWeightsFromDisk = (filePaths: string[]) =>\n *   filePaths.map(filePath => fs.readFileSync(filePath).buffer)\n *\n * const loadWeights = tf.io.weightsLoaderFactory(fetchWeightsFromDisk)\n *\n * const manifest = JSON.parse(\n *   fs.readFileSync('./my_model-weights_manifest').toString()\n * )\n * const weightMap = await loadWeights(manifest, './')\n * ```\n * @param fetchWeightsFunction The function used for fetching the weight files.\n * @returns Weight loading function.\n */\nexport function weightsLoaderFactory(\n    fetchWeightsFunction: (fetchUrls: string[]) => Promise<ArrayBuffer[]>):\n    (manifest: WeightsManifestConfig, filePathPrefix?: string,\n     weightNames?: string[]) => Promise<NamedTensorMap> {\n  return async(\n             manifest: WeightsManifestConfig, filePathPrefix = '',\n             weightNames?: string[]): Promise<NamedTensorMap> => {\n    // Collect all the groups, weights, and their relative offsets to be\n    // fetched.\n    const groupIndicesToFetchMap = manifest.map(() => false);\n    const groupWeightsToFetch: {\n      [group: number]: Array<{\n        manifestEntry: WeightsManifestEntry; groupOffset: number;\n        sizeBytes: number;\n      }>\n    } = {};\n    const weightsFound =\n        weightNames != null ? weightNames.map(() => false) : [];\n    const allManifestWeightNames: string[] = [];\n    manifest.forEach((manifestGroupConfig, groupIndex) => {\n      let groupOffset = 0;\n      manifestGroupConfig.weights.forEach(weightsEntry => {\n        const rawDtype = ('quantization' in weightsEntry) ?\n            weightsEntry.quantization.dtype :\n            weightsEntry.dtype;\n\n        const weightsBytes = DTYPE_VALUE_SIZE_MAP[rawDtype] *\n            util.sizeFromShape(weightsEntry.shape);\n\n        const enqueueWeightsForFetchingFn = () => {\n          groupIndicesToFetchMap[groupIndex] = true;\n          if (groupWeightsToFetch[groupIndex] == null) {\n            groupWeightsToFetch[groupIndex] = [];\n          }\n\n          groupWeightsToFetch[groupIndex].push({\n            manifestEntry: weightsEntry,\n            groupOffset,\n            sizeBytes: weightsBytes\n          });\n        };\n\n        if (weightNames != null) {\n          weightNames.forEach((weightName, weightIndex) => {\n            if (weightName === weightsEntry.name) {\n              enqueueWeightsForFetchingFn();\n              weightsFound[weightIndex] = true;\n            }\n          });\n        } else {\n          enqueueWeightsForFetchingFn();\n        }\n\n        allManifestWeightNames.push(weightsEntry.name);\n        groupOffset += weightsBytes;\n      });\n    });\n\n    if (!weightsFound.every(found => found)) {\n      const weightsNotFound = weightNames.filter((_, i) => !weightsFound[i]);\n      throw new Error(\n          `Could not find weights in manifest with names: ` +\n          `${weightsNotFound.join(', ')}. \\n` +\n          `Manifest JSON has weights with names: ` +\n          `${allManifestWeightNames.join(', ')}.`);\n    }\n\n    // Convert the one-hot boolean groupId => shouldFetch map to a list of group\n    // IDs.\n    const groupIndicesToFetch =\n        groupIndicesToFetchMap.reduce((accumulator, shouldFetch, i) => {\n          if (shouldFetch) {\n            accumulator.push(i);\n          }\n          return accumulator;\n        }, []);\n\n    const fetchUrls: string[] = [];\n    groupIndicesToFetch.forEach(i => {\n      manifest[i].paths.forEach(filepath => {\n        const fetchUrl = filePathPrefix +\n            (!filePathPrefix.endsWith('/') ? '/' : '') + filepath;\n        fetchUrls.push(fetchUrl);\n      });\n    });\n    const buffers = await fetchWeightsFunction(fetchUrls);\n\n    const weightsTensorMap: NamedTensorMap = {};\n    let bufferIndexOffset = 0;\n    groupIndicesToFetch.forEach(i => {\n      const numBuffers = manifest[i].paths.length;\n\n      let groupBytes = 0;\n      for (let i = 0; i < numBuffers; i++) {\n        groupBytes += buffers[bufferIndexOffset + i].byteLength;\n      }\n\n      // Create a buffer for the whole group.\n      const groupBuffer = new ArrayBuffer(groupBytes);\n      const groupByteBuffer = new Uint8Array(groupBuffer);\n      let groupBufferOffset = 0;\n      for (let i = 0; i < numBuffers; i++) {\n        const buffer = new Uint8Array(buffers[bufferIndexOffset + i]);\n        groupByteBuffer.set(buffer, groupBufferOffset);\n        groupBufferOffset += buffer.byteLength;\n      }\n\n      const weightsEntries = groupWeightsToFetch[i];\n      weightsEntries.forEach(weightsEntry => {\n        const byteBuffer = groupBuffer.slice(\n            weightsEntry.groupOffset,\n            weightsEntry.groupOffset + weightsEntry.sizeBytes);\n        const nameToTensorMap =\n            decodeWeights(byteBuffer, [weightsEntry.manifestEntry]);\n        for (const name in nameToTensorMap) {\n          weightsTensorMap[name] = nameToTensorMap[name];\n        }\n      });\n\n      bufferIndexOffset += numBuffers;\n    });\n\n    return weightsTensorMap;\n  };\n}\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n/**\n * IOHandler implementations based on HTTP requests in the web browser.\n *\n * Uses [`fetch`](https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API).\n */\n\nimport {env} from '../environment';\n\nimport {assert} from '../util';\nimport {concatenateArrayBuffers, getModelArtifactsForJSON, getModelArtifactsInfoForJSON, getModelJSONForModelArtifacts, getWeightSpecs} from './io_utils';\nimport {IORouter, IORouterRegistry} from './router_registry';\nimport {IOHandler, LoadOptions, ModelArtifacts, ModelJSON, OnProgressCallback, SaveResult, WeightsManifestConfig, WeightsManifestEntry} from './types';\nimport {loadWeightsAsArrayBuffer} from './weights_loader';\n\nconst OCTET_STREAM_MIME_TYPE = 'application/octet-stream';\nconst JSON_TYPE = 'application/json';\nexport class HTTPRequest implements IOHandler {\n  protected readonly path: string;\n  protected readonly requestInit: RequestInit;\n\n  private readonly fetch: Function;\n  private readonly weightUrlConverter: (weightName: string) => Promise<string>;\n\n  readonly DEFAULT_METHOD = 'POST';\n\n  static readonly URL_SCHEME_REGEX = /^https?:\\/\\//;\n\n  private readonly weightPathPrefix: string;\n  private readonly onProgress: OnProgressCallback;\n\n  constructor(path: string, loadOptions?: LoadOptions) {\n    if (loadOptions == null) {\n      loadOptions = {};\n    }\n    this.weightPathPrefix = loadOptions.weightPathPrefix;\n    this.onProgress = loadOptions.onProgress;\n    this.weightUrlConverter = loadOptions.weightUrlConverter;\n\n    if (loadOptions.fetchFunc != null) {\n      assert(\n          typeof loadOptions.fetchFunc === 'function',\n          () => 'Must pass a function that matches the signature of ' +\n              '`fetch` (see ' +\n              'https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API)');\n      this.fetch = loadOptions.fetchFunc;\n    } else {\n      this.fetch = env().platform.fetch;\n    }\n\n    assert(\n        path != null && path.length > 0,\n        () => 'URL path for http must not be null, undefined or ' +\n            'empty.');\n\n    if (Array.isArray(path)) {\n      assert(\n          path.length === 2,\n          () => 'URL paths for http must have a length of 2, ' +\n              `(actual length is ${path.length}).`);\n    }\n    this.path = path;\n\n    if (loadOptions.requestInit != null &&\n        loadOptions.requestInit.body != null) {\n      throw new Error(\n          'requestInit is expected to have no pre-existing body, but has one.');\n    }\n    this.requestInit = loadOptions.requestInit || {};\n  }\n\n  async save(modelArtifacts: ModelArtifacts): Promise<SaveResult> {\n    if (modelArtifacts.modelTopology instanceof ArrayBuffer) {\n      throw new Error(\n          'BrowserHTTPRequest.save() does not support saving model topology ' +\n          'in binary formats yet.');\n    }\n\n    const init = Object.assign({method: this.DEFAULT_METHOD}, this.requestInit);\n    init.body = new FormData();\n\n    const weightsManifest: WeightsManifestConfig = [{\n      paths: ['./model.weights.bin'],\n      weights: modelArtifacts.weightSpecs,\n    }];\n    const modelTopologyAndWeightManifest: ModelJSON =\n        getModelJSONForModelArtifacts(modelArtifacts, weightsManifest);\n\n    init.body.append(\n        'model.json',\n        new Blob(\n            [JSON.stringify(modelTopologyAndWeightManifest)],\n            {type: JSON_TYPE}),\n        'model.json');\n\n    if (modelArtifacts.weightData != null) {\n      init.body.append(\n          'model.weights.bin',\n          new Blob([modelArtifacts.weightData], {type: OCTET_STREAM_MIME_TYPE}),\n          'model.weights.bin');\n    }\n\n    const response = await this.fetch(this.path, init);\n\n    if (response.ok) {\n      return {\n        modelArtifactsInfo: getModelArtifactsInfoForJSON(modelArtifacts),\n        responses: [response],\n      };\n    } else {\n      throw new Error(\n          `BrowserHTTPRequest.save() failed due to HTTP response status ` +\n          `${response.status}.`);\n    }\n  }\n\n  /**\n   * Load model artifacts via HTTP request(s).\n   *\n   * See the documentation to `tf.io.http` for details on the saved\n   * artifacts.\n   *\n   * @returns The loaded model artifacts (if loading succeeds).\n   */\n  async load(): Promise<ModelArtifacts> {\n    const modelConfigRequest = await this.fetch(this.path, this.requestInit);\n\n    if (!modelConfigRequest.ok) {\n      throw new Error(\n          `Request to ${this.path} failed with status code ` +\n          `${modelConfigRequest.status}. Please verify this URL points to ` +\n          `the model JSON of the model to load.`);\n    }\n    let modelJSON: ModelJSON;\n    try {\n      modelJSON = await modelConfigRequest.json();\n    } catch (e) {\n      let message = `Failed to parse model JSON of response from ${this.path}.`;\n      // TODO(nsthorat): Remove this after some time when we're comfortable that\n      // .pb files are mostly gone.\n      if (this.path.endsWith('.pb')) {\n        message += ' Your path contains a .pb file extension. ' +\n            'Support for .pb models have been removed in TensorFlow.js 1.0 ' +\n            'in favor of .json models. You can re-convert your Python ' +\n            'TensorFlow model using the TensorFlow.js 1.0 conversion scripts ' +\n            'or you can convert your.pb models with the \\'pb2json\\'' +\n            'NPM script in the tensorflow/tfjs-converter repository.';\n      } else {\n        message += ' Please make sure the server is serving valid ' +\n            'JSON for this request.';\n      }\n      throw new Error(message);\n    }\n\n    // We do not allow both modelTopology and weightsManifest to be missing.\n    const modelTopology = modelJSON.modelTopology;\n    const weightsManifest = modelJSON.weightsManifest;\n    if (modelTopology == null && weightsManifest == null) {\n      throw new Error(\n          `The JSON from HTTP path ${this.path} contains neither model ` +\n          `topology or manifest for weights.`);\n    }\n\n    return getModelArtifactsForJSON(\n        modelJSON, (weightsManifest) => this.loadWeights(weightsManifest));\n  }\n\n  private async loadWeights(weightsManifest: WeightsManifestConfig):\n      Promise<[WeightsManifestEntry[], ArrayBuffer]> {\n    const weightPath = Array.isArray(this.path) ? this.path[1] : this.path;\n    const [prefix, suffix] = parseUrl(weightPath);\n    const pathPrefix = this.weightPathPrefix || prefix;\n\n    const weightSpecs = getWeightSpecs(weightsManifest);\n\n    const fetchURLs: string[] = [];\n    const urlPromises: Array<Promise<string>> = [];\n    for (const weightsGroup of weightsManifest) {\n      for (const path of weightsGroup.paths) {\n        if (this.weightUrlConverter != null) {\n          urlPromises.push(this.weightUrlConverter(path));\n        } else {\n          fetchURLs.push(pathPrefix + path + suffix);\n        }\n      }\n    }\n\n    if (this.weightUrlConverter) {\n      fetchURLs.push(...await Promise.all(urlPromises));\n    }\n\n    const buffers = await loadWeightsAsArrayBuffer(fetchURLs, {\n      requestInit: this.requestInit,\n      fetchFunc: this.fetch,\n      onProgress: this.onProgress\n    });\n    return [weightSpecs, concatenateArrayBuffers(buffers)];\n  }\n}\n\n/**\n * Extract the prefix and suffix of the url, where the prefix is the path before\n * the last file, and suffix is the search params after the last file.\n * ```\n * const url = 'http://tfhub.dev/model/1/tensorflowjs_model.pb?tfjs-format=file'\n * [prefix, suffix] = parseUrl(url)\n * // prefix = 'http://tfhub.dev/model/1/'\n * // suffix = '?tfjs-format=file'\n * ```\n * @param url the model url to be parsed.\n */\nexport function parseUrl(url: string): [string, string] {\n  const lastSlash = url.lastIndexOf('/');\n  const lastSearchParam = url.lastIndexOf('?');\n  const prefix = url.substring(0, lastSlash);\n  const suffix =\n      lastSearchParam > lastSlash ? url.substring(lastSearchParam) : '';\n  return [prefix + '/', suffix];\n}\n\nexport function isHTTPScheme(url: string): boolean {\n  return url.match(HTTPRequest.URL_SCHEME_REGEX) != null;\n}\n\nexport const httpRouter: IORouter =\n    (url: string, loadOptions?: LoadOptions) => {\n      if (typeof fetch === 'undefined' &&\n          (loadOptions == null || loadOptions.fetchFunc == null)) {\n        // `http` uses `fetch` or `node-fetch`, if one wants to use it in\n        // an environment that is not the browser or node they have to setup a\n        // global fetch polyfill.\n        return null;\n      } else {\n        let isHTTP = true;\n        if (Array.isArray(url)) {\n          isHTTP = url.every(urlItem => isHTTPScheme(urlItem));\n        } else {\n          isHTTP = isHTTPScheme(url);\n        }\n        if (isHTTP) {\n          return http(url, loadOptions);\n        }\n      }\n      return null;\n    };\nIORouterRegistry.registerSaveRouter(httpRouter);\nIORouterRegistry.registerLoadRouter(httpRouter);\n\n/**\n * Creates an IOHandler subtype that sends model artifacts to HTTP server.\n *\n * An HTTP request of the `multipart/form-data` mime type will be sent to the\n * `path` URL. The form data includes artifacts that represent the topology\n * and/or weights of the model. In the case of Keras-style `tf.Model`, two\n * blobs (files) exist in form-data:\n *   - A JSON file consisting of `modelTopology` and `weightsManifest`.\n *   - A binary weights file consisting of the concatenated weight values.\n * These files are in the same format as the one generated by\n * [tfjs_converter](https://js.tensorflow.org/tutorials/import-keras.html).\n *\n * The following code snippet exemplifies the client-side code that uses this\n * function:\n *\n * ```js\n * const model = tf.sequential();\n * model.add(\n *     tf.layers.dense({units: 1, inputShape: [100], activation: 'sigmoid'}));\n *\n * const saveResult = await model.save(tf.io.http(\n *     'http://model-server:5000/upload', {requestInit: {method: 'PUT'}}));\n * console.log(saveResult);\n * ```\n *\n * If the default `POST` method is to be used, without any custom parameters\n * such as headers, you can simply pass an HTTP or HTTPS URL to `model.save`:\n *\n * ```js\n * const saveResult = await model.save('http://model-server:5000/upload');\n * ```\n *\n * The following GitHub Gist\n * https://gist.github.com/dsmilkov/1b6046fd6132d7408d5257b0976f7864\n * implements a server based on [flask](https://github.com/pallets/flask) that\n * can receive the request. Upon receiving the model artifacts via the requst,\n * this particular server reconstitutes instances of [Keras\n * Models](https://keras.io/models/model/) in memory.\n *\n *\n * @param path A URL path to the model.\n *   Can be an absolute HTTP path (e.g.,\n *   'http://localhost:8000/model-upload)') or a relative path (e.g.,\n *   './model-upload').\n * @param requestInit Request configurations to be used when sending\n *    HTTP request to server using `fetch`. It can contain fields such as\n *    `method`, `credentials`, `headers`, `mode`, etc. See\n *    https://developer.mozilla.org/en-US/docs/Web/API/Request/Request\n *    for more information. `requestInit` must not have a body, because the\n * body will be set by TensorFlow.js. File blobs representing the model\n * topology (filename: 'model.json') and the weights of the model (filename:\n * 'model.weights.bin') will be appended to the body. If `requestInit` has a\n * `body`, an Error will be thrown.\n * @param loadOptions Optional configuration for the loading. It includes the\n *   following fields:\n *   - weightPathPrefix Optional, this specifies the path prefix for weight\n *     files, by default this is calculated from the path param.\n *   - fetchFunc Optional, custom `fetch` function. E.g., in Node.js,\n *     the `fetch` from node-fetch can be used here.\n *   - onProgress Optional, progress callback function, fired periodically\n *     before the load is completed.\n * @returns An instance of `IOHandler`.\n *\n * @doc {\n *   heading: 'Models',\n *   subheading: 'Loading',\n *   namespace: 'io',\n *   ignoreCI: true\n * }\n */\nexport function http(path: string, loadOptions?: LoadOptions): IOHandler {\n  return new HTTPRequest(path, loadOptions);\n}\n\n/**\n * Deprecated. Use `tf.io.http`.\n * @param path\n * @param loadOptions\n */\nexport function browserHTTPRequest(\n    path: string, loadOptions?: LoadOptions): IOHandler {\n  return http(path, loadOptions);\n}\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n/**\n * IOHandlers that pass through the in-memory ModelArtifacts format.\n */\n\nimport {IOHandler, IOHandlerSync, LoadHandler, ModelArtifacts, SaveHandler, SaveResult, TrainingConfig, WeightsManifestEntry} from './types';\n\nclass PassthroughLoader implements IOHandlerSync {\n  constructor(private readonly modelArtifacts?: ModelArtifacts) {}\n\n  load(): ModelArtifacts {\n    return this.modelArtifacts;\n  }\n}\n\nclass PassthroughSaver<R extends SaveResult | Promise<SaveResult>> {\n  constructor(\n    private readonly saveHandler: (artifacts: ModelArtifacts) => R) {}\n\n  save(modelArtifacts: ModelArtifacts): R {\n    return this.saveHandler(modelArtifacts);\n  }\n}\n\nclass PassthroughAsync implements IOHandler {\n  load?: LoadHandler;\n  save?: SaveHandler;\n\n  constructor(handler: IOHandlerSync) {\n    if (handler.load) {\n      this.load = () => Promise.resolve(handler.load());\n    }\n    if (handler.save) {\n      this.save = (modelArtifacts: ModelArtifacts) =>\n        Promise.resolve(handler.save(modelArtifacts));\n    }\n  }\n}\n\n/**\n * Creates an IOHandler that loads model artifacts from memory.\n *\n * When used in conjunction with `tf.loadLayersModel`, an instance of\n * `tf.LayersModel` (Keras-style) can be constructed from the loaded artifacts.\n *\n * ```js\n * const model = await tf.loadLayersModel(tf.io.fromMemory(\n *     modelTopology, weightSpecs, weightData));\n * ```\n *\n * @param modelArtifacts a object containing model topology (i.e., parsed from\n *   the JSON format).\n * @param weightSpecs An array of `WeightsManifestEntry` objects describing the\n *   names, shapes, types, and quantization of the weight data. Optional.\n * @param weightData A single `ArrayBuffer` containing the weight data,\n *   concatenated in the order described by the weightSpecs. Optional.\n * @param trainingConfig Model training configuration. Optional.\n *\n * @returns A passthrough `IOHandler` that simply loads the provided data.\n */\nexport function fromMemory(\n    modelArtifacts: {}|ModelArtifacts, weightSpecs?: WeightsManifestEntry[],\n    weightData?: ArrayBuffer, trainingConfig?: TrainingConfig): IOHandler {\n\n  const args = arguments as unknown as Parameters<typeof fromMemory>;\n  return new PassthroughAsync(fromMemorySync(...args));\n}\n\n/**\n * Creates an IOHandler that loads model artifacts from memory.\n *\n * When used in conjunction with `tf.loadLayersModel`, an instance of\n * `tf.LayersModel` (Keras-style) can be constructed from the loaded artifacts.\n *\n * ```js\n * const model = await tf.loadLayersModel(tf.io.fromMemory(\n *     modelTopology, weightSpecs, weightData));\n * ```\n *\n * @param modelArtifacts a object containing model topology (i.e., parsed from\n *   the JSON format).\n * @param weightSpecs An array of `WeightsManifestEntry` objects describing the\n *   names, shapes, types, and quantization of the weight data. Optional.\n * @param weightData A single `ArrayBuffer` containing the weight data,\n *   concatenated in the order described by the weightSpecs. Optional.\n * @param trainingConfig Model training configuration. Optional.\n *\n * @returns A passthrough `IOHandlerSync` that simply loads the provided data.\n */\nexport function fromMemorySync(\n    modelArtifacts: {}|ModelArtifacts, weightSpecs?: WeightsManifestEntry[],\n    weightData?: ArrayBuffer, trainingConfig?: TrainingConfig): IOHandlerSync {\n  if (arguments.length === 1) {\n    const isModelArtifacts =\n        (modelArtifacts as ModelArtifacts).modelTopology != null ||\n        (modelArtifacts as ModelArtifacts).weightSpecs != null;\n    if (isModelArtifacts) {\n      return new PassthroughLoader(modelArtifacts as ModelArtifacts);\n    } else {\n      // Legacy support: with only modelTopology.\n      // TODO(cais): Remove this deprecated API.\n      console.warn(\n          'Please call tf.io.fromMemory() with only one argument. ' +\n          'The argument should be of type ModelArtifacts. ' +\n          'The multi-argument signature of tf.io.fromMemory() has been ' +\n          'deprecated and will be removed in a future release.');\n      return new PassthroughLoader({modelTopology: modelArtifacts as {}});\n    }\n  } else {\n    // Legacy support.\n    // TODO(cais): Remove this deprecated API.\n    console.warn(\n        'Please call tf.io.fromMemory() with only one argument. ' +\n        'The argument should be of type ModelArtifacts. ' +\n        'The multi-argument signature of tf.io.fromMemory() has been ' +\n        'deprecated and will be removed in a future release.');\n    return new PassthroughLoader({\n      modelTopology: modelArtifacts as {},\n      weightSpecs,\n      weightData,\n      trainingConfig\n    });\n  }\n}\n\n/**\n * Creates an IOHandler that passes saved model artifacts to a callback.\n *\n * ```js\n * function handleSave(artifacts) {\n *   // ... do something with the artifacts ...\n *   return {modelArtifactsInfo: {...}, ...};\n * }\n *\n * const saveResult = model.save(tf.io.withSaveHandler(handleSave));\n * ```\n *\n * @param saveHandler A function that accepts a `ModelArtifacts` and returns a\n *     promise that resolves to a `SaveResult`.\n */\nexport function withSaveHandler(\n    saveHandler: (artifacts: ModelArtifacts) =>\n        Promise<SaveResult>): IOHandler {\n  return new PassthroughSaver(saveHandler);\n}\n\n/**\n * Creates an IOHandlerSync that passes saved model artifacts to a callback.\n *\n * ```js\n * function handleSave(artifacts) {\n *   // ... do something with the artifacts ...\n *   return {modelArtifactsInfo: {...}, ...};\n * }\n *\n * const saveResult = model.save(tf.io.withSaveHandler(handleSave));\n * ```\n *\n * @param saveHandler A function that accepts a `ModelArtifacts` and returns a\n *     `SaveResult`.\n */\nexport function withSaveHandlerSync(\n    saveHandler: (artifacts: ModelArtifacts) => SaveResult): IOHandlerSync {\n  return new PassthroughSaver<SaveResult>(saveHandler);\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {ENGINE} from '../engine';\nimport {BatchMatMul, BatchMatMulAttrs, BatchMatMulInputs} from '../kernel_names';\nimport {NamedAttrMap} from '../kernel_registry';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {makeTypesMatch} from '../tensor_util';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {op} from './operation';\n\n/**\n * Computes the dot product of two matrices, A * B. These must be matrices.\n *\n * ```js\n * const a = tf.tensor2d([1, 2], [1, 2]);\n * const b = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n *\n * a.matMul(b).print();  // or tf.matMul(a, b)\n * ```\n * @param a First matrix in dot product operation.\n * @param b Second matrix in dot product operation.\n * @param transposeA If true, `a` is transposed before multiplication.\n * @param transposeB If true, `b` is transposed before multiplication.\n *\n * @doc {heading: 'Operations', subheading: 'Matrices'}\n */\nfunction matMul_<T extends Tensor>(\n    a: Tensor|TensorLike, b: Tensor|TensorLike, transposeA = false,\n    transposeB = false): T {\n  let $a = convertToTensor(a, 'a', 'matMul');\n  let $b = convertToTensor(b, 'b', 'matMul');\n  [$a, $b] = makeTypesMatch($a, $b);\n\n  const inputs: BatchMatMulInputs = {a: $a, b: $b};\n  const attrs: BatchMatMulAttrs = {transposeA, transposeB};\n\n  return ENGINE.runKernel(\n      BatchMatMul, inputs as {} as NamedTensorMap, attrs as {} as NamedAttrMap);\n}\n\nexport const matMul = op({matMul_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {OneHot, OneHotAttrs, OneHotInputs} from '../kernel_names';\nimport {NamedAttrMap} from '../kernel_registry';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {DataType, TensorLike} from '../types';\n\nimport {op} from './operation';\n\n/**\n * Creates a one-hot `tf.Tensor`. The locations represented by `indices` take\n * value `onValue` (defaults to 1), while all other locations take value\n * `offValue` (defaults to 0). If `indices` is rank `R`, the output has rank\n * `R+1` with the last axis of size `depth`.\n * `indices` used to encode prediction class must start from 0. For example,\n *  if you have 3 classes of data, class 1 should be encoded as 0, class 2\n *  should be 1, and class 3 should be 2.\n *\n * ```js\n * tf.oneHot(tf.tensor1d([0, 1], 'int32'), 3).print();\n * ```\n *\n * @param indices `tf.Tensor` of indices with dtype `int32`. Indices must\n * start from 0.\n * @param depth The depth of the one hot dimension.\n * @param onValue A number used to fill in the output when the index matches\n * the location.\n * @param offValue A number used to fill in the output when the index does\n *     not match the location.\n * @param dtype The dtype of the output tensor, default to 'int32'.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nfunction oneHot_(\n    indices: Tensor|TensorLike, depth: number, onValue = 1, offValue = 0,\n    dtype: DataType = 'int32'): Tensor {\n  if (depth < 2) {\n    throw new Error(`Error in oneHot: depth must be >=2, but it is ${depth}`);\n  }\n  const $indices = convertToTensor(indices, 'indices', 'oneHot', 'int32');\n\n  const inputs: OneHotInputs = {indices: $indices};\n  const attrs: OneHotAttrs = {dtype, depth, onValue, offValue};\n\n  return ENGINE.runKernel(\n      OneHot, inputs as unknown as NamedTensorMap,\n      attrs as unknown as NamedAttrMap);\n}\n\nexport const oneHot = op({oneHot_});\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelBackend} from './backends/backend';\nimport {ENGINE, Engine, MemoryInfo, ProfileInfo, ScopeFn, TimingInfo} from './engine';\nimport {env} from './environment';\n\nimport {Platform} from './platforms/platform';\nimport {setDeprecationWarningFn, Tensor} from './tensor';\nimport {TensorContainer} from './tensor_types';\nimport {getTensorsInContainer} from './tensor_util';\n\n/**\n * Enables production mode which disables correctness checks in favor of\n * performance.\n *\n * @doc {heading: 'Environment'}\n */\nexport function enableProdMode(): void {\n  env().set('PROD', true);\n}\n\n/**\n * Enables debug mode which will log information about all executed kernels:\n * the elapsed time of the kernel execution, as well as the rank, shape, and\n * size of the output tensor.\n *\n * Debug mode will significantly slow down your application as it will\n * download the result of every operation to the CPU. This should not be used in\n * production. Debug mode does not affect the timing information of the kernel\n * execution as we do not measure download time in the kernel execution time.\n *\n * See also: `tf.profile`, `tf.memory`.\n *\n * @doc {heading: 'Environment'}\n */\nexport function enableDebugMode(): void {\n  env().set('DEBUG', true);\n}\n\n/** Globally disables deprecation warnings */\nexport function disableDeprecationWarnings(): void {\n  env().set('DEPRECATION_WARNINGS_ENABLED', false);\n  console.warn(`TensorFlow.js deprecation warnings have been disabled.`);\n}\n\n/** Warn users about deprecated functionality. */\nexport function deprecationWarn(msg: string) {\n  if (env().getBool('DEPRECATION_WARNINGS_ENABLED')) {\n    console.warn(\n        msg + ' You can disable deprecation warnings with ' +\n        'tf.disableDeprecationWarnings().');\n  }\n}\nsetDeprecationWarningFn(deprecationWarn);\n\n/**\n * Dispose all variables kept in backend engine.\n *\n * @doc {heading: 'Environment'}\n */\nexport function disposeVariables(): void {\n  ENGINE.disposeVariables();\n}\n\n/**\n * It returns the global engine that keeps track of all tensors and backends.\n *\n * @doc {heading: 'Environment'}\n */\nexport function engine(): Engine {\n  return ENGINE;\n}\n\n/**\n * Returns memory info at the current time in the program. The result is an\n * object with the following properties:\n *\n * - `numBytes`: Number of bytes allocated (undisposed) at this time.\n * - `numTensors`: Number of unique tensors allocated.\n * - `numDataBuffers`: Number of unique data buffers allocated\n *   (undisposed) at this time, which is ≤ the number of tensors\n *   (e.g. `a.reshape(newShape)` makes a new Tensor that shares the same\n *   data buffer with `a`).\n * - `unreliable`: True if the memory usage is unreliable. See `reasons` when\n *    `unreliable` is true.\n * - `reasons`: `string[]`, reasons why the memory is unreliable, present if\n *    `unreliable` is true.\n *\n * WebGL Properties:\n * - `numBytesInGPU`: Number of bytes allocated (undisposed) in the GPU only at\n *     this time.\n *\n * @doc {heading: 'Performance', subheading: 'Memory'}\n */\nexport function memory(): MemoryInfo {\n  return ENGINE.memory();\n}\n\n/**\n * Executes the provided function `f()` and returns a promise that resolves\n * with information about the function's memory use:\n * - `newBytes`: the number of new bytes allocated\n * - `newTensors`: the number of new tensors created\n * - `peakBytes`: the peak number of bytes allocated\n * - `kernels`: an array of objects for each kernel involved that reports\n * their input and output shapes, number of bytes used, and number of new\n * tensors created.\n * - `kernelNames`: an array of unique strings with just the names of the\n * kernels in the `kernels` array.\n *\n * ```js\n * const profile = await tf.profile(() => {\n *   const x = tf.tensor1d([1, 2, 3]);\n *   let x2 = x.square();\n *   x2.dispose();\n *   x2 = x.square();\n *   x2.dispose();\n *   return x;\n * });\n *\n * console.log(`newBytes: ${profile.newBytes}`);\n * console.log(`newTensors: ${profile.newTensors}`);\n * console.log(`byte usage over all kernels: ${profile.kernels.map(k =>\n * k.totalBytesSnapshot)}`);\n * ```\n *\n *\n * @doc {heading: 'Performance', subheading: 'Profile'}\n */\nexport function profile(f: () => (TensorContainer | Promise<TensorContainer>)):\n    Promise<ProfileInfo> {\n  return ENGINE.profile(f);\n}\n\n/**\n * Executes the provided function `fn` and after it is executed, cleans up all\n * intermediate tensors allocated by `fn` except those returned by `fn`.\n * `fn` must not return a Promise (async functions not allowed). The returned\n * result can be a complex object.\n *\n * Using this method helps avoid memory leaks. In general, wrap calls to\n * operations in `tf.tidy` for automatic memory cleanup.\n *\n * NOTE: Variables do *not* get cleaned up when inside a tidy(). If you want to\n * dispose variables, please use `tf.disposeVariables` or call dispose()\n * directly on variables.\n *\n * ```js\n * // y = 2 ^ 2 + 1\n * const y = tf.tidy(() => {\n *   // a, b, and one will be cleaned up when the tidy ends.\n *   const one = tf.scalar(1);\n *   const a = tf.scalar(2);\n *   const b = a.square();\n *\n *   console.log('numTensors (in tidy): ' + tf.memory().numTensors);\n *\n *   // The value returned inside the tidy function will return\n *   // through the tidy, in this case to the variable y.\n *   return b.add(one);\n * });\n *\n * console.log('numTensors (outside tidy): ' + tf.memory().numTensors);\n * y.print();\n * ```\n *\n * @param nameOrFn The name of the closure, or the function to execute.\n *     If a name is provided, the 2nd argument should be the function.\n *     If debug mode is on, the timing and the memory usage of the function\n *     will be tracked and displayed on the console using the provided name.\n * @param fn The function to execute.\n *\n * @doc {heading: 'Performance', subheading: 'Memory'}\n */\nexport function tidy<T extends TensorContainer>(\n    nameOrFn: string|ScopeFn<T>, fn?: ScopeFn<T>): T {\n  return ENGINE.tidy(nameOrFn, fn);\n}\n\n/**\n * Disposes any `tf.Tensor`s found within the provided object.\n *\n * @param container an object that may be a `tf.Tensor` or may directly\n *     contain `tf.Tensor`s, such as a `Tensor[]` or `{key: Tensor, ...}`. If\n *     the object is not a `tf.Tensor` or does not contain `Tensors`, nothing\n *     happens. In general it is safe to pass any object here, except that\n *     `Promise`s are not supported.\n *\n * @doc {heading: 'Performance', subheading: 'Memory'}\n */\nexport function dispose(container: TensorContainer) {\n  const tensors = getTensorsInContainer(container);\n  tensors.forEach(tensor => tensor.dispose());\n}\n\n/**\n * Keeps a `tf.Tensor` generated inside a `tf.tidy` from being disposed\n * automatically.\n *\n * ```js\n * let b;\n * const y = tf.tidy(() => {\n *   const one = tf.scalar(1);\n *   const a = tf.scalar(2);\n *\n *   // b will not be cleaned up by the tidy. a and one will be cleaned up\n *   // when the tidy ends.\n *   b = tf.keep(a.square());\n *\n *   console.log('numTensors (in tidy): ' + tf.memory().numTensors);\n *\n *   // The value returned inside the tidy function will return\n *   // through the tidy, in this case to the variable y.\n *   return b.add(one);\n * });\n *\n * console.log('numTensors (outside tidy): ' + tf.memory().numTensors);\n * console.log('y:');\n * y.print();\n * console.log('b:');\n * b.print();\n * ```\n *\n * @param result The tensor to keep from being disposed.\n *\n * @doc {heading: 'Performance', subheading: 'Memory'}\n */\nexport function keep<T extends Tensor>(result: T): T {\n  return ENGINE.keep(result);\n}\n\n/**\n * Executes `f()` and returns a promise that resolves with timing\n * information.\n *\n * The result is an object with the following properties:\n *\n * - `wallMs`: Wall execution time.\n * - `kernelMs`: Kernel execution time, ignoring data transfer. If using the\n * WebGL backend and the query timer extension is not available, this will\n * return an error object.\n * - On `WebGL` The following additional properties exist:\n *   - `uploadWaitMs`: CPU blocking time on texture uploads.\n *   - `downloadWaitMs`: CPU blocking time on texture downloads (readPixels).\n *\n * ```js\n * const x = tf.randomNormal([20, 20]);\n * const time = await tf.time(() => x.matMul(x));\n *\n * console.log(`kernelMs: ${time.kernelMs}, wallTimeMs: ${time.wallMs}`);\n * ```\n *\n * @param f The function to execute and time.\n *\n * @doc {heading: 'Performance', subheading: 'Timing'}\n */\nexport function time(f: () => void): Promise<TimingInfo> {\n  return ENGINE.time(f);\n}\n\n/**\n * Sets the backend (cpu, webgl, wasm, etc) responsible for creating tensors and\n * executing operations on those tensors. Returns a promise that resolves\n * to a boolean if the backend initialization was successful.\n *\n * Note this disposes the current backend, if any, as well as any tensors\n * associated with it. A new backend is initialized, even if it is of the\n * same type as the previous one.\n *\n * @param backendName The name of the backend. Currently supports\n *     `'webgl'|'cpu'` in the browser, `'tensorflow'` under node.js\n *     (requires tfjs-node), and `'wasm'` (requires tfjs-backend-wasm).\n *\n * @doc {heading: 'Backends'}\n */\nexport function setBackend(backendName: string): Promise<boolean> {\n  return ENGINE.setBackend(backendName);\n}\n\n/**\n * Returns a promise that resolves when the currently selected backend (or the\n * highest priority one) has initialized. Await this promise when you are using\n * a backend that has async initialization.\n *\n * @doc {heading: 'Backends'}\n */\nexport function ready(): Promise<void> {\n  return ENGINE.ready();\n}\n\n/**\n * Returns the current backend name (cpu, webgl, etc). The backend is\n * responsible for creating tensors and executing operations on those tensors.\n *\n * @doc {heading: 'Backends'}\n */\nexport function getBackend(): string {\n  return ENGINE.backendName;\n}\n\n/**\n * Removes a backend and the registered factory.\n *\n * @doc {heading: 'Backends'}\n */\nexport function removeBackend(name: string): void {\n  ENGINE.removeBackend(name);\n}\n\n/**\n * Finds the backend registered under the provided name. Returns null if the\n * name is not in the registry, or the registration hasn't finished yet.\n */\nexport function findBackend(name: string): KernelBackend {\n  return ENGINE.findBackend(name);\n}\n\n/**\n * Finds the backend factory registered under the provided name. Returns a\n * function that produces a new backend when called. Returns null if the name\n * is not in the registry.\n */\nexport function findBackendFactory(name: string): () =>\n    KernelBackend | Promise<KernelBackend> {\n  return ENGINE.findBackendFactory(name);\n}\n\n/**\n * Registers a global backend. The registration should happen when importing\n * a module file (e.g. when importing `backend_webgl.ts`), and is used for\n * modular builds (e.g. custom tfjs bundle with only webgl support).\n *\n * @param factory The backend factory function. When called, it should\n * return a backend instance, or a promise of an instance.\n * @param priority The priority of the backend (higher = more important).\n *     In case multiple backends are registered, the priority is used to find\n *     the best backend. Defaults to 1.\n * @return False if there is already a registered backend under this name, true\n *     if not.\n *\n * @doc {heading: 'Backends'}\n */\nexport function registerBackend(\n    name: string, factory: () => KernelBackend | Promise<KernelBackend>,\n    priority = 1): boolean {\n  return ENGINE.registerBackend(name, factory, priority);\n}\n\n/**\n * Gets the current backend. If no backends have been initialized, this will\n * attempt to initialize the best backend. Will throw an error if the highest\n * priority backend has async initialization, in which case you should call\n * 'await tf.ready()' before running other code.\n *\n * @doc {heading: 'Backends'}\n */\nexport function backend(): KernelBackend {\n  return ENGINE.backend;\n}\n\n/**\n * Sets the global platform.\n *\n * @param platformName The name of this platform.\n * @param platform A platform implementation.\n */\nexport function setPlatform(platformName: string, platform: Platform) {\n  env().setPlatform(platformName, platform);\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {Imag, ImagInputs} from '../kernel_names';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\nimport {op} from './operation';\n/**\n * Returns the imaginary part of a complex (or real) tensor.\n *\n * Given a tensor input, this operation returns a tensor of type float that is\n * the imaginary part of each element in input considered as a complex number.\n * If input is real, a tensor of all zeros is returned.\n *\n * ```js\n * const x = tf.complex([-2.25, 3.25], [4.75, 5.75]);\n * tf.imag(x).print();\n * ```\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nfunction imag_<T extends Tensor>(input: T|TensorLike): T {\n  const $input = convertToTensor(input, 'input', 'imag');\n\n  const inputs: ImagInputs = {input: $input};\n  return ENGINE.runKernel(Imag, inputs as {} as NamedTensorMap);\n}\n\nexport const imag = op({imag_});\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {Neg, NegInputs} from '../kernel_names';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {op} from './operation';\n\n/**\n * Computes `-1 * x` element-wise.\n *\n * ```js\n * const x = tf.tensor2d([1, 2, -2, 0], [2, 2]);\n *\n * x.neg().print();  // or tf.neg(x)\n * ```\n *\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction neg_<T extends Tensor>(x: T|TensorLike): T {\n  const $x = convertToTensor(x, 'x', 'neg');\n\n  const inputs: NegInputs = {x: $x};\n  return ENGINE.runKernel(Neg, inputs as {} as NamedTensorMap);\n}\nexport const neg = op({neg_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {Real, RealInputs} from '../kernel_names';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\nimport {op} from './operation';\n\n/**\n * Returns the real part of a complex (or real) tensor.\n *\n * Given a tensor input, this operation returns a tensor of type float that is\n * the real part of each element in input considered as a complex number.\n *\n * If the input is real, it simply makes a clone.\n *\n * ```js\n * const x = tf.complex([-2.25, 3.25], [4.75, 5.75]);\n * tf.real(x).print();\n * ```\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nfunction real_<T extends Tensor>(input: T|TensorLike): T {\n  const $input = convertToTensor(input, 'input', 'real');\n\n  const inputs: RealInputs = {input: $input};\n  return ENGINE.runKernel(Real, inputs as {} as NamedTensorMap);\n}\n\nexport const real = op({real_});\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {tidy} from '../globals';\nimport {Transpose, TransposeAttrs, TransposeInputs} from '../kernel_names';\nimport {NamedAttrMap} from '../kernel_registry';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\nimport * as util from '../util';\nimport {complex} from './complex';\nimport {imag} from './imag';\nimport {neg} from './neg';\nimport {op} from './operation';\nimport {real} from './real';\n\n/**\n * Transposes the `tf.Tensor`. Permutes the dimensions according to `perm`.\n *\n * The returned `tf.Tensor`'s dimension `i` will correspond to the input\n * dimension `perm[i]`. If `perm` is not given, it is set to `[n-1...0]`,\n * where `n` is the rank of the input `tf.Tensor`. Hence by default, this\n * operation performs a regular matrix transpose on 2-D input `tf.Tensor`s.\n *\n * ```js\n * const a = tf.tensor2d([1, 2, 3, 4, 5, 6], [2, 3]);\n *\n * a.transpose().print();  // or tf.transpose(a)\n * ```\n *\n * @param x The tensor to transpose.\n * @param perm The permutation of the dimensions of a.\n * @param conjugate Will conjugate complex input if true.\n *\n * @doc {heading: 'Operations', subheading: 'Matrices'}\n */\nfunction transpose_<T extends Tensor>(\n    x: T|TensorLike, perm?: number[], conjugate?: boolean): T {\n  const $x = convertToTensor(x, 'x', 'transpose');\n\n  if (perm == null) {\n    perm = $x.shape.map((s, i) => i).reverse();\n  }\n  util.assert(\n      $x.rank === perm.length,\n      () => `Error in transpose: rank of input ${$x.rank} ` +\n          `must match length of perm ${perm}.`);\n  perm.forEach(axis => {\n    util.assert(\n        axis >= 0 && axis < $x.rank,\n        () => `All entries in 'perm' must be between 0 and ${$x.rank - 1}` +\n            ` but got ${perm}`);\n  });\n\n  if ($x.rank <= 1) {\n    return $x.clone();\n  }\n\n  const inputs: TransposeInputs = {x: $x};\n  const attrs: TransposeAttrs = {perm};\n\n  if ($x.dtype === 'complex64') {\n    return tidy(() => {\n      let $real = real($x);\n      let $imag = imag($x);\n      $real = ENGINE.runKernel(\n          Transpose, {x: $real} as {} as NamedTensorMap,\n          attrs as {} as NamedAttrMap);\n      $imag = ENGINE.runKernel(\n          Transpose, {x: $imag} as {} as NamedTensorMap,\n          attrs as {} as NamedAttrMap);\n      if (conjugate) {\n        $imag = neg($imag);\n      }\n      return complex($real, $imag);\n    });\n  }\n\n  return ENGINE.runKernel(\n      Transpose, inputs as {} as NamedTensorMap, attrs as {} as NamedAttrMap);\n}\n\nexport const transpose = op({transpose_});\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor1D, Tensor2D} from '../tensor';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\nimport * as util from '../util';\n\nimport {cast} from './cast';\nimport {matMul} from './mat_mul';\nimport {oneHot} from './one_hot';\nimport {op} from './operation';\nimport {transpose} from './transpose';\n\n/**\n * Computes the confusion matrix from true labels and predicted labels.\n *\n * ```js\n * const labels = tf.tensor1d([0, 1, 2, 1, 0], 'int32');\n * const predictions = tf.tensor1d([0, 2, 2, 1, 0], 'int32');\n * const numClasses = 3;\n * const out = tf.math.confusionMatrix(labels, predictions, numClasses);\n * out.print();\n * // Expected output matrix:\n * // [[2, 0, 0],\n * //  [0, 1, 1],\n * //  [0, 0, 1]]\n * ```\n *\n * @param labels The target labels, assumed to be 0-based integers\n *   for the classes. The shape is `[numExamples]`, where\n *   `numExamples` is the number of examples included.\n * @param predictions The predicted classes, assumed to be\n *   0-based integers for the classes. Must have the same shape as `labels`.\n * @param numClasses Number of all classes, as an integer.\n *   Its value must be larger than the largest element in `labels` and\n *   `predictions`.\n * @returns The confusion matrix as a int32-type 2D tensor. The value at\n *   row `r` and column `c` is the number of times examples of actual class\n *   `r` were predicted as class `c`.\n *\n * @doc {heading: 'Operations', subheading: 'Evaluation'}\n */\nexport function confusionMatrix_(\n    labels: Tensor1D|TensorLike, predictions: Tensor1D|TensorLike,\n    numClasses: number): Tensor2D {\n  const $labels = convertToTensor(labels, 'labels', 'confusionMatrix');\n  const $predictions =\n      convertToTensor(predictions, 'predictions', 'confusionMatrix');\n\n  util.assert(\n      numClasses == null || numClasses > 0 && Number.isInteger(numClasses),\n      () => `If provided, numClasses must be a positive integer, ` +\n          `but got ${numClasses}`);\n  util.assert(\n      $labels.rank === 1,\n      () => `Expected the rank of labels to be 1, but got ${$labels.rank}`);\n  util.assert(\n      $predictions.rank === 1,\n      () => `Expected the rank of predictions to be 1, ` +\n          `but got ${$predictions.rank}`);\n  util.assert(\n      $labels.shape[0] === $predictions.shape[0],\n      () => `Mismatch in the number of examples: ` +\n          `${$labels.shape[0]} vs. ${$predictions.shape[0]}. ` +\n          `Labels and predictions should have the same number of elements.`);\n  util.assert(\n      numClasses > 0 && Number.isInteger(numClasses),\n      () => `numClasses is required to be a positive integer, but got ` +\n          `${numClasses}`);\n  // TODO(cais): In the future, if oneHot supports tensors inputs for\n  //   `numClasses`, `confusionMatrix` can make `numClasses` optional.\n\n  const oneHotLabels = oneHot(cast($labels, 'int32'), numClasses) as Tensor2D;\n  const oneHotPredictions =\n      oneHot(cast($predictions, 'int32'), numClasses) as Tensor2D;\n  const oneHotLabelsT: Tensor2D = transpose(oneHotLabels);\n  const product: Tensor2D = matMul(oneHotLabelsT, oneHotPredictions);\n  return cast(product, 'int32');\n}\n\nexport const confusionMatrix = op({confusionMatrix_});\n","/**\n * @license\n * Copyright 2017 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n/**\n * Returns the dimensions in the input shape that are broadcasted to\n * produce the provided output shape.\n *\n * The returned dimensions are 0-indexed and sorted. An example:\n * inShape = [4, 1, 3]\n * outShape = [5, 4, 3, 3]\n * result = [1]. Dimension 1 (2nd dimension of input) gets broadcasted 1 => 3.\n */\nexport function getBroadcastDims(\n    inShape: number[], outShape: number[]): number[] {\n  const inRank = inShape.length;\n  const dims: number[] = [];\n  for (let i = 0; i < inRank; i++) {\n    const dim = inRank - 1 - i;\n    const a = inShape[dim] || 1;\n    const b = outShape[outShape.length - 1 - i] || 1;\n    if (b > 1 && a === 1) {\n      dims.unshift(dim);\n    }\n  }\n  return dims;\n}\n\n/**\n * Returns the axes in the output space that should be reduced to produce\n * the input space.\n */\nexport function getReductionAxes(\n    inShape: number[], outShape: number[]): number[] {\n  const result: number[] = [];\n  for (let i = 0; i < outShape.length; i++) {\n    const inDim = inShape[inShape.length - i - 1];\n    const outAxis = outShape.length - i - 1;\n    const outDim = outShape[outAxis];\n    if (inDim == null || (inDim === 1 && outDim > 1)) {\n      result.unshift(outAxis);\n    }\n  }\n  return result;\n}\n\nexport function assertAndGetBroadcastShape(\n    shapeA: number[], shapeB: number[]): number[] {\n  const result: number[] = [];\n  const l = Math.max(shapeA.length, shapeB.length);\n\n  for (let i = 0; i < l; i++) {\n    let a = shapeA[shapeA.length - i - 1];\n    if (a == null) {\n      a = 1;\n    }\n    let b = shapeB[shapeB.length - i - 1];\n    if (b == null) {\n      b = 1;\n    }\n    if (a === 1) {\n      result.unshift(b);\n    } else if (b === 1) {\n      result.unshift(a);\n    } else if (a !== b) {\n      const errMsg = `Operands could not be broadcast together with shapes ` +\n          `${shapeA} and ${shapeB}.`;\n      throw Error(errMsg);\n    } else {\n      result.unshift(a);\n    }\n  }\n  return result;\n}\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor3D} from '../tensor';\nimport {inferShape} from '../tensor_util_env';\nimport {TensorLike3D} from '../types';\nimport {DataType} from '../types';\nimport {assertNonNull} from '../util';\nimport {makeTensor} from './tensor_ops_util';\n\n/**\n * Creates rank-3 `tf.Tensor` with the provided values, shape and dtype.\n *\n * The same functionality can be achieved with `tf.tensor`, but in general\n * we recommend using `tf.tensor3d` as it makes the code more readable.\n *\n *  ```js\n * // Pass a nested array.\n * tf.tensor3d([[[1], [2]], [[3], [4]]]).print();\n * ```\n * ```js\n * // Pass a flat array and specify a shape.\n * tf.tensor3d([1, 2, 3, 4], [2, 2, 1]).print();\n * ```\n *\n * @param values The values of the tensor. Can be nested array of numbers,\n *     or a flat array, or a `TypedArray`.\n * @param shape The shape of the tensor. If not provided,  it is inferred from\n *     `values`.\n * @param dtype The data type.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nexport function tensor3d(\n    values: TensorLike3D, shape?: [number, number, number],\n    dtype?: DataType): Tensor3D {\n  assertNonNull(values);\n  if (shape != null && shape.length !== 3) {\n    throw new Error('tensor3d() requires shape to have three numbers');\n  }\n  const inferredShape = inferShape(values, dtype);\n  if (inferredShape.length !== 3 && inferredShape.length !== 1) {\n    throw new Error(\n        'tensor3d() requires values to be number[][][] or flat/TypedArray');\n  }\n  if (inferredShape.length === 1 && shape == null) {\n    throw new Error(\n        'tensor3d() requires shape to be provided when `values` ' +\n        'are a flat array');\n  }\n  return makeTensor(values, shape, inferredShape, dtype) as Tensor3D;\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {env} from '../environment';\nimport {FromPixels, FromPixelsAttrs, FromPixelsInputs} from '../kernel_names';\nimport {getKernel, NamedAttrMap} from '../kernel_registry';\nimport {Tensor, Tensor2D, Tensor3D} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {PixelData, TensorLike} from '../types';\n\nimport {cast} from './cast';\nimport {op} from './operation';\nimport {tensor3d} from './tensor3d';\n\nlet fromPixels2DContext: CanvasRenderingContext2D;\n\n/**\n * Creates a `tf.Tensor` from an image.\n *\n * ```js\n * const image = new ImageData(1, 1);\n * image.data[0] = 100;\n * image.data[1] = 150;\n * image.data[2] = 200;\n * image.data[3] = 255;\n *\n * tf.browser.fromPixels(image).print();\n * ```\n *\n * @param pixels The input image to construct the tensor from. The\n * supported image types are all 4-channel. You can also pass in an image\n * object with following attributes:\n * `{data: Uint8Array; width: number; height: number}`\n * @param numChannels The number of channels of the output tensor. A\n * numChannels value less than 4 allows you to ignore channels. Defaults to\n * 3 (ignores alpha channel of input image).\n *\n * @returns A Tensor3D with the shape `[height, width, numChannels]`.\n *\n * Note: fromPixels can be lossy in some cases, same image may result in\n * slightly different tensor values, if rendered by different rendering\n * engines. This means that results from different browsers, or even same\n * browser with CPU and GPU rendering engines can be different. See discussion\n * in details:\n * https://github.com/tensorflow/tfjs/issues/5482\n *\n * @doc {heading: 'Browser', namespace: 'browser', ignoreCI: true}\n */\nfunction fromPixels_(\n    pixels: PixelData|ImageData|HTMLImageElement|HTMLCanvasElement|\n    HTMLVideoElement|ImageBitmap,\n    numChannels = 3): Tensor3D {\n  // Sanity checks.\n  if (numChannels > 4) {\n    throw new Error(\n        'Cannot construct Tensor with more than 4 channels from pixels.');\n  }\n  if (pixels == null) {\n    throw new Error('pixels passed to tf.browser.fromPixels() can not be null');\n  }\n  let isPixelData = false;\n  let isImageData = false;\n  let isVideo = false;\n  let isImage = false;\n  let isCanvasLike = false;\n  let isImageBitmap = false;\n  if ((pixels as PixelData).data instanceof Uint8Array) {\n    isPixelData = true;\n  } else if (\n      typeof (ImageData) !== 'undefined' && pixels instanceof ImageData) {\n    isImageData = true;\n  } else if (\n      typeof (HTMLVideoElement) !== 'undefined' &&\n      pixels instanceof HTMLVideoElement) {\n    isVideo = true;\n  } else if (\n      typeof (HTMLImageElement) !== 'undefined' &&\n      pixels instanceof HTMLImageElement) {\n    isImage = true;\n    // tslint:disable-next-line: no-any\n  } else if ((pixels as any).getContext != null) {\n    isCanvasLike = true;\n  } else if (\n      typeof (ImageBitmap) !== 'undefined' && pixels instanceof ImageBitmap) {\n    isImageBitmap = true;\n  } else {\n    throw new Error(\n        'pixels passed to tf.browser.fromPixels() must be either an ' +\n        `HTMLVideoElement, HTMLImageElement, HTMLCanvasElement, ImageData ` +\n        `in browser, or OffscreenCanvas, ImageData in webworker` +\n        ` or {data: Uint32Array, width: number, height: number}, ` +\n        `but was ${(pixels as {}).constructor.name}`);\n  }\n  // If the current backend has 'FromPixels' registered, it has a more\n  // efficient way of handling pixel uploads, so we call that.\n  const kernel = getKernel(FromPixels, ENGINE.backendName);\n  if (kernel != null) {\n    const inputs: FromPixelsInputs = {pixels};\n    const attrs: FromPixelsAttrs = {numChannels};\n    return ENGINE.runKernel(\n        FromPixels, inputs as {} as NamedTensorMap,\n        attrs as {} as NamedAttrMap);\n  }\n\n  const [width, height] = isVideo ?\n      [\n        (pixels as HTMLVideoElement).videoWidth,\n        (pixels as HTMLVideoElement).videoHeight\n      ] :\n      [pixels.width, pixels.height];\n  let vals: Uint8ClampedArray|Uint8Array;\n\n  if (isCanvasLike) {\n    vals =\n        // tslint:disable-next-line:no-any\n        (pixels as any).getContext('2d').getImageData(0, 0, width, height).data;\n  } else if (isImageData || isPixelData) {\n    vals = (pixels as PixelData | ImageData).data;\n  } else if (isImage || isVideo || isImageBitmap) {\n    if (fromPixels2DContext == null) {\n      if (typeof document === 'undefined') {\n        if (typeof OffscreenCanvas !== 'undefined' &&\n            typeof OffscreenCanvasRenderingContext2D !== 'undefined') {\n          // @ts-ignore\n          fromPixels2DContext = new OffscreenCanvas(1, 1).getContext('2d');\n        } else {\n          throw new Error(\n              'Cannot parse input in current context. ' +\n              'Reason: OffscreenCanvas Context2D rendering is not supported.');\n        }\n      } else {\n        fromPixels2DContext =\n            document.createElement('canvas').getContext(\n                '2d', {willReadFrequently: true}) as CanvasRenderingContext2D;\n      }\n    }\n    fromPixels2DContext.canvas.width = width;\n    fromPixels2DContext.canvas.height = height;\n    fromPixels2DContext.drawImage(\n        pixels as HTMLVideoElement, 0, 0, width, height);\n    vals = fromPixels2DContext.getImageData(0, 0, width, height).data;\n  }\n  let values: Int32Array;\n  if (numChannels === 4) {\n    values = new Int32Array(vals);\n  } else {\n    const numPixels = width * height;\n    values = new Int32Array(numPixels * numChannels);\n    for (let i = 0; i < numPixels; i++) {\n      for (let channel = 0; channel < numChannels; ++channel) {\n        values[i * numChannels + channel] = vals[i * 4 + channel];\n      }\n    }\n  }\n  const outShape: [number, number, number] = [height, width, numChannels];\n  return tensor3d(values, outShape, 'int32');\n}\n\n// Helper functions for |fromPixelsAsync| to check whether the input can\n// be wrapped into imageBitmap.\nfunction isPixelData(pixels: PixelData|ImageData|HTMLImageElement|\n                     HTMLCanvasElement|HTMLVideoElement|\n                     ImageBitmap): pixels is PixelData {\n  return (pixels != null) && ((pixels as PixelData).data instanceof Uint8Array);\n}\n\nfunction isImageBitmapFullySupported() {\n  return typeof window !== 'undefined' &&\n      typeof (ImageBitmap) !== 'undefined' &&\n      window.hasOwnProperty('createImageBitmap');\n}\n\nfunction isNonEmptyPixels(pixels: PixelData|ImageData|HTMLImageElement|\n                          HTMLCanvasElement|HTMLVideoElement|ImageBitmap) {\n  return pixels != null && pixels.width !== 0 && pixels.height !== 0;\n}\n\nfunction canWrapPixelsToImageBitmap(pixels: PixelData|ImageData|\n                                    HTMLImageElement|HTMLCanvasElement|\n                                    HTMLVideoElement|ImageBitmap) {\n  return isImageBitmapFullySupported() && !(pixels instanceof ImageBitmap) &&\n      isNonEmptyPixels(pixels) && !isPixelData(pixels);\n}\n\n/**\n * Creates a `tf.Tensor` from an image in async way.\n *\n * ```js\n * const image = new ImageData(1, 1);\n * image.data[0] = 100;\n * image.data[1] = 150;\n * image.data[2] = 200;\n * image.data[3] = 255;\n *\n * (await tf.browser.fromPixelsAsync(image)).print();\n * ```\n * This API is the async version of fromPixels. The API will first\n * check |WRAP_TO_IMAGEBITMAP| flag, and try to wrap the input to\n * imageBitmap if the flag is set to true.\n *\n * @param pixels The input image to construct the tensor from. The\n * supported image types are all 4-channel. You can also pass in an image\n * object with following attributes:\n * `{data: Uint8Array; width: number; height: number}`\n * @param numChannels The number of channels of the output tensor. A\n * numChannels value less than 4 allows you to ignore channels. Defaults to\n * 3 (ignores alpha channel of input image).\n *\n * @doc {heading: 'Browser', namespace: 'browser', ignoreCI: true}\n */\nexport async function fromPixelsAsync(\n    pixels: PixelData|ImageData|HTMLImageElement|HTMLCanvasElement|\n    HTMLVideoElement|ImageBitmap,\n    numChannels = 3) {\n  let inputs: PixelData|ImageData|HTMLImageElement|HTMLCanvasElement|\n      HTMLVideoElement|ImageBitmap = null;\n\n  // Check whether the backend needs to wrap |pixels| to imageBitmap and\n  // whether |pixels| can be wrapped to imageBitmap.\n  if (env().getBool('WRAP_TO_IMAGEBITMAP') &&\n      canWrapPixelsToImageBitmap(pixels)) {\n    // Force the imageBitmap creation to not do any premultiply alpha\n    // ops.\n    let imageBitmap;\n\n    try {\n      // wrap in try-catch block, because createImageBitmap may not work\n      // properly in some browsers, e.g.\n      // https://bugzilla.mozilla.org/show_bug.cgi?id=1335594\n      // tslint:disable-next-line: no-any\n      imageBitmap = await (createImageBitmap as any)(\n          pixels as ImageBitmapSource, {premultiplyAlpha: 'none'});\n    } catch (e) {\n      imageBitmap = null;\n    }\n\n    // createImageBitmap will clip the source size.\n    // In some cases, the input will have larger size than its content.\n    // E.g. new Image(10, 10) but with 1 x 1 content. Using\n    // createImageBitmap will clip the size from 10 x 10 to 1 x 1, which\n    // is not correct. We should avoid wrapping such resouce to\n    // imageBitmap.\n    if (imageBitmap != null && imageBitmap.width === pixels.width &&\n        imageBitmap.height === pixels.height) {\n      inputs = imageBitmap;\n    } else {\n      inputs = pixels;\n    }\n  } else {\n    inputs = pixels;\n  }\n\n  return fromPixels_(inputs, numChannels);\n}\n\n/**\n * Draws a `tf.Tensor` of pixel values to a byte array or optionally a\n * canvas.\n *\n * When the dtype of the input is 'float32', we assume values in the range\n * [0-1]. Otherwise, when input is 'int32', we assume values in the range\n * [0-255].\n *\n * Returns a promise that resolves when the canvas has been drawn to.\n *\n * @param img A rank-2 tensor with shape `[height, width]`, or a rank-3 tensor\n * of shape `[height, width, numChannels]`. If rank-2, draws grayscale. If\n * rank-3, must have depth of 1, 3 or 4. When depth of 1, draws\n * grayscale. When depth of 3, we draw with the first three components of\n * the depth dimension corresponding to r, g, b and alpha = 1. When depth of\n * 4, all four components of the depth dimension correspond to r, g, b, a.\n * @param canvas The canvas to draw to.\n *\n * @doc {heading: 'Browser', namespace: 'browser'}\n */\nexport async function toPixels(\n    img: Tensor2D|Tensor3D|TensorLike,\n    canvas?: HTMLCanvasElement): Promise<Uint8ClampedArray> {\n  let $img = convertToTensor(img, 'img', 'toPixels');\n  if (!(img instanceof Tensor)) {\n    // Assume int32 if user passed a native array.\n    const originalImgTensor = $img;\n    $img = cast(originalImgTensor, 'int32');\n    originalImgTensor.dispose();\n  }\n  if ($img.rank !== 2 && $img.rank !== 3) {\n    throw new Error(\n        `toPixels only supports rank 2 or 3 tensors, got rank ${$img.rank}.`);\n  }\n  const [height, width] = $img.shape.slice(0, 2);\n  const depth = $img.rank === 2 ? 1 : $img.shape[2];\n\n  if (depth > 4 || depth === 2) {\n    throw new Error(\n        `toPixels only supports depth of size ` +\n        `1, 3 or 4 but got ${depth}`);\n  }\n\n  if ($img.dtype !== 'float32' && $img.dtype !== 'int32') {\n    throw new Error(\n        `Unsupported type for toPixels: ${$img.dtype}.` +\n        ` Please use float32 or int32 tensors.`);\n  }\n\n  const data = await $img.data();\n  const multiplier = $img.dtype === 'float32' ? 255 : 1;\n  const bytes = new Uint8ClampedArray(width * height * 4);\n\n  for (let i = 0; i < height * width; ++i) {\n    const rgba = [0, 0, 0, 255];\n\n    for (let d = 0; d < depth; d++) {\n      const value = data[i * depth + d];\n\n      if ($img.dtype === 'float32') {\n        if (value < 0 || value > 1) {\n          throw new Error(\n              `Tensor values for a float32 Tensor must be in the ` +\n              `range [0 - 1] but encountered ${value}.`);\n        }\n      } else if ($img.dtype === 'int32') {\n        if (value < 0 || value > 255) {\n          throw new Error(\n              `Tensor values for a int32 Tensor must be in the ` +\n              `range [0 - 255] but encountered ${value}.`);\n        }\n      }\n\n      if (depth === 1) {\n        rgba[0] = value * multiplier;\n        rgba[1] = value * multiplier;\n        rgba[2] = value * multiplier;\n      } else {\n        rgba[d] = value * multiplier;\n      }\n    }\n\n    const j = i * 4;\n    bytes[j + 0] = Math.round(rgba[0]);\n    bytes[j + 1] = Math.round(rgba[1]);\n    bytes[j + 2] = Math.round(rgba[2]);\n    bytes[j + 3] = Math.round(rgba[3]);\n  }\n\n  if (canvas != null) {\n    canvas.width = width;\n    canvas.height = height;\n    const ctx = canvas.getContext('2d');\n    const imageData = new ImageData(bytes, width, height);\n    ctx.putImageData(imageData, 0, 0);\n  }\n  if ($img !== img) {\n    $img.dispose();\n  }\n  return bytes;\n}\n\nexport const fromPixels = op({fromPixels_});\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {TensorInfo} from '../kernel_registry';\nimport {computeStrides, sizeFromShape} from '../util';\n\n/**\n * Validate gather nd inputs.\n *\n * @param tensor The tensor contains the source values.\n * @param indices The tensor contains the indices to slice the source.\n *\n * @returns [resultShape, numUpdates, sliceSize, strides]\n */\nexport function prepareAndValidate(tensor: TensorInfo, indices: TensorInfo):\n    [number[], number, number, number[]] {\n  const tensorRank = tensor.shape.length;\n  const indicesRank = indices.shape.length;\n  if (tensorRank < 1) {\n    throw new Error(\n        'tf.gatherND() expects the input to be rank 1 or higher,' +\n        ` but the rank was ${tensorRank}.`);\n  }\n  if (indicesRank < 1) {\n    throw new Error(\n        'tf.gatherND() expects the indices to be rank 1 or higher,' +\n        ` but the rank was ${indicesRank}.`);\n  }\n  if (indices.dtype !== 'int32') {\n    throw new Error(\n        'tf.gatherND() expects the indices to be int32 type,' +\n        ` but the dtype was ${indices.dtype}.`);\n  }\n  if (indices.shape[indicesRank - 1] > tensorRank) {\n    throw new Error(\n        'index innermost dimension length must be <= tensor rank; saw: ' +\n        `${indices.shape[indicesRank - 1]} vs. ${tensorRank}`);\n  }\n\n  if (sizeFromShape(tensor.shape) === 0) {\n    throw new Error(\n        'Requested more than 0 entries, but input is empty.' +\n        ` Input shape: ${tensor.shape}.`);\n  }\n\n  const indicesShape = indices.shape;\n  const sliceRank = indicesShape[indicesShape.length - 1];\n\n  // The result shape is\n  //   indices.shape[:-1] + params.shape[indices.shape[-1]:]\n  let nResult = 1;\n  for (let i = 0; i < indicesShape.length - 1; ++i) {\n    nResult *= indicesShape[i];\n  }\n\n  const inputShape = tensor.shape;\n\n  const resultShape = indicesShape.slice();\n  resultShape.pop();\n\n  let sliceSize = 1;\n  for (let i = sliceRank; i < tensorRank; ++i) {\n    sliceSize *= inputShape[i];\n    resultShape.push(inputShape[i]);\n  }\n\n  const strides =\n      [...computeStrides(tensor.shape).map(stride => stride / sliceSize),\n       1].slice(0, sliceRank);\n\n  return [resultShape, nResult, sliceSize, strides];\n}\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {TensorInfo} from '../kernel_registry';\nimport {Tensor} from '../tensor';\nimport {computeStrides, sizeFromShape} from '../util';\n\n/**\n * Check whether updates.shape = indices.shape[:batchDim] +\n * shape[sliceDim:]\n *\n * @param x The input tensor.\n */\nexport function validateUpdateShape(\n    shape: number[], indices: Tensor, updates: Tensor) {\n  const sliceDim = (indices.rank > 1) ? indices.shape[indices.rank - 1] : 1;\n  const batchDim = (indices.rank > 1) ? indices.rank - 1 : 1;\n\n  const shapeError = 'Must have updates.shape = indices.shape[:batchDim] + ' +\n      `shape[sliceDim:], got updates.shape: ${updates.shape}` +\n      `, indices.shape: ${indices.shape}, shape: ${shape}` +\n      `, sliceDim: ${sliceDim}, and batchDim: ${batchDim}.`;\n\n  if (updates.rank < batchDim) {\n    throw new Error(shapeError + ` update.rank < ${batchDim}. `);\n  }\n  if (shape.length < sliceDim + (updates.rank - batchDim)) {\n    throw new Error(\n        shapeError +\n        ` Output shape length < ${sliceDim + (updates.rank - batchDim)}`);\n  }\n  if (updates.rank !== batchDim + shape.length - sliceDim) {\n    throw new Error(\n        shapeError + ` update.rank != ${batchDim + shape.length - sliceDim}`);\n  }\n  for (let d = 0; d < batchDim; ++d) {\n    if (updates.shape[d] !== indices.shape[d]) {\n      throw new Error(\n          shapeError +\n          ` updates.shape[${d}] (${updates.shape[d]}) != indices.shape[${d}] (${\n              indices.shape[d]}).`);\n    }\n  }\n  for (let d = 0; d < updates.rank - batchDim; ++d) {\n    if (updates.shape[d + batchDim] !== shape[d + sliceDim]) {\n      throw new Error(\n          shapeError +\n          ` updates.shape[${d + batchDim}] (${\n              updates.shape[d + batchDim]}) != shape[${d + batchDim}] (${\n              shape[d + batchDim]})`);\n    }\n  }\n}\n\nexport interface ScatterShapeInfo {\n  sliceRank: number;\n  numUpdates: number;\n  sliceSize: number;\n  strides: number[];\n  outputSize: number;\n}\n/**\n * Validate scatter nd inputs.\n *\n * @param update The tensor contains the update values.\n * @param indices The tensor contains the indices for the update values.\n * @param shape The shape of the output tensor.\n */\nexport function validateInput(\n    updates: Tensor, indices: Tensor, shape: number[]) {\n  if (indices.rank < 1) {\n    throw new Error(\n        'tf.scatterND() expects the indices to be rank 1 or higher,' +\n        ` but the rank was ${indices.rank}.`);\n  }\n  if (updates.rank < 1) {\n    throw new Error(\n        'tf.scatterND() expects the updates to be rank 1 or higher,' +\n        ` but the rank was ${updates.rank}.`);\n  }\n  if (indices.dtype !== 'int32') {\n    throw new Error(`The dtype of 'indices' should be int32, but got dtype: ${\n        indices.dtype}`);\n  }\n  if (shape.length < 1) {\n    throw new Error(\n        `Output rank must be greater or equal to 1, but got shape: ${shape}`);\n  }\n\n  if (shape.length === 0) {\n    if (indices.size === 0) {\n      throw new Error(`Indices specified for empty output. indices shape: ${\n          indices.shape}`);\n    }\n    if (updates.size === 0) {\n      throw new Error(`Updates specified for empty output. updates shape: ${\n          updates.shape}`);\n    }\n  }\n\n  validateUpdateShape(shape, indices, updates);\n}\n\n/**\n * Calculate the shape information for the output.\n *\n * @param update The tensor contains the update values.\n * @param indices The tensor contains the indices for the update values.\n * @param shape The shape of the output tensor.\n *\n * @returns ScatterShapeInfo\n */\nexport function calculateShapes(\n    updates: TensorInfo, indices: TensorInfo,\n    shape: number[]): ScatterShapeInfo {\n  // Calculate the number of dimensions in indices\n  const indicesRank = indices.shape.length;\n  const sliceRank = (indicesRank > 1) ? indices.shape[indicesRank - 1] : 1;\n\n  // Calculate the number of elements that make up each slice of our updated\n  // tensor. This allows us to work with flattened tensors and copy over whole\n  // slices at a time.\n  const totalNd = shape.length;\n\n  let sliceSize = 1;\n  for (let i = sliceRank; i < totalNd; ++i) {\n    sliceSize *= shape[i];\n  }\n\n  const safeSliceDim = (sliceRank < 1) ? 1 : sliceRank;\n  const numUpdates = sizeFromShape(indices.shape) / safeSliceDim;\n\n  const strides = [...computeStrides(shape.slice(0, sliceRank)), 1];\n  const outputSize = sizeFromShape(shape);\n  return {sliceRank, numUpdates, sliceSize, strides, outputSize};\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {TensorInfo} from '../kernel_registry';\nimport * as util from '../util';\n\nconst NEW_AXIS = -2;\nconst SHRINK_AXIS = -1;\n\n// Sparse slicing specification\n// if one does foo[3:5, ..., -3], the begin, end and strides will have length\n// of 3.\ninterface StridedSliceSparseSpec {\n  dims: number;\n  numAddAxisAfterEllipsis: number;\n  begin: number[];\n  end: number[];\n  strides: number[];\n  beginMask: number;\n  endMask: number;\n  ellipsisMask: number;\n  newAxisMask: number;\n  shrinkAxisMask: number;\n}\n\n// Dense slicing specification\n// all ellipses and newaxis are expanded out. So if foo[3:5, ..., -3] where foo\n// is 10 dimensional, each array of begin, end, strides will have 10 entries\n// where as the sparse can have length less than the rank of foo.\ninterface StridedSliceDenseSpec {\n  dims: number;\n  beginMask?: number;\n  endMask?: number;\n  beginValid: boolean;\n  endValid: boolean;\n  begin?: number[];\n  end?: number[];\n  strides?: number[];\n  // This array helps construct the final shape of the slice.\n  // The final tensor is reduced in rank whenever a single index e.g. foo[3]\n  // is called for. The final tensor increases in rank with newAxis entries.\n  // If an index in this array is positive, the size of the dimension is\n  // obtained from canonical end-begin.  Otherwise, if it is a NEW_AXIS, it will\n  // be 1. A shrunk dimension is skipped.\n  finalShapeGatherIndices?: number[];\n  // This array has the same size as finalShapeGatherIndices, but it remembers\n  // the sparse index that a dimension comes from, instead of dense index.\n  // A -1 in this vector means the index is not from the sparse input.\n  finalShapeGatherIndicesSparse?: number[];\n  inputShapeGatherIndicesSparse?: number[];\n  // The dense indexed shrink mask is which processing dimensions should be\n  // shrunk. For example, if foo.shape = [10, 10, 10, 10], foo[3, ..., 5] has\n  // sparseShrinkAxisMask of 5 (0101) and denseShrinkAxisMask of 9 (1001),\n  // yielding a final shape [10, 10].\n  shrinkAxisMask?: number;\n}\n\nexport type SliceInfo = {\n  finalShapeSparse: number[],\n  finalShape: number[],\n  isIdentity: boolean,\n  sliceDim0: boolean,\n  isSimpleSlice: boolean,\n  begin: number[],\n  end: number[],\n  strides: number[]\n};\n\nexport function assertParamsValid(\n    input: TensorInfo, begin: number[], size: number[]): void {\n  const inputRank = input.shape.length;\n  util.assert(\n      inputRank === begin.length,\n      () => `Error in slice${inputRank}D: Length of begin ${begin} must ` +\n          `match the rank of the array (${inputRank}).`);\n  util.assert(\n      inputRank === size.length,\n      () => `Error in slice${inputRank}D: Length of size ${size} must ` +\n          `match the rank of the array (${inputRank}).`);\n\n  for (let i = 0; i < inputRank; ++i) {\n    util.assert(\n        begin[i] + size[i] <= input.shape[i],\n        () => `Error in slice${inputRank}D: begin[${i}] + size[${i}] ` +\n            `(${begin[i] + size[i]}) would overflow input.shape[${i}] (${\n                  input.shape[i]})`);\n  }\n}\n\n/** Converts a binary mask to an array of axes. Used in stridedSlice(). */\nexport function maskToAxes(mask: number): number[] {\n  const axes = [];\n  let axis = 0;\n  while (mask > 0) {\n    if (mask & 1) {\n      axes.push(axis);\n    }\n    mask /= 2;\n    axis++;\n  }\n  return axes;\n}\n\n/** Computes the output shape given the strided slice params. */\nexport function computeOutShape(\n    begin: number[], end: number[], strides: number[]): number[] {\n  const size = [];\n  for (let axis = 0; axis < begin.length; axis++) {\n    size[axis] = Math.ceil((end[axis] - begin[axis]) / strides[axis]);\n  }\n  return size;\n}\n\n// Creates full selection at the elided dimensions. If the dimension matches\n// the ellipsis mask, override the current stride value. Otherwise, insert.\nexport function stridesWithElidedDims(\n    strides: number[], ellipsisInsertionIndex: number, numElidedAxes: number,\n    inputShape: number[]): number[] {\n  const newStrides = [...strides];\n  for (let i = newStrides.length; i < inputShape.length; i++) {\n    newStrides.push(1);\n  }\n  for (let i = 0; i < numElidedAxes; i++) {\n    if (i === 0) {\n      newStrides[ellipsisInsertionIndex] = 1;\n    } else {\n      newStrides.splice(\n          ellipsisInsertionIndex, 0 /* num elements to delete */,\n          1 /* element to add */);\n      newStrides.pop();\n    }\n  }\n  return newStrides;\n}\n\nfunction unnormalizeAxis(\n    ellipsisInsertionIndex: number, numElidedAxes: number,\n    normalizedAxis: number): number {\n  if (normalizedAxis <= ellipsisInsertionIndex) {\n    return normalizedAxis;\n  }\n\n  return normalizedAxis - (numElidedAxes - 1);\n}\n\nfunction getElidedAxes(numElidedAxes: number, ellipsisInsertionIndex: number) {\n  const elidedAxes = [];\n  for (let i = 0; i < numElidedAxes; i++) {\n    elidedAxes.push(ellipsisInsertionIndex + i);\n  }\n  return elidedAxes;\n}\n\n// Normalize the start, end and strides.\nexport function getNormalizedAxes(\n    inputShape: number[], ellipsisAxes: number[], numInterpolatedAxes: number,\n    begin: number[], end: number[], strides: number[], beginMask: number,\n    endMask: number,\n    ellipsisMask: number): {begin: number[], end: number[], strides: number[]} {\n  const inputRank = inputShape.length;\n  let normalizedBegin = new Array(inputRank),\n      normalizedEnd = new Array(inputRank),\n      normalizedStrides = new Array(inputRank);\n  if (ellipsisAxes.length && numInterpolatedAxes > 0) {\n    const fullIndex = ellipsisAxes[0];\n\n    // The ellipsis applies to the masked index as well as any dimensions\n    // that are interpolated.\n    const numElidedAxes = numInterpolatedAxes + 1;\n    normalizedBegin = startIndicesWithElidedDims(\n        beginMask, fullIndex, numElidedAxes, begin, inputShape);\n    normalizedEnd = stopIndicesWithElidedDims(\n        endMask, fullIndex, numElidedAxes, end, inputShape);\n    normalizedStrides =\n        stridesWithElidedDims(strides, fullIndex, numElidedAxes, inputShape);\n  } else {\n    for (let axis = 0; axis < inputRank; axis++) {\n      normalizedBegin[axis] = startForAxis(\n          beginMask, begin, strides, inputShape, axis, ellipsisMask);\n      normalizedEnd[axis] =\n          stopForAxis(endMask, end, strides, inputShape, axis, ellipsisMask);\n      normalizedStrides[axis] = stridesForAxis(strides, axis, ellipsisMask);\n    }\n  }\n\n  return {\n    begin: normalizedBegin,\n    end: normalizedEnd,\n    strides: normalizedStrides\n  };\n}\n\n// Creates full selection at the elided dimensions. If the dimension matches\n// the ellipsis mask, override the current start value. Otherwise, insert.\nexport function startIndicesWithElidedDims(\n    beginMask: number, ellipsisInsertionIndex: number, numElidedAxes: number,\n    originalBegin: number[], inputShape: number[]): number[] {\n  const newIndices = [...inputShape];\n  const elidedAxes = getElidedAxes(numElidedAxes, ellipsisInsertionIndex);\n\n  for (let axis = 0; axis < newIndices.length; axis++) {\n    if (elidedAxes.indexOf(axis) > -1) {\n      newIndices[axis] = 0;\n    } else {\n      const originalAxis =\n          unnormalizeAxis(ellipsisInsertionIndex, numElidedAxes, axis);\n      let originalValue = originalBegin[originalAxis];\n      if (beginMask & 1 << originalAxis) {\n        originalValue = 0;\n      }\n\n      newIndices[axis] = originalValue;\n    }\n  }\n  return newIndices;\n}\n\n// Creates full selection at the elided dimensions. If the dimension matches\n// the ellipsis mask, override the current stop value. Otherwise, insert.\nexport function stopIndicesWithElidedDims(\n    endMask: number, ellipsisInsertionIndex: number, numElidedAxes: number,\n    originalEnd: number[], inputShape: number[]): number[] {\n  const newIndices = [...inputShape];\n  const elidedAxes = getElidedAxes(numElidedAxes, ellipsisInsertionIndex);\n\n  for (let axis = 0; axis < newIndices.length; axis++) {\n    if (elidedAxes.indexOf(axis) > -1) {\n      newIndices[axis] = Number.MAX_SAFE_INTEGER;\n    } else {\n      const originalAxis =\n          unnormalizeAxis(ellipsisInsertionIndex, numElidedAxes, axis);\n      let originalValue = originalEnd[originalAxis];\n      if (endMask & 1 << originalAxis) {\n        originalValue = Number.MAX_SAFE_INTEGER;\n      }\n      newIndices[axis] = originalValue;\n    }\n  }\n\n  for (let i = 0; i < newIndices.length; i++) {\n    // Handle negative indices\n    const axisSize = inputShape[i];\n    if (newIndices[i] < 0) {\n      newIndices[i] += axisSize;\n    }\n    newIndices[i] = util.clamp(0, newIndices[i], inputShape[i]);\n  }\n  return newIndices;\n}\n\nexport function stridesForAxis(\n    strides: number[], axis: number, ellipsisMask: number): number {\n  let stride = strides[axis];\n  if (ellipsisMask & (1 << axis) || stride == null) {\n    stride = 1;\n  }\n\n  return stride;\n}\n\nexport function startForAxis(\n    beginMask: number, startIndices: number[], strides: number[],\n    inputShape: number[], axis: number, ellipsisMask: number): number {\n  // Begin with the specified index\n  let start = startIndices[axis];\n  const stride = strides[axis] || 1;\n\n  // Check the axis bit from right of masked axes, or the begin index is not set\n  // for the axis.\n  if (beginMask & 1 << axis || ellipsisMask & 1 << axis || start == null) {\n    if (stride > 0) {\n      // Forward iteration - use the first element. These values will get\n      // clamped below (Note: We could have set them to 0 and axis_size-1, but\n      // use lowest() and max() to maintain symmetry with StopForAxis())\n      start = Number.MIN_SAFE_INTEGER;\n    } else {\n      // Backward iteration - use the last element.\n      start = Number.MAX_SAFE_INTEGER;\n    }\n  }\n\n  // Handle negative indices\n  const axisSize = inputShape[axis];\n  if (start < 0) {\n    start += axisSize;\n  }\n\n  // Clamping\n  start = util.clamp(0, start, axisSize - 1);\n\n  return start;\n}\n\nexport function stopForAxis(\n    endMask: number, stopIndices: number[], strides: number[],\n    inputShape: number[], axis: number, ellipsisMask: number): number {\n  // Begin with the specified index\n  let stop = stopIndices[axis];\n  const stride = strides[axis] || 1;\n\n  // Check the axis bit from right of masked axes, or if the stop index is not\n  // set for this axis.\n  if (endMask & (1 << axis) || ellipsisMask & (1 << axis) || stop == null) {\n    if (stride > 0) {\n      // Forward iteration - use the last element. These values will get\n      // clamped below\n      stop = Number.MAX_SAFE_INTEGER;\n    } else {\n      // Backward iteration - use the first element.\n      stop = Number.MIN_SAFE_INTEGER;\n    }\n  }\n\n  // Handle negative indices\n  const axisSize = inputShape[axis];\n  if (stop < 0) {\n    stop += axisSize;\n  }\n\n  // Clamping\n  // Because the end index points one past the last element, we need slightly\n  // different clamping ranges depending on the direction.\n  if (stride > 0) {\n    // Forward iteration\n    stop = util.clamp(0, stop, axisSize);\n  } else {\n    // Backward iteration\n    stop = util.clamp(-1, stop, axisSize - 1);\n  }\n\n  return stop;\n}\n\n/**\n * Returns true if the slice occupies a continous set of elements in the\n * 'flat' space.\n */\nexport function isSliceContinous(\n    shape: number[], begin: number[], size: number[]) {\n  // Index of the first axis that has size > 1.\n  let firstNonOneAxis = size.length;\n  for (let i = 0; i < size.length; i++) {\n    if (size[i] > 1) {\n      firstNonOneAxis = i;\n      break;\n    }\n  }\n\n  for (let i = firstNonOneAxis + 1; i < size.length; i++) {\n    if (begin[i] > 0 || size[i] !== shape[i]) {\n      return false;\n    }\n  }\n  return true;\n}\n\nexport function computeFlatOffset(begin: number[], strides: number[]): number {\n  let flatOffset = begin.length > 0 ? begin[begin.length - 1] : 1;\n  for (let i = 0; i < begin.length - 1; i++) {\n    flatOffset += begin[i] * strides[i];\n  }\n  return flatOffset;\n}\n\nexport function parseSliceParams(\n    x: TensorInfo, begin: number|number[], size?: number|number[]) {\n  // The following logic allows for more ergonomic calls.\n  let begin_: number[];\n  const xRank = x.shape.length;\n  if (typeof begin === 'number') {\n    begin_ = [begin, ...new Array(xRank - 1).fill(0)];\n  } else if (begin.length < xRank) {\n    begin_ = begin.concat(new Array(xRank - begin.length).fill(0));\n  } else {\n    begin_ = begin.slice();\n  }\n  begin_.forEach(d => {\n    util.assert(\n        d !== -1, () => 'slice() does not support negative begin indexing.');\n  });\n  let size_: number[];\n  if (size == null) {\n    size_ = new Array(xRank).fill(-1);\n  } else if (typeof size === 'number') {\n    size_ = [size, ...new Array(xRank - 1).fill(-1)];\n  } else if (size.length < xRank) {\n    size_ = size.concat(new Array(xRank - size.length).fill(-1));\n  } else {\n    size_ = size;\n  }\n  size_ = size_.map((d, i) => {\n    if (d >= 0) {\n      return d;\n    } else {\n      util.assert(\n          d === -1,\n          () => `Negative size values should be exactly -1 but got ` +\n              `${d} for the slice() size at index ${i}.`);\n      return x.shape[i] - begin_[i];\n    }\n  });\n  return [begin_, size_];\n}\n\n// Convert the slicing specification from a sparse representation to a dense\n// representation. This means that all ellipses and newaxis are expanded out.\nexport function sliceInfo(\n    xShape: number[], begin: number[], end: number[], strides: number[],\n    beginMask: number, endMask: number, ellipsisMask: number,\n    newAxisMask: number, shrinkAxisMask: number): SliceInfo {\n  let stridesNonNull;\n  if (strides == null) {\n    stridesNonNull = new Array(begin.length);\n    stridesNonNull.fill(1);\n  } else {\n    stridesNonNull = strides;\n  }\n\n  // Only one non-zero bit is allowed in ellipsisMask, which means ellipsisMask\n  // is a power of 2. Use bit compares to ensure ellipsisMask is 0 or a power\n  // of 2. When i is a power of 2, i & (i - 1) is always 0.\n  // Also ref:\n  // https://stackoverflow.com/questions/600293/how-to-check-if-a-number-is-a-power-of-2\n  if (ellipsisMask != null && (ellipsisMask & (ellipsisMask - 1)) !== 0) {\n    throw new Error('Multiple ellipses in slice is not allowed.');\n  }\n\n  // Step 1: Account for ellipsis and new axis.\n  // Check for ellipsis and count how many non-newaxis there are after.\n  let ellipsisSeen = false;\n\n  const sparseSpec: StridedSliceSparseSpec = {\n    dims: stridesNonNull.length,\n    numAddAxisAfterEllipsis: 0,\n    begin: begin.slice(),\n    end: end.slice(),\n    strides: stridesNonNull.slice(),\n    beginMask,\n    endMask,\n    ellipsisMask,\n    newAxisMask,\n    shrinkAxisMask\n  };\n\n  for (let i = 0; i < sparseSpec.dims; i++) {\n    if (ellipsisSeen && ((1 << i) & newAxisMask) !== 0) {\n      sparseSpec.numAddAxisAfterEllipsis++;\n    }\n    if ((1 << i) & ellipsisMask) {\n      ellipsisSeen = true;\n    }\n  }\n  // If no ellipsis insert one at the end.\n  if (!ellipsisSeen) {\n    sparseSpec.ellipsisMask |= (1 << sparseSpec.dims);\n    sparseSpec.dims++;  // this effects loop iteration below\n  }\n\n  // Step 2: Make a sparse spec into a full index spec.\n  //\n  // The sparse spec deos not correspond to the number of dimensions.\n  // Make a dense spec that cooresponds to the number of dimensions.\n  //\n  // For example suppose foo[...,3:] on foo.shape = [2, 2, 3] then we need to\n  // produce the missing beginMask for the first two dimensions i.e. from\n  // beginMaskSpec = 0, endMaskSpec = 2, we achieve beginMask = 6 (110),\n  // endMask = 7 (111).\n  const denseSpec: StridedSliceDenseSpec = {\n    dims: xShape.length,\n    beginMask: 0,\n    endMask: 0,\n    beginValid: false,\n    endValid: false\n  };\n\n  buildDenseSpec(sparseSpec, denseSpec);\n\n  // Step 3: Make implicit ranges (non-zero beginMasks and endMasks) explicit\n  // and bounds check.\n  let isIdentity = true;\n  let sliceDim0 = true;\n  let isSimpleSlice = true;\n  const processingShape = [];\n  const finalShape = [];\n\n  for (let i = 0; i < xShape.length; ++i) {\n    if (denseSpec.strides[i] === 0) {\n      throw Error(`strides[${i}] must be non-zero`);\n    }\n    const shrinkI = !!(denseSpec.shrinkAxisMask & (1 << i));\n    const dimI = xShape[i];\n    if (dimI === -1) {\n      processingShape.push(shrinkI ? 1 : -1);\n      continue;\n    }\n\n    const masks =\n        [denseSpec.beginMask & (1 << i), denseSpec.endMask & (1 << i)];\n    const validRange = [\n      denseSpec.strides[i] > 0 ? 0 : -1,\n      denseSpec.strides[i] > 0 ? dimI : dimI - 1\n    ];\n\n    if (shrinkI && denseSpec.strides[i] <= 0) {\n      throw Error('only stride 1 allowed on non-range indexing.');\n    }\n\n    isSimpleSlice = isSimpleSlice && (denseSpec.strides[i] === 1);\n\n    const beginAndEndMasked =\n        !!((denseSpec.beginMask & (1 << i)) && (denseSpec.endMask & (1 << i)));\n\n    if (denseSpec.beginValid && denseSpec.endValid) {\n      if (shrinkI) {\n        // If we are shrinking, the end index is now possibly incorrect. In\n        // particular foo[-1] produces sparseBegin = -1, sparseEnd = 0.\n        // and canonical puts these to n-1 and 0, which implies a degenerate\n        // interval. Fortunately, it is now safe to re-create end as begin + 1.\n        const xFwd = denseSpec.begin[i] < 0 ? dimI + denseSpec.begin[i] :\n                                              denseSpec.begin[i];\n        denseSpec.begin[i] = xFwd;\n        denseSpec.end[i] = denseSpec.begin[i] + 1;\n        if (xFwd < 0 || xFwd >= dimI) {\n          throw Error(`slice index ${denseSpec.begin[i]} of dimension ${\n              i} out of bounds.`);\n        }\n      } else {\n        denseSpec.begin[i] = canonical(\n            denseSpec.begin[i], 0, denseSpec.strides[i], dimI, masks,\n            validRange);\n        denseSpec.end[i] = canonical(\n            denseSpec.end[i], 1, denseSpec.strides[i], dimI, masks, validRange);\n      }\n      // Update optimization values\n      const takeAllInDimension = denseSpec.strides[i] === 1 &&\n          denseSpec.begin[i] === 0 && denseSpec.end[i] === dimI;\n      isIdentity = isIdentity && takeAllInDimension;\n      sliceDim0 = sliceDim0 &&\n          ((i === 0 && denseSpec.strides[i] === 1) || takeAllInDimension);\n    } else {\n      isIdentity =\n          isIdentity && ((denseSpec.strides[i] === 1) && beginAndEndMasked);\n      sliceDim0 = sliceDim0 &&\n          ((i === 0 && denseSpec.strides[i] === 1) || beginAndEndMasked);\n    }\n    // Compute the processing shape (the intermediate Eigen will produce)\n    let intervalLength;\n    let knownInterval = false;\n    if (denseSpec.beginValid && denseSpec.endValid) {\n      intervalLength = denseSpec.end[i] - denseSpec.begin[i];\n      knownInterval = true;\n    } else if (shrinkI) {\n      // The dimension is still known as 1 for the processingShape, but will be\n      // discarded for the final shape.\n      intervalLength = 1;\n      knownInterval = true;\n    } else if (beginAndEndMasked) {\n      // Even if we don't have values for begin or end, we do know that this\n      // dimension covers the whole interval. If we have shape information for\n      // this dimension, that tells us the interval length.\n      if (dimI >= 0) {\n        if (denseSpec.strides[i] < 0) {\n          intervalLength = -dimI;\n        } else {\n          intervalLength = dimI;\n        }\n        knownInterval = true;\n      }\n    }\n    if (knownInterval) {\n      let sizeI;\n      // Hold zero if the interval is degenerate, otherwise account for\n      // remainder\n      if (intervalLength === 0 ||\n          ((intervalLength < 0) !== (denseSpec.strides[i] < 0))) {\n        sizeI = 0;\n      } else {\n        sizeI = Math.trunc(intervalLength / denseSpec.strides[i]) +\n            (intervalLength % denseSpec.strides[i] !== 0 ? 1 : 0);\n      }\n      processingShape.push(sizeI);\n    } else {\n      processingShape.push(-1);\n    }\n  }\n\n  // Step 4: Compute the final shape\n  //\n  // newAxis will increase dimension by 1 (with a one-size dimension)\n  // slices like foo[3, ...] will reduce dimension by 1.\n  // This cannot be done earlier, because it depends on Step 3.\n  for (let denseDim = 0; denseDim < denseSpec.finalShapeGatherIndices.length;\n       ++denseDim) {\n    const gatherIndex = denseSpec.finalShapeGatherIndices[denseDim];\n    if (gatherIndex >= 0) {\n      finalShape.push(processingShape[gatherIndex]);\n    } else if (gatherIndex === NEW_AXIS) {\n      finalShape.push(1);\n    }\n  }\n\n  const finalShapeSparse = finalShape.filter(\n      (dim, i) => denseSpec.finalShapeGatherIndices[i] !== NEW_AXIS);\n\n  return {\n    finalShapeSparse,\n    finalShape,\n    isIdentity,\n    sliceDim0,\n    isSimpleSlice,\n    begin: denseSpec.begin,\n    end: denseSpec.end,\n    strides: denseSpec.strides\n  };\n}\n\nfunction buildDenseSpec(\n    sparse: StridedSliceSparseSpec, dense: StridedSliceDenseSpec) {\n  dense.beginMask = 0;\n  dense.endMask = 0;\n  dense.shrinkAxisMask = 0;\n\n  let fullIndex = 0;\n  dense.beginValid = sparse.begin != null;\n  dense.endValid = sparse.end != null;\n\n  dense.begin = new Array(dense.dims);\n  dense.end = new Array(dense.dims);\n  dense.strides = new Array(dense.dims);\n  dense.finalShapeGatherIndices = [];\n  dense.finalShapeGatherIndicesSparse = [];\n  dense.inputShapeGatherIndicesSparse = new Array(dense.dims);\n\n  for (let i = 0; i < sparse.dims; i++) {\n    if ((1 << i) & sparse.ellipsisMask) {\n      // Only the bit that has ellipsis will fall in this condition.\n      // Expand the ellipsis into the appropriate indices\n      // Note: this only works because we guaranteed one ellipsis.\n      const nextIndex = Math.min(\n          dense.dims - (sparse.dims - i) + 1 + sparse.numAddAxisAfterEllipsis,\n          dense.dims);\n      for (; fullIndex < nextIndex; fullIndex++) {\n        // newAxis aren't real axis so you have to skip.\n        dense.begin[fullIndex] = 0;\n        dense.end[fullIndex] = 0;\n        dense.strides[fullIndex] = 1;\n        dense.beginMask |= (1 << fullIndex);\n        dense.endMask |= (1 << fullIndex);\n        dense.finalShapeGatherIndices.push(fullIndex);\n        dense.finalShapeGatherIndicesSparse.push(-1);\n        dense.inputShapeGatherIndicesSparse[fullIndex] = i;\n      }\n    } else if ((1 << i) & sparse.newAxisMask) {\n      // Only the bit that has newAxis will fall in this condition.\n      dense.finalShapeGatherIndices.push(NEW_AXIS);\n      dense.finalShapeGatherIndicesSparse.push(-1);\n    } else {\n      if (fullIndex === dense.begin.length) {\n        throw Error(\n            `Index out of range using input dim ${fullIndex}; input ` +\n            `has only ${dense.dims} dims, ${dense.begin.length}.`);\n      }\n\n      // Gather slicing spec into appropriate index.\n      if (sparse.begin != null) {\n        dense.begin[fullIndex] = sparse.begin[i];\n      }\n      if (sparse.end != null) {\n        dense.end[fullIndex] = sparse.end[i];\n      }\n      dense.strides[fullIndex] = sparse.strides[i];\n      if (sparse.beginMask & (1 << i)) {\n        dense.beginMask |= (1 << fullIndex);\n      }\n      if (sparse.endMask & (1 << i)) {\n        dense.endMask |= (1 << fullIndex);\n      }\n      // If shrink, record where to get the dimensionality from (i.e. newAxis)\n      // creates a fake 1 size dimension. Also remember shrink axis (now in\n      // dense form) so we can ignore dense.end below.\n      if (sparse.shrinkAxisMask & (1 << i)) {\n        dense.finalShapeGatherIndices.push(SHRINK_AXIS);\n        dense.finalShapeGatherIndicesSparse.push(-1);\n        dense.shrinkAxisMask |= (1 << fullIndex);\n      } else {\n        dense.finalShapeGatherIndices.push(fullIndex);\n        // Remember that where in the sparse shape the dense dim comes from.\n        dense.finalShapeGatherIndicesSparse.push(i);\n      }\n      dense.inputShapeGatherIndicesSparse[fullIndex] = i;\n      fullIndex++;\n    }\n  }\n}\n\nfunction canonical(\n    x: number, c: number, strideI: number, dimI: number, masks: number[],\n    validRange: number[]) {\n  if (masks[c]) {\n    return strideI > 0 ? validRange[c] : validRange[(c + 1) & 1];\n  } else {\n    const xFwd = x < 0 ? dimI + x : x;  // make negative indices positive\n    return xFwd < validRange[0] ? validRange[0] :\n                                  xFwd > validRange[1] ? validRange[1] : xFwd;\n  }\n}\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {assert} from './util';\n\n/**\n * Types to support JSON-esque data structures internally.\n *\n * Internally ConfigDict's use camelCase keys and values where the\n * values are class names to be instantiated.  On the python side, these\n * will be snake_case.  Internally we allow Enums into the values for better\n * type safety, but these need to be converted to raw primitives (usually\n * strings) for round-tripping with python.\n *\n * toConfig returns the TS-friendly representation. model.toJSON() returns\n * the pythonic version as that's the portable format.  If you need to\n * python-ify a non-model level toConfig output, you'll need to use a\n * convertTsToPythonic from serialization_utils in -Layers.\n *\n */\nexport declare type ConfigDictValue =\n    boolean | number | string | null | ConfigDictArray | ConfigDict;\nexport declare interface ConfigDict {\n  [key: string]: ConfigDictValue;\n}\nexport declare interface ConfigDictArray extends Array<ConfigDictValue> {}\n\n/**\n * Type to represent the class-type of Serializable objects.\n *\n * Ie the class prototype with access to the constructor and any\n * static members/methods. Instance methods are not listed here.\n *\n * Source for this idea: https://stackoverflow.com/a/43607255\n */\nexport declare type SerializableConstructor<T extends Serializable> = {\n  // tslint:disable-next-line:no-any\n  new (...args: any[]): T; className: string; fromConfig: FromConfigMethod<T>;\n};\nexport declare type FromConfigMethod<T extends Serializable> =\n    (cls: SerializableConstructor<T>, config: ConfigDict) => T;\n\n/**\n * Serializable defines the serialization contract.\n *\n * TFJS requires serializable classes to return their className when asked\n * to avoid issues with minification.\n */\nexport abstract class Serializable {\n  /**\n   * Return the class name for this class to use in serialization contexts.\n   *\n   * Generally speaking this will be the same thing that constructor.name\n   * would have returned.  However, the class name needs to be robust\n   * against minification for serialization/deserialization to work properly.\n   *\n   * There's also places such as initializers.VarianceScaling, where\n   * implementation details between different languages led to different\n   * class hierarchies and a non-leaf node is used for serialization purposes.\n   */\n  getClassName(): string {\n    return (this.constructor as SerializableConstructor<Serializable>)\n        .className;\n  }\n\n  /**\n   * Return all the non-weight state needed to serialize this object.\n   */\n  abstract getConfig(): ConfigDict;\n\n  /**\n   * Creates an instance of T from a ConfigDict.\n   *\n   * This works for most descendants of serializable.  A few need to\n   * provide special handling.\n   * @param cls A Constructor for the class to instantiate.\n   * @param config The Configuration for the object.\n   */\n  /** @nocollapse */\n  static fromConfig<T extends Serializable>(\n      cls: SerializableConstructor<T>, config: ConfigDict): T {\n    return new cls(config);\n  }\n}\n\n/**\n * Maps string keys to class constructors.\n *\n * Used during (de)serialization from the cross-language JSON format, which\n * requires the class name in the serialization format matches the class\n * names as used in Python, should it exist.\n */\nexport class SerializationMap {\n  private static instance: SerializationMap;\n  classNameMap: {\n    [className: string]:\n        [SerializableConstructor<Serializable>, FromConfigMethod<Serializable>]\n  };\n\n  private constructor() {\n    this.classNameMap = {};\n  }\n\n  /**\n   * Returns the singleton instance of the map.\n   */\n  static getMap(): SerializationMap {\n    if (SerializationMap.instance == null) {\n      SerializationMap.instance = new SerializationMap();\n    }\n    return SerializationMap.instance;\n  }\n\n  /**\n   * Registers the class as serializable.\n   */\n  static register<T extends Serializable>(cls: SerializableConstructor<T>) {\n    SerializationMap.getMap().classNameMap[cls.className] =\n        [cls, cls.fromConfig];\n  }\n}\n\n/**\n * Register a class with the serialization map of TensorFlow.js.\n *\n * This is often used for registering custom Layers, so they can be\n * serialized and deserialized.\n *\n * Example:\n *\n * ```js\n * class MyCustomLayer extends tf.layers.Layer {\n *   static className = 'MyCustomLayer';\n *\n *   constructor(config) {\n *     super(config);\n *   }\n * }\n * tf.serialization.registerClass(MyCustomLayer);\n * ```\n *\n * @param cls The class to be registered. It must have a public static member\n *   called `className` defined and the value must be a non-empty string.\n *\n * @doc {heading: 'Models', subheading: 'Serialization', ignoreCI: true}\n */\nexport function registerClass<T extends Serializable>(\n    cls: SerializableConstructor<T>) {\n  assert(\n      cls.className != null,\n      () => `Class being registered does not have the static className ` +\n          `property defined.`);\n  assert(\n      typeof cls.className === 'string',\n      () => `className is required to be a string, but got type ` +\n          typeof cls.className);\n  assert(\n      cls.className.length > 0,\n      () => `Class being registered has an empty-string as its className, ` +\n          `which is disallowed.`);\n\n  SerializationMap.register(cls);\n}\n","/**\n * @license\n * Copyright 2017 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from './engine';\nimport {inferShape} from './tensor_util_env';\nimport {RecursiveArray, TensorLike, TypedArray} from './types';\nimport {arraysEqual, encodeString, flatten, isString, isTypedArray} from './util';\n\nconst TEST_EPSILON_FLOAT32 = 1e-3;\nexport const TEST_EPSILON_FLOAT16 = 1e-1;\n\nexport function expectArraysClose(\n    actual: TypedArray|number|RecursiveArray<number>,\n    expected: TypedArray|number|RecursiveArray<number>, epsilon?: number) {\n  if (epsilon == null) {\n    epsilon = testEpsilon();\n  }\n  return expectArraysPredicate(\n      actual, expected, (a, b) => areClose(a as number, b as number, epsilon));\n}\n\nexport function testEpsilon() {\n  return ENGINE.backend.floatPrecision() === 32 ? TEST_EPSILON_FLOAT32 :\n                                                  TEST_EPSILON_FLOAT16;\n}\n\nfunction expectArraysPredicate(\n    actual: TensorLike, expected: TensorLike,\n    predicate: (a: {}, b: {}) => boolean) {\n  let checkClassType = true;\n  if (isTypedArray(actual) || isTypedArray(expected)) {\n    checkClassType = false;\n  }\n  if (isTypedArray(actual) && isTypedArray(expected)) {\n    checkClassType = true;\n  }\n  if (checkClassType) {\n    const aType = actual.constructor.name;\n    const bType = expected.constructor.name;\n\n    if (aType !== bType) {\n      throw new Error(\n          `Arrays are of different type. Actual: ${aType}. ` +\n          `Expected: ${bType}`);\n    }\n  }\n\n  if (Array.isArray(actual) && Array.isArray(expected)) {\n    const actualShape = inferShape(actual);\n    const expectedShape = inferShape(expected);\n    if (!arraysEqual(actualShape, expectedShape)) {\n      throw new Error(\n          `Arrays have different shapes. ` +\n          `Actual: [${actualShape}]. Expected: [${expectedShape}]`);\n    }\n  }\n\n  const actualFlat =\n      isTypedArray(actual) ? actual : flatten(actual as RecursiveArray<number>);\n  const expectedFlat = isTypedArray(expected) ?\n      expected :\n      flatten(expected as RecursiveArray<number>);\n\n  if (actualFlat.length !== expectedFlat.length) {\n    throw new Error(\n        `Arrays have different lengths actual: ${actualFlat.length} vs ` +\n        `expected: ${expectedFlat.length}.\\n` +\n        `Actual:   ${actualFlat}.\\n` +\n        `Expected: ${expectedFlat}.`);\n  }\n  for (let i = 0; i < expectedFlat.length; ++i) {\n    const a = actualFlat[i];\n    const e = expectedFlat[i];\n\n    if (!predicate(a, e)) {\n      throw new Error(\n          `Arrays differ: actual[${i}] = ${a}, expected[${i}] = ${e}.\\n` +\n          `Actual:   ${actualFlat}.\\n` +\n          `Expected: ${expectedFlat}.`);\n    }\n  }\n  if (typeof expect !== 'undefined') {\n    expect().nothing();\n  }\n}\n\nexport interface DoneFn {\n  (): void;\n  fail: (message?: Error|string) => void;\n}\n\nexport function expectPromiseToFail(fn: () => Promise<{}>, done: DoneFn): void {\n  fn().then(() => done.fail(), () => done());\n  if (typeof expect !== 'undefined') {\n    expect().nothing();\n  }\n}\n\nexport function expectArraysEqual(actual: TensorLike, expected: TensorLike) {\n  const exp = typeof expected === 'string' || typeof expected === 'number' ||\n          typeof expected === 'boolean' ?\n      [expected] as number[] :\n      expected as number[];\n  if (isString(actual) || isString((actual as string[])[0]) ||\n      isString(expected) || isString((expected as string[])[0])) {\n    // tslint:disable-next-line: triple-equals\n    return expectArraysPredicate(actual, exp, (a, b) => a == b);\n  }\n  return expectArraysPredicate(\n      actual, expected, (a, b) => areClose(a as number, b as number, 0));\n}\n\nexport function expectNumbersClose(a: number, e: number, epsilon?: number) {\n  if (epsilon == null) {\n    epsilon = testEpsilon();\n  }\n  if (!areClose(a, e, epsilon)) {\n    throw new Error(`Numbers differ: actual === ${a}, expected === ${e}`);\n  }\n  if (typeof expect !== 'undefined') {\n    expect().nothing();\n  }\n}\n\nfunction areClose(a: number, e: number, epsilon: number): boolean {\n  if (!isFinite(a) && !isFinite(e)) {\n    return true;\n  }\n  if (isNaN(a) || isNaN(e) || Math.abs(a - e) > epsilon) {\n    return false;\n  }\n  return true;\n}\n\nexport function expectValuesInRange(\n    actual: TypedArray|number[], low: number, high: number) {\n  for (let i = 0; i < actual.length; i++) {\n    if (actual[i] < low || actual[i] > high) {\n      throw new Error(\n          `Value out of range:${actual[i]} low: ${low}, high: ${high}`);\n    }\n  }\n}\n\nexport function expectArrayBuffersEqual(\n    actual: ArrayBuffer, expected: ArrayBuffer) {\n  // Safari does not like comparing ArrayBuffers directly. Wrapping in\n  // a Float32Array solves this issue.\n  const actualArray = new Float32Array(actual);\n  const expectedArray = new Float32Array(expected);\n  if (actualArray.length !== expectedArray.length) {\n    throw new Error(\n        'Expected ArrayBuffer to be of length ' +\n        `${expectedArray.length}, but it was ${actualArray.length}`);\n  }\n\n  for (let i = 0; i < expectedArray.length; i++) {\n    if (actualArray[i] !== expectedArray[i]) {\n      throw new Error(\n          `Expected ArrayBuffer value at ${i} to be ` +\n          `${expectedArray[i]} but got ${actualArray[i]} instead`);\n    }\n  }\n}\n\n/** Encodes strings into utf-8 bytes. */\nexport function encodeStrings(a: RecursiveArray<{}>):\n    RecursiveArray<Uint8Array> {\n  for (let i = 0; i < (a as Array<{}>).length; i++) {\n    const val = a[i];\n    if (Array.isArray(val)) {\n      encodeStrings(val);\n    } else {\n      a[i] = encodeString(val as string);\n    }\n  }\n  return a as RecursiveArray<Uint8Array>;\n}\n\n/** Creates an HTMLVideoElement with autoplay-friendly default settings. */\nexport function createVideoElement(source: HTMLSourceElement):\n    Promise<HTMLVideoElement> {\n  const video = document.createElement('video');\n  if ('playsInline' in video) {\n    // tslint:disable-next-line:no-any\n    (video as any).playsInline = true;\n  }\n  video.muted = true;\n  video.loop = true;\n  video.style.position = 'fixed';\n  video.style.left = '0px';\n  video.style.top = '0px';\n\n  video.preload = 'auto';\n  video.appendChild(source);\n  return new Promise(resolve => {\n    video.addEventListener('loadeddata', _ => resolve(video));\n    video.load();\n  });\n}\n\nexport async function play(video: HTMLVideoElement) {\n  await video.play();\n  if ('requestVideoFrameCallback' in video) {\n    await new Promise(resolve => {\n      // tslint:disable-next-line:no-any\n      (video as any).requestVideoFrameCallback(resolve);\n    });\n  }\n}\n","/** @license See the LICENSE file. */\n\n// This code is auto-generated, do not modify this file!\nconst version = '3.21.0';\nexport {version};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {ENGINE} from '../engine';\nimport {Add, AddInputs} from '../kernel_names';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {makeTypesMatch} from '../tensor_util';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {op} from './operation';\n\n/**\n * Adds two `tf.Tensor`s element-wise, A + B. Supports broadcasting.\n *\n *\n * ```js\n * const a = tf.tensor1d([1, 2, 3, 4]);\n * const b = tf.tensor1d([10, 20, 30, 40]);\n *\n * a.add(b).print();  // or tf.add(a, b)\n * ```\n *\n * ```js\n * // Broadcast add a with b.\n * const a = tf.scalar(5);\n * const b = tf.tensor1d([10, 20, 30, 40]);\n *\n * a.add(b).print();  // or tf.add(a, b)\n * ```\n * @param a The first `tf.Tensor` to add.\n * @param b The second `tf.Tensor` to add. Must have the same type as `a`.\n *\n * @doc {heading: 'Operations', subheading: 'Arithmetic'}\n */\nfunction add_<T extends Tensor>(a: Tensor|TensorLike, b: Tensor|TensorLike): T {\n  let $a = convertToTensor(a, 'a', 'add');\n  let $b = convertToTensor(b, 'b', 'add');\n  [$a, $b] = makeTypesMatch($a, $b);\n\n  const inputs: AddInputs = {a: $a, b: $b};\n\n  return ENGINE.runKernel(Add, inputs as {} as NamedTensorMap);\n}\n\nexport const add = op({add_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {FloorDiv, FloorDivInputs} from '../kernel_names';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {makeTypesMatch} from '../tensor_util';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {op} from './operation';\n\n/**\n * Divides two `tf.Tensor`s element-wise, A / B. Supports broadcasting.\n * The result is rounded with floor function.\n *\n *\n * ```js\n * const a = tf.tensor1d([1, 4, 9, 16]);\n * const b = tf.tensor1d([1, 2, 3, 4]);\n *\n * a.floorDiv(b).print();  // or tf.div(a, b)\n * ```\n *\n * ```js\n * // Broadcast div a with b.\n * const a = tf.tensor1d([2, 4, 6, 8]);\n * const b = tf.scalar(2);\n *\n * a.floorDiv(b).print();  // or tf.floorDiv(a, b)\n * ```\n *\n * @param a The first tensor as the numerator.\n * @param b The second tensor as the denominator. Must have the same dtype as\n * `a`.\n *\n * @doc {heading: 'Operations', subheading: 'Arithmetic'}\n */\nfunction floorDiv_<T extends Tensor>(\n    a: Tensor|TensorLike, b: Tensor|TensorLike): T {\n  let $a = convertToTensor(a, 'a', 'floorDiv');\n  let $b = convertToTensor(b, 'b', 'floorDiv');\n  [$a, $b] = makeTypesMatch($a, $b);\n\n  const inputs: FloorDivInputs = {a: $a, b: $b};\n\n  return ENGINE.runKernel(FloorDiv, inputs as {} as NamedTensorMap);\n}\n\nexport const floorDiv = op({floorDiv_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {RealDiv, RealDivInputs} from '../kernel_names';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {makeTypesMatch} from '../tensor_util';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {floorDiv} from './floorDiv';\nimport {op} from './operation';\n\n/**\n * Divides two `tf.Tensor`s element-wise, A / B. Supports broadcasting.\n *\n * ```js\n * const a = tf.tensor1d([1, 4, 9, 16]);\n * const b = tf.tensor1d([1, 2, 3, 4]);\n *\n * a.div(b).print();  // or tf.div(a, b)\n * ```\n *\n * ```js\n * // Broadcast div a with b.\n * const a = tf.tensor1d([2, 4, 6, 8]);\n * const b = tf.scalar(2);\n *\n * a.div(b).print();  // or tf.div(a, b)\n * ```\n *\n * @param a The first tensor as the numerator.\n * @param b The second tensor as the denominator. Must have the same dtype as\n * `a`.\n *\n * @doc {heading: 'Operations', subheading: 'Arithmetic'}\n */\nfunction div_<T extends Tensor>(a: Tensor|TensorLike, b: Tensor|TensorLike): T {\n  let $a = convertToTensor(a, 'a', 'div');\n  let $b = convertToTensor(b, 'b', 'div');\n  [$a, $b] = makeTypesMatch($a, $b);\n\n  if ($a.dtype === 'int32' && $b.dtype === 'int32') {\n    return floorDiv($a, $b);\n  }\n\n  const inputs: RealDivInputs = {a: $a, b: $b};\n  const attrs = {};\n\n  // tslint:disable-next-line: no-unnecessary-type-assertion\n  return ENGINE.runKernel(RealDiv, inputs as {} as NamedTensorMap, attrs) as T;\n}\n\nexport const div = op({div_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {Multiply, MultiplyInputs} from '../kernel_names';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {makeTypesMatch} from '../tensor_util';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {op} from './operation';\n\n/**\n * Multiplies two `tf.Tensor`s element-wise, A * B. Supports broadcasting.\n *\n * We also expose `tf.mulStrict` which has the same signature as this op and\n * asserts that `a` and `b` are the same shape (does not broadcast).\n *\n * ```js\n * const a = tf.tensor1d([1, 2, 3, 4]);\n * const b = tf.tensor1d([2, 3, 4, 5]);\n *\n * a.mul(b).print();  // or tf.mul(a, b)\n * ```\n *\n * ```js\n * // Broadcast mul a with b.\n * const a = tf.tensor1d([1, 2, 3, 4]);\n * const b = tf.scalar(5);\n *\n * a.mul(b).print();  // or tf.mul(a, b)\n * ```\n * @param a The first tensor to multiply.\n * @param b The second tensor to multiply. Must have the same dtype as `a`.\n *\n * @doc {heading: 'Operations', subheading: 'Arithmetic'}\n */\nfunction mul_<T extends Tensor>(a: Tensor|TensorLike, b: Tensor|TensorLike): T {\n  let $a = convertToTensor(a, 'a', 'mul');\n  let $b = convertToTensor(b, 'b', 'mul');\n  [$a, $b] = makeTypesMatch($a, $b);\n\n  const inputs: MultiplyInputs = {a: $a, b: $b};\n\n  return ENGINE.runKernel(Multiply, inputs as {} as NamedTensorMap);\n}\nexport const mul = op({mul_});\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {Sqrt, SqrtInputs} from '../kernel_names';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {op} from './operation';\n\n/**\n * Computes square root of the input `tf.Tensor` element-wise: `y = sqrt(x)`\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 4, -1]);\n *\n * x.sqrt().print();  // or tf.sqrt(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction sqrt_<T extends Tensor>(x: T|TensorLike): T {\n  const $x = convertToTensor(x, 'x', 'sqrt', 'float32');\n\n  const inputs: SqrtInputs = {x: $x};\n\n  return ENGINE.runKernel(Sqrt, inputs as {} as NamedTensorMap);\n}\nexport const sqrt = op({sqrt_});\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {Tensor} from '../tensor';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\nimport {op} from './operation';\n\n/**\n * Computes square of `x` element-wise: `x ^ 2`\n *\n * ```js\n * const x = tf.tensor1d([1, 2, Math.sqrt(2), -1]);\n *\n * x.square().print();  // or tf.square(x)\n * ```\n * @param x The input Tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction square_<T extends Tensor>(x: T|TensorLike): T {\n  const $x = convertToTensor(x, 'x', 'square');\n  const attrs = {};\n  return ENGINE.runKernel('Square', {x: $x}, attrs);\n}\n\nexport const square = op({square_});\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {ZerosLike, ZerosLikeInputs} from '../kernel_names';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {op} from './operation';\n\n/**\n * Creates a `tf.Tensor` with all elements set to 0 with the same shape as the\n * given tensor.\n *\n * ```js\n * const x = tf.tensor([1, 2]);\n * tf.zerosLike(x).print();\n * ```\n *\n * @param x The tensor of required shape.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nfunction zerosLike_<T extends Tensor>(x: T|TensorLike): T {\n  const $x = convertToTensor(x, 'x', 'zerosLike');\n  const inputs: ZerosLikeInputs = {x: $x};\n  return ENGINE.runKernel(ZerosLike, inputs as {} as NamedTensorMap);\n}\nexport const zerosLike = op({zerosLike_});\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {CustomGradientFunc, ENGINE} from './engine';\nimport {Scalar, Tensor, Variable} from './tensor';\nimport {NamedTensorMap} from './tensor_types';\nimport {convertToTensor, convertToTensorArray} from './tensor_util_env';\nimport {TensorLike} from './types';\nimport * as util from './util';\n\n/**\n * Provided `f(x)`, returns another function `g(x, dy?)`, which gives the\n * gradient of `f(x)` with respect to `x`.\n *\n * If `dy` is provided, the gradient of `f(x).mul(dy).sum()` with respect to\n * `x` is computed instead. `f(x)` must take a single tensor `x` and return a\n * single tensor `y`. If `f()` takes multiple inputs, use `tf.grads` instead.\n *\n * ```js\n * // f(x) = x ^ 2\n * const f = x => x.square();\n * // f'(x) = 2x\n * const g = tf.grad(f);\n *\n * const x = tf.tensor1d([2, 3]);\n * g(x).print();\n * ```\n *\n * ```js\n * // f(x) = x ^ 3\n * const f = x => x.pow(tf.scalar(3, 'int32'));\n * // f'(x) = 3x ^ 2\n * const g = tf.grad(f);\n * // f''(x) = 6x\n * const gg = tf.grad(g);\n *\n * const x = tf.tensor1d([2, 3]);\n * gg(x).print();\n * ```\n *\n * @param f The function f(x), to compute gradient for.\n *\n * @doc {heading: 'Training', subheading: 'Gradients'}\n */\nfunction grad(f: (x: Tensor) => Tensor): (\n    x: TensorLike|Tensor, dy?: TensorLike|Tensor) => Tensor {\n  util.assert(\n      util.isFunction(f), () => 'The f passed in grad(f) must be a function');\n  return (x: TensorLike|Tensor, dy?: TensorLike|Tensor): Tensor => {\n    // x can be of any dtype, thus null as the last argument.\n    const $x = convertToTensor(x, 'x', 'tf.grad', 'string_or_numeric');\n    const $dy: Tensor =\n        (dy != null) ? convertToTensor(dy, 'dy', 'tf.grad') : null;\n    return ENGINE.tidy(() => {\n      const {value, grads} = ENGINE.gradients(() => f($x), [$x], $dy);\n      if ($dy != null) {\n        util.assertShapesMatch(\n            value.shape, $dy.shape,\n            'The shape of dy passed in grad(f)(x, dy) must match the shape ' +\n                'returned by f(x)');\n      }\n      checkGrads(grads);\n      return grads[0];\n    });\n  };\n}\n\n/**\n * Provided `f(x1, x2,...)`, returns another function `g([x1, x2,...], dy?)`,\n * which gives an array of gradients of `f()` with respect to each input\n * [`x1`,`x2`,...].\n *\n * If `dy` is passed when calling `g()`, the gradient of\n * `f(x1,...).mul(dy).sum()` with respect to each input is computed instead.\n * The provided `f` must take one or more tensors and return a single tensor\n * `y`. If `f()` takes a single input, we recommend using `tf.grad` instead.\n *\n * ```js\n * // f(a, b) = a * b\n * const f = (a, b) => a.mul(b);\n * // df / da = b, df / db = a\n * const g = tf.grads(f);\n *\n * const a = tf.tensor1d([2, 3]);\n * const b = tf.tensor1d([-2, -3]);\n * const [da, db] = g([a, b]);\n * console.log('da');\n * da.print();\n * console.log('db');\n * db.print();\n * ```\n *\n * @param f The function `f(x1, x2,...)` to compute gradients for.\n *\n * @doc {heading: 'Training', subheading: 'Gradients'}\n */\nfunction grads(f: (...args: Tensor[]) => Tensor): (\n    args: Array<Tensor|TensorLike>, dy?: Tensor|TensorLike) => Tensor[] {\n  util.assert(\n      util.isFunction(f), () => 'The f passed in grads(f) must be a function');\n  return (args: Array<Tensor|TensorLike>, dy?: Tensor|TensorLike): Tensor[] => {\n    util.assert(\n        Array.isArray(args),\n        () => 'The args passed in grads(f)(args) must be an array ' +\n            'of `Tensor`s or `TensorLike`s');\n    // args can be of any dtype, thus null as the last argument.\n    const $args =\n        convertToTensorArray(args, 'args', 'tf.grads', 'string_or_numeric');\n    const $dy: Tensor =\n        (dy != null) ? convertToTensor(dy, 'dy', 'tf.grads') : null;\n    return ENGINE.tidy(() => {\n      const {value, grads} = ENGINE.gradients(() => f(...$args), $args, $dy);\n      if ($dy != null) {\n        util.assertShapesMatch(\n            value.shape, $dy.shape,\n            'The shape of dy passed in grads(f)([x1,...], dy) must ' +\n                'match the shape returned by f([x1,...])');\n      }\n      checkGrads(grads);\n      return grads;\n    });\n  };\n}\n\n/**\n * Like `tf.grad`, but also returns the value of `f()`. Useful when `f()`\n * returns a metric you want to show.\n *\n * The result is a rich object with the following properties:\n * - grad: The gradient of `f(x)` w.r.t. `x` (result of `tf.grad`).\n * - value: The value returned by `f(x)`.\n *\n * ```js\n * // f(x) = x ^ 2\n * const f = x => x.square();\n * // f'(x) = 2x\n * const g = tf.valueAndGrad(f);\n *\n * const x = tf.tensor1d([2, 3]);\n * const {value, grad} = g(x);\n *\n * console.log('value');\n * value.print();\n * console.log('grad');\n * grad.print();\n * ```\n *\n * @doc {heading: 'Training', subheading: 'Gradients'}\n */\nfunction valueAndGrad<I extends Tensor, O extends Tensor>(f: (x: I) => O): (\n    x: I, dy?: O) => {\n  value: O;\n  grad: I;\n} {\n  util.assert(\n      util.isFunction(f),\n      () => 'The f passed in valueAndGrad(f) must be a function');\n  return (x: I, dy?: O) => {\n    util.assert(\n        x instanceof Tensor,\n        () => 'The x passed in valueAndGrad(f)(x) must be a tensor');\n    util.assert(\n        dy == null || dy instanceof Tensor,\n        () => 'The dy passed in valueAndGrad(f)(x, dy) must be a tensor');\n    const {grads, value} = ENGINE.gradients(() => f(x), [x], dy);\n    checkGrads(grads);\n    return {grad: grads[0] as I, value};\n  };\n}\n\n/**\n * Like `tf.grads`, but returns also the value of `f()`. Useful when `f()`\n * returns a metric you want to show.\n *\n * The result is a rich object with the following properties:\n * - grads: The gradients of `f()` w.r.t. each input (result of `tf.grads`).\n * - value: The value returned by `f(x)`.\n *\n * ```js\n * // f(a, b) = a * b\n * const f = (a, b) => a.mul(b);\n * // df/da = b, df/db = a\n * const g = tf.valueAndGrads(f);\n *\n * const a = tf.tensor1d([2, 3]);\n * const b = tf.tensor1d([-2, -3]);\n * const {value, grads} = g([a, b]);\n *\n * const [da, db] = grads;\n *\n * console.log('value');\n * value.print();\n *\n * console.log('da');\n * da.print();\n * console.log('db');\n * db.print();\n * ```\n *\n * @doc {heading: 'Training', subheading: 'Gradients'}\n */\nfunction valueAndGrads<O extends Tensor>(f: (...args: Tensor[]) => O): (\n    args: Tensor[], dy?: O) => {\n  grads: Tensor[];\n  value: O;\n} {\n  util.assert(\n      util.isFunction(f),\n      () => 'The f passed in valueAndGrads(f) must be a function');\n  return (args: Tensor[], dy?: O) => {\n    util.assert(\n        Array.isArray(args) && args.every(arg => arg instanceof Tensor),\n        () => 'The args passed in valueAndGrads(f)(args) must be array of ' +\n            'tensors');\n    util.assert(\n        dy == null || dy instanceof Tensor,\n        () => 'The dy passed in valueAndGrads(f)(args, dy) must be a tensor');\n    const res = ENGINE.gradients(() => f(...args), args, dy);\n    if (dy != null) {\n      util.assertShapesMatch(\n          res.value.shape, dy.shape,\n          'The shape of dy passed in valueAndGrads(f)([x1,...], dy) must ' +\n              'match the shape returned by f([x1,...])');\n    }\n    checkGrads(res.grads);\n    return res;\n  };\n}\n\n/**\n * Computes and returns the gradient of f(x) with respect to the list of\n * trainable variables provided by `varList`. If no list is provided, it\n * defaults to all trainable variables.\n *\n * ```js\n * const a = tf.variable(tf.tensor1d([3, 4]));\n * const b = tf.variable(tf.tensor1d([5, 6]));\n * const x = tf.tensor1d([1, 2]);\n *\n * // f(a, b) = a * x ^ 2 + b * x\n * const f = () => a.mul(x.square()).add(b.mul(x)).sum();\n * // df/da = x ^ 2, df/db = x\n * const {value, grads} = tf.variableGrads(f);\n *\n * Object.keys(grads).forEach(varName => grads[varName].print());\n * ```\n *\n * @param f The function to execute. f() should return a scalar.\n * @param varList The list of variables to compute the gradients with respect\n *     to. Defaults to all trainable variables.\n * @returns An object with the following keys and values:\n *   - `value`: The value of the function `f`.\n *   - `grads`: A map from the names of the variables to the gradients.\n *     If the `varList` argument is provided explicitly and contains a subset of\n *     non-trainable variables, this map in the return value will contain keys\n *     that map the names of the non-trainable variables to `null`.\n *\n * @doc {heading: 'Training', subheading: 'Gradients'}\n */\nfunction variableGrads(f: () => Scalar, varList?: Variable[]):\n    {value: Scalar, grads: NamedTensorMap} {\n  util.assert(\n      util.isFunction(f),\n      () => 'The f passed in variableGrads(f) must be a function');\n  util.assert(\n      varList == null ||\n          Array.isArray(varList) && varList.every(v => v instanceof Variable),\n      () =>\n          'The varList passed in variableGrads(f, varList) must be an array ' +\n          'of variables');\n\n  const specifiedVarList = varList != null;\n  if (!specifiedVarList) {\n    // Get all of the trainable variables.\n    varList = [];\n    for (const varName in ENGINE.registeredVariables) {\n      varList.push(ENGINE.registeredVariables[varName]);\n    }\n  }\n\n  const specifiedNonTrainable: Variable[] =\n      specifiedVarList ? varList.filter(variable => !variable.trainable) : null;\n\n  // Prune non-trainable variables.\n  const originalVarCount = varList.length;\n  varList = varList.filter(variable => variable.trainable);\n  util.assert(\n      varList.length > 0,\n      () => `variableGrads() expects at least one of the input variables to ` +\n          `be trainable, but none of the ${originalVarCount} variables is ` +\n          `trainable.`);\n\n  const allowNoGradients = true;\n  const {value, grads} = ENGINE.gradients(f, varList, null, allowNoGradients);\n\n  util.assert(\n      grads.some(g => g != null),\n      () => 'Cannot find a connection between any variable and the result of ' +\n          'the loss function y=f(x). Please make sure the operations that ' +\n          'use variables are inside the function f passed to minimize().');\n  util.assert(\n      value.rank === 0,\n      () => `The f passed in variableGrads(f) must return a scalar, but it ` +\n          `returned a rank-${value.rank} tensor`);\n\n  const namedGrads: NamedTensorMap = {};\n  varList.forEach((v, i) => {\n    if (grads[i] != null) {\n      namedGrads[v.name] = grads[i];\n    }\n  });\n  if (specifiedNonTrainable != null) {\n    // If varList is explicitly provided and contains non-trainable values,\n    // add them to the returned gradients with `null` values.\n    specifiedNonTrainable.forEach(v => namedGrads[v.name] = null);\n  }\n  return {value, grads: namedGrads};\n}\n\n/**\n * Overrides the gradient computation of a function `f`.\n *\n * Takes a function\n * `f(...inputs, save) => {value: Tensor, gradFunc: (dy, saved) => Tensor[]}`\n * and returns another function `g(...inputs)` which takes the same inputs as\n * `f`. When called, `g` returns `f().value`. In backward mode, custom gradients\n * with respect to each input of `f` are computed using `f().gradFunc`.\n *\n * The `save` function passed to `f` should be used for saving tensors needed\n * in the gradient. And the `saved` passed to the `gradFunc` is a\n * `NamedTensorMap`, which contains those saved tensors.\n *\n * ```js\n * const customOp = tf.customGrad((x, save) => {\n *   // Save x to make sure it's available later for the gradient.\n *   save([x]);\n *   // Override gradient of our custom x ^ 2 op to be dy * abs(x);\n *   return {\n *     value: x.square(),\n *     // Note `saved.x` which points to the `x` we saved earlier.\n *     gradFunc: (dy, saved) => [dy.mul(saved[0].abs())]\n *   };\n * });\n *\n * const x = tf.tensor1d([-1, -2, 3]);\n * const dx = tf.grad(x => customOp(x));\n *\n * console.log(`f(x):`);\n * customOp(x).print();\n * console.log(`f'(x):`);\n * dx(x).print();\n * ```\n *\n * @param f The function to evaluate in forward mode, which should return\n *     `{value: Tensor, gradFunc: (dy, saved) => Tensor[]}`, where `gradFunc`\n *     returns the custom gradients of `f` with respect to its inputs.\n *\n * @doc {heading: 'Training', subheading: 'Gradients'}\n */\nfunction customGrad<T extends Tensor>(f: CustomGradientFunc<T>):\n    (...args: Tensor[]) => T {\n  return ENGINE.customGrad(f);\n}\n\nfunction checkGrads(grads: Tensor[]) {\n  const numNullGradients = grads.filter(g => g == null).length;\n  if (numNullGradients > 0) {\n    throw new Error(\n        `Cannot compute gradient of y=f(x) with respect to x. Make sure that\n    the f you passed encloses all operations that lead from x to y.`);\n  }\n}\n\nexport {\n  customGrad,\n  variableGrads,\n  valueAndGrad,\n  valueAndGrads,\n  grad,\n  grads,\n};\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Scalar} from '../tensor';\nimport {DataType} from '../types';\nimport {isTypedArray} from '../util';\nimport {makeTensor} from './tensor_ops_util';\n\n/**\n * Creates rank-0 `tf.Tensor` (scalar) with the provided value and dtype.\n *\n * The same functionality can be achieved with `tf.tensor`, but in general\n * we recommend using `tf.scalar` as it makes the code more readable.\n *\n * ```js\n * tf.scalar(3.14).print();\n * ```\n *\n * @param value The value of the scalar.\n * @param dtype The data type.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nexport function scalar(\n    value: number|boolean|string|Uint8Array, dtype?: DataType): Scalar {\n  if (((isTypedArray(value) && dtype !== 'string') || Array.isArray(value)) &&\n      dtype !== 'complex64') {\n    throw new Error(\n        'Error creating a new Scalar: value must be a primitive ' +\n        '(number|boolean|string)');\n  }\n  if (dtype === 'string' && isTypedArray(value) &&\n      !(value instanceof Uint8Array)) {\n    throw new Error(\n        'When making a scalar from encoded string, ' +\n        'the value must be `Uint8Array`.');\n  }\n  const shape: number[] = [];\n  const inferredShape: number[] = [];\n  return makeTensor(value, shape, inferredShape, dtype) as Scalar;\n}\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {dispose} from '../globals';\nimport {variableGrads} from '../gradients';\nimport {scalar} from '../ops/ops';\nimport {Serializable} from '../serialization';\nimport {Scalar, Variable} from '../tensor';\nimport {NamedTensor, NamedTensorMap} from '../tensor_types';\n\n/**\n * A variable that belongs to an optimizer.\n *\n * The `originalName` field is required for keeping track of the canonical\n * name of the variable, which is usually the name of the model weight that\n * the variable is related to plus a suffix, e.g., 'dense1/kernel/momentum'.\n * The name of the `Variable` object itself cannot be used directly due to\n * possible deduplication: Every `Variable` must have a unique name but more\n * than one optimizer objects of the same type may be created for the same model\n * or the same `Variable`.\n */\nexport interface OptimizerVariable {\n  originalName: string;\n  variable: Variable;\n}\n\n/** @doc {heading: 'Training', subheading: 'Classes', namespace: 'train'} */\nexport abstract class Optimizer extends Serializable {\n  protected iterations_: number;\n\n  /**\n   * Executes `f()` and minimizes the scalar output of `f()` by computing\n   * gradients of y with respect to the list of trainable variables provided by\n   * `varList`. If no list is provided, it defaults to all trainable variables.\n   *\n   * @param f The function to execute and whose output to minimize.\n   * @param returnCost Whether to return the scalar cost value produced by\n   * executing `f()`.\n   * @param varList An optional list of variables to update. If specified, only\n   * the trainable variables in varList will be updated by minimize. Defaults to\n   * all trainable variables.\n   *\n   * @doc {heading: 'Training', subheading: 'Optimizers'}\n   */\n  minimize(f: () => Scalar, returnCost = false, varList?: Variable[]): Scalar\n      |null {\n    const {value, grads} = this.computeGradients(f, varList);\n\n    if (varList != null) {\n      const gradArray: NamedTensor[] =\n          varList.map(v => ({name: v.name, tensor: grads[v.name]}));\n      this.applyGradients(gradArray);\n    } else {\n      this.applyGradients(grads);\n    }\n\n    // Dispose gradients.\n    dispose(grads);\n\n    if (returnCost) {\n      return value;\n    } else {\n      value.dispose();\n      return null;\n    }\n  }\n\n  /**\n   * The number of iterations that this optimizer instance has been invoked for.\n   */\n  get iterations(): number {\n    if (this.iterations_ == null) {\n      this.iterations_ = 0;\n    }\n    return this.iterations_;\n  }\n\n  protected incrementIterations() {\n    this.iterations_ = this.iterations + 1;\n  }\n\n  /**\n   * Executes f() and computes the gradient of the scalar output of f() with\n   * respect to the list of trainable variables provided by `varList`. If no\n   * list is provided, it defaults to all trainable variables.\n   *\n   * @param f The function to execute and whose output to use for computing\n   * gradients with respect to variables.\n   * @param varList An optional list of variables to compute gradients with\n   * respect to. If specified, only the trainable variables in varList will have\n   * gradients computed with respect to. Defaults to all trainable variables.\n   *\n   * @doc {heading: 'Training', subheading: 'Optimizers'}\n   */\n  computeGradients(f: () => Scalar, varList?: Variable[]):\n      {value: Scalar, grads: NamedTensorMap} {\n    return variableGrads(f, varList);\n  }\n\n  /**\n   * Updates variables by using the computed gradients.\n   *\n   * @param variableGradients A mapping of variable name to its gradient value.\n   *\n   * @doc {heading: 'Training', subheading: 'Optimizers'}\n   */\n  abstract applyGradients(variableGradients: NamedTensorMap|\n                          NamedTensor[]): void;\n\n  /**\n   * Dispose the variables (if any) owned by this optimizer instance.\n   */\n  dispose(): void {\n    if (this.iterations_ != null) {\n      dispose(this.iterations_);\n    }\n  }\n\n  async saveIterations(): Promise<NamedTensor> {\n    if (this.iterations_ == null) {\n      this.iterations_ = 0;\n    }\n    return {\n      name: 'iter',  // Named for Python compatibility.\n      // TODO(cais): Use 'int64' type when available.\n      tensor: scalar(this.iterations_, 'int32')\n    };\n  }\n\n  async getWeights(): Promise<NamedTensor[]> {\n    throw new Error('getWeights() is not implemented for this optimizer yet.');\n  }\n\n  async setWeights(weightValues: NamedTensor[]): Promise<void> {\n    throw new Error(\n        `setWeights() is not implemented for this optimizer class ` +\n        `${this.getClassName()}`);\n  }\n\n  /**\n   * Extract the first element of the weight values and set it\n   * as the iterations counter variable of this instance of optimizer.\n   *\n   * @param weightValues\n   * @returns Weight values with the first element consumed and excluded.\n   */\n  protected async extractIterations(weightValues: NamedTensor[]):\n      Promise<NamedTensor[]> {\n    this.iterations_ = (await weightValues[0].tensor.data())[0];\n    return weightValues.slice(1);\n  }\n}\n\nObject.defineProperty(Optimizer, Symbol.hasInstance, {\n  value: (instance: Optimizer) => {\n    return instance.minimize != null && instance.computeGradients != null &&\n        instance.applyGradients != null;\n  }\n});\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {dispose, tidy} from '../globals';\nimport {add} from '../ops/add';\nimport {div} from '../ops/div';\nimport {mul} from '../ops/mul';\nimport {sqrt} from '../ops/ops';\nimport {square} from '../ops/square';\nimport {zerosLike} from '../ops/zeros_like';\nimport {ConfigDict, registerClass, Serializable, SerializableConstructor} from '../serialization';\nimport {NamedTensor, NamedVariableMap} from '../tensor_types';\n\nimport {Optimizer, OptimizerVariable} from './optimizer';\n\n/** @doclink Optimizer */\nexport class AdadeltaOptimizer extends Optimizer {\n  /** @nocollapse */\n  static className = 'Adadelta';  // Name matters for Python compatibility.\n  private accumulatedGrads: OptimizerVariable[] = [];\n  private accumulatedUpdates: OptimizerVariable[] = [];\n\n  constructor(\n      protected learningRate: number, protected rho: number,\n      protected epsilon: number = null) {\n    super();\n\n    if (epsilon == null) {\n      this.epsilon = ENGINE.backend.epsilon();\n    }\n  }\n\n  applyGradients(variableGradients: NamedVariableMap|NamedTensor[]) {\n    const variableNames = Array.isArray(variableGradients) ?\n        variableGradients.map(item => item.name) :\n        Object.keys(variableGradients);\n\n    variableNames.forEach((name, i) => {\n      const value = ENGINE.registeredVariables[name];\n      const trainable = false;\n      if (this.accumulatedGrads[i] == null) {\n        this.accumulatedGrads[i] = {\n          originalName: `${name}/accum_grad`,\n          variable: tidy(() => zerosLike(value).variable(trainable))\n        };\n      }\n      if (this.accumulatedUpdates[i] == null) {\n        this.accumulatedUpdates[i] = {\n          originalName: `${name}/accum_var`,\n          variable: tidy(() => zerosLike(value).variable(trainable))\n        };\n      }\n\n      const gradient = Array.isArray(variableGradients) ?\n          variableGradients[i].tensor :\n          variableGradients[name];\n      if (gradient == null) {\n        return;\n      }\n\n      const accumulatedGrad = this.accumulatedGrads[i].variable;\n      const accumulatedUpdate = this.accumulatedUpdates[i].variable;\n\n      tidy(() => {\n        const newAccumulatedGrad =\n            add(mul(accumulatedGrad, this.rho),\n                mul(square(gradient), 1 - this.rho));\n\n        const updates =\n            mul(div(sqrt(add(accumulatedUpdate, this.epsilon)),\n                    sqrt(add(accumulatedGrad, this.epsilon))),\n                gradient);\n\n        const newAccumulatedUpdate =\n            add(mul(accumulatedUpdate, this.rho),\n                mul(square(updates), 1 - this.rho));\n\n        accumulatedGrad.assign(newAccumulatedGrad);\n        accumulatedUpdate.assign(newAccumulatedUpdate);\n\n        const newValue = add(mul(updates, -this.learningRate), value);\n        value.assign(newValue);\n      });\n    });\n    this.incrementIterations();\n  }\n\n  dispose(): void {\n    if (this.accumulatedUpdates != null) {\n      dispose(this.accumulatedGrads.map(v => v.variable));\n      dispose(this.accumulatedUpdates.map(v => v.variable));\n    }\n  }\n\n  async getWeights(): Promise<NamedTensor[]> {\n    // Order matters for Python compatibility.\n    const variables: OptimizerVariable[] =\n        [...this.accumulatedGrads, ...this.accumulatedUpdates];\n    return [await this.saveIterations()].concat(\n        variables.map(v => ({name: v.originalName, tensor: v.variable})));\n  }\n\n  async setWeights(weightValues: NamedTensor[]): Promise<void> {\n    weightValues = await this.extractIterations(weightValues);\n    const variableCount = weightValues.length / 2;\n    const trainable = false;\n    this.accumulatedGrads =\n        weightValues.slice(0, variableCount).map(v => ({\n                                                   originalName: v.name,\n                                                   variable: v.tensor.variable(\n                                                       trainable)\n                                                 }));\n    this.accumulatedUpdates =\n        weightValues.slice(variableCount, variableCount * 2)\n            .map(v => ({\n                   originalName: v.name,\n                   variable: v.tensor.variable(trainable)\n                 }));\n  }\n\n  getConfig(): ConfigDict {\n    return {\n      'learningRate': this.learningRate,\n      'rho': this.rho,\n      'epsilon': this.epsilon\n    };\n  }\n\n  /** @nocollapse */\n  static fromConfig<T extends Serializable>(\n      cls: SerializableConstructor<T>, config: ConfigDict): T {\n    return new cls(config['learningRate'], config['rho'], config['epsilon']);\n  }\n}\nregisterClass(AdadeltaOptimizer);\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {Fill, FillAttrs} from '../kernel_names';\nimport {NamedAttrMap} from '../kernel_registry';\nimport {Tensor} from '../tensor';\nimport {DataType, Rank, ShapeMap} from '../types';\n\n/**\n * Creates a `tf.Tensor` filled with a scalar value.\n *\n * ```js\n * tf.fill([2, 2], 4).print();\n * ```\n *\n * @param shape An array of integers defining the output tensor shape.\n * @param value The scalar value to fill the tensor with.\n * @param dtype The type of an element in the resulting tensor. Defaults to\n * 'float'.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nfunction fill<R extends Rank>(\n    shape: ShapeMap[R], value: number|string, dtype?: DataType): Tensor<R> {\n  const attrs: FillAttrs = {shape, value, dtype};\n\n  return ENGINE.runKernel(Fill, {}, attrs as {} as NamedAttrMap);\n}\n\nexport {fill};\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {dispose, tidy} from '../globals';\nimport {add} from '../ops/add';\nimport {div} from '../ops/div';\nimport {fill} from '../ops/fill';\nimport {mul} from '../ops/mul';\nimport {sqrt} from '../ops/sqrt';\nimport {square} from '../ops/square';\nimport {ConfigDict, registerClass, Serializable, SerializableConstructor} from '../serialization';\nimport {NamedTensor, NamedVariableMap} from '../tensor_types';\n\nimport {Optimizer, OptimizerVariable} from './optimizer';\n\n/** @doclink Optimizer */\nexport class AdagradOptimizer extends Optimizer {\n  /** @nocollapse */\n  static className = 'Adagrad';  // Note: Name matters for Python compatibility.\n\n  private accumulatedGrads: OptimizerVariable[] = [];\n\n  constructor(\n      protected learningRate: number, private initialAccumulatorValue = 0.1) {\n    super();\n  }\n\n  applyGradients(variableGradients: NamedVariableMap|NamedTensor[]) {\n    const variableNames = Array.isArray(variableGradients) ?\n        variableGradients.map(item => item.name) :\n        Object.keys(variableGradients);\n\n    variableNames.forEach((name, i) => {\n      const value = ENGINE.registeredVariables[name];\n      if (this.accumulatedGrads[i] == null) {\n        const trainable = false;\n        this.accumulatedGrads[i] = {\n          originalName: `${name}/accumulator`,\n          variable: tidy(\n              () => fill(value.shape, this.initialAccumulatorValue)\n                        .variable(trainable))\n        };\n      }\n\n      const gradient = Array.isArray(variableGradients) ?\n          variableGradients[i].tensor :\n          variableGradients[name];\n      if (gradient == null) {\n        return;\n      }\n\n      const accumulatedGrad = this.accumulatedGrads[i].variable;\n\n      tidy(() => {\n        const newAccumulatedGrad = add(accumulatedGrad, square(gradient));\n        accumulatedGrad.assign(newAccumulatedGrad);\n\n        const newValue = add(\n            mul(div(gradient,\n                    sqrt(add(newAccumulatedGrad, ENGINE.backend.epsilon()))),\n                -this.learningRate),\n            value);\n        value.assign(newValue);\n      });\n    });\n    this.incrementIterations();\n  }\n\n  dispose(): void {\n    if (this.accumulatedGrads != null) {\n      dispose(this.accumulatedGrads.map(v => v.variable));\n    }\n  }\n\n  async getWeights(): Promise<NamedTensor[]> {\n    // Order matters for Python compatibility.\n    return [await this.saveIterations()].concat(this.accumulatedGrads.map(\n        v => ({name: v.originalName, tensor: v.variable})));\n  }\n\n  async setWeights(weightValues: NamedTensor[]): Promise<void> {\n    weightValues = await this.extractIterations(weightValues);\n    const trainable = false;\n    this.accumulatedGrads = weightValues.map(\n        v => ({originalName: v.name, variable: v.tensor.variable(trainable)}));\n  }\n\n  getConfig(): ConfigDict {\n    return {\n      'learningRate': this.learningRate,\n      'initialAccumulatorValue': this.initialAccumulatorValue,\n    };\n  }\n\n  /** @nocollapse */\n  static fromConfig<T extends Serializable>(\n      cls: SerializableConstructor<T>, config: ConfigDict): T {\n    return new cls(config['learningRate'], config['initialAccumulatorValue']);\n  }\n}\nregisterClass(AdagradOptimizer);\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {ENGINE} from '../engine';\nimport {Pow, PowInputs} from '../kernel_names';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {makeTypesMatch} from '../tensor_util';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {op} from './operation';\n\n/**\n * Computes the power of one `tf.Tensor` to another. Supports broadcasting.\n *\n * Given a `tf.Tensor` x and a `tf.Tensor` y, this operation computes x^y for\n * corresponding elements in x and y. The result's dtype will be the upcasted\n * type of the `base` and `exp` dtypes.\n *\n * ```js\n * const a = tf.tensor([[2, 3], [4, 5]])\n * const b = tf.tensor([[1, 2], [3, 0]]).toInt();\n *\n * a.pow(b).print();  // or tf.pow(a, b)\n * ```\n *\n * ```js\n * const a = tf.tensor([[1, 2], [3, 4]])\n * const b = tf.tensor(2).toInt();\n *\n * a.pow(b).print();  // or tf.pow(a, b)\n * ```\n * We also expose `powStrict` which has the same signature as this op and\n * asserts that `base` and `exp` are the same shape (does not broadcast).\n *\n * @param base The base `tf.Tensor` to pow element-wise.\n * @param exp The exponent `tf.Tensor` to pow element-wise.\n *\n * @doc {heading: 'Operations', subheading: 'Arithmetic'}\n */\nfunction pow_<T extends Tensor>(\n    base: Tensor|TensorLike, exp: Tensor|TensorLike): T {\n  let $base = convertToTensor(base, 'base', 'pow');\n  let $exp = convertToTensor(exp, 'exp', 'pow');\n  [$base, $exp] = makeTypesMatch($base, $exp);\n\n  const inputs: PowInputs = {a: $base, b: $exp};\n\n  return ENGINE.runKernel(Pow, inputs as {} as NamedTensorMap);\n}\n\nexport const pow = op({pow_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {ENGINE} from '../engine';\nimport {Sub, SubInputs} from '../kernel_names';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {makeTypesMatch} from '../tensor_util';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {op} from './operation';\n\n/**\n * Subtracts two `tf.Tensor`s element-wise, A - B. Supports broadcasting.\n *\n * ```js\n * const a = tf.tensor1d([10, 20, 30, 40]);\n * const b = tf.tensor1d([1, 2, 3, 4]);\n *\n * a.sub(b).print();  // or tf.sub(a, b)\n * ```\n *\n * ```js\n * // Broadcast subtract a with b.\n * const a = tf.tensor1d([10, 20, 30, 40]);\n * const b = tf.scalar(5);\n *\n * a.sub(b).print();  // or tf.sub(a, b)\n * ```\n * @param a The first `tf.Tensor` to subtract from.\n * @param b The second `tf.Tensor` to be subtracted. Must have the same dtype as\n * `a`.\n *\n * @doc {heading: 'Operations', subheading: 'Arithmetic'}\n */\nfunction sub_<T extends Tensor>(a: Tensor|TensorLike, b: Tensor|TensorLike): T {\n  let $a = convertToTensor(a, 'a', 'sub');\n  let $b = convertToTensor(b, 'b', 'sub');\n  [$a, $b] = makeTypesMatch($a, $b);\n\n  const inputs: SubInputs = {a: $a, b: $b};\n\n  return ENGINE.runKernel(Sub, inputs as {} as NamedTensorMap);\n}\n\nexport const sub = op({sub_});\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {dispose, tidy} from '../globals';\nimport {add} from '../ops/add';\nimport {div} from '../ops/div';\nimport {mul} from '../ops/mul';\nimport {pow} from '../ops/pow';\nimport {scalar} from '../ops/scalar';\nimport {sqrt} from '../ops/sqrt';\nimport {square} from '../ops/square';\nimport {sub} from '../ops/sub';\nimport {zerosLike} from '../ops/zeros_like';\nimport {ConfigDict, registerClass, Serializable, SerializableConstructor} from '../serialization';\nimport {Variable} from '../tensor';\nimport {NamedTensor, NamedVariableMap} from '../tensor_types';\n\nimport {Optimizer, OptimizerVariable} from './optimizer';\n\nexport class AdamOptimizer extends Optimizer {\n  /** @nocollapse */\n  static className = 'Adam';  // Note: Name matters for Python compatibility.\n  private accBeta1: Variable;\n  private accBeta2: Variable;\n\n  private accumulatedFirstMoment: OptimizerVariable[] = [];\n  private accumulatedSecondMoment: OptimizerVariable[] = [];\n\n  constructor(\n      protected learningRate: number, protected beta1: number,\n      protected beta2: number, protected epsilon: number = null) {\n    super();\n    tidy(() => {\n      // accB* will be updated by batch.\n      this.accBeta1 = scalar(beta1).variable();\n      this.accBeta2 = scalar(beta2).variable();\n    });\n\n    if (epsilon == null) {\n      this.epsilon = ENGINE.backend.epsilon();\n    }\n  }\n\n  applyGradients(variableGradients: NamedVariableMap|NamedTensor[]) {\n    const varNames = Array.isArray(variableGradients) ?\n        variableGradients.map(v => v.name) :\n        Object.keys(variableGradients);\n    tidy(() => {\n      const oneMinusAccBeta1 = sub(1, this.accBeta1);\n      const oneMinusAccBeta2 = sub(1, this.accBeta2);\n\n      varNames.forEach((name, i) => {\n        const value = ENGINE.registeredVariables[name];\n        const trainable = false;\n        if (this.accumulatedFirstMoment[i] == null) {\n          this.accumulatedFirstMoment[i] = {\n            originalName: `${name}/m`,\n            variable: tidy(() => zerosLike(value).variable(trainable))\n          };\n        }\n        if (this.accumulatedSecondMoment[i] == null) {\n          this.accumulatedSecondMoment[i] = {\n            originalName: `${name}/v`,\n            variable: tidy(() => zerosLike(value).variable(trainable))\n          };\n        }\n\n        const gradient = Array.isArray(variableGradients) ?\n            variableGradients[i].tensor :\n            variableGradients[name];\n        if (gradient == null) {\n          return;\n        }\n\n        const firstMoment = this.accumulatedFirstMoment[i].variable;\n        const secondMoment = this.accumulatedSecondMoment[i].variable;\n\n        const newFirstMoment =\n            add(mul(firstMoment, this.beta1), mul(gradient, 1 - this.beta1));\n        const newSecondMoment =\n            add(mul(secondMoment, this.beta2),\n                mul(square(gradient), 1 - this.beta2));\n\n        const biasCorrectedFirstMoment = div(newFirstMoment, oneMinusAccBeta1);\n        const biasCorrectedSecondMoment =\n            div(newSecondMoment, oneMinusAccBeta2);\n\n        firstMoment.assign(newFirstMoment);\n        secondMoment.assign(newSecondMoment);\n\n        const newValue =\n            add(mul(div(biasCorrectedFirstMoment,\n                        add(sqrt(biasCorrectedSecondMoment), this.epsilon)),\n                    -this.learningRate),\n                value);\n        value.assign(newValue);\n      });\n\n      this.accBeta1.assign(mul(this.accBeta1, this.beta1));\n      this.accBeta2.assign(mul(this.accBeta2, this.beta2));\n    });\n    this.incrementIterations();\n  }\n\n  dispose(): void {\n    this.accBeta1.dispose();\n    this.accBeta2.dispose();\n\n    if (this.accumulatedFirstMoment != null) {\n      dispose(this.accumulatedFirstMoment.map(v => v.variable));\n    }\n    if (this.accumulatedSecondMoment != null) {\n      dispose(this.accumulatedSecondMoment.map(v => v.variable));\n    }\n  }\n\n  async getWeights(): Promise<NamedTensor[]> {\n    // Order matters for Python compatibility.\n    const variables: OptimizerVariable[] =\n        [...this.accumulatedFirstMoment, ...this.accumulatedSecondMoment];\n    return [await this.saveIterations()].concat(\n        variables.map(v => ({name: v.originalName, tensor: v.variable})));\n  }\n\n  async setWeights(weightValues: NamedTensor[]): Promise<void> {\n    weightValues = await this.extractIterations(weightValues);\n    tidy(() => {\n      this.accBeta1.assign(pow(this.beta1, this.iterations_ + 1));\n      this.accBeta2.assign(pow(this.beta2, this.iterations_ + 1));\n    });\n\n    const variableCount = weightValues.length / 2;\n    const trainable = false;\n    this.accumulatedFirstMoment =\n        weightValues.slice(0, variableCount).map(v => ({\n                                                   originalName: v.name,\n                                                   variable: v.tensor.variable(\n                                                       trainable)\n                                                 }));\n    this.accumulatedSecondMoment =\n        weightValues.slice(variableCount, variableCount * 2)\n            .map(v => ({\n                   originalName: v.name,\n                   variable: v.tensor.variable(trainable)\n                 }));\n  }\n\n  getConfig(): ConfigDict {\n    return {\n      'learningRate': this.learningRate,\n      'beta1': this.beta1,\n      'beta2': this.beta2,\n      'epsilon': this.epsilon,\n    };\n  }\n\n  /** @nocollapse */\n  static fromConfig<T extends Serializable>(\n      cls: SerializableConstructor<T>, config: ConfigDict): T {\n    return new cls(\n        config['learningRate'], config['beta1'], config['beta2'],\n        config['epsilon']);\n  }\n}\nregisterClass(AdamOptimizer);\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {Abs, AbsInputs, ComplexAbs, ComplexAbsInputs} from '../kernel_names';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {op} from './operation';\n\n/**\n * Computes absolute value element-wise: `abs(x)`\n *\n * ```js\n * const x = tf.tensor1d([-1, 2, -3, 4]);\n *\n * x.abs().print();  // or tf.abs(x)\n * ```\n * @param x The input `tf.Tensor`.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction abs_<T extends Tensor>(x: T|TensorLike): T {\n  const $x = convertToTensor(x, 'x', 'abs');\n\n  if ($x.dtype === 'complex64') {\n    const inputs: ComplexAbsInputs = {x: $x};\n    return ENGINE.runKernel(ComplexAbs, inputs as {} as NamedTensorMap);\n  } else {\n    const inputs: AbsInputs = {x: $x};\n    return ENGINE.runKernel(Abs, inputs as {} as NamedTensorMap);\n  }\n}\n\nexport const abs = op({abs_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {Maximum, MaximumInputs} from '../kernel_names';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {makeTypesMatch} from '../tensor_util';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {assertAndGetBroadcastShape} from './broadcast_util';\nimport {cast} from './cast';\nimport {op} from './operation';\n\n/**\n * Returns the max of a and b (`a > b ? a : b`) element-wise.\n * Supports broadcasting.\n *\n * We also expose `tf.maximumStrict` which has the same signature as this op and\n * asserts that `a` and `b` are the same shape (does not broadcast).\n *\n * ```js\n * const a = tf.tensor1d([1, 4, 3, 16]);\n * const b = tf.tensor1d([1, 2, 9, 4]);\n *\n * a.maximum(b).print();  // or tf.maximum(a, b)\n * ```\n *\n * ```js\n * // Broadcast maximum a with b.\n * const a = tf.tensor1d([2, 4, 6, 8]);\n * const b = tf.scalar(5);\n *\n * a.maximum(b).print();  // or tf.maximum(a, b)\n * ```\n *\n * @param a The first tensor.\n * @param b The second tensor. Must have the same type as `a`.\n *\n * @doc {heading: 'Operations', subheading: 'Arithmetic'}\n */\nfunction maximum_<T extends Tensor>(\n    a: Tensor|TensorLike, b: Tensor|TensorLike): T {\n  let $a = convertToTensor(a, 'a', 'maximum');\n  let $b = convertToTensor(b, 'b', 'maximum');\n  [$a, $b] = makeTypesMatch($a, $b);\n\n  if ($a.dtype === 'bool') {\n    $a = cast($a, 'int32');\n    $b = cast($b, 'int32');\n  }\n  assertAndGetBroadcastShape($a.shape, $b.shape);\n\n  const inputs: MaximumInputs = {a: $a, b: $b};\n\n  return ENGINE.runKernel(Maximum, inputs as {} as NamedTensorMap);\n}\n\nexport const maximum = op({maximum_});\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {dispose, tidy} from '../globals';\nimport {abs} from '../ops/abs';\nimport {add} from '../ops/add';\nimport {div} from '../ops/div';\nimport {maximum} from '../ops/maximum';\nimport {mul} from '../ops/mul';\nimport {scalar} from '../ops/scalar';\nimport {sub} from '../ops/sub';\nimport {zerosLike} from '../ops/zeros_like';\nimport {ConfigDict, registerClass, Serializable, SerializableConstructor} from '../serialization';\nimport {Variable} from '../tensor';\nimport {NamedTensor, NamedVariableMap} from '../tensor_types';\n\nimport {Optimizer, OptimizerVariable} from './optimizer';\n\nexport class AdamaxOptimizer extends Optimizer {\n  /** @nocollapse */\n  static className = 'Adamax';  // Note: Name matters for Python compatbility.\n  private accBeta1: Variable;\n  private iteration: Variable;\n\n  private accumulatedFirstMoment: OptimizerVariable[] = [];\n  private accumulatedWeightedInfNorm: OptimizerVariable[] = [];\n\n  constructor(\n      protected learningRate: number, protected beta1: number,\n      protected beta2: number, protected epsilon: number = null,\n      protected decay = 0.0) {\n    super();\n\n    tidy(() => {\n      this.iteration = scalar(0).variable();\n      this.accBeta1 = scalar(beta1).variable();\n    });\n\n    if (epsilon == null) {\n      this.epsilon = ENGINE.backend.epsilon();\n    }\n  }\n\n  applyGradients(variableGradients: NamedVariableMap|NamedTensor[]) {\n    const variableNames = Array.isArray(variableGradients) ?\n        variableGradients.map(item => item.name) :\n        Object.keys(variableGradients);\n\n    tidy(() => {\n      const oneMinusAccBeta1 = sub(1, this.accBeta1);\n      const lr =\n          div(-this.learningRate, add(mul(this.iteration, this.decay), 1));\n\n      variableNames.forEach((name, i) => {\n        const value = ENGINE.registeredVariables[name];\n        const trainable = false;\n        if (this.accumulatedFirstMoment[i] == null) {\n          this.accumulatedFirstMoment[i] = {\n            originalName: `${name}/m`,\n            variable: zerosLike(value).variable(trainable)\n          };\n        }\n        if (this.accumulatedWeightedInfNorm[i] == null) {\n          this.accumulatedWeightedInfNorm[i] = {\n            originalName: `${name}/v`,\n            variable: zerosLike(value).variable(trainable)\n          };\n        }\n\n        const gradient = Array.isArray(variableGradients) ?\n            variableGradients[i].tensor :\n            variableGradients[name];\n        if (gradient == null) {\n          return;\n        }\n\n        const firstMoment = this.accumulatedFirstMoment[i].variable;\n        const weightedInfNorm = this.accumulatedWeightedInfNorm[i].variable;\n\n        const newFirstMoment =\n            add(mul(firstMoment, this.beta1), mul(gradient, 1 - this.beta1));\n\n        const ut0 = mul(weightedInfNorm, this.beta2);\n        const ut1 = abs(gradient);\n\n        const newWeightedInfNorm = maximum(ut0, ut1);\n\n        firstMoment.assign(newFirstMoment);\n        weightedInfNorm.assign(newWeightedInfNorm);\n\n        const newValue =\n            add(mul(div(lr, oneMinusAccBeta1),\n                    div(newFirstMoment, add(newWeightedInfNorm, this.epsilon))),\n                value);\n\n        value.assign(newValue);\n      });\n\n      this.iteration.assign(add(this.iteration, 1));\n      this.accBeta1.assign(mul(this.accBeta1, this.beta1));\n    });\n    this.incrementIterations();\n  }\n\n  dispose(): void {\n    this.accBeta1.dispose();\n    this.iteration.dispose();\n\n    if (this.accumulatedFirstMoment != null) {\n      dispose(this.accumulatedFirstMoment.map(v => v.variable));\n    }\n    if (this.accumulatedWeightedInfNorm != null) {\n      dispose(this.accumulatedWeightedInfNorm.map(v => v.variable));\n    }\n  }\n\n  async getWeights(): Promise<NamedTensor[]> {\n    throw new Error('getWeights() is not implemented for Adamax yet.');\n  }\n\n  async setWeights(weightValues: NamedTensor[]): Promise<void> {\n    throw new Error('setWeights() is not implemented for Adamax yet.');\n  }\n\n  getConfig(): ConfigDict {\n    return {\n      'learningRate': this.learningRate,\n      'beta1': this.beta1,\n      'beta2': this.beta2,\n      'epsilon': this.epsilon,\n      'decay': this.decay\n    };\n  }\n\n  /** @nocollapse */\n  static fromConfig<T extends Serializable>(\n      cls: SerializableConstructor<T>, config: ConfigDict): T {\n    return new cls(\n        config['learningRate'], config['beta1'], config['beta2'],\n        config['epsilon'], config['decay']);\n  }\n}\nregisterClass(AdamaxOptimizer);\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {keep, tidy} from '../globals';\nimport {add} from '../ops/add';\nimport {mul} from '../ops/mul';\nimport {scalar} from '../ops/scalar';\nimport {ConfigDict, registerClass, Serializable, SerializableConstructor} from '../serialization';\nimport {Scalar} from '../tensor';\nimport {NamedTensor, NamedTensorMap} from '../tensor_types';\n\nimport {Optimizer} from './optimizer';\n\n/** @doclink Optimizer */\nexport class SGDOptimizer extends Optimizer {\n  /** @nocollapse */\n  static className = 'SGD';  // Note: Name matters for Python compatibility.\n  protected c: Scalar;\n\n  constructor(protected learningRate: number) {\n    super();\n    this.setLearningRate(learningRate);\n  }\n\n  applyGradients(variableGradients: NamedTensorMap|NamedTensor[]) {\n    const varNames = Array.isArray(variableGradients) ?\n        variableGradients.map(v => v.name) :\n        Object.keys(variableGradients);\n    varNames.forEach((name, i) => {\n      const gradient = Array.isArray(variableGradients) ?\n          variableGradients[i].tensor :\n          variableGradients[name];\n      if (gradient == null) {\n        return;\n      }\n      const value = ENGINE.registeredVariables[name];\n      tidy(() => {\n        const newValue = add(mul(this.c, gradient), value);\n        value.assign(newValue);\n      });\n    });\n    this.incrementIterations();\n  }\n\n  /**\n   * Sets the learning rate of the optimizer.\n   */\n  setLearningRate(learningRate: number) {\n    this.learningRate = learningRate;\n    if (this.c != null) {\n      this.c.dispose();\n    }\n    this.c = keep(scalar(-learningRate));\n  }\n\n  dispose() {\n    this.c.dispose();\n  }\n\n  async getWeights(): Promise<NamedTensor[]> {\n    return [await this.saveIterations()];\n  }\n\n  async setWeights(weightValues: NamedTensor[]): Promise<void> {\n    weightValues = await this.extractIterations(weightValues);\n    if (weightValues.length !== 0) {\n      throw new Error('SGD optimizer does not have settable weights.');\n    }\n  }\n\n  getConfig(): ConfigDict {\n    return {'learningRate': this.learningRate};\n  }\n\n  /** @nocollapse */\n  static fromConfig<T extends Serializable>(\n      cls: SerializableConstructor<T>, config: ConfigDict): T {\n    return new cls(config['learningRate']);\n  }\n}\nregisterClass(SGDOptimizer);\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {dispose, tidy} from '../globals';\nimport {add} from '../ops/add';\nimport {mul} from '../ops/mul';\nimport {scalar} from '../ops/scalar';\nimport {zerosLike} from '../ops/zeros_like';\nimport {ConfigDict, registerClass, Serializable, SerializableConstructor} from '../serialization';\nimport {Scalar, Tensor} from '../tensor';\nimport {NamedTensor, NamedVariableMap} from '../tensor_types';\n\nimport {OptimizerVariable} from './optimizer';\nimport {SGDOptimizer} from './sgd_optimizer';\n\n/** @doclink Optimizer */\nexport class MomentumOptimizer extends SGDOptimizer {\n  /** @nocollapse */\n  static className = 'Momentum';  // Name matters for Python compatibility.\n  private m: Scalar;\n  private accumulations: OptimizerVariable[] = [];\n\n  constructor(\n      protected learningRate: number, private momentum: number,\n      private useNesterov = false) {\n    super(learningRate);\n    this.m = scalar(this.momentum);\n  }\n\n  applyGradients(variableGradients: NamedVariableMap|NamedTensor[]) {\n    const variableNames = Array.isArray(variableGradients) ?\n        variableGradients.map(item => item.name) :\n        Object.keys(variableGradients);\n\n    variableNames.forEach((name, i) => {\n      const value = ENGINE.registeredVariables[name];\n      if (this.accumulations[i] == null) {\n        const trainable = false;\n        this.accumulations[i] = {\n          originalName: `${name}/momentum`,\n          variable: tidy(() => zerosLike(value).variable(trainable))\n        };\n      }\n\n      const accumulation = this.accumulations[i].variable;\n      const gradient = Array.isArray(variableGradients) ?\n          variableGradients[i].tensor :\n          variableGradients[name];\n      if (gradient == null) {\n        return;\n      }\n\n      tidy(() => {\n        let newValue: Tensor;\n        const newAccumulation = add(mul(this.m, accumulation), gradient);\n        if (this.useNesterov) {\n          newValue = add(\n              mul(this.c, add(gradient, mul(newAccumulation, this.m))), value);\n        } else {\n          newValue = add(mul(this.c, newAccumulation), value);\n        }\n        accumulation.assign(newAccumulation);\n        value.assign(newValue);\n      });\n    });\n    this.incrementIterations();\n  }\n\n  dispose(): void {\n    this.m.dispose();\n    if (this.accumulations != null) {\n      dispose(this.accumulations.map(v => v.variable));\n    }\n  }\n\n  /**\n   * Sets the momentum of the optimizer.\n   *\n   * @param momentum\n   */\n  setMomentum(momentum: number) {\n    this.momentum = momentum;\n  }\n\n  async getWeights(): Promise<NamedTensor[]> {\n    // Order matters for Python compatibility.\n    return [await this.saveIterations()].concat(this.accumulations.map(\n        v => ({name: v.originalName, tensor: v.variable})));\n  }\n\n  async setWeights(weightValues: NamedTensor[]): Promise<void> {\n    weightValues = await this.extractIterations(weightValues);\n    const trainable = false;\n    this.accumulations = weightValues.map(\n        v => ({originalName: v.name, variable: v.tensor.variable(trainable)}));\n  }\n\n  getConfig(): ConfigDict {\n    return {\n      'learningRate': this.learningRate,\n      'momentum': this.momentum,\n      'useNesterov': this.useNesterov\n    };\n  }\n\n  /** @nocollapse */\n  static fromConfig<T extends Serializable>(\n      cls: SerializableConstructor<T>, config: ConfigDict): T {\n    return new cls(\n        config['learningRate'], config['momentum'], config['useNesterov']);\n  }\n}\nregisterClass(MomentumOptimizer);\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {dispose, tidy} from '../globals';\nimport {add} from '../ops/add';\nimport {div} from '../ops/div';\nimport {mul} from '../ops/mul';\nimport {sqrt} from '../ops/sqrt';\nimport {square} from '../ops/square';\nimport {sub} from '../ops/sub';\nimport {zerosLike} from '../ops/zeros_like';\nimport {ConfigDict, registerClass, Serializable, SerializableConstructor} from '../serialization';\nimport {NamedTensor, NamedTensorMap} from '../tensor_types';\n\nimport {Optimizer, OptimizerVariable} from './optimizer';\n\n/** @doclink Optimizer */\nexport class RMSPropOptimizer extends Optimizer {\n  /** @nocollapse */\n  static className = 'RMSProp';  // Note: Name matters for Python compatibility.\n  private centered: boolean;\n\n  private accumulatedMeanSquares: OptimizerVariable[] = [];\n  private accumulatedMoments: OptimizerVariable[] = [];\n  private accumulatedMeanGrads: OptimizerVariable[] = [];\n\n  constructor(\n      protected learningRate: number, protected decay = 0.9,\n      protected momentum = 0.0, protected epsilon: number = null,\n      centered = false) {\n    super();\n\n    this.centered = centered;\n\n    if (epsilon == null) {\n      this.epsilon = ENGINE.backend.epsilon();\n    }\n    if (learningRate == null) {\n      throw new Error(`learningRate for RMSPropOptimizer must be defined.`);\n    }\n  }\n\n  applyGradients(variableGradients: NamedTensorMap|NamedTensor[]) {\n    const variableNames = Array.isArray(variableGradients) ?\n        variableGradients.map(item => item.name) :\n        Object.keys(variableGradients);\n\n    variableNames.forEach((name, i) => {\n      const value = ENGINE.registeredVariables[name];\n      const trainable = false;\n      if (this.accumulatedMeanSquares[i] == null) {\n        this.accumulatedMeanSquares[i] = {\n          originalName: `${name}/rms`,\n          variable: tidy(() => zerosLike(value).variable(trainable))\n        };\n      }\n      if (this.accumulatedMoments[i] == null) {\n        this.accumulatedMoments[i] = {\n          originalName: `${name}/momentum`,\n          variable: tidy(() => zerosLike(value).variable(trainable))\n        };\n      }\n      if (this.accumulatedMeanGrads[i] == null && this.centered) {\n        this.accumulatedMeanGrads[i] = {\n          originalName: `${name}/mg`,\n          variable: tidy(() => zerosLike(value).variable(trainable))\n        };\n      }\n\n      const gradient = Array.isArray(variableGradients) ?\n          variableGradients[i].tensor :\n          variableGradients[name];\n      if (gradient == null) {\n        return;\n      }\n\n      const accumulatedMeanSquare = this.accumulatedMeanSquares[i].variable;\n      const accumulatedMoments = this.accumulatedMoments[i].variable;\n      tidy(() => {\n        const newAccumulatedMeanSquare =\n            add(mul(accumulatedMeanSquare, this.decay),\n                mul(square(gradient), 1 - this.decay));\n\n        if (this.centered) {\n          const accumulatedMeanGrad = this.accumulatedMeanGrads[i].variable;\n          // Centered gradient\n          const newAccumulatedMeanGrad =\n              add(mul(accumulatedMeanGrad, this.decay),\n                  mul(gradient, 1 - this.decay));\n\n          const gradContribution =\n              div(mul(gradient, this.learningRate),\n                  sqrt(\n                      sub(newAccumulatedMeanSquare,\n                          add(square(newAccumulatedMeanGrad), this.epsilon))));\n          const newAccumulatedMoments =\n              add(mul(accumulatedMoments, this.momentum), gradContribution);\n\n          accumulatedMeanSquare.assign(newAccumulatedMeanSquare);\n          accumulatedMeanGrad.assign(newAccumulatedMeanGrad);\n          accumulatedMoments.assign(newAccumulatedMoments);\n\n          const newValue = sub(value, newAccumulatedMoments);\n          value.assign(newValue);\n        } else {\n          // Plain gradient\n          const newAccumulatedMeanSquare =\n              add(mul(accumulatedMeanSquare, this.decay),\n                  mul(square(gradient), 1 - this.decay));\n\n          const newAccumulatedMoments =\n              add(mul(accumulatedMoments, this.momentum),\n                  div(mul(gradient, this.learningRate),\n                      sqrt(add(newAccumulatedMeanSquare, this.epsilon))));\n\n          accumulatedMeanSquare.assign(newAccumulatedMeanSquare);\n          accumulatedMoments.assign(newAccumulatedMoments);\n\n          const newValue = sub(value, newAccumulatedMoments);\n          value.assign(newValue);\n        }\n      });\n    });\n    this.incrementIterations();\n  }\n\n  dispose(): void {\n    if (this.accumulatedMeanSquares != null) {\n      dispose(this.accumulatedMeanSquares.map(v => v.variable));\n    }\n    if (this.accumulatedMeanGrads != null && this.centered) {\n      dispose(this.accumulatedMeanGrads.map(v => v.variable));\n    }\n    if (this.accumulatedMoments != null) {\n      dispose(this.accumulatedMoments.map(v => v.variable));\n    }\n  }\n\n  async getWeights(): Promise<NamedTensor[]> {\n    // Order matters for Python compatibility.\n    const variables: OptimizerVariable[] =\n        [...this.accumulatedMeanSquares, ...this.accumulatedMoments];\n    if (this.centered) {\n      variables.push(...this.accumulatedMeanGrads);\n    }\n    return [await this.saveIterations()].concat(\n        variables.map(v => ({name: v.originalName, tensor: v.variable})));\n  }\n\n  async setWeights(weightValues: NamedTensor[]): Promise<void> {\n    weightValues = await this.extractIterations(weightValues);\n    const variableCount =\n        this.centered ? weightValues.length / 3 : weightValues.length / 2;\n    const trainable = false;\n    this.accumulatedMeanSquares =\n        weightValues.slice(0, variableCount).map(v => ({\n                                                   originalName: v.name,\n                                                   variable: v.tensor.variable(\n                                                       trainable)\n                                                 }));\n    this.accumulatedMoments =\n        weightValues.slice(variableCount, variableCount * 2)\n            .map(v => ({\n                   originalName: v.name,\n                   variable: v.tensor.variable(trainable)\n                 }));\n    if (this.centered) {\n      this.accumulatedMeanGrads =\n          weightValues.slice(variableCount * 2, variableCount * 3)\n              .map(v => ({\n                     originalName: v.name,\n                     variable: v.tensor.variable(trainable)\n                   }));\n    }\n  }\n\n  getConfig(): ConfigDict {\n    return {\n      'learningRate': this.learningRate,\n      'decay': this.decay,\n      'momentum': this.momentum,\n      'epsilon': this.epsilon,\n      'centered': this.centered\n    };\n  }\n\n  /** @nocollapse */\n  static fromConfig<T extends Serializable>(\n      cls: SerializableConstructor<T>, config: ConfigDict): T {\n    return new cls(\n        config['learningRate'], config['decay'], config['momentum'],\n        config['epsilon'], config['centered']);\n  }\n}\nregisterClass(RMSPropOptimizer);\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {AdadeltaOptimizer} from './adadelta_optimizer';\nimport {AdagradOptimizer} from './adagrad_optimizer';\nimport {AdamOptimizer} from './adam_optimizer';\nimport {AdamaxOptimizer} from './adamax_optimizer';\nimport {MomentumOptimizer} from './momentum_optimizer';\nimport {RMSPropOptimizer} from './rmsprop_optimizer';\nimport {SGDOptimizer} from './sgd_optimizer';\n\nexport class OptimizerConstructors {\n  /**\n   * Constructs a `tf.SGDOptimizer` that uses stochastic gradient descent.\n   *\n   * ```js\n   * // Fit a quadratic function by learning the coefficients a, b, c.\n   * const xs = tf.tensor1d([0, 1, 2, 3]);\n   * const ys = tf.tensor1d([1.1, 5.9, 16.8, 33.9]);\n   *\n   * const a = tf.scalar(Math.random()).variable();\n   * const b = tf.scalar(Math.random()).variable();\n   * const c = tf.scalar(Math.random()).variable();\n   *\n   * // y = a * x^2 + b * x + c.\n   * const f = x => a.mul(x.square()).add(b.mul(x)).add(c);\n   * const loss = (pred, label) => pred.sub(label).square().mean();\n   *\n   * const learningRate = 0.01;\n   * const optimizer = tf.train.sgd(learningRate);\n   *\n   * // Train the model.\n   * for (let i = 0; i < 10; i++) {\n   *   optimizer.minimize(() => loss(f(xs), ys));\n   * }\n   *\n   * // Make predictions.\n   * console.log(\n   *     `a: ${a.dataSync()}, b: ${b.dataSync()}, c: ${c.dataSync()}`);\n   * const preds = f(xs).dataSync();\n   * preds.forEach((pred, i) => {\n   *   console.log(`x: ${i}, pred: ${pred}`);\n   * });\n   * ```\n   *\n   * @param learningRate The learning rate to use for the SGD algorithm.\n   *\n   * @doc {heading: 'Training', subheading: 'Optimizers', namespace: 'train'}\n   */\n  static sgd(learningRate: number): SGDOptimizer {\n    return new SGDOptimizer(learningRate);\n  }\n\n  /**\n   * Constructs a `tf.MomentumOptimizer` that uses momentum gradient\n   * descent.\n   *\n   * See\n   * [http://proceedings.mlr.press/v28/sutskever13.pdf](\n   * http://proceedings.mlr.press/v28/sutskever13.pdf)\n   *\n   * @param learningRate The learning rate to use for the Momentum gradient\n   * descent algorithm.\n   * @param momentum The momentum to use for the momentum gradient descent\n   * algorithm.\n   *\n   * @doc {heading: 'Training', subheading: 'Optimizers', namespace: 'train'}\n   */\n  static momentum(learningRate: number, momentum: number, useNesterov = false):\n      MomentumOptimizer {\n    return new MomentumOptimizer(learningRate, momentum, useNesterov);\n  }\n\n  /**\n   * Constructs a `tf.RMSPropOptimizer` that uses RMSProp gradient\n   * descent. This implementation uses plain momentum and is not centered\n   * version of RMSProp.\n   *\n   * See\n   * [http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf](\n   * http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf)\n   *\n   * @param learningRate The learning rate to use for the RMSProp gradient\n   * descent algorithm.\n   * @param decay The discounting factor for the history/coming gradient.\n   * @param momentum The momentum to use for the RMSProp gradient descent\n   * algorithm.\n   * @param epsilon Small value to avoid zero denominator.\n   * @param centered If true, gradients are normalized by the estimated\n   * variance of the gradient.\n   *\n   * @doc {heading: 'Training', subheading: 'Optimizers', namespace: 'train'}\n   */\n  static rmsprop(\n      learningRate: number, decay = .9, momentum = 0.0, epsilon: number = null,\n      centered = false): RMSPropOptimizer {\n    return new RMSPropOptimizer(\n        learningRate, decay, momentum, epsilon, centered);\n  }\n\n  /**\n   * Constructs a `tf.AdamOptimizer` that uses the Adam algorithm.\n   * See [https://arxiv.org/abs/1412.6980](https://arxiv.org/abs/1412.6980)\n   *\n   * @param learningRate The learning rate to use for the Adam gradient\n   * descent algorithm.\n   * @param beta1 The exponential decay rate for the 1st moment estimates.\n   * @param beta2 The exponential decay rate for the 2nd moment estimates.\n   * @param epsilon A small constant for numerical stability.\n   *\n   * @doc {heading: 'Training', subheading: 'Optimizers', namespace: 'train'}\n   */\n  static adam(\n      learningRate = 0.001, beta1 = 0.9, beta2 = 0.999,\n      epsilon: number = null): AdamOptimizer {\n    return new AdamOptimizer(learningRate, beta1, beta2, epsilon);\n  }\n\n  /**\n   * Constructs a `tf.AdadeltaOptimizer` that uses the Adadelta algorithm.\n   * See [https://arxiv.org/abs/1212.5701](https://arxiv.org/abs/1212.5701)\n   *\n   * @param learningRate The learning rate to use for the Adadelta gradient\n   * descent algorithm.\n   * @param rho The learning rate decay over each update.\n   * @param epsilon A constant epsilon used to better condition the grad\n   * update.\n   *\n   * @doc {heading: 'Training', subheading: 'Optimizers', namespace: 'train'}\n   */\n  static adadelta(learningRate = .001, rho = .95, epsilon: number = null):\n      AdadeltaOptimizer {\n    return new AdadeltaOptimizer(learningRate, rho, epsilon);\n  }\n\n  /**\n   * Constructs a `tf.AdamaxOptimizer` that uses the Adamax algorithm.\n   * See [https://arxiv.org/abs/1412.6980](https://arxiv.org/abs/1412.6980)\n   *\n   * @param learningRate The learning rate to use for the Adamax gradient\n   * descent algorithm.\n   * @param beta1 The exponential decay rate for the 1st moment estimates.\n   * @param beta2 The exponential decay rate for the 2nd moment estimates.\n   * @param epsilon A small constant for numerical stability.\n   * @param decay The learning rate decay over each update.\n   *\n   * @doc {heading: 'Training', subheading: 'Optimizers', namespace: 'train'}\n   */\n  static adamax(\n      learningRate = 0.002, beta1 = 0.9, beta2 = 0.999, epsilon: number = null,\n      decay = 0.0): AdamaxOptimizer {\n    return new AdamaxOptimizer(learningRate, beta1, beta2, epsilon, decay);\n  }\n\n  /**\n   * Constructs a `tf.AdagradOptimizer` that uses the Adagrad algorithm.\n   * See\n   * [http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf](\n   * http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf)\n   * or\n   * [http://ruder.io/optimizing-gradient-descent/index.html#adagrad](\n   * http://ruder.io/optimizing-gradient-descent/index.html#adagrad)\n   *\n   * @param learningRate The learning rate to use for the Adagrad gradient\n   * descent algorithm.\n   * @param initialAccumulatorValue Starting value for the accumulators, must be\n   * positive.\n   *\n   * @doc {heading: 'Training', subheading: 'Optimizers', namespace: 'train'}\n   */\n  static adagrad(learningRate: number, initialAccumulatorValue = 0.1):\n      AdagradOptimizer {\n    return new AdagradOptimizer(learningRate, initialAccumulatorValue);\n  }\n}\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {ENGINE} from '../engine';\nimport {Acos, AcosInputs} from '../kernel_names';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {op} from './operation';\n\n/**\n * Computes acos of the input `tf.Tensor` element-wise: `acos(x)`\n *\n * ```js\n * const x = tf.tensor1d([0, 1, -1, .7]);\n *\n * x.acos().print();  // or tf.acos(x)\n * ```\n * @param x The input tensor.\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction acos_<T extends Tensor>(x: T|TensorLike): T {\n  const $x = convertToTensor(x, 'x', 'acos');\n  const inputs: AcosInputs = {x: $x};\n\n  return ENGINE.runKernel(Acos, inputs as {} as NamedTensorMap);\n}\nexport const acos = op({acos_});\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {Acosh, AcoshInputs} from '../kernel_names';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {op} from './operation';\n\n/**\n * Computes the inverse hyperbolic cos of the input `tf.Tensor` element-wise:\n * `acosh(x)`\n *\n * ```js\n * const x = tf.tensor1d([10, 1, 3, 5.7]);\n *\n * x.acosh().print();  // or tf.acosh(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction acosh_<T extends Tensor>(x: T|TensorLike): T {\n  const $x = convertToTensor(x, 'x', 'acosh');\n  const inputs: AcoshInputs = {x: $x};\n\n  return ENGINE.runKernel(Acosh, inputs as {} as NamedTensorMap);\n}\nexport const acosh = op({acosh_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {ENGINE} from '../engine';\nimport {AddN, AddNInputs} from '../kernel_names';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\nimport * as util from '../util';\n\nimport {op} from './operation';\n\n/**\n * Adds a list of `tf.Tensor`s element-wise, each with the same shape and dtype.\n *\n * ```js\n * const a = tf.tensor1d([1, 2]);\n * const b = tf.tensor1d([3, 4]);\n * const c = tf.tensor1d([5, 6]);\n *\n * tf.addN([a, b, c]).print();\n * ```\n * @param tensors A list of tensors with the same shape and dtype.\n * @doc {heading: 'Operations', subheading: 'Arithmetic'}\n */\nfunction addN_<T extends Tensor>(tensors: Array<T|TensorLike>): T {\n  util.assert(\n      Array.isArray(tensors),\n      () => 'The argument passed to tf.addN() must be a list of tensors');\n  util.assert(\n      tensors.length >= 1,\n      () => `Must pass at least one tensor to tf.addN(), but got ` +\n          `${tensors.length}`);\n\n  const $tensors =\n      tensors.map((t, i) => convertToTensor(t, `tensors${i}`, 'addN'));\n\n  const firstTensor = $tensors[0];\n  $tensors.forEach(t => {\n    if (t.dtype !== firstTensor.dtype) {\n      throw new Error(\n          'All tensors passed to tf.addN() must have the same dtype');\n    }\n  });\n\n  $tensors.forEach(t => {\n    if (!util.arraysEqual(t.shape, firstTensor.shape)) {\n      throw new Error(\n          'All tensors passed to tf.addN() must have the same shape');\n    }\n  });\n\n  const inputs: AddNInputs = $tensors;\n\n  return ENGINE.runKernel(AddN, inputs as {} as NamedTensorMap);\n}\n\nexport const addN = op({addN_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {All, AllAttrs, AllInputs} from '../kernel_names';\nimport {NamedAttrMap} from '../kernel_registry';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {op} from './operation';\n\n/**\n * Computes the logical and of elements across dimensions of a `tf.Tensor`.\n *\n * Reduces the input along the dimensions given in `axes`. Unless `keepDims`\n * is true, the rank of the `tf.Tensor` is reduced by 1 for each entry in\n * `axes`. If `keepDims` is true, the reduced dimensions are retained with\n * length 1. If `axes` has no entries, all dimensions are reduced, and a\n * `tf.Tensor` with a single element is returned.\n *\n * ```js\n * const x = tf.tensor1d([1, 1, 1], 'bool');\n *\n * x.all().print();  // or tf.all(x)\n * ```\n *\n * ```js\n * const x = tf.tensor2d([1, 1, 0, 0], [2, 2], 'bool');\n *\n * const axis = 1;\n * x.all(axis).print();  // or tf.all(x, axis)\n * ```\n *\n * @param x The input tensor. Must be of dtype bool.\n * @param axis The dimension(s) to reduce. By default it reduces\n *     all dimensions.\n * @param keepDims If true, retains reduced dimensions with size 1.\n *\n * @doc {heading: 'Operations', subheading: 'Reduction'}\n */\nfunction all_<T extends Tensor>(\n    x: Tensor|TensorLike, axis: number|number[] = null, keepDims = false): T {\n  const $x = convertToTensor(x, 'x', 'all', 'bool');\n\n  const inputs: AllInputs = {x: $x};\n  const attrs: AllAttrs = {axis, keepDims};\n\n  return ENGINE.runKernel(\n      All, inputs as {} as NamedTensorMap, attrs as {} as NamedAttrMap);\n}\n\nexport const all = op({all_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {Any, AnyAttrs, AnyInputs} from '../kernel_names';\nimport {NamedAttrMap} from '../kernel_registry';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {op} from './operation';\n\n/**\n * Computes the logical or of elements across dimensions of a `tf.Tensor`.\n *\n * Reduces the input along the dimensions given in `axes`. Unless `keepDims`\n * is true, the rank of the `tf.Tensor` is reduced by 1 for each entry in\n * `axes`. If `keepDims` is true, the reduced dimensions are retained with\n * length 1. If `axes` has no entries, all dimensions are reduced, and a\n * `tf.Tensor` with a single element is returned.\n *\n * ```js\n * const x = tf.tensor1d([1, 1, 1], 'bool');\n *\n * x.any().print();  // or tf.any(x)\n * ```\n *\n * ```js\n * const x = tf.tensor2d([1, 1, 0, 0], [2, 2], 'bool');\n *\n * const axis = 1;\n * x.any(axis).print();  // or tf.any(x, axis)\n * ```\n *\n * @param x The input tensor. Must be of dtype bool.\n * @param axis The dimension(s) to reduce. By default it reduces\n *     all dimensions.\n * @param keepDims If true, retains reduced dimensions with size 1.\n *\n * @doc {heading: 'Operations', subheading: 'Reduction'}\n */\nfunction any_<T extends Tensor>(\n    x: Tensor|TensorLike, axis: number|number[] = null, keepDims = false): T {\n  const $x = convertToTensor(x, 'x', 'any', 'bool');\n\n  const inputs: AnyInputs = {x: $x};\n  const attrs: AnyAttrs = {axis, keepDims};\n\n  return ENGINE.runKernel(\n      Any, inputs as {} as NamedTensorMap, attrs as {} as NamedAttrMap);\n}\n\n// tslint:disable-next-line:variable-name\nexport const any = op({any_});\n","/**\n * @license\n * Copyright 2020 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {ArgMax, ArgMaxAttrs, ArgMaxInputs} from '../kernel_names';\nimport {NamedAttrMap} from '../kernel_registry';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {op} from './operation';\n\n/**\n * Returns the indices of the maximum values along an `axis`.\n *\n * The result has the same shape as `input` with the dimension along `axis`\n * removed.\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3]);\n *\n * x.argMax().print();  // or tf.argMax(x)\n * ```\n *\n * ```js\n * const x = tf.tensor2d([1, 2, 4, 3], [2, 2]);\n *\n * const axis = 1;\n * x.argMax(axis).print();  // or tf.argMax(x, axis)\n * ```\n *\n * @param x The input tensor.\n * @param axis The dimension to reduce. Defaults to 0 (outer-most dimension).\n *\n * @doc {heading: 'Operations', subheading: 'Reduction'}\n */\nfunction argMax_<T extends Tensor>(x: Tensor|TensorLike, axis = 0): T {\n  const $x = convertToTensor(x, 'x', 'argMax');\n\n  const inputs: ArgMaxInputs = {x: $x};\n  const attrs: ArgMaxAttrs = {axis};\n\n  return ENGINE.runKernel(\n      ArgMax, inputs as {} as NamedTensorMap, attrs as {} as NamedAttrMap);\n}\n\nexport const argMax = op({argMax_});\n","/**\n * @license\n * Copyright 2020 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {ArgMin, ArgMinAttrs, ArgMinInputs} from '../kernel_names';\nimport {NamedAttrMap} from '../kernel_registry';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {op} from './operation';\n\n/**\n * Returns the indices of the minimum values along an `axis`.\n *\n * The result has the same shape as `input` with the dimension along `axis`\n * removed.\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3]);\n *\n * x.argMin().print();  // or tf.argMin(x)\n * ```\n *\n * ```js\n * const x = tf.tensor2d([1, 2, 4, 3], [2, 2]);\n *\n * const axis = 1;\n * x.argMin(axis).print();  // or tf.argMin(x, axis)\n * ```\n *\n * @param x The input tensor.\n * @param axis The dimension to reduce. Defaults to 0 (outer-most dimension).\n *\n * @doc {heading: 'Operations', subheading: 'Reduction'}\n */\nfunction argMin_<T extends Tensor>(x: Tensor|TensorLike, axis = 0): T {\n  const $x = convertToTensor(x, 'x', 'argMin');\n\n  const inputs: ArgMinInputs = {x: $x};\n  const attrs: ArgMinAttrs = {axis};\n\n  return ENGINE.runKernel(\n      ArgMin, inputs as {} as NamedTensorMap, attrs as {} as NamedAttrMap);\n}\n\nexport const argMin = op({argMin_});\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {Asin, AsinInputs} from '../kernel_names';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {op} from './operation';\n\n/**\n * Computes asin of the input `tf.Tensor` element-wise: `asin(x)`\n *\n * ```js\n * const x = tf.tensor1d([0, 1, -1, .7]);\n *\n * x.asin().print();  // or tf.asin(x)\n * ```\n * @param x The input tensor.\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction asin_<T extends Tensor>(x: T|TensorLike): T {\n  const $x = convertToTensor(x, 'x', 'asin');\n  const inputs: AsinInputs = {x: $x};\n\n  return ENGINE.runKernel(Asin, inputs as {} as NamedTensorMap);\n}\nexport const asin = op({asin_});\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {Asinh, AsinhInputs} from '../kernel_names';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {op} from './operation';\n\n/**\n * Computes inverse hyperbolic sin of the input `tf.Tensor` element-wise:\n * `asinh(x)`\n *\n * ```js\n * const x = tf.tensor1d([0, 1, -1, .7]);\n *\n * x.asinh().print();  // or tf.asinh(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction asinh_<T extends Tensor>(x: T|TensorLike): T {\n  const $x = convertToTensor(x, 'x', 'asinh');\n\n  const inputs: AsinhInputs = {x: $x};\n\n  return ENGINE.runKernel(Asinh, inputs as {} as NamedTensorMap);\n}\nexport const asinh = op({asinh_});\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {Atan, AtanInputs} from '../kernel_names';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {op} from './operation';\n\n/**\n * Computes atan of the input `tf.Tensor` element-wise: `atan(x)`\n *\n * ```js\n * const x = tf.tensor1d([0, 1, -1, .7]);\n *\n * x.atan().print();  // or tf.atan(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction atan_<T extends Tensor>(x: T|TensorLike): T {\n  const $x = convertToTensor(x, 'x', 'atan');\n\n  const inputs: AtanInputs = {x: $x};\n\n  return ENGINE.runKernel(Atan, inputs as {} as NamedTensorMap);\n}\nexport const atan = op({atan_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {Atan2, Atan2Inputs} from '../kernel_names';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {makeTypesMatch} from '../tensor_util';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {op} from './operation';\n\n/**\n * Computes arctangent of `tf.Tensor`s a / b element-wise: `atan2(a, b)`.\n * Supports broadcasting.\n *\n * ```js\n * const a = tf.tensor1d([1.0, 1.0, -1.0, .7]);\n * const b = tf.tensor1d([2.0, 13.0, 3.5, .21]);\n *\n * tf.atan2(a, b).print()\n * ```\n *\n * @param a The first tensor.\n * @param b The second tensor. Must have the same dtype as `a`.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction atan2_<T extends Tensor>(\n    a: Tensor|TensorLike, b: Tensor|TensorLike): T {\n  let $a = convertToTensor(a, 'a', 'atan2');\n  let $b = convertToTensor(b, 'b', 'atan2');\n  [$a, $b] = makeTypesMatch($a, $b);\n\n  const inputs: Atan2Inputs = {a: $a, b: $b};\n\n  return ENGINE.runKernel(Atan2, inputs as {} as NamedTensorMap);\n}\n\nexport const atan2 = op({atan2_});\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {Atanh, AtanhInputs} from '../kernel_names';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {op} from './operation';\n\n/**\n * Computes inverse hyperbolic tan of the input `tf.Tensor` element-wise:\n * `atanh(x)`\n *\n * ```js\n * const x = tf.tensor1d([0, .1, -.1, .7]);\n *\n * x.atanh().print();  // or tf.atanh(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction atanh_<T extends Tensor>(x: T|TensorLike): T {\n  const $x = convertToTensor(x, 'x', 'atanh');\n\n  const inputs: AtanhInputs = {x: $x};\n\n  return ENGINE.runKernel(Atanh, inputs as {} as NamedTensorMap);\n}\nexport const atanh = op({atanh_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as util from '../util';\n\ntype PadType = 'SAME'|'VALID'|'NUMBER'|'EXPLICIT';\n\n// For NHWC should be in the following form:\n//  [[0, 0], [pad_top,pad_bottom], [pad_left, pad_right], [0, 0]]\n// For NCHW should be in the following form:\n//  [[0, 0], [0, 0], [pad_top,pad_bottom], [pad_left, pad_right]]\n// Reference: https://www.tensorflow.org/api_docs/python/tf/nn/conv2d\nexport type ExplicitPadding =\n    [[number, number], [number, number], [number, number], [number, number]];\n\nexport type PadInfo = {\n  top: number,\n  left: number,\n  right: number,\n  bottom: number,\n  type: PadType\n};\n\nexport type PadInfo3D = {\n  top: number,\n  left: number,\n  right: number,\n  bottom: number,\n  front: number,\n  back: number,\n  type: PadType\n};\n\n/**\n * Information about the forward pass of a convolution/pooling operation.\n * It includes input and output shape, strides, filter size and padding\n * information.\n */\nexport type Conv2DInfo = {\n  batchSize: number,\n  inHeight: number,\n  inWidth: number,\n  inChannels: number,\n  outHeight: number,\n  outWidth: number,\n  outChannels: number,\n  dataFormat: 'channelsFirst'|'channelsLast',\n  strideHeight: number,\n  strideWidth: number,\n  dilationHeight: number,\n  dilationWidth: number,\n  filterHeight: number,\n  filterWidth: number,\n  effectiveFilterHeight: number,\n  effectiveFilterWidth: number,\n  padInfo: PadInfo,\n  inShape: [number, number, number, number],\n  outShape: [number, number, number, number],\n  filterShape: [number, number, number, number]\n};\n\n/**\n *\n * @param inputShape Input tensor shape is of the following dimensions:\n *     `[batch, height, width, inChannels]`.\n * @param filterShape The filter shape is of the following dimensions:\n *     `[filterHeight, filterWidth, depth]`.\n * @param strides The strides of the sliding window for each dimension of the\n *     input tensor: `[strideHeight, strideWidth]`.\n *     If `strides` is a single number,\n *     then `strideHeight == strideWidth`.\n * @param pad The type of padding algorithm.\n *    - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *    - `valid`: output will be smaller than input if filter is larger\n *       than 1*1x1.\n *    - For more info, see this guide:\n *     [https://www.tensorflow.org/api_docs/python/tf/nn/convolution](\n *          https://www.tensorflow.org/api_docs/python/tf/nn/convolution)\n * @param dataFormat The data format of the input and output data.\n *     Defaults to 'NHWC'.\n * @param dilations The dilation rates: `[dilationHeight, dilationWidth]`.\n *     Defaults to `[1, 1]`. If `dilations` is a single number, then\n *     `dilationHeight == dilationWidth`.\n */\nexport function computeDilation2DInfo(\n    inputShape: [number, number, number, number],\n    filterShape: [number, number, number], strides: number|[number, number],\n    pad: 'same'|'valid'|number, dataFormat: 'NHWC' = 'NHWC',\n    dilations: number|[number, number]) {\n  // `computerConv2DInfo` require filterShape to be in the dimension of:\n  // `[filterHeight, filterWidth, depth, outDepth]`, dilation2d doesn't have\n  // outDepth, it should have the same depth as the input.\n  // Input shape: [batch, height, width, inChannels]\n  const inputChannels = inputShape[3];\n  const $filterShape =\n      [...filterShape, inputChannels] as [number, number, number, number];\n  const $dataFormat = convertConv2DDataFormat(dataFormat);\n\n  return computeConv2DInfo(\n      inputShape, $filterShape, strides, dilations, pad,\n      null /* roundingMode */, null /* depthWise */, $dataFormat);\n}\n\nexport function computePool2DInfo(\n    inShape: [number, number, number, number],\n    filterSize: [number, number]|number, strides: number|[number, number],\n    dilations: number|[number, number],\n    pad: 'same'|'valid'|number|ExplicitPadding,\n    roundingMode?: 'floor'|'round'|'ceil',\n    dataFormat: 'channelsFirst'|'channelsLast' = 'channelsLast'): Conv2DInfo {\n  const [filterHeight, filterWidth] = parseTupleParam(filterSize);\n\n  let filterShape: [number, number, number, number];\n  if (dataFormat === 'channelsLast') {\n    filterShape = [filterHeight, filterWidth, inShape[3], inShape[3]];\n  } else if (dataFormat === 'channelsFirst') {\n    filterShape = [filterHeight, filterWidth, inShape[1], inShape[1]];\n  } else {\n    throw new Error(`Unknown dataFormat ${dataFormat}`);\n  }\n\n  return computeConv2DInfo(\n      inShape, filterShape, strides, dilations, pad, roundingMode, false,\n      dataFormat);\n}\n\n/**\n * Computes the information for a forward pass of a pooling3D operation.\n */\nexport function computePool3DInfo(\n    inShape: [number, number, number, number, number],\n    filterSize: number|[number, number, number],\n    strides: number|[number, number, number],\n    dilations: number|[number, number, number], pad: 'same'|'valid'|number,\n    roundingMode?: 'floor'|'round'|'ceil',\n    dataFormat: 'NDHWC'|'NCDHW' = 'NDHWC'): Conv3DInfo {\n  const [filterDepth, filterHeight, filterWidth] = parse3TupleParam(filterSize);\n\n  let filterShape: [number, number, number, number, number];\n  let $dataFormat: 'channelsFirst'|'channelsLast';\n  if (dataFormat === 'NDHWC') {\n    $dataFormat = 'channelsLast';\n    filterShape =\n        [filterDepth, filterHeight, filterWidth, inShape[4], inShape[4]];\n  } else if (dataFormat === 'NCDHW') {\n    $dataFormat = 'channelsFirst';\n    filterShape =\n        [filterDepth, filterHeight, filterWidth, inShape[1], inShape[1]];\n  } else {\n    throw new Error(`Unknown dataFormat ${dataFormat}`);\n  }\n\n  return computeConv3DInfo(\n      inShape, filterShape, strides, dilations, pad, false, $dataFormat,\n      roundingMode);\n}\n\n/**\n * Computes the information for a forward pass of a convolution/pooling\n * operation.\n */\nexport function computeConv2DInfo(\n    inShape: [number, number, number, number],\n    filterShape: [number, number, number, number],\n    strides: number|[number, number], dilations: number|[number, number],\n    pad: 'same'|'valid'|number|ExplicitPadding,\n    roundingMode?: 'floor'|'round'|'ceil', depthwise = false,\n    dataFormat: 'channelsFirst'|'channelsLast' = 'channelsLast'): Conv2DInfo {\n  let [batchSize, inHeight, inWidth, inChannels] = [-1, -1, -1, -1];\n  if (dataFormat === 'channelsLast') {\n    [batchSize, inHeight, inWidth, inChannels] = inShape;\n  } else if (dataFormat === 'channelsFirst') {\n    [batchSize, inChannels, inHeight, inWidth] = inShape;\n  } else {\n    throw new Error(`Unknown dataFormat ${dataFormat}`);\n  }\n\n  const [filterHeight, filterWidth, , filterChannels] = filterShape;\n  const [strideHeight, strideWidth] = parseTupleParam(strides);\n  const [dilationHeight, dilationWidth] = parseTupleParam(dilations);\n\n  const effectiveFilterHeight =\n      getEffectiveFilterSize(filterHeight, dilationHeight);\n  const effectiveFilterWidth =\n      getEffectiveFilterSize(filterWidth, dilationWidth);\n  const {padInfo, outHeight, outWidth} = getPadAndOutInfo(\n      pad, inHeight, inWidth, strideHeight, strideWidth, effectiveFilterHeight,\n      effectiveFilterWidth, roundingMode, dataFormat);\n\n  const outChannels = depthwise ? filterChannels * inChannels : filterChannels;\n\n  let outShape: [number, number, number, number];\n  if (dataFormat === 'channelsFirst') {\n    outShape = [batchSize, outChannels, outHeight, outWidth];\n  } else if (dataFormat === 'channelsLast') {\n    outShape = [batchSize, outHeight, outWidth, outChannels];\n  }\n\n  return {\n    batchSize,\n    dataFormat,\n    inHeight,\n    inWidth,\n    inChannels,\n    outHeight,\n    outWidth,\n    outChannels,\n    padInfo,\n    strideHeight,\n    strideWidth,\n    filterHeight,\n    filterWidth,\n    effectiveFilterHeight,\n    effectiveFilterWidth,\n    dilationHeight,\n    dilationWidth,\n    inShape,\n    outShape,\n    filterShape\n  };\n}\n\n/**\n * Information about the forward pass of a 3D convolution/pooling operation.\n * It includes input and output shape, strides, filter size and padding\n * information.\n */\nexport type Conv3DInfo = {\n  batchSize: number,\n  inDepth: number,\n  inHeight: number,\n  inWidth: number,\n  inChannels: number,\n  outDepth: number,\n  outHeight: number,\n  outWidth: number,\n  outChannels: number,\n  dataFormat: 'channelsFirst'|'channelsLast',\n  strideDepth: number,\n  strideHeight: number,\n  strideWidth: number,\n  dilationDepth: number,\n  dilationHeight: number,\n  dilationWidth: number,\n  filterDepth: number,\n  filterHeight: number,\n  filterWidth: number,\n  effectiveFilterDepth: number,\n  effectiveFilterHeight: number,\n  effectiveFilterWidth: number,\n  padInfo: PadInfo3D,\n  inShape: [number, number, number, number, number],\n  outShape: [number, number, number, number, number],\n  filterShape: [number, number, number, number, number]\n};\n\n/**\n * Computes the information for a forward pass of a 3D convolution/pooling\n * operation.\n */\nexport function computeConv3DInfo(\n    inShape: [number, number, number, number, number],\n    filterShape: [number, number, number, number, number],\n    strides: number|[number, number, number],\n    dilations: number|[number, number, number], pad: 'same'|'valid'|number,\n    depthwise = false,\n    dataFormat: 'channelsFirst'|'channelsLast' = 'channelsLast',\n    roundingMode?: 'floor'|'round'|'ceil'): Conv3DInfo {\n  let [batchSize, inDepth, inHeight, inWidth, inChannels] =\n      [-1, -1, -1, -1, -1];\n  if (dataFormat === 'channelsLast') {\n    [batchSize, inDepth, inHeight, inWidth, inChannels] = inShape;\n  } else if (dataFormat === 'channelsFirst') {\n    [batchSize, inChannels, inDepth, inHeight, inWidth] = inShape;\n  } else {\n    throw new Error(`Unknown dataFormat ${dataFormat}`);\n  }\n\n  const [filterDepth, filterHeight, filterWidth, , filterChannels] =\n      filterShape;\n  const [strideDepth, strideHeight, strideWidth] = parse3TupleParam(strides);\n  const [dilationDepth, dilationHeight, dilationWidth] =\n      parse3TupleParam(dilations);\n\n  const effectiveFilterDepth =\n      getEffectiveFilterSize(filterDepth, dilationDepth);\n  const effectiveFilterHeight =\n      getEffectiveFilterSize(filterHeight, dilationHeight);\n  const effectiveFilterWidth =\n      getEffectiveFilterSize(filterWidth, dilationWidth);\n  const {padInfo, outDepth, outHeight, outWidth} = get3DPadAndOutInfo(\n      pad, inDepth, inHeight, inWidth, strideDepth, strideHeight, strideWidth,\n      effectiveFilterDepth, effectiveFilterHeight, effectiveFilterWidth,\n      roundingMode);\n\n  const outChannels = depthwise ? filterChannels * inChannels : filterChannels;\n\n  let outShape: [number, number, number, number, number];\n  if (dataFormat === 'channelsFirst') {\n    outShape = [batchSize, outChannels, outDepth, outHeight, outWidth];\n  } else if (dataFormat === 'channelsLast') {\n    outShape = [batchSize, outDepth, outHeight, outWidth, outChannels];\n  }\n\n  return {\n    batchSize,\n    dataFormat,\n    inDepth,\n    inHeight,\n    inWidth,\n    inChannels,\n    outDepth,\n    outHeight,\n    outWidth,\n    outChannels,\n    padInfo,\n    strideDepth,\n    strideHeight,\n    strideWidth,\n    filterDepth,\n    filterHeight,\n    filterWidth,\n    effectiveFilterDepth,\n    effectiveFilterHeight,\n    effectiveFilterWidth,\n    dilationDepth,\n    dilationHeight,\n    dilationWidth,\n    inShape,\n    outShape,\n    filterShape\n  };\n}\n\nfunction computeOutputShape2D(\n    inShape: [number, number], fieldSize: number, stride: number,\n    zeroPad?: number, roundingMode?: 'floor'|'round'|'ceil'): [number, number] {\n  if (zeroPad == null) {\n    zeroPad = computeDefaultPad(inShape, fieldSize, stride);\n  }\n  const inputRows = inShape[0];\n  const inputCols = inShape[1];\n\n  const outputRows =\n      round((inputRows - fieldSize + 2 * zeroPad) / stride + 1, roundingMode);\n  const outputCols =\n      round((inputCols - fieldSize + 2 * zeroPad) / stride + 1, roundingMode);\n\n  return [outputRows, outputCols];\n}\n\nfunction computeOutputShape4D(\n    inShape: [number, number, number, number], fieldSize: number,\n    outChannels: number, stride: number, zeroPad?: number,\n    roundingMode?: 'floor'|'round'|'ceil'): [number, number, number, number] {\n  if (zeroPad == null) {\n    zeroPad = computeDefaultPad(inShape, fieldSize, stride);\n  }\n  const inputDepth = inShape[0];\n  const inputRows = inShape[1];\n  const inputCols = inShape[2];\n\n  const outputDepths =\n      round((inputDepth - fieldSize + 2 * zeroPad) / stride + 1, roundingMode);\n  const outputRows =\n      round((inputRows - fieldSize + 2 * zeroPad) / stride + 1, roundingMode);\n  const outputCols =\n      round((inputCols - fieldSize + 2 * zeroPad) / stride + 1, roundingMode);\n\n  return [outputDepths, outputRows, outputCols, outChannels];\n}\n\nexport function computeDefaultPad(\n    inputShape: [number, number]|[number, number, number, number],\n    fieldSize: number, stride: number, dilation = 1): number {\n  const effectiveFieldSize = getEffectiveFilterSize(fieldSize, dilation);\n  return Math.floor(\n      (inputShape[0] * (stride - 1) - stride + effectiveFieldSize) / 2);\n}\n\nfunction parseTupleParam(param: number|number[]): [number, number, number] {\n  if (typeof param === 'number') {\n    return [param, param, param];\n  }\n  if (param.length === 2) {\n    return [param[0], param[1], 1];\n  }\n  return param as [number, number, number];\n}\n\nfunction parse3TupleParam(param: number|[number, number, number]):\n    [number, number, number] {\n  return typeof param === 'number' ? [param, param, param] : param;\n}\n\n/* See https://www.tensorflow.org/api_docs/python/tf/nn/atrous_conv2d\n * Atrous convolution is equivalent to standard convolution with upsampled\n * filters with effective_filter_height =\n * filter_height + (filter_height - 1) * (dilation - 1)\n * and effective_filter_width =\n * filter_width + (filter_width - 1) * (dilation - 1),\n * produced by inserting dilation - 1 zeros along consecutive elements across\n * the filters' spatial dimensions.\n * When there is a dilation, this converts a filter dimension to the\n * effective filter dimension, so it can be used in a standard convolution.\n */\nfunction getEffectiveFilterSize(filterSize: number, dilation: number) {\n  if (dilation <= 1) {\n    return filterSize;\n  }\n\n  return filterSize + (filterSize - 1) * (dilation - 1);\n}\n\nfunction getPadAndOutInfo(\n    pad: 'same'|'valid'|number|ExplicitPadding, inHeight: number,\n    inWidth: number, strideHeight: number, strideWidth: number,\n    filterHeight: number, filterWidth: number,\n    roundingMode: 'floor'|'round'|'ceil',\n    dataFormat: 'channelsFirst'|\n    'channelsLast'): {padInfo: PadInfo, outHeight: number, outWidth: number} {\n  let padInfo: PadInfo;\n  let outHeight: number;\n  let outWidth: number;\n\n  if (typeof pad === 'number') {\n    const padType = (pad === 0) ? 'VALID' : 'NUMBER';\n    padInfo = {top: pad, bottom: pad, left: pad, right: pad, type: padType};\n    const outShape = computeOutputShape2D(\n        [inHeight, inWidth], filterHeight, strideHeight, pad, roundingMode);\n    outHeight = outShape[0];\n    outWidth = outShape[1];\n  } else if (pad === 'same') {\n    outHeight = Math.ceil(inHeight / strideHeight);\n    outWidth = Math.ceil(inWidth / strideWidth);\n    const padAlongHeight =\n        Math.max(0, (outHeight - 1) * strideHeight + filterHeight - inHeight);\n    const padAlongWidth =\n        Math.max(0, (outWidth - 1) * strideWidth + filterWidth - inWidth);\n    const top = Math.floor(padAlongHeight / 2);\n    const bottom = padAlongHeight - top;\n    const left = Math.floor(padAlongWidth / 2);\n    const right = padAlongWidth - left;\n    padInfo = {top, bottom, left, right, type: 'SAME'};\n  } else if (pad === 'valid') {\n    padInfo = {top: 0, bottom: 0, left: 0, right: 0, type: 'VALID'};\n    outHeight = Math.ceil((inHeight - filterHeight + 1) / strideHeight);\n    outWidth = Math.ceil((inWidth - filterWidth + 1) / strideWidth);\n  } else if (typeof pad === 'object') {\n    const top = dataFormat === 'channelsLast' ? pad[1][0] : pad[2][0];\n    const bottom = dataFormat === 'channelsLast' ? pad[1][1] : pad[2][1];\n    const left = dataFormat === 'channelsLast' ? pad[2][0] : pad[3][0];\n    const right = dataFormat === 'channelsLast' ? pad[2][1] : pad[3][1];\n    const padType = (top === 0 && bottom === 0 && left === 0 && right === 0) ?\n        'VALID' :\n        'EXPLICIT';\n    padInfo = {top, bottom, left, right, type: padType};\n    outHeight = round(\n        (inHeight - filterHeight + top + bottom) / strideHeight + 1,\n        roundingMode);\n    outWidth = round(\n        (inWidth - filterWidth + left + right) / strideWidth + 1, roundingMode);\n  } else {\n    throw Error(`Unknown padding parameter: ${pad}`);\n  }\n  return {padInfo, outHeight, outWidth};\n}\n\nfunction get3DPadAndOutInfo(\n    pad: 'same'|'valid'|number, inDepth: number, inHeight: number,\n    inWidth: number, strideDepth: number, strideHeight: number,\n    strideWidth: number, filterDepth: number, filterHeight: number,\n    filterWidth: number, roundingMode?: 'floor'|'round'|'ceil'): {\n  padInfo: PadInfo3D,\n  outDepth: number,\n  outHeight: number,\n  outWidth: number\n} {\n  let padInfo: PadInfo3D;\n  let outDepth: number;\n  let outHeight: number;\n  let outWidth: number;\n\n  if (typeof pad === 'number') {\n    const padType = (pad === 0) ? 'VALID' : 'NUMBER';\n    padInfo = {\n      top: pad,\n      bottom: pad,\n      left: pad,\n      right: pad,\n      front: pad,\n      back: pad,\n      type: padType\n    };\n    const outShape = computeOutputShape4D(\n        [inDepth, inHeight, inWidth, 1], filterDepth, 1, strideDepth, pad,\n        roundingMode);\n    outDepth = outShape[0];\n    outHeight = outShape[1];\n    outWidth = outShape[2];\n  } else if (pad === 'same') {\n    outDepth = Math.ceil(inDepth / strideDepth);\n    outHeight = Math.ceil(inHeight / strideHeight);\n    outWidth = Math.ceil(inWidth / strideWidth);\n    const padAlongDepth = (outDepth - 1) * strideDepth + filterDepth - inDepth;\n    const padAlongHeight =\n        (outHeight - 1) * strideHeight + filterHeight - inHeight;\n    const padAlongWidth = (outWidth - 1) * strideWidth + filterWidth - inWidth;\n    const front = Math.floor(padAlongDepth / 2);\n    const back = padAlongDepth - front;\n    const top = Math.floor(padAlongHeight / 2);\n    const bottom = padAlongHeight - top;\n    const left = Math.floor(padAlongWidth / 2);\n    const right = padAlongWidth - left;\n\n    padInfo = {top, bottom, left, right, front, back, type: 'SAME'};\n  } else if (pad === 'valid') {\n    padInfo = {\n      top: 0,\n      bottom: 0,\n      left: 0,\n      right: 0,\n      front: 0,\n      back: 0,\n      type: 'VALID'\n    };\n    outDepth = Math.ceil((inDepth - filterDepth + 1) / strideDepth);\n    outHeight = Math.ceil((inHeight - filterHeight + 1) / strideHeight);\n    outWidth = Math.ceil((inWidth - filterWidth + 1) / strideWidth);\n  } else {\n    throw Error(`Unknown padding parameter: ${pad}`);\n  }\n  return {padInfo, outDepth, outHeight, outWidth};\n}\n\n/**\n * Rounds a value depending on the rounding mode\n * @param value\n * @param roundingMode A string from: 'ceil', 'round', 'floor'. If none is\n *     provided, it will default to truncate.\n */\nfunction round(value: number, roundingMode?: 'floor'|'round'|'ceil') {\n  if (!roundingMode) {\n    return Math.trunc(value);\n  }\n  switch (roundingMode) {\n    case 'round':\n      // used for Caffe Conv\n      return Math.round(value);\n    case 'ceil':\n      // used for Caffe Pool\n      return Math.ceil(value);\n    case 'floor':\n      return Math.floor(value);\n    default:\n      throw new Error(`Unknown roundingMode ${roundingMode}`);\n  }\n}\n\nexport function tupleValuesAreOne(param: number|number[]): boolean {\n  const [dimA, dimB, dimC] = parseTupleParam(param);\n  return dimA === 1 && dimB === 1 && dimC === 1;\n}\n\nexport function eitherStridesOrDilationsAreOne(\n    strides: number|number[], dilations: number|number[]): boolean {\n  return tupleValuesAreOne(strides) || tupleValuesAreOne(dilations);\n}\n\n/**\n * Convert Conv2D dataFormat from 'NHWC'|'NCHW' to\n *    'channelsLast'|'channelsFirst'\n * @param dataFormat in 'NHWC'|'NCHW' mode\n * @return dataFormat in 'channelsLast'|'channelsFirst' mode\n * @throws unknown dataFormat\n */\nexport function convertConv2DDataFormat(dataFormat: 'NHWC'|'NCHW'):\n    'channelsLast'|'channelsFirst' {\n  if (dataFormat === 'NHWC') {\n    return 'channelsLast';\n  } else if (dataFormat === 'NCHW') {\n    return 'channelsFirst';\n  } else {\n    throw new Error(`Unknown dataFormat ${dataFormat}`);\n  }\n}\n\n/**\n * Check validity of pad when using dimRoundingMode.\n * @param opDesc A string of op description\n * @param pad The type of padding algorithm.\n *   - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *   - `valid` output will be smaller than input if filter is larger\n *       than 1x1.\n *   - For more info, see this guide:\n *     [https://www.tensorflow.org/api_docs/python/tf/nn/convolution](\n *          https://www.tensorflow.org/api_docs/python/tf/nn/convolution)\n * @param dimRoundingMode A string from: 'ceil', 'round', 'floor'. If none is\n *     provided, it will default to truncate.\n * @throws unknown padding parameter\n */\nexport function checkPadOnDimRoundingMode(\n    opDesc: string, pad: 'valid'|'same'|number|ExplicitPadding,\n    dimRoundingMode?: 'floor'|'round'|'ceil') {\n  if (dimRoundingMode != null) {\n    if (typeof pad === 'string') {\n      throw Error(\n          `Error in ${opDesc}: pad must be an integer when using `  +\n          `dimRoundingMode ${dimRoundingMode} but got pad ${pad}.`);\n    } else if (typeof pad === 'number') {\n      util.assert(\n        util.isInt(pad),\n          () => `Error in ${opDesc}: pad must be an integer when using ` +\n              `dimRoundingMode ${dimRoundingMode} but got pad ${pad}.`);\n    } else if (typeof pad === 'object') {\n      (pad as ExplicitPadding).forEach(p => {p.forEach(v =>{\n        util.assert(\n          util.isInt(v),\n            () => `Error in ${opDesc}: pad must be an integer when using ` +\n                `dimRoundingMode ${dimRoundingMode} but got pad ${v}.`);\n        });\n      });\n    } else {\n      throw Error(`Error in ${opDesc}: Unknown padding parameter: ${pad}`);\n    }\n  }\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {Reshape, ReshapeAttrs, ReshapeInputs} from '../kernel_names';\nimport {NamedAttrMap} from '../kernel_registry';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {Rank, ShapeMap, TensorLike} from '../types';\n\nimport {op} from './operation';\n\n/**\n * Reshapes a `tf.Tensor` to a given shape.\n *\n * Given an input tensor, returns a new tensor with the same values as the\n * input tensor with shape `shape`.\n *\n * If one component of shape is the special value -1, the size of that\n * dimension is computed so that the total size remains constant. In\n * particular, a shape of [-1] flattens into 1-D. At most one component of\n * shape can be -1.\n *\n * If shape is 1-D or higher, then the operation returns a tensor with shape\n * shape filled with the values of tensor. In this case, the number of\n * elements implied by shape must be the same as the number of elements in\n * tensor.\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3, 4]);\n * x.reshape([2, 2]).print();\n * ```\n *\n * @param x The input tensor to be reshaped.\n * @param shape An array of integers defining the output tensor shape.\n *\n * @doc {heading: 'Tensors', subheading: 'Transformations'}\n */\nfunction reshape_<R extends Rank>(\n    x: Tensor|TensorLike, shape: ShapeMap[R]): Tensor<R> {\n  const $x = convertToTensor(x, 'x', 'reshape', 'string_or_numeric');\n\n  const inputs: ReshapeInputs = {x: $x};\n  const attrs: ReshapeAttrs = {shape};\n  return ENGINE.runKernel(\n      Reshape, inputs as {} as NamedTensorMap, attrs as {} as NamedAttrMap);\n}\nexport const reshape = op({reshape_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {AvgPool, AvgPoolAttrs, AvgPoolInputs} from '../kernel_names';\nimport {NamedAttrMap} from '../kernel_registry';\nimport {Tensor3D, Tensor4D} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\nimport * as util from '../util';\n\nimport {cast} from './cast';\nimport * as conv_util from './conv_util';\nimport {op} from './operation';\nimport {reshape} from './reshape';\n\n/**\n * Computes the 2D average pooling of an image.\n *\n * @param x The input tensor, of rank 4 or rank 3 of shape\n *     `[batch, height, width, inChannels]`. If rank 3, batch of 1 is assumed.\n * @param filterSize The filter size: `[filterHeight, filterWidth]`. If\n *     `filterSize` is a single number, then `filterHeight == filterWidth`.\n * @param strides The strides of the pooling: `[strideHeight, strideWidth]`. If\n *     `strides` is a single number, then `strideHeight == strideWidth`.\n * @param pad The type of padding algorithm:\n *    - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *    - `valid`: output will be smaller than input if filter is larger\n *       than 1x1.\n *    - For more info, see this guide:\n *     [https://www.tensorflow.org/api_docs/python/tf/nn/convolution](\n *         https://www.tensorflow.org/api_docs/python/tf/nn/convolution)\n * @param dimRoundingMode A string from: 'ceil', 'round', 'floor'. If none is\n *     provided, it will default to truncate.\n */\nfunction avgPool_<T extends Tensor3D|Tensor4D>(\n    x: T|TensorLike, filterSize: [number, number]|number,\n    strides: [number, number]|number,\n    pad: 'valid'|'same'|number|conv_util.ExplicitPadding,\n    dimRoundingMode?: 'floor'|'round'|'ceil'): T {\n  const $x = convertToTensor(x, 'x', 'avgPool', 'float32');\n  const dilations = 1;\n\n  util.assert(\n      conv_util.eitherStridesOrDilationsAreOne(strides, dilations),\n      () => 'Error in avgPool: Either strides or dilations must be 1. ' +\n          `Got strides ${strides} and dilations '${dilations}'`);\n\n  let x4D = $x as Tensor4D;\n  let reshapedTo4D = false;\n  if ($x.rank === 3) {\n    reshapedTo4D = true;\n    x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);\n  }\n\n  util.assert(\n      x4D.rank === 4,\n      () => `Error in avgPool: x must be rank 4 but got rank ${x4D.rank}.`);\n  conv_util.checkPadOnDimRoundingMode('avgPool', pad, dimRoundingMode);\n  const inputs: AvgPoolInputs = {x: x4D};\n  const attrs: AvgPoolAttrs = {filterSize, strides, pad, dimRoundingMode};\n\n  // tslint:disable-next-line: no-unnecessary-type-assertion\n  let res = ENGINE.runKernel(\n                AvgPool, inputs as {} as NamedTensorMap,\n                attrs as {} as NamedAttrMap) as T;\n\n  res = cast(res, $x.dtype);\n\n  if (reshapedTo4D) {\n    return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]) as T;\n  }\n\n  return res;\n}\n\nexport const avgPool = op({avgPool_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {AvgPool3D, AvgPool3DAttrs, AvgPool3DInputs} from '../kernel_names';\nimport {NamedAttrMap} from '../kernel_registry';\nimport {Tensor4D, Tensor5D} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\nimport * as util from '../util';\n\nimport {checkPadOnDimRoundingMode} from './conv_util';\nimport {cast} from './cast';\nimport {op} from './operation';\nimport {reshape} from './reshape';\n\n/**\n * Computes the 3D average pooling.\n *\n * ```js\n * const x = tf.tensor5d([1, 2, 3, 4, 5, 6, 7, 8], [1, 2, 2, 2, 1]);\n * const result = tf.avgPool3d(x, 2, 1, 'valid');\n * result.print();\n * ```\n *\n * @param x The input tensor, of rank 5 or rank 4 of shape\n *     `[batch, depth, height, width, inChannels]`.\n * @param filterSize The filter size:\n *     `[filterDepth, filterHeight, filterWidth]`.\n *     If `filterSize` is a single number,\n *     then `filterDepth == filterHeight == filterWidth`.\n * @param strides The strides of the pooling:\n *     `[strideDepth, strideHeight, strideWidth]`.\n *     If `strides` is a single number,\n *     then `strideDepth == strideHeight == strideWidth`.\n * @param pad The type of padding algorithm.\n *    - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *    - `valid`: output will be smaller than input if filter is larger\n *       than 1*1x1.\n *    - For more info, see this guide:\n *     [https://www.tensorflow.org/api_docs/python/tf/nn/convolution](\n *          https://www.tensorflow.org/api_docs/python/tf/nn/convolution)\n * @param dimRoundingMode A string from: 'ceil', 'round', 'floor'. If none is\n *     provided, it will default to truncate.\n * @param dataFormat An optional string from: \"NDHWC\", \"NCDHW\". Defaults to\n *     \"NDHWC\". Specify the data format of the input and output data. With the\n *     default format \"NDHWC\", the data is stored in the order of: [batch,\n *     depth, height, width, channels]. Only \"NDHWC\" is currently supported.\n *\n * @doc {heading: 'Operations', subheading: 'Convolution'}\n */\nfunction avgPool3d_<T extends Tensor4D|Tensor5D>(\n    x: T|TensorLike, filterSize: [number, number, number]|number,\n    strides: [number, number, number]|number, pad: 'valid'|'same'|number,\n    dimRoundingMode?: 'floor'|'round'|'ceil',\n    dataFormat: 'NDHWC'|'NCDHW' = 'NDHWC'): T {\n  const $x = convertToTensor(x, 'x', 'avgPool3d', 'float32');\n\n  let x5D = $x as Tensor5D;\n  let reshapedTo5D = false;\n  if ($x.rank === 4) {\n    reshapedTo5D = true;\n    x5D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2], $x.shape[3]]);\n  }\n\n  util.assert(\n      x5D.rank === 5,\n      () => `Error in avgPool3d: x must be rank 5 but got rank ${x5D.rank}.`);\n  util.assert(\n      dataFormat === 'NDHWC',\n      () => `Error in avgPool3d: Only NDHWC is currently supported, ` +\n          `but got dataFormat of ${dataFormat}`);\n  checkPadOnDimRoundingMode('avgPool3d', pad, dimRoundingMode);\n  const inputs: AvgPool3DInputs = {x: x5D};\n  const attrs:\n      AvgPool3DAttrs = {filterSize, strides, pad, dimRoundingMode, dataFormat};\n\n  // tslint:disable-next-line: no-unnecessary-type-assertion\n  let res = ENGINE.runKernel(\n                AvgPool3D, inputs as {} as NamedTensorMap,\n                attrs as {} as NamedAttrMap) as T;\n\n  res = cast(res, x5D.dtype);\n\n  if (reshapedTo5D) {\n    return reshape(\n               res, [res.shape[1], res.shape[2], res.shape[3], res.shape[4]]) as\n        T;\n  }\n\n  return res;\n}\n\nexport const avgPool3d = op({avgPool3d_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {ENGINE} from '../engine';\nimport {Concat, ConcatAttrs, ConcatInputs} from '../kernel_names';\nimport {NamedAttrMap} from '../kernel_registry';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensorArray} from '../tensor_util_env';\nimport {TensorLike} from '../types';\nimport {assert} from '../util';\n\nimport {clone} from './clone';\nimport {op} from './operation';\n\n/**\n * Concatenates a list of `tf.Tensor`s along a given axis.\n *\n * The tensors ranks and types must match, and their sizes must match in all\n * dimensions except `axis`.\n *\n * Also available are stricter rank-specific methods that assert that\n * `tensors` are of the given rank:\n *   - `tf.concat1d`\n *   - `tf.concat2d`\n *   - `tf.concat3d`\n *   - `tf.concat4d`\n *\n * Except `tf.concat1d` (which does not have axis param), all methods have\n * same signature as this method.\n *\n * ```js\n * const a = tf.tensor1d([1, 2]);\n * const b = tf.tensor1d([3, 4]);\n * a.concat(b).print();  // or a.concat(b)\n * ```\n *\n * ```js\n * const a = tf.tensor1d([1, 2]);\n * const b = tf.tensor1d([3, 4]);\n * const c = tf.tensor1d([5, 6]);\n * tf.concat([a, b, c]).print();\n * ```\n *\n * ```js\n * const a = tf.tensor2d([[1, 2], [10, 20]]);\n * const b = tf.tensor2d([[3, 4], [30, 40]]);\n * const axis = 1;\n * tf.concat([a, b], axis).print();\n * ```\n * @param tensors A list of tensors to concatenate.\n * @param axis The axis to concatenate along. Defaults to 0 (the first dim).\n *\n * @doc {heading: 'Tensors', subheading: 'Slicing and Joining'}\n */\nfunction concat_<T extends Tensor>(tensors: Array<T|TensorLike>, axis = 0): T {\n  assert(tensors.length >= 1, () => 'Pass at least one tensor to concat');\n\n  const $tensors =\n      convertToTensorArray(tensors, 'tensors', 'concat', 'string_or_numeric');\n\n  if ($tensors[0].dtype === 'complex64') {\n    $tensors.forEach(tensor => {\n      if (tensor.dtype !== 'complex64') {\n        throw new Error(`Cannot concatenate complex64 tensors with a tensor\n          with dtype ${tensor.dtype}. `);\n      }\n    });\n  }\n\n  if ($tensors.length === 1) {\n    return clone($tensors[0]);\n  }\n\n  const inputs: ConcatInputs = $tensors;\n  const attr: ConcatAttrs = {axis};\n\n  return ENGINE.runKernel(\n      Concat, inputs as {} as NamedTensorMap, attr as {} as NamedAttrMap);\n}\n\nexport const concat = op({concat_});\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {Sigmoid, SigmoidInputs} from '../kernel_names';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {op} from './operation';\n\n/**\n * Computes sigmoid element-wise, `1 / (1 + exp(-x))`\n *\n * ```js\n * const x = tf.tensor1d([0, -1, 2, -3]);\n *\n * x.sigmoid().print();  // or tf.sigmoid(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction sigmoid_<T extends Tensor>(x: T|TensorLike): T {\n  const $x = convertToTensor(x, 'x', 'sigmoid', 'float32');\n\n  const inputs: SigmoidInputs = {x: $x};\n\n  return ENGINE.runKernel(Sigmoid, inputs as {} as NamedTensorMap);\n}\nexport const sigmoid = op({sigmoid_});\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {Slice, SliceAttrs, SliceInputs} from '../kernel_names';\nimport {NamedAttrMap} from '../kernel_registry';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {Rank, TensorLike} from '../types';\n\nimport {op} from './operation';\n\n/**\n * Extracts a slice from a `tf.Tensor` starting at coordinates `begin`\n * and is of size `size`.\n *\n * Also available are stricter rank-specific methods with the same signature\n * as this method that assert that `x` is of the given rank:\n *   - `tf.slice1d`\n *   - `tf.slice2d`\n *   - `tf.slice3d`\n *   - `tf.slice4d`\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3, 4]);\n *\n * x.slice([1], [2]).print();\n * ```\n *\n * ```js\n * const x = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n *\n * x.slice([1, 0], [1, 2]).print();\n * ```\n * @param x The input `tf.Tensor` to slice from.\n * @param begin The coordinates to start the slice from. The length can be\n *     less than the rank of x - the rest of the axes will have implicit 0 as\n *     start. Can also be a single number, in which case it specifies the\n *     first axis.\n * @param size The size of the slice. The length can be less than the rank of\n *     x - the rest of the axes will have implicit -1. A value of -1 requests\n *     the rest of the dimensions in the axis. Can also be a single number,\n *     in which case it specifies the size of the first axis.\n *\n * @doc {heading: 'Tensors', subheading: 'Slicing and Joining'}\n */\nfunction slice_<R extends Rank, T extends Tensor<R>>(\n    x: T|TensorLike, begin: number|number[], size?: number|number[]): T {\n  const $x = convertToTensor(x, 'x', 'slice', 'string_or_numeric');\n\n  if ($x.rank === 0) {\n    throw new Error('Slicing scalar is not possible');\n  }\n\n  const inputs: SliceInputs = {x: $x};\n  const attrs: SliceAttrs = {begin, size};\n\n  return ENGINE.runKernel(\n      Slice, inputs as {} as NamedTensorMap, attrs as {} as NamedAttrMap);\n}\n\nexport const slice = op({slice_});\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {Tanh, TanhInputs} from '../kernel_names';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {op} from './operation';\n\n/**\n * Computes hyperbolic tangent of the input `tf.Tensor` element-wise: `tanh(x)`\n *\n * ```js\n * const x = tf.tensor1d([0, 1, -1, 70]);\n *\n * x.tanh().print();  // or tf.tanh(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction tanh_<T extends Tensor>(x: T|TensorLike): T {\n  const $x = convertToTensor(x, 'x', 'tanh', 'float32');\n\n  const inputs: TanhInputs = {x: $x};\n\n  return ENGINE.runKernel(Tanh, inputs as {} as NamedTensorMap);\n}\nexport const tanh = op({tanh_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Scalar, Tensor1D, Tensor2D} from '../tensor';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {add} from './add';\nimport {concat} from './concat';\nimport {matMul} from './mat_mul';\nimport {mul} from './mul';\nimport {op} from './operation';\nimport {sigmoid} from './sigmoid';\nimport {slice} from './slice';\nimport {tanh} from './tanh';\n\n/**\n * Computes the next state and output of a BasicLSTMCell.\n *\n * Returns `[newC, newH]`.\n *\n * Derived from tf.contrib.rnn.BasicLSTMCell.\n *\n * @param forgetBias Forget bias for the cell.\n * @param lstmKernel The weights for the cell.\n * @param lstmBias The bias for the cell.\n * @param data The input to the cell.\n * @param c Previous cell state.\n * @param h Previous cell output.\n *\n * @doc {heading: 'Operations', subheading: 'RNN'}\n */\nfunction basicLSTMCell_(\n    forgetBias: Scalar|TensorLike, lstmKernel: Tensor2D|TensorLike,\n    lstmBias: Tensor1D|TensorLike, data: Tensor2D|TensorLike,\n    c: Tensor2D|TensorLike, h: Tensor2D|TensorLike): [Tensor2D, Tensor2D] {\n  const $forgetBias =\n      convertToTensor(forgetBias, 'forgetBias', 'basicLSTMCell');\n  const $lstmKernel =\n      convertToTensor(lstmKernel, 'lstmKernel', 'basicLSTMCell');\n  const $lstmBias = convertToTensor(lstmBias, 'lstmBias', 'basicLSTMCell');\n  const $data = convertToTensor(data, 'data', 'basicLSTMCell');\n  const $c = convertToTensor(c, 'c', 'basicLSTMCell');\n  const $h = convertToTensor(h, 'h', 'basicLSTMCell');\n\n  const combined = concat([$data, $h], 1);\n  const weighted = matMul(combined, $lstmKernel);\n  const res: Tensor2D = add(weighted, $lstmBias);\n\n  // i = input_gate, j = new_input, f = forget_gate, o = output_gate\n  const batchSize = res.shape[0];\n  const sliceCols = res.shape[1] / 4;\n  const sliceSize: [number, number] = [batchSize, sliceCols];\n  const i = slice(res, [0, 0], sliceSize);\n  const j = slice(res, [0, sliceCols], sliceSize);\n  const f = slice(res, [0, sliceCols * 2], sliceSize);\n  const o = slice(res, [0, sliceCols * 3], sliceSize);\n\n  const newC: Tensor2D =\n      add(mul(sigmoid(i), tanh(j)),\n          mul($c, sigmoid(add($forgetBias, f)) as Tensor2D));\n  const newH: Tensor2D = mul(tanh(newC), sigmoid(o));\n  return [newC, newH];\n}\n\nexport const basicLSTMCell = op({basicLSTMCell_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {BatchToSpaceND, BatchToSpaceNDAttrs, BatchToSpaceNDInputs} from '../kernel_names';\nimport {NamedAttrMap} from '../kernel_registry';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\nimport * as util from '../util';\n\nimport {op} from './operation';\n\n/**\n * This operation reshapes the \"batch\" dimension 0 into `M + 1` dimensions of\n * shape `blockShape + [batch]`, interleaves these blocks back into the grid\n * defined by the spatial dimensions `[1, ..., M]`, to obtain a result with\n * the same rank as the input. The spatial dimensions of this intermediate\n * result are then optionally cropped according to `crops` to produce the\n * output. This is the reverse of `tf.spaceToBatchND`. See below for a precise\n * description.\n *\n * ```js\n * const x = tf.tensor4d([1, 2, 3, 4], [4, 1, 1, 1]);\n * const blockShape = [2, 2];\n * const crops = [[0, 0], [0, 0]];\n *\n * x.batchToSpaceND(blockShape, crops).print();\n * ```\n *\n * @param x A `tf.Tensor`. N-D with `x.shape` = `[batch] + spatialShape +\n * remainingShape`, where spatialShape has `M` dimensions.\n * @param blockShape A 1-D array. Must have shape `[M]`, all values must\n * be >= 1.\n * @param crops A 2-D array.  Must have shape `[M, 2]`, all values must be >= 0.\n * `crops[i] = [cropStart, cropEnd]` specifies the amount to crop from input\n * dimension `i + 1`, which corresponds to spatial dimension `i`. It is required\n * that `cropStart[i] + cropEnd[i] <= blockShape[i] * inputShape[i + 1]`\n *\n * This operation is equivalent to the following steps:\n *\n * 1. Reshape `x` to `reshaped` of shape: `[blockShape[0], ...,\n * blockShape[M-1], batch / prod(blockShape), x.shape[1], ...,\n * x.shape[N-1]]`\n *\n * 2. Permute dimensions of `reshaped` to produce `permuted` of shape `[batch /\n * prod(blockShape),x.shape[1], blockShape[0], ..., x.shape[M],\n * blockShape[M-1],x.shape[M+1], ..., x.shape[N-1]]`\n *\n * 3. Reshape `permuted` to produce `reshapedPermuted` of shape `[batch /\n * prod(blockShape),x.shape[1] * blockShape[0], ..., x.shape[M] *\n * blockShape[M-1],x.shape[M+1], ..., x.shape[N-1]]`\n *\n * 4. Crop the start and end of dimensions `[1, ..., M]` of `reshapedPermuted`\n * according to `crops` to produce the output of shape: `[batch /\n * prod(blockShape),x.shape[1] * blockShape[0] - crops[0,0] - crops[0,1],\n * ..., x.shape[M] * blockShape[M-1] - crops[M-1,0] -\n * crops[M-1,1],x.shape[M+1], ..., x.shape[N-1]]`\n *\n * @doc {heading: 'Tensors', subheading: 'Transformations'}\n */\nfunction batchToSpaceND_<T extends Tensor>(\n    x: T|TensorLike, blockShape: number[], crops: number[][]): T {\n  const $x = convertToTensor(x, 'x', 'batchToSpaceND');\n  const prod = blockShape.reduce((a, b) => a * b);\n\n  util.assert(\n      $x.rank >= 1 + blockShape.length,\n      () => `input rank is ${$x.rank} but should be > than blockShape.length ${\n          blockShape.length}`);\n\n  util.assert(\n      crops.length === blockShape.length,\n      () => `crops.length is ${\n          crops.length} but should be equal to blockShape.length  ${\n          blockShape.length}`);\n\n  util.assert(\n      $x.shape[0] % prod === 0,\n      () => `input tensor batch is ${\n                $x.shape[0]} but is not divisible by the product of ` +\n          `the elements of blockShape ${blockShape.join(' * ')} === ${prod}`);\n\n  const inputs: BatchToSpaceNDInputs = {x: $x};\n  const attrs: BatchToSpaceNDAttrs = {blockShape, crops};\n\n  return ENGINE.runKernel(\n      BatchToSpaceND, inputs as {} as NamedTensorMap,\n      attrs as {} as NamedAttrMap);\n}\n\nexport const batchToSpaceND = op({batchToSpaceND_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {FusedBatchNorm, FusedBatchNormAttrs, FusedBatchNormInputs} from '../kernel_names';\nimport {NamedAttrMap} from '../kernel_registry';\nimport {Tensor, Tensor1D, Tensor4D} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {Rank, TensorLike} from '../types';\nimport * as util from '../util';\n\nimport {xAs4D} from './batchnorm_util';\nimport {op} from './operation';\nimport {reshape} from './reshape';\n\n/**\n * Batch normalization.\n *\n * As described in\n * [http://arxiv.org/abs/1502.03167](http://arxiv.org/abs/1502.03167).\n *\n * Mean, variance, scale, and offset can be of two shapes:\n *   - The same shape as the input.\n *   - In the common case, the depth dimension is the last dimension of x, so\n *     the values would be a `tf.Tensor1D` of shape [depth].\n *\n * Also available are stricter rank-specific methods with the same signature\n * as this method that assert that parameters passed are of given rank\n *   - `tf.batchNorm2d`\n *   - `tf.batchNorm3d`\n *   - `tf.batchNorm4d`\n *\n * @param x The input Tensor.\n * @param mean A mean Tensor.\n * @param variance A variance Tensor.\n * @param offset An offset Tensor.\n * @param scale A scale Tensor.\n * @param varianceEpsilon A small float number to avoid dividing by 0.\n *\n * @doc {heading: 'Operations', subheading: 'Normalization'}\n */\nfunction batchNorm_<R extends Rank>(\n    x: Tensor<R>|TensorLike, mean: Tensor<R>|Tensor1D|TensorLike,\n    variance: Tensor<R>|Tensor1D|TensorLike,\n    offset?: Tensor<R>|Tensor1D|TensorLike,\n    scale?: Tensor<R>|Tensor1D|TensorLike,\n    varianceEpsilon?: number): Tensor<R> {\n  if (varianceEpsilon == null) {\n    varianceEpsilon = 0.001;\n  }\n  const $x = convertToTensor(x, 'x', 'batchNorm');\n  const $mean = convertToTensor(mean, 'mean', 'batchNorm');\n  const $variance = convertToTensor(variance, 'variance', 'batchNorm');\n  let $scale: Tensor<R>|Tensor1D;\n  if (scale != null) {\n    $scale = convertToTensor(scale, 'scale', 'batchNorm');\n  }\n  let $offset: Tensor<R>|Tensor1D;\n  if (offset != null) {\n    $offset = convertToTensor(offset, 'offset', 'batchNorm');\n  }\n\n  util.assert(\n      $mean.rank === $variance.rank,\n      () => 'Batch normalization gradient requires mean and variance to have ' +\n          'equal ranks.');\n  util.assert(\n      $offset == null || $mean.rank === $offset.rank,\n      () => 'Batch normalization gradient requires mean and offset to have ' +\n          'equal ranks.');\n  util.assert(\n      $scale == null || $mean.rank === $scale.rank,\n      () => 'Batch normalization gradient requires mean and scale to have ' +\n          'equal ranks.');\n\n  const x4D: Tensor4D = xAs4D($x);\n\n  const inputs: FusedBatchNormInputs = {\n    x: x4D,\n    scale: $scale,\n    offset: $offset,\n    mean: $mean,\n    variance: $variance\n  };\n\n  const attrs: FusedBatchNormAttrs = {varianceEpsilon};\n\n  // tslint:disable-next-line: no-unnecessary-type-assertion\n  const res = ENGINE.runKernel(\n                  FusedBatchNorm, inputs as {} as NamedTensorMap,\n                  attrs as {} as NamedAttrMap) as Tensor<R>;\n\n  return reshape(res, $x.shape);\n}\n\nexport const batchNorm = op({batchNorm_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {Tensor, Tensor4D} from '../tensor';\nimport {Rank} from '../types';\nimport {reshape} from './reshape';\n\nexport function xAs4D<R extends Rank>(x: Tensor<R>) {\n  let x4D: Tensor4D;\n  if (x.rank === 0 || x.rank === 1) {\n    x4D = reshape(x, [1, 1, 1, x.size]);\n  } else if (x.rank === 2) {\n    x4D = reshape(x, [1, 1, x.shape[0], x.shape[1]]);\n  } else if (x.rank === 3) {\n    x4D = reshape(x, [1, x.shape[0], x.shape[1], x.shape[2]]);\n  } else {\n    x4D = x as Tensor4D;\n  }\n\n  return x4D;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {Tensor1D, Tensor2D} from '../tensor';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\nimport * as util from '../util';\n\nimport {batchNorm} from './batchnorm';\nimport {op} from './operation';\n\n/**\n * Batch normalization, strictly for 2D. For the more relaxed version, see\n * `tf.batchNorm`.\n *\n * @param x The input Tensor.\n * @param mean A mean Tensor.\n * @param variance A variance Tensor.\n * @param offset An offset Tensor.\n * @param scale A scale Tensor.\n * @param varianceEpsilon A small float number to avoid dividing by 0.\n */\nfunction batchNorm2d_(\n    x: Tensor2D|TensorLike, mean: Tensor2D|Tensor1D|TensorLike,\n    variance: Tensor2D|Tensor1D|TensorLike,\n    offset?: Tensor2D|Tensor1D|TensorLike, scale?: Tensor2D|Tensor1D|TensorLike,\n    varianceEpsilon?: number): Tensor2D {\n  const $x = convertToTensor(x, 'x', 'batchNorm');\n  const $mean = convertToTensor(mean, 'mean', 'batchNorm');\n  const $variance = convertToTensor(variance, 'variance', 'batchNorm');\n  let $scale: Tensor2D|Tensor1D;\n  if (scale != null) {\n    $scale = convertToTensor(scale, 'scale', 'batchNorm');\n  }\n  let $offset: Tensor2D|Tensor1D;\n  if (offset != null) {\n    $offset = convertToTensor(offset, 'offset', 'batchNorm');\n  }\n  util.assert(\n      $x.rank === 2,\n      () => `Error in batchNorm2D: x must be rank 2 but got rank ` +\n          `${$x.rank}.`);\n  util.assert(\n      $mean.rank === 2 || $mean.rank === 1,\n      () => `Error in batchNorm2D: mean must be rank 2 or rank 1 but ` +\n          `got rank ${$mean.rank}.`);\n  util.assert(\n      $variance.rank === 2 || $variance.rank === 1,\n      () => `Error in batchNorm2D: variance must be rank 2 or rank 1 ` +\n          `but got rank ${$variance.rank}.`);\n  if ($scale != null) {\n    util.assert(\n        $scale.rank === 2 || $scale.rank === 1,\n        () => `Error in batchNorm2D: scale must be rank 2 or rank 1 ` +\n            `but got rank ${$scale.rank}.`);\n  }\n  if ($offset != null) {\n    util.assert(\n        $offset.rank === 2 || $offset.rank === 1,\n        () => `Error in batchNorm2D: offset must be rank 2 or rank 1 ` +\n            `but got rank ${$offset.rank}.`);\n  }\n\n  return batchNorm($x, $mean, $variance, $offset, $scale, varianceEpsilon);\n}\n\nexport const batchNorm2d = op({batchNorm2d_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {Tensor1D, Tensor3D} from '../tensor';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\nimport * as util from '../util';\n\nimport {batchNorm} from './batchnorm';\nimport {op} from './operation';\n\n/**\n * Batch normalization, strictly for 3D. For the more relaxed version, see\n * `tf.batchNorm`.\n *\n * @param x The input Tensor.\n * @param mean A mean Tensor.\n * @param variance A variance Tensor.\n * @param offset An offset Tensor.\n * @param scale A scale Tensor.\n * @param varianceEpsilon A small float number to avoid dividing by 0.\n */\nfunction batchNorm3d_(\n    x: Tensor3D|TensorLike, mean: Tensor3D|Tensor1D|TensorLike,\n    variance: Tensor3D|Tensor1D|TensorLike,\n    offset?: Tensor3D|Tensor1D|TensorLike, scale?: Tensor3D|Tensor1D|TensorLike,\n    varianceEpsilon?: number): Tensor3D {\n  const $x = convertToTensor(x, 'x', 'batchNorm');\n  const $mean = convertToTensor(mean, 'mean', 'batchNorm');\n  const $variance = convertToTensor(variance, 'variance', 'batchNorm');\n  let $scale: Tensor3D|Tensor1D;\n  if (scale != null) {\n    $scale = convertToTensor(scale, 'scale', 'batchNorm');\n  }\n  let $offset: Tensor3D|Tensor1D;\n  if (offset != null) {\n    $offset = convertToTensor(offset, 'offset', 'batchNorm');\n  }\n  util.assert(\n      $x.rank === 3,\n      () => `Error in batchNorm3D: x must be rank 3 but got rank ` +\n          `${$x.rank}.`);\n  util.assert(\n      $mean.rank === 3 || $mean.rank === 1,\n      () => `Error in batchNorm3D: mean must be rank 3 or rank 1 but ` +\n          `got rank ${$mean.rank}.`);\n  util.assert(\n      $variance.rank === 3 || $variance.rank === 1,\n      () => `Error in batchNorm3D: variance must be rank 3 or rank 1 ` +\n          `but got rank ${$variance.rank}.`);\n  if ($scale != null) {\n    util.assert(\n        $scale.rank === 3 || $scale.rank === 1,\n        () => `Error in batchNorm3D: scale must be rank 3 or rank 1 ` +\n            `but got rank ${$scale.rank}.`);\n  }\n  if ($offset != null) {\n    util.assert(\n        $offset.rank === 3 || $offset.rank === 1,\n        () => `Error in batchNorm3D: offset must be rank 3 or rank 1 ` +\n            `but got rank ${$offset.rank}.`);\n  }\n\n  return batchNorm($x, $mean, $variance, $offset, $scale, varianceEpsilon);\n}\n\nexport const batchNorm3d = op({batchNorm3d_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {Tensor1D, Tensor4D} from '../tensor';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\nimport * as util from '../util';\n\nimport {batchNorm} from './batchnorm';\nimport {op} from './operation';\n\n/**\n * Batch normalization, strictly for 4D. For the more relaxed version, see\n * `tf.batchNorm`.\n *\n * @param x The input Tensor.\n * @param mean A mean Tensor.\n * @param variance A variance Tensor.\n * @param offset An offset Tensor.\n * @param scale A scale Tensor.\n * @param varianceEpsilon A small float number to avoid dividing by 0.\n */\nfunction batchNorm4d_(\n    x: Tensor4D|TensorLike, mean: Tensor4D|Tensor1D|TensorLike,\n    variance: Tensor4D|Tensor1D|TensorLike,\n    offset?: Tensor4D|Tensor1D|TensorLike, scale?: Tensor4D|Tensor1D|TensorLike,\n    varianceEpsilon?: number): Tensor4D {\n  const $x = convertToTensor(x, 'x', 'batchNorm');\n  const $mean = convertToTensor(mean, 'mean', 'batchNorm');\n  const $variance = convertToTensor(variance, 'variance', 'batchNorm');\n  let $scale: Tensor4D|Tensor1D;\n  if (scale != null) {\n    $scale = convertToTensor(scale, 'scale', 'batchNorm');\n  }\n  let $offset: Tensor4D|Tensor1D;\n  if (offset != null) {\n    $offset = convertToTensor(offset, 'offset', 'batchNorm');\n  }\n  util.assert(\n      $x.rank === 4,\n      () => `Error in batchNorm4D: x must be rank 4 but got rank ` +\n          `${$x.rank}.`);\n  util.assert(\n      $mean.rank === 4 || $mean.rank === 1,\n      () => `Error in batchNorm4D: mean must be rank 4 or rank 1 but ` +\n          `got rank ${$mean.rank}.`);\n  util.assert(\n      $variance.rank === 4 || $variance.rank === 1,\n      () => `Error in batchNorm4D: variance must be rank 4 or rank 1 ` +\n          `but got rank ${$variance.rank}.`);\n  if ($scale != null) {\n    util.assert(\n        $scale.rank === 4 || $scale.rank === 1,\n        () => `Error in batchNorm4D: scale must be rank 4 or rank 1 ` +\n            `but got rank ${$scale.rank}.`);\n  }\n  if ($offset != null) {\n    util.assert(\n        $offset.rank === 4 || $offset.rank === 1,\n        () => `Error in batchNorm4D: offset must be rank 4 or rank 1 ` +\n            `but got rank ${$offset.rank}.`);\n  }\n  return batchNorm($x, $mean, $variance, $offset, $scale, varianceEpsilon);\n}\n\nexport const batchNorm4d = op({batchNorm4d_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {Bincount, BincountAttrs, BincountInputs} from '../kernel_names';\nimport {NamedAttrMap} from '../kernel_registry';\nimport {Tensor1D} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\nimport * as util from '../util';\n\nimport {op} from './operation';\n\n/**\n * Outputs a vector with length `size` and the same dtype as `weights`.\n *\n * If `weights` are empty, then index `i` stores the number of times the value\n * `i` is counted in `x`. If `weights` are non-empty, then index `i` stores the\n * sum of the value in `weights` at each index where the corresponding value in\n * `x` is `i`.\n *\n * Values in `x` outside of the range [0, size) are ignored.\n *\n * @param x The input int tensor, rank 1.\n * @param weights The weights tensor, must have the same shape as x, or a\n *     length-0 Tensor, in which case it acts as all weights equal to 1.\n * @param size Non-negative integer.\n *\n * @doc {heading: 'Operations', subheading: 'Reduction'}\n */\nfunction bincount_<T extends Tensor1D>(\n    x: T|TensorLike, weights: T|TensorLike, size: number): T {\n  const $x = convertToTensor(x, 'x', 'bincount');\n  const $weights = convertToTensor(weights, 'weights', 'bincount');\n\n  util.assert(\n      $x.dtype === 'int32',\n      () => `Error in bincount: input ` +\n          `dtype must be int32, but got ${$x.dtype}`);\n  util.assert(size >= 0, () => `size must be non-negative, but got ${size}.`);\n  util.assert(\n      $weights.size === $x.size || $weights.size === 0,\n      () => `Error in bincount: weights must have the same size as input or` +\n          `0-length, but got input shape: ${$x.shape}, weights shape: ` +\n          `${$weights.shape}.`);\n\n  const inputs: BincountInputs = {x: $x, weights: $weights};\n  const attrs: BincountAttrs = {size};\n\n  return ENGINE.runKernel(\n      Bincount, inputs as {} as NamedTensorMap, attrs as {} as NamedAttrMap);\n}\n\nexport const bincount = op({bincount_});\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport { NamedTensorMap } from '../tensor_types';\nimport { ENGINE } from '../engine';\nimport { BroadcastArgs, BroadcastArgsInputs } from '../kernel_names';\nimport { Tensor } from '../tensor';\nimport { convertToTensor } from '../tensor_util_env';\nimport { Rank, TensorLike } from '../types';\n\nimport { op } from './operation';\n\n/**\n * Return the shape of s0 op s1 with broadcast.\n *\n * compute r0, the broadcasted shape as a tensor.\n * s0, s1 and r0 are all integer vectors.\n *\n * This function returns the shape of the result of an operation between\n * two tensors of size s0 and s1 performed with broadcast.\n *\n * @param s0 A tensor representing a shape\n * @param s1 A tensor representing a shape\n *\n * @doc {heading: 'Tensors', subheading: 'Transformations'}\n */\nfunction broadcastArgs_<R extends Rank>(\n  s0: Tensor | TensorLike, s1: Tensor | TensorLike): Tensor<R> {\n  const shape1Input = convertToTensor(s0, 's0', 'broadcastArgs', 'int32');\n  const shape2Input = convertToTensor(s1, 's1', 'broadcastArgs', 'int32');\n\n  if (shape1Input.rank !== 1) {\n    throw new Error(\n      'broadcastArgs(): first input must be a vector (rank=1). ' +\n      `Has rank ${shape1Input.rank}`);\n  }\n\n  if (shape2Input.rank !== 1) {\n    throw new Error(\n      'broadcastArgs(): second input must be a vector (rank=1). ' +\n      `Has rank ${shape2Input.rank}`);\n  }\n\n  const inputs: BroadcastArgsInputs = { s0: shape1Input, s1: shape2Input };\n  return ENGINE.runKernel(BroadcastArgs, inputs as {} as NamedTensorMap);\n}\n\nexport const broadcastArgs = op({ broadcastArgs_ });\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {Tile, TileAttrs, TileInputs} from '../kernel_names';\nimport {NamedAttrMap} from '../kernel_registry';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {Rank, ShapeMap, TensorLike} from '../types';\n\nimport {clone} from './clone';\nimport {op} from './operation';\nimport {reshape} from './reshape';\n\n/**\n * Broadcast an array to a compatible shape NumPy-style.\n *\n * The tensor's shape is compared to the broadcast shape from end to beginning.\n * Ones are prepended to the tensor's shape until it has the same length as\n * the broadcast shape. If input.shape[i]==shape[i], the (i+1)-th axis is\n * already broadcast-compatible. If input.shape[i]==1 and shape[i]==N, then\n * the input tensor is tiled N times along that axis (using tf.tile).\n *\n * @param input The tensor that is to be broadcasted.\n * @param shape The input is to be broadcast to this shape.\n *\n * @doc {heading: 'Tensors', subheading: 'Transformations'}\n */\nfunction broadcastTo_<R extends Rank>(\n    x: Tensor|TensorLike, shape: ShapeMap[R]): Tensor<R> {\n  let input = convertToTensor(x, 'broadcastTo', 'x');\n  const xShape = input.shape;\n\n  if (shape.some(d => !(d > 0) || d % 1 !== 0)) {\n    throw new Error(`broadcastTo(): Invalid broadcast shape [${shape}].`);\n  }\n\n  if (shape.length < input.rank) {\n    throw new Error(`broadcastTo(): shape.length=${shape.length} < input.rank=${\n        input.rank}.`);\n  }\n\n  if (shape.length > input.rank) {\n    const newShape = input.shape.slice();\n    while (newShape.length < shape.length) {\n      newShape.unshift(1);\n    }\n    input = reshape(input, newShape);\n  }\n\n  const inputShape = input.shape;\n  const reps: number[] = Array.from(shape);\n  for (let i = shape.length - 1; i >= 0; i--) {\n    if (inputShape[i] === shape[i]) {\n      reps[i] = 1;\n    } else if (input.shape[i] !== 1) {\n      throw new Error(\n          `broadcastTo(): [${xShape}] cannot be broadcast to [${shape}].`);\n    }\n  }\n  const axes = reps.map((n, i) => n > 1 ? i : -1).filter(i => i >= 0);\n\n  if (axes.length === 0) {\n    return clone(input) as Tensor<R>;\n  }\n\n  // TODO call broadcastTo kernel directly once backends implement broadcstTo\n  const inputs: TileInputs = {x: input};\n  const attrs: TileAttrs = {reps};\n  return ENGINE.runKernel(\n      Tile, inputs as {} as NamedTensorMap, attrs as unknown as NamedAttrMap);\n}\n\nexport const broadcastTo = op({broadcastTo_});\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {Ceil, CeilInputs} from '../kernel_names';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {op} from './operation';\n\n/**\n * Computes ceiling of input `tf.Tensor` element-wise: `ceil(x)`\n *\n * ```js\n * const x = tf.tensor1d([.6, 1.1, -3.3]);\n *\n * x.ceil().print();  // or tf.ceil(x)\n * ```\n * @param x The input Tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction ceil_<T extends Tensor>(x: T|TensorLike): T {\n  const $x = convertToTensor(x, 'x', 'ceil', 'float32');\n\n  const inputs: CeilInputs = {x: $x};\n  return ENGINE.runKernel(Ceil, inputs as {} as NamedTensorMap);\n}\nexport const ceil = op({ceil_});\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {ENGINE} from '../engine';\nimport {ClipByValue, ClipByValueAttrs, ClipByValueInputs} from '../kernel_names';\nimport {NamedAttrMap} from '../kernel_registry';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\nimport * as util from '../util';\nimport {fill} from './fill';\n\nimport {op} from './operation';\n\n/**\n * Clips values element-wise. `max(min(x, clipValueMax), clipValueMin)`\n *\n * ```js\n * const x = tf.tensor1d([-1, 2, -3, 4]);\n *\n * x.clipByValue(-2, 3).print();  // or tf.clipByValue(x, -2, 3)\n * ```\n * @param x The input tensor.\n * @param clipValueMin Lower bound of range to be clipped to.\n * @param clipValueMax Upper bound of range to be clipped to.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction clipByValue_<T extends Tensor>(\n    x: T|TensorLike, clipValueMin: number, clipValueMax: number): T {\n  const $x = convertToTensor(x, 'x', 'clipByValue');\n  util.assert(\n      (clipValueMin <= clipValueMax),\n      () => `Error in clip: min (${clipValueMin}) must be ` +\n          `less than or equal to max (${clipValueMax}).`);\n\n  if (clipValueMin === clipValueMax) {\n    return fill($x.shape, clipValueMin, $x.dtype) as T;\n  }\n\n  const inputs: ClipByValueInputs = {x: $x};\n  const attrs: ClipByValueAttrs = {clipValueMin, clipValueMax};\n\n  return ENGINE.runKernel(\n      ClipByValue, inputs as {} as NamedTensorMap, attrs as {} as NamedAttrMap);\n}\n\nexport const clipByValue = op({clipByValue_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {Tensor1D} from '../tensor';\nimport {TensorLike} from '../types';\n\nimport {concat} from './concat';\nimport {op} from './operation';\n\n/**\n * Concatenates a list of`tf.Tensor1D`s along an axis. See `concat` for details.\n *\n * For example, if:\n * A: shape(3) = |r1, g1, b1|\n * B: shape(2) = |r2, g2|\n * C = tf.concat1d([A, B]) == |r1, g1, b1, r2, g2|\n *\n * @param tensors A list of`tf.Tensor`s to concatenate.\n * @return The concatenated array.\n */\nfunction concat1d_(tensors: Array<Tensor1D|TensorLike>): Tensor1D {\n  return concat(tensors, 0 /* axis */);\n}\n\nexport const concat1d = op({concat1d_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {Tensor2D} from '../tensor';\nimport {TensorLike} from '../types';\n\nimport {concat} from './concat';\nimport {op} from './operation';\n\n/**\n * Concatenates a list of`tf.Tensor2D`s along an axis. See `concat` for details.\n *\n * For example, if:\n * A: shape(2, 3) = | r1, g1, b1 |\n *                  | r2, g2, b2 |\n *\n * B: shape(2, 3) = | r3, g3, b3 |\n *                  | r4, g4, b4 |\n *\n * C = tf.concat2d([A, B], axis)\n *\n * if axis = 0:\n * C: shape(4, 3) = | r1, g1, b1 |\n *                  | r2, g2, b2 |\n *                  | r3, g3, b3 |\n *                  | r4, g4, b4 |\n *\n * if axis = 1:\n * C = shape(2, 6) = | r1, g1, b1, r3, g3, b3 |\n *                   | r2, g2, b2, r4, g4, b4 |\n *\n *\n * @param tensors A list of `tf.Tensor`s to concatenate.\n * @param axis The axis to concatenate along.\n * @return The concatenated array.\n */\nfunction concat2d_(\n    tensors: Array<Tensor2D|TensorLike>, axis: number): Tensor2D {\n  return concat(tensors, axis);\n}\n\nexport const concat2d = op({concat2d_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {Tensor3D} from '../tensor';\nimport {TensorLike} from '../types';\n\nimport {concat} from './concat';\nimport {op} from './operation';\n\n/**\n * Concatenates a list of `tf.Tensor3D`s along an axis.\n * See `concat` for details.\n *\n * For example, if:\n * A: shape(2, 1, 3) = | r1, g1, b1 |\n *                     | r2, g2, b2 |\n *\n * B: shape(2, 1, 3) = | r3, g3, b3 |\n *                     | r4, g4, b4 |\n *\n * C = tf.concat3d([A, B], axis)\n *\n * if axis = 0:\n * C: shape(4, 1, 3) = | r1, g1, b1 |\n *                     | r2, g2, b2 |\n *                     | r3, g3, b3 |\n *                     | r4, g4, b4 |\n *\n * if axis = 1:\n * C: shape(2, 2, 3) = | r1, g1, b1, r3, g3, b3 |\n *                     | r2, g2, b2, r4, g4, b4 |\n *\n * if axis = 2:\n * C = shape(2, 1, 6) = | r1, g1, b1, r3, g3, b3 |\n *                      | r2, g2, b2, r4, g4, b4 |\n *\n * @param tensors A list of`tf.Tensor`s to concatenate.\n * @param axis The axis to concate along.\n * @return The concatenated array.\n */\nfunction concat3d_(\n    tensors: Array<Tensor3D|TensorLike>, axis: number): Tensor3D {\n  return concat(tensors, axis);\n}\n\nexport const concat3d = op({concat3d_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {Tensor4D} from '../tensor';\nimport {TensorLike} from '../types';\n\nimport {concat} from './concat';\nimport {op} from './operation';\n\n/**\n * Concatenates a list of `tf.Tensor4D`s along an axis.\n * See `concat` for details.\n *\n * @param tensors A list of `tf.Tensor`s to concatenate.\n * @param axis The axis to concate along.\n * @return The concatenated array.\n */\nfunction concat4d_(\n    tensors: Array<Tensor4D|TensorLike>, axis: number): Tensor4D {\n  return concat(tensors, axis);\n}\n\nexport const concat4d = op({concat4d_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {ENGINE} from '../engine';\nimport {Conv2D, Conv2DAttrs, Conv2DInputs} from '../kernel_names';\nimport {NamedAttrMap} from '../kernel_registry';\nimport {Tensor3D, Tensor4D} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\nimport * as util from '../util';\n\nimport * as conv_util from './conv_util';\nimport {op} from './operation';\nimport {reshape} from './reshape';\n\n/**\n * Computes a 2D convolution over the input x.\n *\n * @param x The input tensor, of rank 4 or rank 3, of shape\n *     `[batch, height, width, inChannels]`. If rank 3, batch of 1 is\n * assumed.\n * @param filter The filter, rank 4, of shape\n *     `[filterHeight, filterWidth, inDepth, outDepth]`.\n * @param strides The strides of the convolution: `[strideHeight,\n * strideWidth]`.\n * @param pad The type of padding algorithm.\n *    - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *    - `valid`: output will be smaller than input if filter is larger\n *       than 1x1.\n *   - For more info, see this guide:\n *     [https://www.tensorflow.org/api_docs/python/tf/nn/convolution](\n *          https://www.tensorflow.org/api_docs/python/tf/nn/convolution)\n * @param dataFormat: An optional string from: \"NHWC\", \"NCHW\". Defaults to\n *     \"NHWC\". Specify the data format of the input and output data. With the\n *     default format \"NHWC\", the data is stored in the order of: [batch,\n *     height, width, channels].\n * @param dilations The dilation rates: `[dilationHeight, dilationWidth]`\n *     in which we sample input values across the height and width dimensions\n *     in atrous convolution. Defaults to `[1, 1]`. If `dilations` is a single\n *     number, then `dilationHeight == dilationWidth`. If it is greater than\n *     1, then all values of `strides` must be 1.\n * @param dimRoundingMode A string from: 'ceil', 'round', 'floor'. If none is\n *     provided, it will default to truncate.\n *\n * @doc {heading: 'Operations', subheading: 'Convolution'}\n */\nfunction conv2d_<T extends Tensor3D|Tensor4D>(\n    x: T|TensorLike, filter: Tensor4D|TensorLike,\n    strides: [number, number]|number,\n    pad: 'valid'|'same'|number|conv_util.ExplicitPadding,\n    dataFormat: 'NHWC'|'NCHW' = 'NHWC',\n    dilations: [number, number]|number = [1, 1],\n    dimRoundingMode?: 'floor'|'round'|'ceil'): T {\n  const $x = convertToTensor(x, 'x', 'conv2d', 'float32');\n  const $filter = convertToTensor(filter, 'filter', 'conv2d', 'float32');\n\n  let x4D = $x as Tensor4D;\n  let reshapedTo4D = false;\n\n  if ($x.rank === 3) {\n    reshapedTo4D = true;\n    x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);\n  }\n\n  util.assert(\n      x4D.rank === 4,\n      () => `Error in conv2d: input must be rank 4, but got rank ${x4D.rank}.`);\n  util.assert(\n      $filter.rank === 4,\n      () => `Error in conv2d: filter must be rank 4, but got rank ` +\n          `${$filter.rank}.`);\n  conv_util.checkPadOnDimRoundingMode('conv2d', pad, dimRoundingMode);\n  const inDepth = dataFormat === 'NHWC' ? x4D.shape[3] : x4D.shape[1];\n  util.assert(\n      inDepth === $filter.shape[2],\n      () => `Error in conv2d: depth of input (${inDepth}) must match ` +\n          `input depth for filter ${$filter.shape[2]}.`);\n  util.assert(\n      conv_util.eitherStridesOrDilationsAreOne(strides, dilations),\n      () => 'Error in conv2D: Either strides or dilations must be 1. ' +\n          `Got strides ${strides} and dilations '${dilations}'`);\n\n  const inputs: Conv2DInputs = {x: x4D, filter: $filter};\n  const attrs:\n      Conv2DAttrs = {strides, pad, dataFormat, dilations, dimRoundingMode};\n\n  // tslint:disable-next-line: no-unnecessary-type-assertion\n  const res = ENGINE.runKernel(\n                  Conv2D, inputs as {} as NamedTensorMap,\n                  attrs as {} as NamedAttrMap) as T;\n\n  if (reshapedTo4D) {\n    return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]) as T;\n  }\n  return res;\n}\n\nexport const conv2d = op({conv2d_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {Tensor2D, Tensor3D, Tensor4D} from '../tensor';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\nimport * as util from '../util';\n\nimport {conv2d} from './conv2d';\nimport * as conv_util from './conv_util';\nimport {op} from './operation';\nimport {reshape} from './reshape';\n\n/**\n * Computes a 1D convolution over the input x.\n *\n * @param x The input tensor, of rank 3 or rank 2, of shape\n *     `[batch, width, inChannels]`. If rank 2, batch of 1 is assumed.\n * @param filter The filter, rank 3, of shape\n *     `[filterWidth, inDepth, outDepth]`.\n * @param stride The number of entries by which the filter is moved right at\n *     each step.\n * @param pad The type of padding algorithm.\n *    - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *    - `valid`: output will be smaller than input if filter is larger\n *       than 1x1.\n *   - For more info, see this guide:\n *     [https://www.tensorflow.org/api_docs/python/tf/nn/convolution](\n *          https://www.tensorflow.org/api_docs/python/tf/nn/convolution)\n * @param dataFormat An optional string from \"NWC\", \"NCW\". Defaults to \"NWC\",\n *     the data is stored in the order of [batch, in_width, in_channels]. Only\n *     \"NWC\" is currently supported.\n * @param dilation The dilation rate in which we sample input values in\n *     atrous convolution. Defaults to `1`. If it is greater than 1, then\n *     stride must be `1`.\n * @param dimRoundingMode A string from: 'ceil', 'round', 'floor'. If none is\n *     provided, it will default to truncate.\n *\n * @doc {heading: 'Operations', subheading: 'Convolution'}\n */\nfunction conv1d_<T extends Tensor2D|Tensor3D>(\n    x: T|TensorLike, filter: Tensor3D|TensorLike, stride: number,\n    pad: 'valid'|'same'|number|conv_util.ExplicitPadding,\n    dataFormat: 'NWC'|'NCW' = 'NWC', dilation = 1,\n    dimRoundingMode?: 'floor'|'round'|'ceil'): T {\n  const $x = convertToTensor(x, 'x', 'conv1d');\n  const $filter = convertToTensor(filter, 'filter', 'conv1d');\n\n  let x3D = $x as Tensor3D;\n  let reshapedTo3D = false;\n  if ($x.rank === 2) {\n    reshapedTo3D = true;\n    x3D = reshape($x, [1, $x.shape[0], $x.shape[1]]);\n  }\n\n  util.assert(\n      x3D.rank === 3,\n      () => `Error in conv1d: input must be rank 3, but got rank ${x3D.rank}.`);\n  util.assert(\n      $filter.rank === 3,\n      () => `Error in conv1d: filter must be rank 3, but got rank ` +\n          `${$filter.rank}.`);\n  conv_util.checkPadOnDimRoundingMode('conv1d', pad, dimRoundingMode);\n  util.assert(\n      x3D.shape[2] === $filter.shape[1],\n      () => `Error in conv1d: depth of input (${x3D.shape[2]}) must match ` +\n          `input depth for filter ${$filter.shape[1]}.`);\n  util.assert(\n      conv_util.eitherStridesOrDilationsAreOne(stride, dilation),\n      () => 'Error in conv1D: Either stride or dilation must be 1. ' +\n          `Got stride ${stride} and dilation '${dilation}'`);\n  util.assert(\n      dataFormat === 'NWC',\n      () => `Error in conv1d: got dataFormat of ${\n          dataFormat} but only NWC is currently supported.`);\n\n  const filter4D = reshape(\n      $filter, [1, $filter.shape[0], $filter.shape[1], $filter.shape[2]]);\n  const input4D = reshape(x3D, [x3D.shape[0], 1, x3D.shape[1], x3D.shape[2]]);\n  const strides: [number, number] = [1, stride];\n  const dilations: [number, number] = [1, dilation];\n\n  const conv2dDataFormat = 'NHWC';\n\n  const res = conv2d(\n      (input4D as Tensor4D), (filter4D as Tensor4D), strides, pad,\n      conv2dDataFormat, dilations, dimRoundingMode);\n\n  if (reshapedTo3D) {\n    return reshape(res, [res.shape[2], res.shape[3]]) as T;\n  }\n\n  return reshape(res, [res.shape[0], res.shape[2], res.shape[3]]) as T;\n}\n\nexport const conv1d = op({conv1d_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {ENGINE} from '../engine';\nimport {Conv2DBackpropInput, Conv2DBackpropInputAttrs, Conv2DBackpropInputInputs} from '../kernel_names';\nimport {NamedAttrMap} from '../kernel_registry';\nimport {Tensor3D, Tensor4D} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport * as util from '../util';\n\nimport * as conv_util from './conv_util';\nimport {op} from './operation';\nimport {reshape} from './reshape';\n\n/**\n * Computes the derivative of the input of a 2D convolution.\n *\n * @param xShape The shape of the input: [batch, height, width, inDepth].\n * If length of 3, batch of 1 is assumed.\n * @param dy The derivative of the output, of rank 4 or rank 3 of shape\n *   `[batch, outHeight, outWidth, outDepth]`. If rank 3, batch of 1 is\n * assumed.\n * @param filter The filter, rank 4, of shape\n *     `[filterHeight, filterWidth, inDepth, outDepth]`.\n * @param strides The strides of the convolution: `[strideHeight,\n * strideWidth]`.\n * @param pad The type of padding algorithm used:\n *    - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *    - `valid`: output will be smaller than input if filter is larger\n *       than 1x1.\n * @param dataFormat: An optional string from: \"NHWC\", \"NCHW\". Defaults to\n *     \"NHWC\". Specify the data format of the input and output data. With the\n *     default format \"NHWC\", the data is stored in the order of: [batch,\n *     height, width, channels].\n * @param dimRoundingMode A string from: 'ceil', 'round', 'floor'. If none is\n *     provided, it will default to truncate.\n */\nfunction conv2DBackpropInput_<T extends Tensor3D|Tensor4D>(\n    xShape: [number, number, number, number]|[number, number, number], dy: T,\n    filter: Tensor4D, strides: [number, number]|number,\n    pad: 'valid'|'same'|number|conv_util.ExplicitPadding,\n    dataFormat: 'NHWC'|'NCHW' = 'NHWC',\n    dimRoundingMode?: 'floor'|'round'|'ceil'): T {\n  util.assert(\n      xShape.length === dy.rank,\n      () => `Length of inShape ` +\n          `(${xShape.length}) and rank of dy (${dy.rank}) must match`);\n\n  let xShape4D = xShape as [number, number, number, number];\n  let dy4D = dy as Tensor4D;\n  let reshapedTo4D = false;\n  if (dy.rank === 3) {\n    reshapedTo4D = true;\n    dy4D = reshape(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2]]);\n    xShape4D = [1, xShape[0], xShape[1], xShape[2]];\n  }\n\n  util.assert(\n      xShape4D.length === 4,\n      () =>\n          `Error in conv2dDerInput: inShape must be length 4, but got length ` +\n          `${xShape4D.length}.`);\n  util.assert(\n      dy4D.rank === 4,\n      () => `Error in conv2dDerInput: dy must be rank 4, but got ` +\n          `rank ${dy4D.rank}`);\n  util.assert(\n      filter.rank === 4,\n      () => `Error in conv2dDerInput: filter must be rank 4, but got ` +\n          `rank ${filter.rank}`);\n  const inDepth = dataFormat === 'NHWC' ? xShape4D[3] : xShape4D[1];\n  const outDepth = dataFormat === 'NHWC' ? dy4D.shape[3] : dy4D.shape[1];\n  util.assert(\n      inDepth === filter.shape[2],\n      () => `Error in conv2dDerInput: depth of input (${inDepth}) must ` +\n          `match input depth for filter ${filter.shape[2]}.`);\n  util.assert(\n      outDepth === filter.shape[3],\n      () => `Error in conv2dDerInput: depth of output (${outDepth}) must ` +\n          `match output depth for filter ${filter.shape[3]}.`);\n  conv_util.checkPadOnDimRoundingMode('conv2dDerInput', pad, dimRoundingMode);\n  const inputs: Conv2DBackpropInputInputs = {dy: dy4D, filter};\n  const attrs: Conv2DBackpropInputAttrs =\n      {strides, pad, dataFormat, dimRoundingMode, inputShape: xShape4D};\n\n  // tslint:disable-next-line: no-unnecessary-type-assertion\n  const res = ENGINE.runKernel(\n                  Conv2DBackpropInput, inputs as {} as NamedTensorMap,\n                  attrs as {} as NamedAttrMap) as T;\n\n  if (reshapedTo4D) {\n    return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]) as T;\n  }\n  return res;\n}\n\nexport const conv2DBackpropInput = op({conv2DBackpropInput_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {Tensor3D, Tensor4D} from '../tensor';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {conv2DBackpropInput} from './conv2d_backprop_input';\nimport {ExplicitPadding} from './conv_util';\nimport {op} from './operation';\n\n/**\n * Computes the transposed 2D convolution of an image, also known as a\n * deconvolution.\n *\n * @param x The input image, of rank 4 or rank 3, of shape\n *   `[batch, height, width, inDepth]`. If rank 3, batch of 1 is assumed.\n * @param filter The filter, rank 4, of shape\n *     `[filterHeight, filterWidth, outDepth, inDepth]`.\n *     `inDepth` must match `inDepth` in `x`.\n * @param outputShape Output shape, of rank 4 or rank 3:\n *     `[batch, height, width, outDepth]`. If rank 3, batch of 1 is assumed.\n * @param strides The strides of the original convolution:\n *     `[strideHeight, strideWidth]`.\n * @param pad  The type of padding algorithm used in the non-transpose version\n *    of the op.\n * @param dimRoundingMode A string from: 'ceil', 'round', 'floor'. If none is\n *     provided, it will default to truncate.\n *\n * @doc {heading: 'Operations', subheading: 'Convolution'}\n */\nfunction conv2dTranspose_<T extends Tensor3D|Tensor4D>(\n    x: T|TensorLike, filter: Tensor4D|TensorLike,\n    outputShape: [number, number, number, number]|[number, number, number],\n    strides: [number, number]|number,\n    pad: 'valid'|'same'|number|ExplicitPadding,\n    dimRoundingMode?: 'floor'|'round'|'ceil'): T {\n  const $x = convertToTensor(x, 'x', 'conv2dTranspose');\n  const $filter = convertToTensor(filter, 'filter', 'conv2dTranspose');\n\n  return conv2DBackpropInput(\n      outputShape, $x, $filter, strides, pad, 'NHWC', dimRoundingMode);\n}\n\nexport const conv2dTranspose = op({conv2dTranspose_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {ENGINE} from '../engine';\nimport {Conv3D, Conv3DAttrs, Conv3DInputs} from '../kernel_names';\nimport {NamedAttrMap} from '../kernel_registry';\nimport {Tensor4D, Tensor5D} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\nimport * as util from '../util';\n\nimport {eitherStridesOrDilationsAreOne} from './conv_util';\nimport {op} from './operation';\nimport {reshape} from './reshape';\n\n/**\n * Computes a 3D convolution over the input x.\n *\n * @param x The input tensor, of rank 5 or rank 4, of shape\n *     `[batch, depth, height, width, channels]`. If rank 4,\n * batch of 1 is assumed.\n * @param filter The filter, rank 5, of shape\n *     `[filterDepth, filterHeight, filterWidth, inChannels, outChannels]`.\n *      inChannels must match between input and filter.\n * @param strides The strides of the convolution: `[strideDepth, strideHeight,\n * strideWidth]`.\n * @param pad The type of padding algorithm.\n *    - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *    - `valid`: output will be smaller than input if filter is larger\n *       than 1x1.\n *   - For more info, see this guide:\n *     [https://www.tensorflow.org/api_docs/python/tf/nn/convolution](\n *          https://www.tensorflow.org/api_docs/python/tf/nn/convolution)\n * @param dataFormat: An optional string from: \"NDHWC\", \"NCDHW\". Defaults to\n *     \"NDHWC\". Specify the data format of the input and output data. With the\n *     default format \"NDHWC\", the data is stored in the order of: [batch,\n *     depth, height, width, channels]. Only \"NDHWC\" is currently supported.\n * @param dilations The dilation rates: `[dilationDepth, dilationHeight,\n *     dilationWidth]` in which we sample input values across the height\n *     and width dimensions in atrous convolution. Defaults to `[1, 1, 1]`.\n *     If `dilations` is a single number, then\n *     `dilationDepth == dilationHeight == dilationWidth`. If it is greater\n *     than 1, then all values of `strides` must be 1.\n *\n * @doc {heading: 'Operations', subheading: 'Convolution'}\n */\nfunction conv3d_<T extends Tensor4D|Tensor5D>(\n    x: T|TensorLike, filter: Tensor5D|TensorLike,\n    strides: [number, number, number]|number, pad: 'valid'|'same',\n    dataFormat: 'NDHWC'|'NCDHW' = 'NDHWC',\n    dilations: [number, number, number]|number = [1, 1, 1]): T {\n  const $x = convertToTensor(x, 'x', 'conv3d');\n  const $filter = convertToTensor(filter, 'filter', 'conv3d');\n\n  let x5D = $x as Tensor5D;\n  let reshapedTo5D = false;\n\n  if ($x.rank === 4) {\n    reshapedTo5D = true;\n    x5D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2], $x.shape[3]]);\n  }\n  util.assert(\n      x5D.rank === 5,\n      () => `Error in conv3d: input must be rank 5, but got rank ${x5D.rank}.`);\n  util.assert(\n      $filter.rank === 5,\n      () => `Error in conv3d: filter must be rank 5, but got rank ` +\n          `${$filter.rank}.`);\n  util.assert(\n      x5D.shape[4] === $filter.shape[3],\n      () => `Error in conv3d: depth of input (${x5D.shape[4]}) must match ` +\n          `input depth for filter ${$filter.shape[3]}.`);\n  util.assert(\n      eitherStridesOrDilationsAreOne(strides, dilations),\n      () => 'Error in conv3D: Either strides or dilations must be 1. ' +\n          `Got strides ${strides} and dilations '${dilations}'`);\n  util.assert(\n      dataFormat === 'NDHWC',\n      () => `Error in conv3d: got dataFormat of ${\n          dataFormat} but only NDHWC is currently supported.`);\n\n  const inputs: Conv3DInputs = {x: x5D, filter: $filter};\n\n  const attrs: Conv3DAttrs = {strides, pad, dataFormat, dilations};\n\n  // tslint:disable-next-line: no-unnecessary-type-assertion\n  const res = ENGINE.runKernel(\n                  Conv3D, inputs as {} as NamedTensorMap,\n                  attrs as {} as NamedAttrMap) as T;\n\n  if (reshapedTo5D) {\n    return reshape(\n               res, [res.shape[1], res.shape[2], res.shape[3], res.shape[4]]) as\n        T;\n  }\n  return res;\n}\n\nexport const conv3d = op({conv3d_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {ENGINE} from '../engine';\nimport {Conv3DBackpropInputV2, Conv3DBackpropInputV2Attrs, Conv3DBackpropInputV2Inputs} from '../kernel_names';\nimport {NamedAttrMap} from '../kernel_registry';\nimport {Tensor4D, Tensor5D} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport * as util from '../util';\n\nimport {op} from './operation';\nimport {reshape} from './reshape';\n\n/**\n * Computes the derivative of the input of a 3D convolution.\n *\n * @param xShape The shape of the input: [batch, depth, height, width,\n * in_channels]. If length of 4, batch of 1 is assumed.\n * @param dy The derivative of the output, of rank 5 or rank 4 of shape\n *   `[batch, outDepth, outHeight, outWidth, in_channels]`.\n * If rank 4, batch of 1 is assumed.\n * @param filter The filter, rank 5, of shape\n *     `[filterDepth, filterHeight, filterWidth, inDepth, outDepth]`.\n * @param strides The strides of the convolution: `[strideDepth, strideHeight,\n * strideWidth]`.\n * @param pad The type of padding algorithm used:\n *    - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *    - `valid`: output will be smaller than input if filter is larger\n *       than 1x1.\n */\nfunction conv3DBackpropInput_<T extends Tensor4D|Tensor5D>(\n    xShape:\n        [number, number, number, number,\n         number]|[number, number, number, number],\n    dy: T, filter: Tensor5D, strides: [number, number, number]|number,\n    pad: 'valid'|'same'): T {\n  util.assert(\n      xShape.length === dy.rank,\n      () => `Length of inShape ` +\n          `(${xShape.length}) and rank of dy (${dy.rank}) must match`);\n\n  let xShape5D = xShape as [number, number, number, number, number];\n  let dy5D = dy as Tensor5D;\n  let reshapedTo5D = false;\n  if (dy.rank === 4) {\n    reshapedTo5D = true;\n    dy5D = reshape(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2], dy.shape[3]]);\n    xShape5D = [1, xShape[0], xShape[1], xShape[2], xShape[3]];\n  }\n\n  const inDepth = xShape5D[4];\n  const outDepth = dy5D.shape[4];\n  util.assert(\n      xShape5D.length === 5,\n      () =>\n          `Error in conv3dDerInput: inShape must be length 5, but got length ` +\n          `${xShape5D.length}.`);\n  util.assert(\n      dy5D.rank === 5,\n      () => `Error in conv3dDerInput: dy must be rank 5, but got ` +\n          `rank ${dy5D.rank}`);\n  util.assert(\n      filter.rank === 5,\n      () => `Error in conv3dDerInput: filter must be rank 5, but got ` +\n          `rank ${filter.rank}`);\n  util.assert(\n      inDepth === filter.shape[3],\n      () => `Error in conv3dDerInput: depth of input (${inDepth}) must ` +\n          `match input depth for filter ${filter.shape[3]}.`);\n  util.assert(\n      outDepth === filter.shape[4],\n      () => `Error in conv3dDerInput: depth of output (${outDepth}) must ` +\n          `match output depth for filter ${filter.shape[4]}.`);\n\n  const inputs: Conv3DBackpropInputV2Inputs = {dy: dy5D, filter};\n\n  const attrs:\n      Conv3DBackpropInputV2Attrs = {pad, strides, inputShape: xShape5D};\n\n  // tslint:disable-next-line: no-unnecessary-type-assertion\n  const res = ENGINE.runKernel(\n                  Conv3DBackpropInputV2, inputs as {} as NamedTensorMap,\n                  attrs as {} as NamedAttrMap) as T;\n\n  if (reshapedTo5D) {\n    return reshape(\n               res, [res.shape[1], res.shape[2], res.shape[3], res.shape[4]]) as\n        T;\n  }\n  return res;\n}\n\nexport const conv3DBackpropInput = op({conv3DBackpropInput_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {Tensor4D, Tensor5D} from '../tensor';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {conv3DBackpropInput} from './conv3d_backprop_input';\nimport {op} from './operation';\n\n/**\n * Computes the transposed 3D convolution of a volume, also known as a\n * deconvolution.\n *\n * @param x The input image, of rank 5 or rank 4, of shape\n *   `[batch, depth, height, width, inDepth]`. If rank 4, batch of 1 is assumed.\n * @param filter The filter, rank 4, of shape\n *     `[depth, filterHeight, filterWidth, outDepth, inDepth]`.\n *     `inDepth` must match `inDepth` in `x`.\n * @param outputShape Output shape, of rank 5 or rank 4:\n *     `[batch, depth, height, width, outDepth]`. If rank 3, batch of 1 is\n *    assumed.\n * @param strides The strides of the original convolution:\n *     `[strideDepth, strideHeight, strideWidth]`.\n * @param pad  The type of padding algorithm used in the non-transpose version\n *    of the op.\n *\n * @doc {heading: 'Operations', subheading: 'Convolution'}\n */\nfunction conv3dTranspose_<T extends Tensor4D|Tensor5D>(\n    x: T|TensorLike, filter: Tensor5D|TensorLike,\n    outputShape:\n        [number, number, number, number,\n         number]|[number, number, number, number],\n    strides: [number, number, number]|number, pad: 'valid'|'same'): T {\n  const $x = convertToTensor(x, 'x', 'conv3dTranspose');\n  const $filter = convertToTensor(filter, 'filter', 'conv3dTranspose');\n\n  return conv3DBackpropInput(outputShape, $x, $filter, strides, pad);\n}\n\nexport const conv3dTranspose = op({conv3dTranspose_});\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {Cos, CosInputs} from '../kernel_names';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {op} from './operation';\n\n/**\n * Computes cos of the input `tf.Tensor` element-wise: `cos(x)`\n *\n * ```js\n * const x = tf.tensor1d([0, Math.PI / 2, Math.PI * 3 / 4]);\n *\n * x.cos().print();  // or tf.cos(x)\n * ```\n * @param x The input tensor. Must be float32 type.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction cos_<T extends Tensor>(x: T|TensorLike): T {\n  const $x = convertToTensor(x, 'x', 'cos', 'float32');\n\n  const inputs: CosInputs = {x: $x};\n\n  return ENGINE.runKernel(Cos, inputs as {} as NamedTensorMap);\n}\nexport const cos = op({cos_});\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {Cosh, CoshInputs} from '../kernel_names';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {op} from './operation';\n\n/**\n * Computes hyperbolic cos of the input `tf.Tensor` element-wise: `cosh(x)`\n *\n * ```js\n * const x = tf.tensor1d([0, 1, -1, .7]);\n *\n * x.cosh().print();  // or tf.cosh(x)\n * ```\n * @param x The input tensor. Must be float32 type.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction cosh_<T extends Tensor>(x: T|TensorLike): T {\n  const $x = convertToTensor(x, 'x', 'cosh', 'float32');\n  const inputs: CoshInputs = {x: $x};\n\n  return ENGINE.runKernel(Cosh, inputs as {} as NamedTensorMap);\n}\nexport const cosh = op({cosh_});\n","/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the 'License');\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an 'AS IS' BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport { ENGINE } from '../engine';\nimport { Cumprod, CumprodAttrs, CumprodInputs } from '../kernel_names';\nimport { NamedAttrMap } from '../kernel_registry';\nimport { Tensor } from '../tensor';\nimport { NamedTensorMap } from '../tensor_types';\nimport { convertToTensor } from '../tensor_util_env';\nimport { TensorLike } from '../types';\n\nimport { op } from './operation';\n\n/**\n * Computes the cumulative product of a `tf.Tensor` along `axis`.\n *\n * ```js\n * const x = tf.tensor([1, 2, 3, 4]);\n * x.cumprod().print();\n * ```\n * ```js\n * const x = tf.tensor([[1, 2], [3, 4]]);\n * x.cumprod().print();\n * ```\n *\n * @param x The input tensor to cumulatively multiply.\n * @param axis The axis along which to multiply. Optional. Defaults to 0.\n * @param exclusive Whether to perform exclusive cumulative product. Optional.\n *     Defaults to false. If set to true then the product of each tensor entry\n *     does not include its own value, but only the values previous to it\n *     along the specified axis.\n * @param reverse Whether to multiply in the opposite direction. Optional.\n *     Defaults to false.\n *\n * @doc {heading: 'Operations', subheading: 'Scan'}\n */\nfunction cumprod_<T extends Tensor>(\n  x: Tensor | TensorLike,\n  axis = 0,\n  exclusive = false,\n  reverse = false\n): T {\n  const $x = convertToTensor(x, 'x', 'cumprod');\n\n  const inputs: CumprodInputs = { x: $x };\n  const attrs: CumprodAttrs = { axis, exclusive, reverse };\n\n  return ENGINE.runKernel(\n    Cumprod,\n    inputs as {} as NamedTensorMap,\n    attrs as {} as NamedAttrMap\n  );\n}\n\nexport const cumprod = op({ cumprod_ });\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {Cumsum, CumsumAttrs, CumsumInputs} from '../kernel_names';\nimport {NamedAttrMap} from '../kernel_registry';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {op} from './operation';\n\n/**\n * Computes the cumulative sum of a `tf.Tensor` along `axis`.\n *\n * ```js\n * const x = tf.tensor([1, 2, 3, 4]);\n * x.cumsum().print();\n * ```\n * ```js\n * const x = tf.tensor([[1, 2], [3, 4]]);\n * x.cumsum().print();\n * ```\n *\n * @param x The input tensor to be summed.\n * @param axis The axis along which to sum. Optional. Defaults to 0.\n * @param exclusive Whether to perform exclusive cumulative sum. Optional.\n *     Defaults to false. If set to true then the sum of each tensor entry\n *     does not include its own value, but only the values previous to it\n *     along the specified axis.\n * @param reverse Whether to sum in the opposite direction. Optional.\n *     Defaults to false.\n *\n * @doc {heading: 'Operations', subheading: 'Scan'}\n */\nfunction cumsum_<T extends Tensor>(\n    x: Tensor|TensorLike, axis = 0, exclusive = false, reverse = false): T {\n  const $x = convertToTensor(x, 'x', 'cumsum');\n\n  const inputs: CumsumInputs = {x: $x};\n  const attrs: CumsumAttrs = {axis, exclusive, reverse};\n\n  return ENGINE.runKernel(\n      Cumsum, inputs as {} as NamedTensorMap, attrs as {} as NamedAttrMap);\n}\n\nexport const cumsum = op({cumsum_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {DenseBincount, DenseBincountAttrs, DenseBincountInputs} from '../kernel_names';\nimport {NamedAttrMap} from '../kernel_registry';\nimport {Tensor1D, Tensor2D} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\nimport * as util from '../util';\n\nimport {op} from './operation';\n\n/**\n * Outputs a vector with length `size` and the same dtype as `weights`.\n *\n * If `weights` are empty, then index `i` stores the number of times the value\n * `i` is counted in `x`. If `weights` are non-empty, then index `i` stores the\n * sum of the value in `weights` at each index where the corresponding value in\n * `x` is `i`.\n *\n * Values in `x` outside of the range [0, size) are ignored.\n *\n * @param x The input int tensor, rank 1 or rank 2.\n * @param weights The weights tensor, must have the same shape as x, or a\n *     length-0 Tensor, in which case it acts as all weights equal to 1.\n * @param size Non-negative integer.\n * @param binaryOutput Optional. Whether the kernel should count the appearance\n *     or number of occurrences. Defaults to False.\n *\n * @doc {heading: 'Operations', subheading: 'Reduction'}\n */\nfunction denseBincount_<T extends Tensor1D|Tensor2D>(\n    x: T|TensorLike, weights: T|TensorLike, size: number,\n    binaryOutput = false): T {\n  const $x = convertToTensor(x, 'x', 'denseBincount');\n  const $weights = convertToTensor(weights, 'weights', 'denseBincount');\n\n  util.assert(\n      $x.dtype === 'int32',\n      () => `Error in denseBincount: input ` +\n          `dtype must be int32, but got ${$x.dtype}`);\n  util.assert(\n      $x.rank <= 2,\n      () => `Error in denseBincount: input must be at most rank 2, but got ` +\n          `rank ${$x.rank}.`);\n  util.assert(size >= 0, () => `size must be non-negative, but got ${size}.`);\n  util.assert(\n      $weights.size === $x.size || $weights.size === 0,\n      () =>\n          `Error in denseBincount: weights must have the same shape as x or ` +\n          `0-length, but got x shape: ${$x.shape}, weights shape: ` +\n          `${$weights.shape}.`);\n\n  const inputs: DenseBincountInputs = {x: $x, weights: $weights};\n  const attrs: DenseBincountAttrs = {size, binaryOutput};\n\n  return ENGINE.runKernel(\n      DenseBincount, inputs as {} as NamedTensorMap,\n      attrs as {} as NamedAttrMap);\n}\n\nexport const denseBincount = op({denseBincount_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {DepthToSpace, DepthToSpaceAttrs, DepthToSpaceInputs} from '../kernel_names';\nimport {NamedAttrMap} from '../kernel_registry';\nimport {Tensor4D} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike4D} from '../types';\nimport * as util from '../util';\n\nimport {op} from './operation';\n\n/**\n * Rearranges data from depth into blocks of spatial data. More specifically,\n * this op outputs a copy of the input tensor where values from the `depth`\n * dimension are moved in spatial blocks to the `height` and `width` dimensions.\n * The attr `blockSize` indicates the input block size and how the data is\n * moved.\n *\n *  - Chunks of data of size `blockSize * blockSize` from depth are rearranged\n * into non-overlapping blocks of size `blockSize x blockSize`\n *\n *  - The width the output tensor is `inputWidth * blockSize`, whereas the\n * height is `inputHeight * blockSize`\n *\n *  - The Y, X coordinates within each block of the output image are determined\n * by the high order component of the input channel index\n *\n *  - The depth of the input tensor must be divisible by `blockSize *\n * blockSize`\n *\n * The `dataFormat` attr specifies the layout of the input and output tensors\n * with the following options: \"NHWC\": [ `batch, height, width, channels` ]\n * \"NCHW\": [ `batch, channels, height, width` ]\n *\n * ```js\n * const x = tf.tensor4d([1, 2, 3, 4], [1, 1, 1, 4]);\n * const blockSize = 2;\n * const dataFormat = \"NHWC\";\n *\n * tf.depthToSpace(x, blockSize, dataFormat).print();\n * ```\n *\n * @param x The input tensor of rank 4\n * @param blockSIze  An `int` that is `>= 2`. The size of the spatial block\n * @param dataFormat An optional string from: \"NHWC\", \"NCHW\". Defaults to \"NHWC\"\n *\n * @doc {heading: 'Tensors', subheading: 'Transformations'}\n */\nfunction depthToSpace_(\n    x: Tensor4D|TensorLike4D, blockSize: number,\n    dataFormat: 'NHWC'|'NCHW' = 'NHWC'): Tensor4D {\n  const $x = convertToTensor(x, 'x', 'depthToSpace', 'float32') as Tensor4D;\n\n  const inputHeight = (dataFormat === 'NHWC') ? $x.shape[1] : $x.shape[2];\n  const inputWidth = (dataFormat === 'NHWC') ? $x.shape[2] : $x.shape[3];\n  const inputDepth = (dataFormat === 'NHWC') ? $x.shape[3] : $x.shape[1];\n\n  util.assert(\n      blockSize > 1,\n      () => `blockSize should be > 1 for depthToSpace, but was: ${blockSize}`);\n\n  util.assert(\n      inputHeight * blockSize >= 0,\n      () => `Negative dimension size caused by overflow when multiplying\n    ${inputHeight} and ${blockSize}  for depthToSpace with input shape\n    ${$x.shape}`);\n\n  util.assert(\n      inputWidth * blockSize >= 0,\n      () => `Negative dimension size caused by overflow when multiplying\n    ${inputWidth} and ${blockSize} for depthToSpace with input shape\n        ${$x.shape}`);\n\n  util.assert(\n      (inputDepth % (blockSize * blockSize) === 0),\n      () => `Dimension size must be evenly divisible by ${\n          blockSize * blockSize} but is ${\n          inputDepth} for depthToSpace with input shape ${$x.shape}`);\n\n  const inputs: DepthToSpaceInputs = {x: $x};\n  const attrs: DepthToSpaceAttrs = {blockSize, dataFormat};\n\n  return ENGINE.runKernel(\n      DepthToSpace, inputs as {} as NamedTensorMap,\n      attrs as {} as NamedAttrMap);\n}\n\nexport const depthToSpace = op({depthToSpace_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {ENGINE} from '../engine';\nimport {DepthwiseConv2dNative, DepthwiseConv2dNativeAttrs, DepthwiseConv2dNativeInputs} from '../kernel_names';\nimport {NamedAttrMap} from '../kernel_registry';\nimport {Tensor3D, Tensor4D} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\nimport * as util from '../util';\n\nimport * as conv_util from './conv_util';\nimport {op} from './operation';\nimport {reshape} from './reshape';\n\n/**\n * Depthwise 2D convolution.\n *\n * Given a 4D `input` array and a `filter` array of shape\n * `[filterHeight, filterWidth, inChannels, channelMultiplier]` containing\n * `inChannels` convolutional filters of depth 1, this op applies a\n * different filter to each input channel (expanding from 1 channel to\n * `channelMultiplier` channels for each), then concatenates the results\n * together. The output has `inChannels * channelMultiplier` channels.\n *\n * See\n * [https://www.tensorflow.org/api_docs/python/tf/nn/depthwise_conv2d](\n *     https://www.tensorflow.org/api_docs/python/tf/nn/depthwise_conv2d)\n * for more details.\n *\n * @param x The input tensor, of rank 4 or rank 3, of shape\n *     `[batch, height, width, inChannels]`. If rank 3, batch of 1 is\n * assumed.\n * @param filter The filter tensor, rank 4, of shape\n *     `[filterHeight, filterWidth, inChannels, channelMultiplier]`.\n * @param strides The strides of the convolution: `[strideHeight,\n * strideWidth]`. If strides is a single number, then `strideHeight ==\n * strideWidth`.\n * @param pad The type of padding algorithm.\n *   - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *   - `valid`: output will be smaller than input if filter is larger\n *       than 1x1.\n *   - For more info, see this guide:\n *     [https://www.tensorflow.org/api_docs/python/tf/nn/convolution](\n *          https://www.tensorflow.org/api_docs/python/tf/nn/convolution)\n * @param dilations The dilation rates: `[dilationHeight, dilationWidth]`\n *     in which we sample input values across the height and width dimensions\n *     in atrous convolution. Defaults to `[1, 1]`. If `rate` is a single\n *     number, then `dilationHeight == dilationWidth`. If it is greater than\n *     1, then all values of `strides` must be 1.\n * @param dataFormat: An optional string from: \"NHWC\", \"NCHW\". Defaults to\n *     \"NHWC\". Specify the data format of the input and output data. With the\n *     default format \"NHWC\", the data is stored in the order of: [batch,\n *     height, width, channels]. Only \"NHWC\" is currently supported.\n * @param dimRoundingMode A string from: 'ceil', 'round', 'floor'. If none is\n *     provided, it will default to truncate.\n *\n * @doc {heading: 'Operations', subheading: 'Convolution'}\n */\nfunction depthwiseConv2d_<T extends Tensor3D|Tensor4D>(\n    x: T|TensorLike, filter: Tensor4D|TensorLike,\n    strides: [number, number]|number,\n    pad: 'valid'|'same'|number|conv_util.ExplicitPadding,\n    dataFormat: 'NHWC'|'NCHW' = 'NHWC',\n    dilations: [number, number]|number = [1, 1],\n    dimRoundingMode?: 'floor'|'round'|'ceil'): T {\n  const $x = convertToTensor(x, 'x', 'depthwiseConv2d', 'float32');\n  const $filter =\n      convertToTensor(filter, 'filter', 'depthwiseConv2d', 'float32');\n\n  let x4D = $x as Tensor4D;\n  let reshapedTo4D = false;\n  if ($x.rank === 3) {\n    reshapedTo4D = true;\n    x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);\n  }\n  util.assert(\n      x4D.rank === 4,\n      () => `Error in depthwiseConv2d: input must be rank 4, but got ` +\n          `rank ${x4D.rank}.`);\n  util.assert(\n      $filter.rank === 4,\n      () => `Error in depthwiseConv2d: filter must be rank 4, but got rank ` +\n          `${$filter.rank}.`);\n  const inChannels = dataFormat === 'NHWC' ? x4D.shape[3] : x4D.shape[1];\n  util.assert(\n      inChannels === $filter.shape[2],\n      () => `Error in depthwiseConv2d: number of input channels ` +\n          `(${inChannels}) must match the inChannels dimension in ` +\n          `filter ${$filter.shape[2]}.`);\n  conv_util.checkPadOnDimRoundingMode('depthwiseConv2d', pad, dimRoundingMode);\n  const inputs: DepthwiseConv2dNativeInputs = {x: x4D, filter: $filter};\n  const attrs: DepthwiseConv2dNativeAttrs =\n      {strides, pad, dataFormat, dilations, dimRoundingMode};\n\n  // tslint:disable-next-line: no-unnecessary-type-assertion\n  const res = ENGINE.runKernel(\n                  DepthwiseConv2dNative, inputs as {} as NamedTensorMap,\n                  attrs as {} as NamedAttrMap) as T;\n\n  if (reshapedTo4D) {\n    return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]) as T;\n  }\n  return res;\n}\n\nexport const depthwiseConv2d = op({depthwiseConv2d_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {Diag, DiagInputs} from '../kernel_names';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\n\nimport {op} from './operation';\n\n/**\n * Returns a diagonal tensor with given diagonal values.\n *\n * Given a diagonal, this operation returns a tensor with the diagonal and\n * everything else padded with zeros.\n *\n * Assume the input has dimensions `[D1,..., Dk]`, then the output is a tensor\n * of rank 2k with dimensions `[D1,..., Dk, D1,..., Dk]`\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3, 4]);\n *\n * tf.diag(x).print()\n * ```\n * ```js\n * const x = tf.tensor2d([1, 2, 3, 4, 5, 6, 6, 8], [4, 2])\n *\n * tf.diag(x).print()\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nfunction diag_(x: Tensor): Tensor {\n  const $x = convertToTensor(x, 'x', 'diag');\n\n  const inputs: DiagInputs = {x: $x};\n\n  return ENGINE.runKernel(Diag, inputs as {} as NamedTensorMap);\n}\n\nexport const diag = op({diag_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {Dilation2D, Dilation2DAttrs, Dilation2DInputs} from '../kernel_names';\nimport {NamedAttrMap} from '../kernel_registry';\nimport {Tensor3D, Tensor4D} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\nimport * as util from '../util';\n\nimport {op} from './operation';\nimport {reshape} from './reshape';\n\n/**\n * Computes the grayscale dilation over the input `x`.\n *\n * @param x The input tensor, rank 3 or rank 4 of shape\n *     `[batch, height, width, inChannels]`. If rank 3, batch of 1 is assumed.\n * @param filter The filter tensor, rank 3, of shape\n *     `[filterHeight, filterWidth, depth]`.\n * @param strides The strides of the sliding window for each dimension of the\n *     input tensor: `[strideHeight, strideWidth]`.\n *     If `strides` is a single number,\n *     then `strideHeight == strideWidth`.\n * @param pad The type of padding algorithm.\n *    - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *    - `valid`: output will be smaller than input if filter is larger\n *       than 1*1x1.\n *    - For more info, see this guide:\n *     [https://www.tensorflow.org/api_docs/python/tf/nn/convolution](\n *          https://www.tensorflow.org/api_docs/python/tf/nn/convolution)\n * @param dataFormat Specify the data format of the input and output data.\n *      Defaults to 'NHWC'. Only 'NHWC' is currently supported. With the\n *      default format \"NHWC\", the data is stored in the order of: [batch,\n *      height, width, channels].\n * @param dilations The dilation rates: `[dilationHeight, dilationWidth]`\n *     in which we sample input values across the height and width dimensions\n *     for atrous morphological dilation. Defaults to `[1, 1]`. If `dilations`\n *     is a single number, then `dilationHeight == dilationWidth`. If it is\n *     greater than 1, then all values of `strides` must be 1.\n *\n * @doc {heading: 'Operations', subheading: 'Convolution'}\n */\nfunction dilation2d_<T extends Tensor3D|Tensor4D>(\n    x: T|TensorLike, filter: Tensor3D|TensorLike,\n    strides: [number, number]|number, pad: 'valid'|'same',\n    dilations: [number, number]|number = [1, 1],\n    dataFormat: 'NHWC' = 'NHWC'): T {\n  const $x = convertToTensor(x, 'x', 'dilation2d');\n  const $filter = convertToTensor(filter, 'filter', 'dilation2d');\n\n  util.assert(\n      $x.rank === 3 || $x.rank === 4,\n      () => `Error in dilation2d: input must be rank 3 or 4, but got rank ` +\n          `${$x.rank}.`);\n  util.assert(\n      $filter.rank === 3,\n      () => `Error in dilation2d: filter must be rank 3, but got rank ` +\n          `${$filter.rank}.`);\n  util.assert(\n      dataFormat === 'NHWC',\n      () => `Error in dilation2d: Only NHWC is currently supported, ` +\n          `but got dataFormat of ${dataFormat}`);\n\n  let x4D = $x as Tensor4D;\n  let reshapedTo4D = false;\n\n  if ($x.rank === 3) {\n    x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);\n    reshapedTo4D = true;\n  }\n\n  const inputs: Dilation2DInputs = {x: x4D, filter: $filter};\n  const attrs: Dilation2DAttrs = {strides, pad, dilations};\n\n  // tslint:disable-next-line: no-unnecessary-type-assertion\n  const res = ENGINE.runKernel(\n                  Dilation2D, inputs as {} as NamedTensorMap,\n                  attrs as {} as NamedAttrMap) as T;\n\n  if (reshapedTo4D) {\n    return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]) as T;\n  }\n\n  return res;\n}\n\nexport const dilation2d = op({dilation2d_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {ENGINE} from '../engine';\nimport {Equal, EqualInputs} from '../kernel_names';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {makeTypesMatch} from '../tensor_util';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {assertAndGetBroadcastShape} from './broadcast_util';\nimport {op} from './operation';\n\n/**\n * Returns the truth value of (a == b) element-wise. Supports broadcasting.\n *\n * ```js\n * const a = tf.tensor1d([1, 2, 3]);\n * const b = tf.tensor1d([2, 2, 2]);\n *\n * a.equal(b).print();\n * ```\n *\n * @param a The first input tensor.\n * @param b The second input tensor. Must have the same dtype as `a`.\n *\n * @doc {heading: 'Operations', subheading: 'Logical'}\n */\nfunction equal_<T extends Tensor>(\n    a: Tensor|TensorLike, b: Tensor|TensorLike): T {\n  let $a = convertToTensor(a, 'a', 'equal', 'string_or_numeric');\n  let $b = convertToTensor(b, 'b', 'equal', 'string_or_numeric');\n  [$a, $b] = makeTypesMatch($a, $b);\n\n  assertAndGetBroadcastShape($a.shape, $b.shape);\n\n  const inputs: EqualInputs = {a: $a, b: $b};\n\n  return ENGINE.runKernel(Equal, inputs as {} as NamedTensorMap);\n}\n\nexport const equal = op({equal_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {Select, SelectInputs} from '../kernel_names';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {broadcastTo} from './broadcast_to';\nimport {assertAndGetBroadcastShape} from './broadcast_util';\nimport {op} from './operation';\n\n/**\n * Returns the elements, either `a` or `b` depending on the `condition`.\n *\n * If the condition is true, select from `a`, otherwise select from `b`.\n *\n * ```js\n * const cond = tf.tensor1d([false, false, true], 'bool');\n * const a = tf.tensor1d([1 , 2, 3]);\n * const b = tf.tensor1d([-1, -2, -3]);\n *\n * a.where(cond, b).print();\n * ```\n *\n * @param condition The input condition. Must be of dtype bool.\n * @param a If `condition` is rank 1, `a` may have a higher rank but\n *     its first dimension must match the size of `condition`.\n * @param b A tensor with the same dtype as `a` and with shape that is\n *     compatible with `a`.\n * @return A tensor with same dtype as `a` and `b`, and shape that is\n *     broadcastable from `a` and `b`.\n *\n * @doc {heading: 'Operations', subheading: 'Logical'}\n */\nfunction where_<T extends Tensor>(\n    condition: Tensor|TensorLike, a: T|TensorLike, b: T|TensorLike): T {\n  const $a = convertToTensor(a, 'a', 'where');\n  const $b = convertToTensor(b, 'b', 'where');\n  const $condition = convertToTensor(condition, 'condition', 'where', 'bool');\n  // TODO: move this logic to forward function when the broadcastTo op is\n  // implemented in WASM.\n  // Find the broadcastable shape for $condition, $a, and $b.\n  const broadcastShape = assertAndGetBroadcastShape(\n      assertAndGetBroadcastShape($condition.shape, $a.shape), $b.shape);\n  const $broadcastedCondition = broadcastTo($condition, broadcastShape);\n  const $broadcastedA = broadcastTo($a, broadcastShape);\n  const $broadcastedB = broadcastTo($b, broadcastShape);\n\n  const inputs: SelectInputs = {\n    condition: $broadcastedCondition,\n    t: $broadcastedA,\n    e: $broadcastedB\n  };\n  return ENGINE.runKernel(Select, inputs as {} as NamedTensorMap);\n}\n\nexport const where = op({where_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor} from '../tensor';\nimport {makeTypesMatch} from '../tensor_util';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {div} from './div';\nimport {equal} from './equal';\nimport {op} from './operation';\nimport {where} from './where';\nimport {zerosLike} from './zeros_like';\n\n/**\n * Divides two `tf.Tensor`s element-wise, A / B. Supports broadcasting. Return 0\n * if denominator is 0.\n *\n *\n * ```js\n * const a = tf.tensor1d([1, 4, 9, 16]);\n * const b = tf.tensor1d([1, 2, 3, 4]);\n * const c = tf.tensor1d([0, 0, 0, 0]);\n *\n * a.divNoNan(b).print();  // or tf.divNoNan(a, b)\n * a.divNoNan(c).print();  // or tf.divNoNan(a, c)\n * ```\n *\n * ```js\n * // Broadcast div a with b.\n * const a = tf.tensor1d([2, 4, 6, 8]);\n * const b = tf.scalar(2);\n * const c = tf.scalar(0);\n *\n * a.divNoNan(b).print();  // or tf.divNoNan(a, b)\n * a.divNoNan(c).print();  // or tf.divNoNan(a, c)\n * ```\n *\n * @param a The first tensor as the numerator.\n * @param b The second tensor as the denominator. Must have the same dtype as\n * `a`.\n *\n * @doc {heading: 'Operations', subheading: 'Arithmetic'}\n */\nfunction divNoNan_<T extends Tensor>(\n    a: Tensor|TensorLike, b: Tensor|TensorLike): T {\n  // TODO: Make this into its own kernel.\n  let $a = convertToTensor(a, 'a', 'div');\n  let $b = convertToTensor(b, 'b', 'div');\n  [$a, $b] = makeTypesMatch($a, $b);\n\n  const divResult = div($a, $b);\n  const zeros = zerosLike(divResult);\n  const bEqualsZero = equal($b, zeros);\n  return where(bEqualsZero, zeros, divResult) as T;\n}\n\nexport const divNoNan = op({divNoNan_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor,} from '../tensor';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\nimport * as util from '../util';\n\nimport {matMul} from './mat_mul';\nimport {op} from './operation';\nimport {reshape} from './reshape';\n\n/**\n * Computes the dot product of two matrices and/or vectors, `t1` and `t2`.\n *\n * ```js\n * const a = tf.tensor1d([1, 2]);\n * const b = tf.tensor2d([[1, 2], [3, 4]]);\n * const c = tf.tensor2d([[1, 2, 3], [4, 5, 6]]);\n *\n * a.dot(b).print();  // or tf.dot(a, b)\n * b.dot(a).print();\n * b.dot(c).print();\n * ```\n * @param t1 The first tensor in the dot operation.\n * @param t2 The second tensor in the dot operation.\n *\n * @doc {heading: 'Operations', subheading: 'Matrices'}\n */\nfunction dot_(t1: Tensor|TensorLike, t2: Tensor|TensorLike): Tensor {\n  const $t1 = convertToTensor(t1, 't1', 'dot');\n  const $t2 = convertToTensor(t2, 't2', 'dot');\n\n  util.assert(\n      ($t1.rank === 1 || $t1.rank === 2) && ($t2.rank === 1 || $t2.rank === 2),\n      () => `Error in dot: inputs must all be rank 1 or 2, but got ranks ` +\n          `${$t1.rank} and ${$t2.rank}.`);\n\n  const t1Inner = ($t1.rank === 1 ? $t1.size : $t1.shape[1]);\n  const t2Inner = ($t2.rank === 1 ? $t2.size : $t2.shape[0]);\n\n  util.assert(\n      t1Inner === t2Inner,\n      () => `Error in dot: inner dimensions of inputs must match, but got ` +\n          `${t1Inner} and ${t2Inner}.`);\n\n  if ($t1.rank === 1 && $t2.rank === 1) {\n    const t12D = reshape($t1, [1, -1]);\n    const t22D = reshape($t2, [-1, 1]);\n    const t1t2 = matMul(t12D, t22D);\n    return reshape(t1t2, []);\n  } else if ($t1.rank === 1 && $t2.rank === 2) {\n    const t12D = reshape($t1, [1, -1]);\n    const t22D = reshape($t2, [$t2.shape[0], $t2.shape[1]]);\n    const t1t2 = matMul(t12D, t22D);\n    return reshape(t1t2, [t1t2.size]);\n  } else if ($t1.rank === 2 && $t2.rank === 1) {\n    const t22D = reshape($t2, [-1, 1]);\n    const t1t2 = matMul($t1, t22D);\n    return reshape(t1t2, [t1t2.size]);\n  } else {\n    const t22D = reshape($t2, [$t2.shape[0], $t2.shape[1]]);\n    const t1t2 = matMul($t1, t22D);\n    return t1t2;\n  }\n}\n\nexport const dot = op({dot_});\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {Einsum, EinsumAttrs} from '../kernel_names';\nimport {NamedAttrMap} from '../kernel_registry';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\n\nimport {op} from './operation';\n\n/**\n * Tensor contraction over specified indices and outer product.\n *\n * `einsum` allows defining Tensors by defining their element-wise computation.\n * This computation is based on\n * [Einstein summation](https://en.wikipedia.org/wiki/Einstein_notation).\n *\n * Some special cases include:\n *\n * Matrix multiplication:\n * ```js\n * const x = tf.tensor2d([[1, 2, 3], [4, 5, 6]]);\n * const y = tf.tensor2d([[0, 1], [2, 3], [4, 5]]);\n * x.print();\n * y.print();\n * tf.einsum('ij,jk->ik', x, y).print();\n * ```\n *\n * Dot product:\n * ```js\n * const x = tf.tensor1d([1, 2, 3]);\n * const y = tf.tensor1d([0, 1, 2]);\n * x.print();\n * y.print();\n * tf.einsum('i,i->', x, y).print();\n * ```\n *\n * Batch dot product:\n * ```js\n * const x = tf.tensor2d([[1, 2, 3], [4, 5, 6]]);\n * const y = tf.tensor2d([[0, 1, 2], [3, 4, 5]]);\n * x.print();\n * y.print();\n * tf.einsum('bi,bi->b', x, y).print();\n * ```\n *\n * Outer prouduct:\n * ```js\n * const x = tf.tensor1d([1, 3, 5]);\n * const y = tf.tensor1d([2, 4, 6]);\n * x.print();\n * y.print();\n * tf.einsum('i,j->ij', x, y).print();\n * ```\n *\n * Matrix transpose:\n * ```js\n * const x = tf.tensor2d([[1, 2], [3, 4]]);\n * x.print();\n * tf.einsum('ij->ji', x).print();\n * ```\n *\n * Batch matrix transpose:\n * ```js\n * const x = tf.tensor3d([[[1, 2], [3, 4]], [[-1, -2], [-3, -4]]]);\n * x.print();\n * tf.einsum('bij->bji', x).print();\n * ```\n *\n * Limitations:\n *\n * This implementation of einsum has the following limitations:\n *\n * - Does not support >2 input tensors.\n * - Does not support duplicate axes for any given input tensor. E.g., equation\n *   'ii->' is not supported.\n * - The `...` notation is not supported.\n *\n * @param equation a string describing the contraction, in the same format as\n * [numpy.einsum](https://numpy.org/doc/stable/reference/generated/numpy.einsum.html).\n * @param tensors the input(s) to contract (each one a Tensor), whose shapes\n *     should be consistent with equation.\n * @returns The output tensor.\n *\n * @doc {heading: 'Tensors', subheading: 'Matrices'}\n */\nexport function einsum_(equation: string, ...tensors: Tensor[]): Tensor {\n  const $tensors =\n      tensors.map((t, i) => convertToTensor(t, `tensors${i}`, 'einsum'));\n  const attrs: EinsumAttrs = {equation};\n  return ENGINE.runKernel(\n      Einsum, $tensors as {} as NamedTensorMap, attrs as {} as NamedAttrMap);\n}\n\nexport const einsum = op({einsum_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {Elu, EluInputs} from '../kernel_names';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {op} from './operation';\n\n/**\n * Computes exponential linear element-wise: `x > 0 ? x : (e ^ x) - 1`.\n *\n * ```js\n * const x = tf.tensor1d([-1, 1, -3, 2]);\n *\n * x.elu().print();  // or tf.elu(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction elu_<T extends Tensor>(x: T|TensorLike): T {\n  const $x = convertToTensor(x, 'x', 'elu', 'float32');\n\n  const inputs: EluInputs = {x: $x};\n\n  return ENGINE.runKernel(Elu, inputs as {} as NamedTensorMap);\n}\n\nexport const elu = op({elu_});\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {Erf, ErfInputs} from '../kernel_names';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\nimport * as util from '../util';\n\nimport {cast} from './cast';\nimport {op} from './operation';\n\n/**\n * Computes Gauss error function of the input `tf.Tensor` element-wise:\n * `erf(x)`\n *\n * ```js\n * const x = tf.tensor1d([0, .1, -.1, .7]);\n *\n * x.erf().print(); // or tf.erf(x);\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction erf_<T extends Tensor>(x: T|TensorLike): T {\n  let $x = convertToTensor(x, 'x', 'erf');\n  util.assert(\n      $x.dtype === 'int32' || $x.dtype === 'float32',\n      () => 'Input dtype must be `int32` or `float32`.');\n\n  if ($x.dtype === 'int32') {\n    $x = cast($x, 'float32');\n  }\n\n  const inputs: ErfInputs = {x: $x};\n  return ENGINE.runKernel(Erf, inputs as {} as NamedTensorMap);\n}\nexport const erf = op({erf_});\n","/**\n * @license\n * Copyright 2017 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as util from '../util';\n\n/**\n * Returns true if the axis specifies the inner most dimensions of the\n * array.\n */\nexport function axesAreInnerMostDims(axes: number[], rank: number): boolean {\n  for (let i = 0; i < axes.length; ++i) {\n    if (axes[axes.length - i - 1] !== rank - 1 - i) {\n      return false;\n    }\n  }\n  return true;\n}\n\nexport function combineLocations(\n    outputLoc: number[], reduceLoc: number[], axes: number[]): number[] {\n  const rank = outputLoc.length + reduceLoc.length;\n  const loc = [];\n  let outIdx = 0;\n  let reduceIdx = 0;\n    for (let dim = 0; dim < rank; dim++) {\n    if (axes.indexOf(dim) === -1) {\n      loc.push(outputLoc[outIdx++]);\n    } else {\n      loc.push(reduceLoc[reduceIdx++]);\n    }\n  }\n  return loc;\n}\n\nexport function computeOutAndReduceShapes(\n    aShape: number[], axes: number[]): [number[], number[]] {\n  const outShape = [];\n  const rank = aShape.length;\n  for (let dim = 0; dim < rank; dim++) {\n    if (axes.indexOf(dim) === -1) {\n      outShape.push(aShape[dim]);\n    }\n  }\n  const reduceShape = axes.map(dim => aShape[dim]);\n  return [outShape, reduceShape];\n}\n\nexport function expandShapeToKeepDim(\n    shape: number[], axes: number[]): number[] {\n  const reduceSubShape = axes.map(x => 1);\n  return combineLocations(shape, reduceSubShape, axes);\n}\n\nexport function assertAxesAreInnerMostDims(\n    msg: string, axes: number[], rank: number): void {\n  util.assert(\n      axesAreInnerMostDims(axes, rank),\n      () => `${msg} supports only inner-most axes for now. ` +\n          `Got axes ${axes} and rank-${rank} input.`);\n}\n\n/**\n * Returns the axes permutation to be used with `tf.transpose`, if such\n * permutation is necessary. Otherwise it returns null. This method is used by\n * operations that operate only on inner-most axes.\n */\nexport function getAxesPermutation(axes: number[], rank: number): number[]|\n    null {\n  if (axesAreInnerMostDims(axes, rank)) {\n    return null;\n  }\n  const result: number[] = [];\n  for (let i = 0; i < rank; ++i) {\n    if (axes.indexOf(i) === -1) {\n      result.push(i);\n    }\n  }\n  axes.forEach(axis => result.push(axis));\n  return result;\n}\n\n/** Returns the axes permutation that undoes the original permutation. */\nexport function getUndoAxesPermutation(axes: number[]): number[] {\n  return axes.map((axis, i) => [i, axis])\n      .sort((a, b) => a[1] - b[1])\n      .map(x => x[0]);\n}\n\nexport function getInnerMostAxes(numAxes: number, rank: number): number[] {\n  const res: number[] = [];\n  for (let i = rank - numAxes; i < rank; ++i) {\n    res.push(i);\n  }\n  return res;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {Max, MaxAttrs, MaxInputs} from '../kernel_names';\nimport {NamedAttrMap} from '../kernel_registry';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {op} from './operation';\n\n/**\n * Computes the maximum of elements across dimensions of a `tf.Tensor`.\n *\n * Reduces the input along the dimensions given in `axes`. Unless `keepDims`\n * is true, the rank of the `tf.Tensor` is reduced by 1 for each entry in\n * `axes`. If `keepDims` is true, the reduced dimensions are retained with\n * length 1. If `axes` has no entries, all dimensions are reduced, and a\n * `tf.Tensor` with a single element is returned.\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3]);\n *\n * x.max().print();  // or tf.max(x)\n * ```\n *\n * ```js\n * const x = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n *\n * const axis = 1;\n * x.max(axis).print();  // or tf.max(x, axis)\n * ```\n *\n * @param x The input tensor.\n * @param axis The dimension(s) to reduce. By default it reduces\n *     all dimensions.\n * @param keepDims If true, retains reduced dimensions with size 1.\n *\n * @doc {heading: 'Operations', subheading: 'Reduction'}\n */\nfunction max_<T extends Tensor>(\n    x: Tensor|TensorLike, axis: number|number[] = null, keepDims = false): T {\n  const $x = convertToTensor(x, 'x', 'max');\n\n  const inputs: MaxInputs = {x: $x};\n  const attrs: MaxAttrs = {reductionIndices: axis, keepDims};\n\n  return ENGINE.runKernel(\n      Max, inputs as {} as NamedTensorMap, attrs as {} as NamedAttrMap);\n}\n\nexport const max = op({max_});\n","/**\n * @license\n * Copyright 2020 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {ENGINE} from '../engine';\nimport {Min, MinAttrs, MinInputs} from '../kernel_names';\nimport {NamedAttrMap} from '../kernel_registry';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {op} from './operation';\n\n/**\n * Computes the minimum value from the input.\n *\n * Reduces the input along the dimensions given in `axes`. Unless `keepDims`\n * is true, the rank of the array is reduced by 1 for each entry in `axes`.\n * If `keepDims` is true, the reduced dimensions are retained with length 1.\n * If `axes` has no entries, all dimensions are reduced, and an array with a\n * single element is returned.\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3]);\n *\n * x.min().print();  // or tf.min(x)\n * ```\n *\n * ```js\n * const x = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n *\n * const axis = 1;\n * x.min(axis).print();  // or tf.min(x, axis)\n * ```\n *\n * @param x The input Tensor.\n * @param axis The dimension(s) to reduce. By default it reduces\n *     all dimensions.\n * @param keepDims If true, retains reduced dimensions with size 1.\n *\n * @doc {heading: 'Operations', subheading: 'Reduction'}\n */\nfunction min_<T extends Tensor>(\n    x: Tensor|TensorLike, axis: number|number[] = null, keepDims = false): T {\n  const $x = convertToTensor(x, 'x', 'min');\n\n  const inputs: MinInputs = {x: $x};\n  const attrs: MinAttrs = {axis, keepDims};\n\n  // tslint:disable-next-line: no-unnecessary-type-assertion\n  return ENGINE.runKernel(\n             Min, inputs as {} as NamedTensorMap,\n             attrs as {} as NamedAttrMap) as T;\n}\n\nexport const min = op({min_});\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {ENGINE} from '../engine';\nimport {Sum, SumAttrs, SumInputs} from '../kernel_names';\nimport {NamedAttrMap} from '../kernel_registry';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {cast} from './cast';\nimport {op} from './operation';\n\n/**\n * Computes the sum of elements across dimensions of a `tf.Tensor`.\n *\n * Reduces the input along the dimensions given in `axes`. Unless `keepDims`\n * is true, the rank of the `tf.Tensor` is reduced by 1 for each entry in\n * `axes`. If `keepDims` is true, the reduced dimensions are retained with\n * length 1. If axes has no entries, all dimensions are reduced, and a\n * `tf.Tensor` with a single element is returned.\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3]);\n *\n * x.sum().print();  // or tf.sum(x)\n * ```\n *\n * ```js\n * const x = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n *\n * const axis = 1;\n * x.sum(axis).print();  // or tf.sum(x, axis)\n * ```\n *\n * @param x The input tensor to compute the sum over. If the dtype is `bool`\n *   it will be converted to `int32` and the output dtype will be `int32`.\n * @param axis The dimension(s) to reduce. By default it reduces\n *     all dimensions.\n * @param keepDims If true, retains reduced dimensions with size 1.\n *\n * @doc {heading: 'Operations', subheading: 'Reduction'}\n */\nfunction sum_<T extends Tensor>(\n    x: Tensor|TensorLike, axis: number|number[] = null, keepDims = false): T {\n  let $x = convertToTensor(x, 'x', 'sum');\n  if ($x.dtype === 'bool') {\n    $x = cast($x, 'int32');\n  }\n\n  const inputs: SumInputs = {x: $x};\n  const attrs: SumAttrs = {axis, keepDims};\n\n  return ENGINE.runKernel(\n      Sum, inputs as {} as NamedTensorMap, attrs as {} as NamedAttrMap);\n}\n\nexport const sum = op({sum_});\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor} from '../tensor';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\nimport {parseAxisParam} from '../util';\n\nimport {abs} from './abs';\nimport * as axis_util from './axis_util';\nimport {max} from './max';\nimport {min} from './min';\nimport {op} from './operation';\nimport {pow} from './pow';\nimport {reshape} from './reshape';\nimport {scalar} from './scalar';\nimport {sqrt} from './sqrt';\nimport {square} from './square';\nimport {sum} from './sum';\n\n/**\n * Computes the norm of scalar, vectors, and matrices.\n * This function can compute several different vector norms (the 1-norm, the\n * Euclidean or 2-norm, the inf-norm, and in general the p-norm for p > 0)\n * and matrix norms (Frobenius, 1-norm, and inf-norm).\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3, 4]);\n *\n * x.norm().print();  // or tf.norm(x)\n * ```\n *\n * @param x The input array.\n * @param ord Optional. Order of the norm. Supported norm types are\n * following:\n *\n *  | ord        | norm for matrices         | norm for vectors\n *  |------------|---------------------------|---------------------\n *  |'euclidean' |Frobenius norm             |2-norm\n *  |'fro'       |Frobenius norm\t           |\n *  |Infinity    |max(sum(abs(x), axis=1))   |max(abs(x))\n *  |-Infinity   |min(sum(abs(x), axis=1))   |min(abs(x))\n *  |1           |max(sum(abs(x), axis=0))   |sum(abs(x))\n *  |2           |                           |sum(abs(x)^2)^(1/2)\n *\n * @param axis Optional. If axis is null (the default), the input is\n * considered a vector and a single vector norm is computed over the entire\n * set of values in the Tensor, i.e. norm(x, ord) is equivalent\n * to norm(x.reshape([-1]), ord). If axis is an integer, the input\n * is considered a batch of vectors, and axis determines the axis in x\n * over which to compute vector norms. If axis is a 2-tuple of integer it is\n * considered a batch of matrices and axis determines the axes in NDArray\n * over which to compute a matrix norm.\n * @param keepDims Optional. If true, the norm has the same dimensionality\n * as the input.\n *\n * @doc {heading: 'Operations', subheading: 'Matrices'}\n */\nfunction norm_(\n    x: Tensor|TensorLike, ord: number|'euclidean'|'fro' = 'euclidean',\n    axis: number|number[] = null, keepDims = false): Tensor {\n  x = convertToTensor(x, 'x', 'norm');\n\n  const norm = normImpl(x, ord, axis);\n  let keepDimsShape = norm.shape;\n  if (keepDims) {\n    const axes = parseAxisParam(axis, x.shape);\n    keepDimsShape = axis_util.expandShapeToKeepDim(norm.shape, axes);\n  }\n  return reshape(norm, keepDimsShape);\n}\n\nfunction normImpl(\n    x: Tensor, p: number|string, axis: number|number[] = null): Tensor {\n  if (x.rank === 0) {\n    return abs(x);\n  }\n\n  // consider vector when no axis is specified\n  if (x.rank !== 1 && axis === null) {\n    return normImpl(reshape(x, [-1]), p, axis);\n  }\n\n  // vector\n  if (x.rank === 1 || typeof axis === 'number' ||\n      Array.isArray(axis) && axis.length === 1) {\n    if (p === 1) {\n      return sum(abs(x), axis);\n    }\n    if (p === Infinity) {\n      return max(abs(x), axis);\n    }\n    if (p === -Infinity) {\n      return min(abs(x), axis);\n    }\n    if (p === 'euclidean' || p === 2) {\n      // norm(x, 2) = sum(abs(xi) ^ 2) ^ 1/2\n      return sqrt(sum(pow(abs(x), scalar(2, 'int32')), axis));\n    }\n\n    throw new Error(`Error in norm: invalid ord value: ${p}`);\n  }\n\n  // matrix (assumption axis[0] < axis[1])\n  if (Array.isArray(axis) && axis.length === 2) {\n    if (p === 1) {\n      return max(sum(abs(x), axis[0]), axis[1] - 1);\n    }\n    if (p === Infinity) {\n      return max(sum(abs(x), axis[1]), axis[0]);\n    }\n    if (p === -Infinity) {\n      return min(sum(abs(x), axis[1]), axis[0]);\n    }\n    if (p === 'fro' || p === 'euclidean') {\n      // norm(x) = sqrt(sum(pow(x, 2)))\n      return sqrt(sum(square(x), axis));\n    }\n\n    throw new Error(`Error in norm: invalid ord value: ${p}`);\n  }\n\n  throw new Error(`Error in norm: invalid axis: ${axis}`);\n}\n\nexport const norm = op({norm_});\n","/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor} from '../tensor';\nimport {TensorLike} from '../types';\n\nimport {norm} from './norm';\nimport {op} from './operation';\n\n/**\n * Computes the Euclidean norm of scalar, vectors, and matrices.\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3, 4]);\n *\n * x.euclideanNorm().print();  // or tf.euclideanNorm(x)\n * ```\n *\n * @param x The input array.\n * @param axis Optional. If axis is null (the default), the input is\n * considered a vector and a single vector norm is computed over the entire\n * set of values in the Tensor, i.e. euclideanNorm(x) is equivalent\n * to euclideanNorm(x.reshape([-1])). If axis is an integer, the input\n * is considered a batch of vectors, and axis determines the axis in x\n * over which to compute vector norms. If axis is a 2-tuple of integer it is\n * considered a batch of matrices and axis determines the axes in NDArray\n * over which to compute a matrix norm.\n * @param keepDims Optional. If true, the norm has the same dimensionality\n * as the input.\n *\n * @doc {heading: 'Operations', subheading: 'Matrices'}\n */\nfunction euclideanNorm_(\n    x: Tensor|TensorLike, axis: number|number[] = null,\n    keepDims = false): Tensor {\n  return norm(x, 'euclidean', axis, keepDims);\n}\n\nexport const euclideanNorm = op({euclideanNorm_});\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {Exp, ExpInputs} from '../kernel_names';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {op} from './operation';\n\n/**\n * Computes exponential of the input `tf.Tensor` element-wise. `e ^ x`\n *\n * ```js\n * const x = tf.tensor1d([1, 2, -3]);\n *\n * x.exp().print();  // or tf.exp(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction exp_<T extends Tensor>(x: T|TensorLike): T {\n  const $x = convertToTensor(x, 'x', 'exp');\n\n  const inputs: ExpInputs = {x: $x};\n  return ENGINE.runKernel(Exp, inputs as {} as NamedTensorMap);\n}\nexport const exp = op({exp_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {ExpandDims, ExpandDimsAttrs, ExpandDimsInputs} from '../kernel_names';\nimport {NamedAttrMap} from '../kernel_registry';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\nimport * as util from '../util';\n\nimport {op} from './operation';\n\n/**\n * Returns a `tf.Tensor` that has expanded rank, by inserting a dimension\n * into the tensor's shape.\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3, 4]);\n * const axis = 1;\n * x.expandDims(axis).print();\n * ```\n *\n * @param x The input tensor whose dimensions are to be expanded.\n * @param axis The dimension index at which to insert shape of `1`. Defaults\n *     to 0 (the first dimension).\n *\n * @doc {heading: 'Tensors', subheading: 'Transformations'}\n */\nfunction expandDims_<T extends Tensor>(x: Tensor|TensorLike, axis = 0): T {\n  const $x = convertToTensor(x, 'x', 'expandDims', 'string_or_numeric');\n\n  util.assert(axis <= $x.rank, () => 'Axis must be <= rank of the tensor');\n\n  const inputs: ExpandDimsInputs = {input: $x};\n  const attrs: ExpandDimsAttrs = {dim: axis};\n\n  return ENGINE.runKernel(\n      ExpandDims, inputs as {} as NamedTensorMap, attrs as {} as NamedAttrMap);\n}\n\nexport const expandDims = op({expandDims_});\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {Expm1, Expm1Inputs} from '../kernel_names';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {op} from './operation';\n\n/**\n * Computes exponential of the input `tf.Tensor` minus one element-wise.\n * `e ^ x - 1`\n *\n * ```js\n * const x = tf.tensor1d([1, 2, -3]);\n *\n * x.expm1().print();  // or tf.expm1(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction expm1_<T extends Tensor>(x: T|TensorLike): T {\n  const $x = convertToTensor(x, 'x', 'expm1');\n\n  const inputs: Expm1Inputs = {x: $x};\n  return ENGINE.runKernel(Expm1, inputs as {} as NamedTensorMap);\n}\nexport const expm1 = op({expm1_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {Tile, TileAttrs, TileInputs} from '../kernel_names';\nimport {NamedAttrMap} from '../kernel_registry';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\nimport * as util from '../util';\n\nimport {op} from './operation';\n\n/**\n * Construct a tensor by repeating it the number of times given by reps.\n *\n * This operation creates a new tensor by replicating `input` `reps`\n * times. The output tensor's `i`th dimension has `input.shape[i] *\n * reps[i]` elements, and the values of `input` are replicated\n * `reps[i]` times along the `i`th dimension. For example, tiling\n * `[a, b, c, d]` by `[2]` produces `[a, b, c, d, a, b, c, d]`.\n *\n * ```js\n * const a = tf.tensor1d([1, 2]);\n *\n * a.tile([2]).print();    // or a.tile([2])\n * ```\n *\n * ```js\n * const a = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n *\n * a.tile([1, 2]).print();  // or a.tile([1, 2])\n * ```\n * @param x The tensor to tile.\n * @param reps Determines the number of replications per dimension.\n *\n * @doc {heading: 'Tensors', subheading: 'Slicing and Joining'}\n */\nfunction tile_<T extends Tensor>(x: T|TensorLike, reps: number[]): T {\n  const $x = convertToTensor(x, 'x', 'tile', 'string_or_numeric');\n  util.assert(\n      $x.rank === reps.length,\n      () => `Error in transpose: rank of input ${$x.rank} ` +\n          `must match length of reps ${reps}.`);\n\n  const inputs: TileInputs = {x: $x};\n  const attrs: TileAttrs = {reps};\n\n  return ENGINE.runKernel(\n      Tile, inputs as unknown as NamedTensorMap,\n      attrs as unknown as NamedAttrMap);\n}\n\nexport const tile = op({tile_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor2D} from '../tensor';\nimport {DataType} from '../types';\n\nimport {buffer} from './buffer';\nimport {expandDims} from './expand_dims';\nimport {op} from './operation';\nimport {reshape} from './reshape';\nimport {tile} from './tile';\n\n/**\n * Create an identity matrix.\n *\n * @param numRows Number of rows.\n * @param numColumns Number of columns. Defaults to `numRows`.\n * @param batchShape If provided, will add the batch shape to the beginning\n *   of the shape of the returned `tf.Tensor` by repeating the identity\n *   matrix.\n * @param dtype Data type.\n * @returns Identity matrix of the specified size and data type, possibly\n *   with batch repetition if `batchShape` is specified.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nfunction eye_(\n    numRows: number, numColumns?: number,\n    batchShape?:\n        [\n          number\n        ]|[number,\n           number]|[number, number, number]|[number, number, number, number],\n    dtype: DataType = 'float32'): Tensor2D {\n  if (numColumns == null) {\n    numColumns = numRows;\n  }\n  const buff = buffer([numRows, numColumns], dtype);\n  const n = numRows <= numColumns ? numRows : numColumns;\n  for (let i = 0; i < n; ++i) {\n    buff.set(1, i, i);\n  }\n  const out: Tensor2D = reshape(buff.toTensor(), [numRows, numColumns]);\n  if (batchShape == null) {\n    return out;\n  } else {\n    if (batchShape.length === 1) {\n      return tile(expandDims(out, 0), [batchShape[0], 1, 1]) as Tensor2D;\n    } else if (batchShape.length === 2) {\n      // tslint:disable-next-line:no-unnecessary-type-assertion\n      return tile(\n                 expandDims(expandDims(out, 0), 0),\n                 [batchShape[0], batchShape[1], 1, 1]) as Tensor2D;\n    } else if (batchShape.length === 3) {\n      // tslint:disable-next-line:no-unnecessary-type-assertion\n      return tile(expandDims(expandDims(expandDims(out, 0), 0), 0), [\n               batchShape[0], batchShape[1], batchShape[2], 1, 1\n             ]) as Tensor2D;\n    } else {\n      throw new Error(\n          `eye() currently supports only 1D and 2D ` +\n          // tslint:disable-next-line:no-any\n          `batchShapes, but received ${(batchShape as any).length}D.`);\n    }\n  }\n}\n\nexport const eye = op({eye_});\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {ENGINE} from '../engine';\nimport {Floor, FloorInputs} from '../kernel_names';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {op} from './operation';\n\n/**\n * Computes floor of input `tf.Tensor` element-wise: `floor(x)`.\n *\n * ```js\n * const x = tf.tensor1d([.6, 1.1, -3.3]);\n *\n * x.floor().print();  // or tf.floor(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction floor_<T extends Tensor>(x: T|TensorLike): T {\n  const $x = convertToTensor(x, 'x', 'floor', 'float32');\n\n  const inputs: FloorInputs = {x: $x};\n  return ENGINE.runKernel(Floor, inputs as {} as NamedTensorMap);\n}\nexport const floor = op({floor_});\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {GatherV2, GatherV2Attrs, GatherV2Inputs} from '../kernel_names';\nimport {NamedAttrMap} from '../kernel_registry';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {op} from './operation';\n\n/**\n * Gather slices from tensor `x`'s axis `axis` according to `indices`.\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3, 4]);\n * const indices = tf.tensor1d([1, 3, 3], 'int32');\n *\n * x.gather(indices).print();\n * ```\n *\n * ```js\n * const x = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n * const indices = tf.tensor1d([1, 1, 0], 'int32');\n *\n * x.gather(indices).print();\n * ```\n * @param x The input tensor whose slices are to be gathered.\n * @param indices The indices of the values to extract.\n * @param axis The axis over which to select values. Defaults to 0.\n * @param batchDims Optional. The number of batch dimensions. It must be less\n *     than or equal to rank(indices). Defaults to 0.\n *     The output tensor will have shape of\n *     `x.shape[:axis] + indices.shape[batchDims:] + x.shape[axis + 1:]`\n *\n * @doc {heading: 'Tensors', subheading: 'Slicing and Joining'}\n */\nfunction gather_<T extends Tensor>(\n    x: T|TensorLike, indices: Tensor|TensorLike, axis = 0, batchDims = 0): T {\n  const $x = convertToTensor(x, 'x', 'gather');\n  const $indices = convertToTensor(indices, 'indices', 'gather', 'int32');\n\n  const inputs: GatherV2Inputs = {x: $x, indices: $indices};\n  const attrs: GatherV2Attrs = {axis, batchDims};\n\n  return ENGINE.runKernel(\n      GatherV2, inputs as {} as NamedTensorMap, attrs as {} as NamedAttrMap);\n}\n\nexport const gather = op({gather_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {ENGINE} from '../engine';\nimport {Greater, GreaterInputs} from '../kernel_names';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {makeTypesMatch} from '../tensor_util';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {assertAndGetBroadcastShape} from './broadcast_util';\nimport {op} from './operation';\n\n/**\n * Returns the truth value of (a > b) element-wise. Supports broadcasting.\n *\n * ```js\n * const a = tf.tensor1d([1, 2, 3]);\n * const b = tf.tensor1d([2, 2, 2]);\n *\n * a.greater(b).print();\n * ```\n *\n * @param a The first input tensor.\n * @param b The second input tensor. Must have the same dtype as `a`.\n *\n * @doc {heading: 'Operations', subheading: 'Logical'}\n */\nfunction greater_<T extends Tensor>(\n    a: Tensor|TensorLike, b: Tensor|TensorLike): T {\n  let $a = convertToTensor(a, 'a', 'greater', 'string_or_numeric');\n  let $b = convertToTensor(b, 'b', 'greater', 'string_or_numeric');\n  [$a, $b] = makeTypesMatch($a, $b);\n\n  assertAndGetBroadcastShape($a.shape, $b.shape);\n\n  const inputs: GreaterInputs = {a: $a, b: $b};\n\n  return ENGINE.runKernel(Greater, inputs as {} as NamedTensorMap);\n}\n\nexport const greater = op({greater_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {ENGINE} from '../engine';\nimport {GreaterEqual, GreaterEqualInputs} from '../kernel_names';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {makeTypesMatch} from '../tensor_util';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {assertAndGetBroadcastShape} from './broadcast_util';\nimport {op} from './operation';\n\n/**\n * Returns the truth value of (a >= b) element-wise. Supports broadcasting.\n *\n * ```js\n * const a = tf.tensor1d([1, 2, 3]);\n * const b = tf.tensor1d([2, 2, 2]);\n *\n * a.greaterEqual(b).print();\n * ```\n *\n * @param a The first input tensor.\n * @param b The second input tensor. Must have the same dtype as `a`.\n *\n * @doc {heading: 'Operations', subheading: 'Logical'}\n */\nfunction greaterEqual_<T extends Tensor>(\n    a: Tensor|TensorLike, b: Tensor|TensorLike): T {\n  let $a = convertToTensor(a, 'a', 'greaterEqual', 'string_or_numeric');\n  let $b = convertToTensor(b, 'b', 'greaterEqual', 'string_or_numeric');\n  [$a, $b] = makeTypesMatch($a, $b);\n\n  assertAndGetBroadcastShape($a.shape, $b.shape);\n\n  const inputs: GreaterEqualInputs = {a: $a, b: $b};\n\n  return ENGINE.runKernel(GreaterEqual, inputs as {} as NamedTensorMap);\n}\n\nexport const greaterEqual = op({greaterEqual_});\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {IsFinite, IsFiniteInputs} from '../kernel_names';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {op} from './operation';\n\n/**\n * Returns which elements of x are finite.\n *\n * ```js\n * const x = tf.tensor1d([NaN, Infinity, -Infinity, 0, 1]);\n *\n * x.isFinite().print();  // or tf.isNaN(x)\n * ```\n * @param x The input Tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction isFinite_<T extends Tensor>(x: T|TensorLike): T {\n  const $x = convertToTensor(x, 'x', 'isFinite');\n\n  const inputs: IsFiniteInputs = {x: $x};\n\n  return ENGINE.runKernel(IsFinite, inputs as {} as NamedTensorMap);\n}\nexport const isFinite = op({isFinite_});\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {IsInf, IsInfInputs} from '../kernel_names';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {op} from './operation';\n\n/**\n * Returns which elements of x are Infinity or -Infinity.\n *\n * ```js\n * const x = tf.tensor1d([NaN, Infinity, -Infinity, 0, 1]);\n *\n * x.isInf().print();  // or tf.isNaN(x)\n * ```\n * @param x The input Tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction isInf_<T extends Tensor>(x: T|TensorLike): T {\n  const $x = convertToTensor(x, 'x', 'isInf');\n\n  const inputs: IsInfInputs = {x: $x};\n\n  return ENGINE.runKernel(IsInf, inputs as {} as NamedTensorMap);\n}\nexport const isInf = op({isInf_});\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {IsNan, IsNanInputs} from '../kernel_names';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {op} from './operation';\n\n/**\n * Returns which elements of x are NaN.\n *\n * ```js\n * const x = tf.tensor1d([NaN, Infinity, -Infinity, 0, 1]);\n *\n * x.isNaN().print();  // or tf.isNaN(x)\n * ```\n * @param x The input Tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction isNaN_<T extends Tensor>(x: T|TensorLike): T {\n  const $x = convertToTensor(x, 'x', 'isNaN');\n  const inputs: IsNanInputs = {x: $x};\n\n  return ENGINE.runKernel(IsNan, inputs as {} as NamedTensorMap);\n}\nexport const isNaN = op({isNaN_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {LeakyRelu, LeakyReluAttrs, LeakyReluInputs} from '../kernel_names';\nimport {NamedAttrMap} from '../kernel_registry';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {op} from './operation';\n\n/**\n * Computes leaky rectified linear element-wise.\n *\n * See\n * [http://web.stanford.edu/~awni/papers/relu_hybrid_icml2013_final.pdf](\n *     http://web.stanford.edu/~awni/papers/relu_hybrid_icml2013_final.pdf)\n *\n * ```js\n * const x = tf.tensor1d([-1, 2, -3, 4]);\n *\n * x.leakyRelu(0.1).print();  // or tf.leakyRelu(x, 0.1)\n * ```\n * @param x The input tensor.\n * @param alpha The scaling factor for negative values, defaults to 0.2.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction leakyRelu_<T extends Tensor>(x: T|TensorLike, alpha = 0.2): T {\n  const $x = convertToTensor(x, 'x', 'leakyRelu');\n\n  const inputs: LeakyReluInputs = {x: $x};\n  const attrs: LeakyReluAttrs = {alpha};\n\n  return ENGINE.runKernel(\n      LeakyRelu, inputs as {} as NamedTensorMap, attrs as {} as NamedAttrMap);\n}\n\nexport const leakyRelu = op({leakyRelu_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {ENGINE} from '../engine';\nimport {Less, LessInputs} from '../kernel_names';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {makeTypesMatch} from '../tensor_util';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {assertAndGetBroadcastShape} from './broadcast_util';\nimport {op} from './operation';\n\n/**\n * Returns the truth value of (a < b) element-wise. Supports broadcasting.\n *\n * ```js\n * const a = tf.tensor1d([1, 2, 3]);\n * const b = tf.tensor1d([2, 2, 2]);\n *\n * a.less(b).print();\n * ```\n * @param a The first input tensor.\n * @param b The second input tensor. Must have the same dtype as `a`.\n *\n * @doc {heading: 'Operations', subheading: 'Logical'}\n */\nfunction less_<T extends Tensor>(\n    a: Tensor|TensorLike, b: Tensor|TensorLike): T {\n  let $a = convertToTensor(a, 'a', 'less', 'string_or_numeric');\n  let $b = convertToTensor(b, 'b', 'less', 'string_or_numeric');\n  [$a, $b] = makeTypesMatch($a, $b);\n\n  assertAndGetBroadcastShape($a.shape, $b.shape);\n\n  const inputs: LessInputs = {a: $a, b: $b};\n\n  return ENGINE.runKernel(Less, inputs as {} as NamedTensorMap);\n}\n\nexport const less = op({less_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {ENGINE} from '../engine';\nimport {LessEqual, LessEqualInputs} from '../kernel_names';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {makeTypesMatch} from '../tensor_util';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {assertAndGetBroadcastShape} from './broadcast_util';\nimport {op} from './operation';\n\n/**\n * Returns the truth value of (a <= b) element-wise. Supports broadcasting.\n *\n * ```js\n * const a = tf.tensor1d([1, 2, 3]);\n * const b = tf.tensor1d([2, 2, 2]);\n *\n * a.lessEqual(b).print();\n * ```\n *\n * @param a The first input tensor.\n * @param b The second input tensor. Must have the same dtype as `a`.\n *\n * @doc {heading: 'Operations', subheading: 'Logical'}\n */\nfunction lessEqual_<T extends Tensor>(\n    a: Tensor|TensorLike, b: Tensor|TensorLike): T {\n  let $a = convertToTensor(a, 'a', 'lessEqual', 'string_or_numeric');\n  let $b = convertToTensor(b, 'b', 'lessEqual', 'string_or_numeric');\n  [$a, $b] = makeTypesMatch($a, $b);\n\n  assertAndGetBroadcastShape($a.shape, $b.shape);\n\n  const inputs: LessEqualInputs = {a: $a, b: $b};\n\n  return ENGINE.runKernel(LessEqual, inputs as {} as NamedTensorMap);\n}\n\nexport const lessEqual = op({lessEqual_});\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {LinSpace, LinSpaceAttrs} from '../kernel_names';\nimport {NamedAttrMap} from '../kernel_registry';\nimport {Tensor1D} from '../tensor';\n\n/**\n * Return an evenly spaced sequence of numbers over the given interval.\n *\n * ```js\n * tf.linspace(0, 9, 10).print();\n * ```\n * @param start The start value of the sequence.\n * @param stop The end value of the sequence.\n * @param num The number of values to generate.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nexport function linspace(start: number, stop: number, num: number): Tensor1D {\n  if (num <= 0) {\n    throw new Error('The number of values should be positive.');\n  }\n\n  const attrs: LinSpaceAttrs = {start, stop, num};\n  return ENGINE.runKernel(LinSpace, {}, attrs as {} as NamedAttrMap);\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {LRN, LRNAttrs, LRNInputs} from '../kernel_names';\nimport {NamedAttrMap} from '../kernel_registry';\nimport {Tensor3D, Tensor4D} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\nimport * as util from '../util';\n\nimport {op} from './operation';\nimport {reshape} from './reshape';\n\n/**\n * Normalizes the activation of a local neighborhood across or within\n * channels.\n *\n * @param x The input tensor. The 4-D input tensor is treated as a 3-D array\n *     of 1D vectors (along the last dimension), and each vector is\n *     normalized independently.\n * @param depthRadius The number of adjacent channels in the 1D normalization\n *     window.\n * @param bias A constant bias term for the basis.\n * @param alpha A scale factor, usually positive.\n * @param beta An exponent.\n *\n * @doc {heading: 'Operations', subheading: 'Normalization'}\n */\nfunction localResponseNormalization_<T extends Tensor3D|Tensor4D>(\n    x: T|TensorLike, depthRadius = 5, bias = 1, alpha = 1, beta = 0.5): T {\n  const $x = convertToTensor(x, 'x', 'localResponseNormalization');\n  util.assert(\n      $x.rank === 4 || $x.rank === 3,\n      () => `Error in localResponseNormalization: x must be rank 3 or 4 but got\n               rank ${$x.rank}.`);\n  util.assert(\n      util.isInt(depthRadius),\n      () => `Error in localResponseNormalization: depthRadius must be an ` +\n          `integer but got depthRadius ${depthRadius}.`);\n\n  let x4D = $x as Tensor4D;\n  let reshapedTo4D = false;\n  if ($x.rank === 3) {\n    reshapedTo4D = true;\n    x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);\n  }\n\n  const inputs: LRNInputs = {x: x4D};\n\n  const attrs: LRNAttrs = {depthRadius, bias, alpha, beta};\n\n  // tslint:disable-next-line: no-unnecessary-type-assertion\n  const res = ENGINE.runKernel(\n                  LRN, inputs as {} as NamedTensorMap,\n                  attrs as {} as NamedAttrMap) as T;\n\n  if (reshapedTo4D) {\n    return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]) as T;\n  } else {\n    return res;\n  }\n}\n\nexport const localResponseNormalization = op({localResponseNormalization_});\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {Log, LogInputs} from '../kernel_names';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {op} from './operation';\n\n/**\n * Computes natural logarithm of the input `tf.Tensor` element-wise: `ln(x)`\n *\n * ```js\n * const x = tf.tensor1d([1, 2, Math.E]);\n *\n * x.log().print();  // or tf.log(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction log_<T extends Tensor>(x: T|TensorLike): T {\n  const $x = convertToTensor(x, 'x', 'log', 'float32');\n\n  const inputs: LogInputs = {x: $x};\n  return ENGINE.runKernel(Log, inputs as {} as NamedTensorMap);\n}\nexport const log = op({log_});\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {Log1p, Log1pInputs} from '../kernel_names';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {op} from './operation';\n\n/**\n * Computes natural logarithm of the input `tf.Tensor` plus one\n * element-wise: `ln(1 + x)`\n *\n * ```js\n * const x = tf.tensor1d([1, 2, Math.E - 1]);\n *\n * x.log1p().print();  // or tf.log1p(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction log1p_<T extends Tensor>(x: T|TensorLike): T {\n  const $x = convertToTensor(x, 'x', 'log1p');\n\n  const inputs: Log1pInputs = {x: $x};\n  return ENGINE.runKernel(Log1p, inputs as {} as NamedTensorMap);\n}\nexport const log1p = op({log1p_});\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {Softplus, SoftplusInputs} from '../kernel_names';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {op} from './operation';\n\n/**\n * Computes softplus of the input `tf.Tensor` element-wise: `log(exp(x) + 1)`\n *\n * ```js\n * const x = tf.tensor1d([0, 1, -1, .7]);\n *\n * x.softplus().print();  // or tf.softplus(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction softplus_<T extends Tensor>(x: T|TensorLike): T {\n  const $x = convertToTensor(x, 'x', 'softplus');\n\n  const inputs: SoftplusInputs = {x: $x};\n  return ENGINE.runKernel(Softplus, inputs as {} as NamedTensorMap);\n}\nexport const softplus = op({softplus_});\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {customGrad} from '../gradients';\nimport {Tensor} from '../tensor';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {mul} from './mul';\nimport {neg} from './neg';\nimport {op} from './operation';\nimport {sigmoid} from './sigmoid';\nimport {softplus} from './softplus';\n\n/**\n * Computes log sigmoid of the input `tf.Tensor` element-wise:\n * `logSigmoid(x)`. For numerical stability, we use `-tf.softplus(-x)`.\n *\n * ```js\n * const x = tf.tensor1d([0, 1, -1, .7]);\n *\n * x.logSigmoid().print();  // or tf.logSigmoid(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction logSigmoid_<T extends Tensor>(x: T|TensorLike): T {\n  const $x = convertToTensor(x, 'x', 'logSigmoid');\n\n  // Use a custom gradient to maintain previous implementation.\n  // There is no LogSigmoid kernel in TF so we can't use engine.runKernel\n  // directly\n  const customOp = customGrad((x: Tensor) => {\n    // TODO(yassogba) we can remove the chained softplus call here only\n    // after backends have modualrized softplus at which point we can call\n    // engine runKernel(..., Sotfplus, ...) directly.\n    const value = neg(softplus(neg(x)));\n\n    const gradFunc = (dy: T) => {\n      const derX = mul(dy, sigmoid(neg(x)));\n      return derX;\n    };\n    return {value, gradFunc};\n  });\n\n  return customOp($x) as T;\n}\nexport const logSigmoid = op({logSigmoid_});\n","/**\n * @license\n * Copyright 2020 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {customGrad} from '../gradients';\n\nimport {Tensor} from '../tensor';\nimport {GradSaveFunc} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {cast} from './cast';\nimport {exp} from './exp';\nimport {log} from './log';\nimport {max} from './max';\nimport {mul} from './mul';\nimport {op} from './operation';\nimport {sub} from './sub';\nimport {sum} from './sum';\n\n/**\n * Computes the log softmax.\n *\n * ```js\n * const a = tf.tensor1d([1, 2, 3]);\n *\n * a.logSoftmax().print();  // or tf.logSoftmax(a)\n * ```\n *\n * ```js\n * const a = tf.tensor2d([2, 4, 6, 1, 2, 3], [2, 3]);\n *\n * a.logSoftmax().print();  // or tf.logSoftmax(a)\n * ```\n *\n * @param logits The logits array.\n * @param axis The dimension softmax would be performed on. Defaults to `-1`\n *     which indicates the last dimension.\n *\n * @doc {heading: 'Operations', subheading: 'Normalization'}\n */\nfunction logSoftmax_<T extends Tensor>(logits: T|TensorLike, axis = -1): T {\n  const $logits = convertToTensor(logits, 'logits', 'logSoftmax');\n\n  if (axis === -1) {\n    axis = $logits.rank - 1;\n  }\n  if (axis !== $logits.rank - 1) {\n    throw Error(\n        'Log Softmax along a non-last dimension is not yet supported. ' +\n        `Logits was rank ${$logits.rank} and axis was ${axis}`);\n  }\n\n  // const forward: ForwardFunc<Tensor> = (backend, save) => {\n  //   const keepDims = true;\n  //   const xMax = max(logits, axis, true);\n  //   const shifted = sub(logits, xMax);\n  //   const value =\n  //       sub(cast(shifted, 'float32'), log(sum(exp(shifted), axis,\n  //       keepDims)));\n  //   save([value]);\n  //   return value;\n  // };\n\n  // Use a custom gradient for numerical stability.\n  const customOp = customGrad((logits: Tensor, save: GradSaveFunc) => {\n    const keepDims = true;\n    const xMax = max(logits, axis, true);\n    const shifted = sub(logits, xMax);\n    const value =\n        sub(cast(shifted, 'float32'), log(sum(exp(shifted), axis, keepDims)));\n    save([value]);\n\n    const gradFunc = (dy: Tensor, saved: Tensor[]) => {\n      const [value] = saved;\n      const keepDims = true;\n      const softmax = exp(value);\n      return sub(dy, mul(sum(dy, axis, keepDims), softmax));\n    };\n    return {value, gradFunc};\n  });\n\n  return customOp($logits) as T;\n\n  // TODO Use Engine.runKernel when CPU/WebGL/WASM backends implement this.\n  // const inputs: LogSoftmaxInputs = {logits: $logits};\n  // const attrs: LogSoftmaxAttrs = {axis};\n  // return ENGINE.runKernel(\n  //            LogSoftmax, inputs as {} as NamedTensorMap,\n  //            attrs as {} as NamedAttrMap);\n}\n\nexport const logSoftmax = op({logSoftmax_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor} from '../tensor';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\nimport {parseAxisParam} from '../util';\n\nimport {add} from './add';\nimport {expandShapeToKeepDim} from './axis_util';\nimport {exp} from './exp';\nimport {log} from './log';\nimport {max} from './max';\nimport {op} from './operation';\nimport {reshape} from './reshape';\nimport {sub} from './sub';\nimport {sum} from './sum';\n\n/**\n * Computes the log(sum(exp(elements across the reduction dimensions))).\n *\n * Reduces the input along the dimensions given in `axis`. Unless `keepDims`\n * is true, the rank of the array is reduced by 1 for each entry in `axis`.\n * If `keepDims` is true, the reduced dimensions are retained with length 1.\n * If `axis` has no entries, all dimensions are reduced, and an array with a\n * single element is returned.\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3]);\n *\n * x.logSumExp().print();  // or tf.logSumExp(x)\n * ```\n *\n * ```js\n * const x = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n *\n * const axis = 1;\n * x.logSumExp(axis).print();  // or tf.logSumExp(a, axis)\n * ```\n * @param x The input tensor.\n * @param axis The dimension(s) to reduce. If null (the default),\n *     reduces all dimensions.\n * @param keepDims If true, retains reduced dimensions with length\n *     of 1. Defaults to false.\n *\n * @doc {heading: 'Operations', subheading: 'Reduction'}\n */\nfunction logSumExp_<T extends Tensor>(\n    x: Tensor|TensorLike, axis: number|number[] = null, keepDims = false): T {\n  const $x = convertToTensor(x, 'x', 'logSumExp');\n\n  const axes = parseAxisParam(axis, $x.shape);\n  const xMax = max($x, axes, true /* keepDims */);\n  const a = sub($x, xMax);\n  const b = exp(a);\n  const c = sum(b, axes);\n  const d = log(c);\n  const res = add(reshape(xMax, d.shape), d);\n\n  if (keepDims) {\n    const newShape = expandShapeToKeepDim(res.shape, axes);\n    return reshape(res, newShape) as T;\n  }\n  return res as T;\n}\n\nexport const logSumExp = op({logSumExp_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {ENGINE} from '../engine';\nimport {LogicalAnd, LogicalAndInputs} from '../kernel_names';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {assertAndGetBroadcastShape} from './broadcast_util';\nimport {op} from './operation';\n\n/**\n * Returns the truth value of `a AND b` element-wise. Supports broadcasting.\n *\n * ```js\n * const a = tf.tensor1d([false, false, true, true], 'bool');\n * const b = tf.tensor1d([false, true, false, true], 'bool');\n *\n * a.logicalAnd(b).print();\n * ```\n *\n * @param a The first input tensor. Must be of dtype bool.\n * @param b The second input tensor. Must be of dtype bool.\n *\n * @doc {heading: 'Operations', subheading: 'Logical'}\n */\nfunction logicalAnd_<T extends Tensor>(\n    a: Tensor|TensorLike, b: Tensor|TensorLike): T {\n  const $a = convertToTensor(a, 'a', 'logicalAnd', 'bool');\n  const $b = convertToTensor(b, 'b', 'logicalAnd', 'bool');\n  assertAndGetBroadcastShape($a.shape, $b.shape);\n\n  const inputs: LogicalAndInputs = {a: $a, b: $b};\n\n  return ENGINE.runKernel(LogicalAnd, inputs as {} as NamedTensorMap);\n}\n\nexport const logicalAnd = op({logicalAnd_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {LogicalNot, LogicalNotInputs} from '../kernel_names';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\nimport {op} from './operation';\n\n/**\n * Returns the truth value of `NOT x` element-wise.\n *\n * ```js\n * const a = tf.tensor1d([false, true], 'bool');\n *\n * a.logicalNot().print();\n * ```\n *\n * @param x The input tensor. Must be of dtype 'bool'.\n *\n * @doc {heading: 'Operations', subheading: 'Logical'}\n */\nfunction logicalNot_<T extends Tensor>(x: T|TensorLike): T {\n  const $x = convertToTensor(x, 'x', 'logicalNot', 'bool');\n  const inputs: LogicalNotInputs = {x: $x};\n  return ENGINE.runKernel(LogicalNot, inputs as {} as NamedTensorMap);\n}\n\nexport const logicalNot = op({logicalNot_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {LogicalOr, LogicalOrInputs} from '../kernel_names';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\nimport {assertAndGetBroadcastShape} from './broadcast_util';\nimport {op} from './operation';\n\n/**\n * Returns the truth value of `a OR b` element-wise. Supports broadcasting.\n *\n * ```js\n * const a = tf.tensor1d([false, false, true, true], 'bool');\n * const b = tf.tensor1d([false, true, false, true], 'bool');\n *\n * a.logicalOr(b).print();\n * ```\n * @param a The first input tensor. Must be of dtype bool.\n * @param b The second input tensor. Must be of dtype bool.\n *\n * @doc {heading: 'Operations', subheading: 'Logical'}\n */\nfunction logicalOr_<T extends Tensor>(\n    a: Tensor|TensorLike, b: Tensor|TensorLike): T {\n  const $a = convertToTensor(a, 'a', 'logicalOr', 'bool');\n  const $b = convertToTensor(b, 'b', 'logicalOr', 'bool');\n  assertAndGetBroadcastShape($a.shape, $b.shape);\n\n  const inputs: LogicalOrInputs = {a: $a, b: $b};\n  return ENGINE.runKernel(LogicalOr, inputs as {} as NamedTensorMap);\n}\nexport const logicalOr = op({logicalOr_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor} from '../tensor';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {assertAndGetBroadcastShape} from './broadcast_util';\nimport {logicalAnd} from './logical_and';\nimport {logicalNot} from './logical_not';\nimport {logicalOr} from './logical_or';\nimport {op} from './operation';\n\n/**\n * Returns the truth value of `a XOR b` element-wise. Supports broadcasting.\n *\n * ```js\n * const a = tf.tensor1d([false, false, true, true], 'bool');\n * const b = tf.tensor1d([false, true, false, true], 'bool');\n *\n * a.logicalXor(b).print();\n * ```\n *\n * @param a The first input tensor. Must be of dtype bool.\n * @param b The second input tensor. Must be of dtype bool.\n *\n * @doc {heading: 'Operations', subheading: 'Logical'}\n */\nfunction logicalXor_<T extends Tensor>(\n    a: Tensor|TensorLike, b: Tensor|TensorLike): T {\n  const $a = convertToTensor(a, 'a', 'logicalXor', 'bool');\n  const $b = convertToTensor(b, 'b', 'logicalXor', 'bool');\n  assertAndGetBroadcastShape($a.shape, $b.shape);\n\n  // x ^ y = (x | y) & ~(x & y)\n  return logicalAnd(logicalOr(a, b), logicalNot(logicalAnd(a, b)));\n}\n\nexport const logicalXor = op({logicalXor_});\n","/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {SearchSorted, SearchSortedAttrs, SearchSortedInputs} from '../kernel_names';\nimport {Tensor} from '../tensor';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\nimport {sizeFromShape} from '../util_base';\nimport {op} from './operation';\nimport {reshape} from './reshape';\n\nconst INT32_MAX = 2147483648;\n/**\n * Searches for where a value would go in a sorted sequence.\n *\n * This is not a method for checking containment (like javascript in).\n *\n * The typical use case for this operation is \"binning\", \"bucketing\", or\n * \"discretizing\". The values are assigned to bucket-indices based on the edges\n * listed in 'sortedSequence'. This operation returns the bucket-index for each\n * value.\n *\n * The side argument controls which index is returned if a value lands exactly\n * on an edge.\n *\n * The axis is not settable for this operation. It always operates on the\n * innermost dimension (axis=-1). The operation will accept any number of outer\n * dimensions.\n *\n * Note: This operation assumes that 'sortedSequence' is sorted along the\n * innermost axis, maybe using 'sort(..., axis=-1)'. If the sequence is not\n * sorted no error is raised and the content of the returned tensor is not well\n * defined.\n *\n * ```js\n * const edges = tf.tensor1d([-1, 3.3, 9.1, 10.0]);\n * let values = tf.tensor1d([0.0, 4.1, 12.0]);\n * const result1 = tf.searchSorted(edges, values, 'left');\n * result1.print(); // [1, 2, 4]\n *\n * const seq = tf.tensor1d([0, 3, 9, 10, 10]);\n * values = tf.tensor1d([0, 4, 10]);\n * const result2 = tf.searchSorted(seq, values, 'left');\n * result2.print(); // [0, 2, 3]\n * const result3 = tf.searchSorted(seq, values, 'right');\n * result3.print(); // [1, 2, 5]\n *\n * const sortedSequence = tf.tensor2d([[0., 3., 8., 9., 10.],\n *                                     [1., 2., 3., 4., 5.]]);\n * values = tf.tensor2d([[9.8, 2.1, 4.3],\n *                       [0.1, 6.6, 4.5, ]]);\n * const result4 = tf.searchSorted(sortedSequence, values, 'left');\n * result4.print(); // [[4, 1, 2], [0, 5, 4]]\n * ```\n * @param sortedSequence: N-D. Sorted sequence.\n * @param values: N-D. Search values.\n * @param side: 'left'|'right'. Defaults to 'left'. 'left' corresponds to lower\n *     bound and 'right' to upper bound.\n * @return An N-D int32 tensor the size of values containing the result of\n *     applying either lower bound or upper bound (depending on side) to each\n *     value. The result is not a global index to the entire Tensor, but the\n *     index in the last dimension.\n * @doc {heading: 'Operations', subheading: 'Evaluation'}\n */\nfunction searchSorted_(\n    sortedSequence: Tensor|TensorLike, values: Tensor|TensorLike,\n    side: 'left'|'right' = 'left'): Tensor {\n  const $sortedSequence =\n      convertToTensor(sortedSequence, 'sortedSequence', 'searchSorted');\n  const $values = convertToTensor(values, 'values', 'searchSorted');\n\n  const sequenceSize = $sortedSequence.shape[$sortedSequence.shape.length - 1];\n  const valuesSize = $values.shape[$values.shape.length - 1];\n  const $sortedSequence2D = reshape($sortedSequence, [-1, sequenceSize]);\n  const $values2D = reshape($values, [-1, valuesSize]);\n\n  if ($sortedSequence2D.rank < 2) {\n    throw new Error(`Sorted input argument must be at least 2-dimensional`);\n  }\n  if ($sortedSequence2D.shape[0] !== $values2D.shape[0]) {\n    throw new Error(\n        `Leading dimension of 'sortedSequence' and 'values' must match.`);\n  }\n  if (sizeFromShape($values2D.shape) >= INT32_MAX) {\n    throw new Error(`values tensor size must less than ${INT32_MAX}`);\n  }\n  if ($sortedSequence2D.shape[1] >= INT32_MAX) {\n    throw new Error(`trailing dim_size must less than ${\n        INT32_MAX} for int32 output type, was ${$sortedSequence2D.shape[1]}`);\n  }\n\n  const inputs: SearchSortedInputs = {\n    sortedSequence: $sortedSequence2D,\n    values: $values2D,\n  };\n  const attrs: SearchSortedAttrs = {side};\n\n  return ENGINE.runKernel(SearchSorted, inputs as {}, attrs as {});\n}\n\nexport const searchSorted = op({searchSorted_});\n","/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor} from '../tensor';\nimport {TensorLike} from '../types';\nimport {searchSorted} from './search_sorted';\n\n/**\n * Searches for where a value would go in a sorted sequence.\n *\n * This is not a method for checking containment (like javascript in).\n *\n * The typical use case for this operation is \"binning\", \"bucketing\", or\n * \"discretizing\". The values are assigned to bucket-indices based on the edges\n * listed in 'sortedSequence'. This operation returns the bucket-index for each\n * value.\n *\n * The index returned corresponds to the first edge greater than or equal to the\n * value.\n *\n * The axis is not settable for this operation. It always operates on the\n * innermost dimension (axis=-1). The operation will accept any number of outer\n * dimensions.\n *\n * Note: This operation assumes that 'lowerBound' is sorted along the\n * innermost axis, maybe using 'sort(..., axis=-1)'. If the sequence is not\n * sorted no error is raised and the content of the returned tensor is not well\n * defined.\n *\n * ```js\n * const edges = tf.tensor1d([-1, 3.3, 9.1, 10.0]);\n * let values = tf.tensor1d([0.0, 4.1, 12.0]);\n * const result1 = tf.lowerBound(edges, values);\n * result1.print(); // [1, 2, 4]\n *\n * const seq = tf.tensor1d([0, 3, 9, 10, 10]);\n * values = tf.tensor1d([0, 4, 10]);\n * const result2 = tf.lowerBound(seq, values);\n * result2.print(); // [0, 2, 3]\n *\n * const sortedSequence = tf.tensor2d([[0., 3., 8., 9., 10.],\n *                                     [1., 2., 3., 4., 5.]]);\n * values = tf.tensor2d([[9.8, 2.1, 4.3],\n *                       [0.1, 6.6, 4.5, ]]);\n * const result3 = tf.lowerBound(sortedSequence, values);\n * result3.print(); // [[4, 1, 2], [0, 5, 4]]\n * ```\n * @param sortedSequence: N-D. Sorted sequence.\n * @param values: N-D. Search values.\n * @return An N-D int32 tensor the size of values containing the result of\n *     applying lower bound to each value. The result is not a global index to\n *     the entire Tensor, but the index in the last dimension.\n * @doc {heading: 'Operations', subheading: 'Evaluation'}\n */\nexport function lowerBound(\n    sortedSequence: Tensor|TensorLike, values: Tensor|TensorLike): Tensor {\n  return searchSorted(sortedSequence, values, 'left');\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {MaxPool, MaxPoolAttrs, MaxPoolInputs} from '../kernel_names';\nimport {NamedAttrMap} from '../kernel_registry';\nimport {Tensor3D, Tensor4D} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\nimport * as util from '../util';\n\nimport * as conv_util from './conv_util';\nimport {op} from './operation';\nimport {reshape} from './reshape';\n\n/**\n * Computes the 2D max pooling of an image.\n *\n * @param x The input tensor, of rank 4 or rank 3 of shape\n *     `[batch, height, width, inChannels]`. If rank 3, batch of 1 is assumed.\n * @param filterSize The filter size: `[filterHeight, filterWidth]`. If\n *     `filterSize` is a single number, then `filterHeight == filterWidth`.\n * @param strides The strides of the pooling: `[strideHeight, strideWidth]`. If\n *     `strides` is a single number, then `strideHeight == strideWidth`.\n * @param dilations The dilation rates: `[dilationHeight, dilationWidth]`\n *     in which we sample input values across the height and width dimensions\n *     in dilated pooling. Defaults to `[1, 1]`. If `dilations` is a single\n *     number, then `dilationHeight == dilationWidth`. If it is greater than\n *     1, then all values of `strides` must be 1.\n * @param pad The type of padding algorithm.\n *    - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *    - `valid`: output will be smaller than input if filter is larger\n *       than 1x1.\n *    - For more info, see this guide:\n *     [https://www.tensorflow.org/api_docs/python/tf/nn/convolution](\n *          https://www.tensorflow.org/api_docs/python/tf/nn/convolution)\n * @param dimRoundingMode A string from: 'ceil', 'round', 'floor'. If none is\n *     provided, it will default to truncate.\n */\nfunction maxPool_<T extends Tensor3D|Tensor4D>(\n    x: T|TensorLike, filterSize: [number, number]|number,\n    strides: [number, number]|number,\n    pad: 'valid'|'same'|number|conv_util.ExplicitPadding,\n    dimRoundingMode?: 'floor'|'round'|'ceil'): T {\n  const $x = convertToTensor(x, 'x', 'maxPool');\n  const dilations = 1;\n\n  let x4D = $x as Tensor4D;\n  let reshapedTo4D = false;\n  if ($x.rank === 3) {\n    reshapedTo4D = true;\n    x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);\n  }\n\n  util.assert(\n      x4D.rank === 4,\n      () => `Error in maxPool: input must be rank 4 but got rank ${x4D.rank}.`);\n  util.assert(\n      conv_util.eitherStridesOrDilationsAreOne(strides, dilations),\n      () => 'Error in maxPool: Either strides or dilations must be 1. ' +\n          `Got strides ${strides} and dilations '${dilations}'`);\n  conv_util.checkPadOnDimRoundingMode('maxPool', pad, dimRoundingMode);\n  const inputs: MaxPoolInputs = {x: x4D};\n  const attrs: MaxPoolAttrs = {filterSize, strides, pad, dimRoundingMode};\n\n  // tslint:disable-next-line: no-unnecessary-type-assertion\n  const res = ENGINE.runKernel(\n                  MaxPool, inputs as {} as NamedTensorMap,\n                  attrs as {} as NamedAttrMap) as T;\n\n  if (reshapedTo4D) {\n    return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]) as T;\n  }\n  return res;\n}\n\nexport const maxPool = op({maxPool_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {MaxPool3D, MaxPool3DAttrs, MaxPool3DInputs} from '../kernel_names';\nimport {NamedAttrMap} from '../kernel_registry';\nimport {Tensor4D, Tensor5D} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\nimport * as util from '../util';\n\nimport {checkPadOnDimRoundingMode} from './conv_util';\nimport {op} from './operation';\nimport {reshape} from './reshape';\n\n/**\n * Computes the 3D max pooling.\n *\n * ```js\n * const x = tf.tensor5d([1, 2, 3, 4, 5, 6, 7, 8], [1, 2, 2, 2, 1]);\n * const result = tf.maxPool3d(x, 2, 1, 'valid');\n * result.print();\n * ```\n *\n * @param x The input tensor, of rank 5 or rank 4 of shape\n *     `[batch, depth, height, width, inChannels]`.\n * @param filterSize The filter size:\n *     `[filterDepth, filterHeight, filterWidth]`.\n *     If `filterSize` is a single number,\n *     then `filterDepth == filterHeight == filterWidth`.\n * @param strides The strides of the pooling:\n *     `[strideDepth, strideHeight, strideWidth]`.\n *     If `strides` is a single number,\n *     then `strideDepth == strideHeight == strideWidth`.\n * @param pad The type of padding algorithm.\n *    - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *    - `valid`: output will be smaller than input if filter is larger\n *       than 1*1x1.\n *    - For more info, see this guide:\n *     [https://www.tensorflow.org/api_docs/python/tf/nn/convolution](\n *          https://www.tensorflow.org/api_docs/python/tf/nn/convolution)\n * @param dimRoundingMode A string from: 'ceil', 'round', 'floor'. If none is\n *     provided, it will default to truncate.\n * @param dataFormat An optional string from: \"NDHWC\", \"NCDHW\". Defaults to\n *     \"NDHWC\". Specify the data format of the input and output data. With the\n *     default format \"NDHWC\", the data is stored in the order of: [batch,\n *     depth, height, width, channels]. Only \"NDHWC\" is currently supported.\n * @doc {heading: 'Operations', subheading: 'Convolution'}\n */\nfunction maxPool3d_<T extends Tensor4D|Tensor5D>(\n    x: T|TensorLike, filterSize: [number, number, number]|number = [1, 1, 1],\n    strides: [number, number, number]|number, pad: 'valid'|'same'|number,\n    dimRoundingMode?: 'floor'|'round'|'ceil',\n    dataFormat: 'NDHWC'|'NCDHW' = 'NDHWC'): T {\n  const $x = convertToTensor(x, 'x', 'maxPool3d');\n\n  let x5D = $x as Tensor5D;\n  let reshapedTo5D = false;\n  if ($x.rank === 4) {\n    reshapedTo5D = true;\n    x5D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2], $x.shape[3]]);\n  }\n\n  util.assert(\n      x5D.rank === 5,\n      () => `Error in maxPool3d: x must be rank 5 but got rank ${x5D.rank}.`);\n  util.assert(\n      dataFormat === 'NDHWC',\n      () => `Error in maxPool3d: Only NDHWC is currently supported, ` +\n          `but got dataFormat of ${dataFormat}`);\n  checkPadOnDimRoundingMode('maxPool3d', pad, dimRoundingMode);\n  const inputs: MaxPool3DInputs = {x: x5D};\n  const attrs:\n      MaxPool3DAttrs = {filterSize, strides, pad, dimRoundingMode, dataFormat};\n\n  // tslint:disable-next-line: no-unnecessary-type-assertion\n  const res = ENGINE.runKernel(\n                  MaxPool3D, inputs as {} as NamedTensorMap,\n                  attrs as {} as NamedAttrMap) as T;\n\n  if (reshapedTo5D) {\n    return reshape(\n               res, [res.shape[1], res.shape[2], res.shape[3], res.shape[4]]) as\n        T;\n  }\n\n  return res;\n}\n\nexport const maxPool3d = op({maxPool3d_});\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {MaxPoolWithArgmax, MaxPoolWithArgmaxAttrs, MaxPoolWithArgmaxInputs} from '../kernel_names';\nimport {NamedAttrMap} from '../kernel_registry';\nimport {Tensor, Tensor4D} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {op} from './operation';\n\n/**\n * Computes the 2D max pooling of an image with Argmax index.\n * The indices in argmax are flattened, so that a maximum value at position `[b,\n * y, x, c]` becomes flattened index: `(y * width + x) * channels + c` if\n * include_batch_in_index is False; `((b * height + y) * width + x) * channels\n * +c` if include_batch_in_index is True.\n *\n * The indices returned are always in `[0, height) x [0, width)` before\n * flattening.\n *\n * @param x The input tensor, of rank 4 or rank 3 of shape\n *     `[batch, height, width, inChannels]`. If rank 3, batch of 1 is assumed.\n * @param filterSize The filter size: `[filterHeight, filterWidth]`. If\n *     `filterSize` is a single number, then `filterHeight == filterWidth`.\n * @param strides The strides of the pooling: `[strideHeight, strideWidth]`. If\n *     `strides` is a single number, then `strideHeight == strideWidth`.\n * @param dataFormat An optional string from: \"NDHWC\", \"NCDHW\". Defaults to\n *     \"NDHWC\". Specify the data format of the input and output data. With the\n *     default format \"NDHWC\", the data is stored in the order of: [batch,\n *     depth, height, width, channels]. Only \"NDHWC\" is currently supported.\n * @param pad The type of padding algorithm.\n *    - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *    - `valid`: output will be smaller than input if filter is larger\n *       than 1x1.\n *    - For more info, see this guide:\n *     [https://www.tensorflow.org/api_docs/python/tf/nn/convolution](\n *          https://www.tensorflow.org/api_docs/python/tf/nn/convolution)\n * @param includeBatchIndex Defaults to False. Whether to include batch\n *    dimension in flattened index of argmax.\n *\n * @doc {heading: 'Operations', subheading: 'Convolution'}\n */\nfunction maxPoolWithArgmax_<T extends Tensor4D>(\n    x: T|TensorLike, filterSize: [number, number]|number,\n    strides: [number, number]|number, pad: 'valid'|'same'|number,\n    includeBatchInIndex = false): NamedTensorMap {\n  const $x = convertToTensor(x, 'x', 'maxPoolWithArgmax');\n\n  const inputs: MaxPoolWithArgmaxInputs = {x: $x};\n  const attrs:\n      MaxPoolWithArgmaxAttrs = {filterSize, strides, pad, includeBatchInIndex};\n\n  // tslint:disable-next-line: no-unnecessary-type-assertion\n  const result = ENGINE.runKernel(\n                     MaxPoolWithArgmax, inputs as {} as NamedTensorMap,\n                     attrs as {} as NamedAttrMap) as Tensor[];\n\n  return {result: result[0], indexes: result[1]};\n}\n\nexport const maxPoolWithArgmax = op({maxPoolWithArgmax_});\n","/**\n * @license\n * Copyright 2020 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {Mean, MeanAttrs, MeanInputs} from '../kernel_names';\nimport {NamedAttrMap} from '../kernel_registry';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {op} from './operation';\n\n/**\n * Computes the mean of elements across dimensions of a `tf.Tensor`.\n *\n * Reduces `x` along the dimensions given in `axis`. Unless `keepDims` is\n * true, the rank of the `tf.Tensor` is reduced by 1 for each entry in `axis`.\n * If `keepDims` is true, the reduced dimensions are retained with length 1.\n * If `axis` has no entries, all dimensions are reduced, and a `tf.Tensor` with\n * a single element is returned.\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3]);\n *\n * x.mean().print();  // or tf.mean(a)\n * ```\n *\n * ```js\n * const x = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n *\n * const axis = 1;\n * x.mean(axis).print();  // or tf.mean(x, axis)\n * ```\n *\n * @param x The input tensor.\n * @param axis The dimension(s) to reduce. By default it reduces\n *     all dimensions.\n * @param keepDims If true, retains reduced dimensions with size 1.\n *\n * @doc {heading: 'Operations', subheading: 'Reduction'}\n */\nfunction mean_<T extends Tensor>(\n    x: Tensor|TensorLike, axis: number|number[] = null, keepDims = false): T {\n  const $x = convertToTensor(x, 'x', 'mean');\n\n  const inputs: MeanInputs = {x: $x};\n  const attrs: MeanAttrs = {axis, keepDims};\n\n  return ENGINE.runKernel(\n      Mean, inputs as {} as NamedTensorMap, attrs as {} as NamedAttrMap);\n}\n\nexport const mean = op({mean_});\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {Tensor} from '../tensor';\nimport {DataType, Rank, ShapeMap} from '../types';\nimport {makeZerosTypedArray, sizeFromShape} from '../util';\n\nimport {complex} from './complex';\n\n/**\n * Creates a `tf.Tensor` with all elements set to 0.\n *\n * ```js\n * tf.zeros([2, 2]).print();\n * ```\n *\n * @param shape An array of integers defining the output tensor shape.\n * @param dtype The type of an element in the resulting tensor. Can\n *     be 'float32', 'int32' or 'bool'. Defaults to 'float'.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nexport function zeros<R extends Rank>(\n    shape: ShapeMap[R], dtype: DataType = 'float32'): Tensor<R> {\n  if (dtype === 'complex64') {\n    const real = zeros(shape, 'float32');\n    const imag = zeros(shape, 'float32');\n    return complex(real, imag);\n  }\n  const values = makeZerosTypedArray(sizeFromShape(shape), dtype);\n  return ENGINE.makeTensor(values, shape, dtype) as Tensor<R>;\n}\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {Tensor} from '../tensor';\nimport {DataType, Rank, ShapeMap} from '../types';\nimport {makeOnesTypedArray, sizeFromShape} from '../util';\n\nimport {complex} from './complex';\nimport {zeros} from './zeros';\n\n/**\n * Creates a `tf.Tensor` with all elements set to 1.\n *\n * ```js\n * tf.ones([2, 2]).print();\n * ```\n *\n * @param shape An array of integers defining the output tensor shape.\n * @param dtype The type of an element in the resulting tensor. Defaults to\n *     'float'.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nexport function ones<R extends Rank>(\n    shape: ShapeMap[R], dtype: DataType = 'float32'): Tensor<R> {\n  if (dtype === 'complex64') {\n    const real = ones(shape, 'float32');\n    const imag = zeros(shape, 'float32');\n    return complex(real, imag);\n  }\n  const values = makeOnesTypedArray(sizeFromShape(shape), dtype);\n  return ENGINE.makeTensor(values, shape, dtype) as Tensor<R>;\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {matMul} from './mat_mul';\nimport {ones} from './ones';\nimport {reshape} from './reshape';\nimport {Tensor} from '../tensor';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\nimport {sizeFromShape} from '../util_base';\n\n/**\n * Broadcasts parameters for evaluation on an N-D grid.\n *\n * Given N one-dimensional coordinate arrays `*args`, returns a list `outputs`\n * of N-D coordinate arrays for evaluating expressions on an N-D grid.\n *\n * Notes:\n * `meshgrid` supports cartesian ('xy') and matrix ('ij') indexing conventions.\n * When the `indexing` argument is set to 'xy' (the default), the broadcasting\n * instructions for the first two dimensions are swapped.\n * Examples:\n * Calling `const [X, Y] = meshgrid(x, y)` with the tensors\n *\n * ```javascript\n * const x = [1, 2, 3];\n * const y = [4, 5, 6];\n * const [X, Y] = tf.meshgrid(x, y);\n * // X = [[1, 2, 3],\n * //      [1, 2, 3],\n * //      [1, 2, 3]]\n * // Y = [[4, 4, 4],\n * //      [5, 5, 5],\n * //      [6, 6, 6]]\n * ```\n *\n * @param x Tensor with rank geq 1.\n * @param y Tensor with rank geq 1.\n * @param indexing\n *\n * @doc {heading: 'Operations', subheading: 'Slicing and Joining'}\n */\nexport function meshgrid<T extends Tensor>(\n    x?: T|TensorLike, y?: T|TensorLike, {indexing = 'xy'} = {}): T[] {\n  if (indexing !== 'xy' && indexing !== 'ij') {\n    throw new TypeError(\n        `${indexing} is not a valid third argument to meshgrid`);\n  }\n  if (x === undefined) {\n    return [];\n  }\n  let $x = convertToTensor(\n      x, 'x', 'meshgrid', x instanceof Tensor ? x.dtype : 'float32');\n\n  if (y === undefined) {\n    return [$x];\n  }\n  let $y = convertToTensor(\n      y, 'y', 'meshgrid', y instanceof Tensor ? y.dtype : 'float32');\n\n  const w = sizeFromShape($x.shape);\n  const h = sizeFromShape($y.shape);\n\n  if (indexing === 'xy') {\n    $x = reshape($x, [1, -1]) as T;\n    $y = reshape($y, [-1, 1]) as T;\n    return [\n      matMul(ones([h, 1], $x.dtype), $x),\n      matMul($y, ones([1, w], $y.dtype)),\n    ];\n  }\n\n  $x = reshape($x, [-1, 1]) as T;\n  $y = reshape($y, [1, -1]) as T;\n  return [\n    matMul($x, ones([1, h], $x.dtype)),\n    matMul(ones([w, 1], $y.dtype), $y),\n  ];\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {Minimum, MinimumInputs} from '../kernel_names';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {makeTypesMatch} from '../tensor_util';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {assertAndGetBroadcastShape} from './broadcast_util';\nimport {cast} from './cast';\nimport {op} from './operation';\n\n/**\n * Returns the min of a and b (`a < b ? a : b`) element-wise.\n * Supports broadcasting.\n *\n * We also expose `minimumStrict` which has the same signature as this op and\n * asserts that `a` and `b` are the same shape (does not broadcast).\n *\n * ```js\n * const a = tf.tensor1d([1, 4, 3, 16]);\n * const b = tf.tensor1d([1, 2, 9, 4]);\n *\n * a.minimum(b).print();  // or tf.minimum(a, b)\n * ```\n *\n * ```js\n * // Broadcast minimum a with b.\n * const a = tf.tensor1d([2, 4, 6, 8]);\n * const b = tf.scalar(5);\n *\n * a.minimum(b).print();  // or tf.minimum(a, b)\n * ```\n *\n * @param a The first tensor.\n * @param b The second tensor. Must have the same type as `a`.\n *\n * @doc {heading: 'Operations', subheading: 'Arithmetic'}\n */\nfunction minimum_<T extends Tensor>(\n    a: Tensor|TensorLike, b: Tensor|TensorLike): T {\n  let $a = convertToTensor(a, 'a', 'minimum');\n  let $b = convertToTensor(b, 'b', 'minimum');\n  [$a, $b] = makeTypesMatch($a, $b);\n\n  if ($a.dtype === 'bool') {\n    $a = cast($a, 'int32');\n    $b = cast($b, 'int32');\n  }\n\n  assertAndGetBroadcastShape($a.shape, $b.shape);\n\n  const inputs: MinimumInputs = {a: $a, b: $b};\n\n  return ENGINE.runKernel(Minimum, inputs as {} as NamedTensorMap);\n}\n\nexport const minimum = op({minimum_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {MirrorPad, MirrorPadAttrs, MirrorPadInputs} from '../kernel_names';\nimport {NamedAttrMap} from '../kernel_registry';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\nimport * as util from '../util';\n\nimport {op} from './operation';\n\n/**\n * Pads a `tf.Tensor` using mirror padding.\n *\n * This operation implements the `REFLECT` and `SYMMETRIC` modes of pad.\n *\n * ```js\n * const x = tf.range(0, 9).reshape([1, 1, 3, 3]);\n * x.mirrorPad([[0, 0], [0, 0], [2, 2], [2, 2]], 'reflect').print();\n * ```\n * @param x The tensor to pad.\n * @param paddings An array of length `R` (the rank of the tensor), where\n * each element is a length-2 tuple of ints `[padBefore, padAfter]`,\n * specifying how much to pad along each dimension of the tensor.\n * In \"reflect\" mode, the padded regions do not include the borders,\n * while in \"symmetric\" mode the padded regions do include the borders.\n * For example, if the input is `[1, 2, 3]` and paddings is `[0, 2]`,\n * then the output is `[1, 2, 3, 2, 1]` in \"reflect\" mode, and\n * `[1, 2, 3, 3, 2]` in \"symmetric\" mode.\n * If `mode` is \"reflect\" then both `paddings[D, 0]` and `paddings[D, 1]`\n * must be no greater than `x.shape[D] - 1`. If mode is \"symmetric\"\n * then both `paddings[D, 0]` and `paddings[D, 1]` must be no greater than\n * `x.shape[D]`\n * @param mode String to specify padding mode. Can be `'reflect' | 'symmetric'`\n */\n/** @doc {heading: 'Tensors', subheading: 'Transformations'} */\nfunction mirrorPad_<T extends Tensor>(\n    x: T|TensorLike, paddings: Array<[number, number]>,\n    mode: 'reflect'|'symmetric'): T {\n  util.assert(\n      mode === 'reflect' || mode === 'symmetric',\n      () => `Invalid mode. Mode must be either reflect or symmetric. ` +\n          `Got ${mode}.`);\n\n  const $x = convertToTensor(x, 'x', 'mirrorPad');\n  if ($x.rank === 0) {\n    throw new Error(\n        'mirrorPad(scalar) is not defined. ' +\n        'Pass non-scalar to mirrorPad');\n  }\n  util.assert(\n      paddings.length === $x.rank,\n      () => `Padding doesn't match input. Must be ${$x.rank}. ` +\n          `Got ${paddings.length}.`);\n  const shapeOffset = mode === 'reflect' ? 1 : 0;\n  for (let i = 0; i < $x.rank; i++) {\n    util.assert(\n        paddings[i].length === 2,\n        () => `Invalid number of paddings. Must be length of 2 each.`);\n    util.assert(\n        paddings[i][0] >= 0 && paddings[i][0] <= $x.shape[i] - shapeOffset &&\n            paddings[i][1] >= 0 && paddings[i][1] <= $x.shape[i] - shapeOffset,\n        () => `Padding in dimension ${i} cannot be greater than or equal ` +\n            `to ${$x.shape[i] - shapeOffset} or less than 0 for input of ` +\n            `shape ${$x.shape}`);\n  }\n\n  const attrs: MirrorPadAttrs = {paddings, mode};\n  const inputs: MirrorPadInputs = {x: $x};\n  return ENGINE.runKernel(\n      MirrorPad, inputs as {} as NamedTensorMap, attrs as {} as NamedAttrMap);\n}\n\nexport const mirrorPad = op({mirrorPad_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {Mod, ModInputs} from '../kernel_names';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {makeTypesMatch} from '../tensor_util';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {op} from './operation';\n\n/**\n * Returns the mod of a and b element-wise.\n * `floor(x / y) * y + mod(x, y) = x`\n * Supports broadcasting.\n *\n * We also expose `tf.modStrict` which has the same signature as this op and\n * asserts that `a` and `b` are the same shape (does not broadcast).\n *\n * ```js\n * const a = tf.tensor1d([1, 4, 3, 16]);\n * const b = tf.tensor1d([1, 2, 9, 4]);\n *\n * a.mod(b).print();  // or tf.mod(a, b)\n * ```\n *\n * ```js\n * // Broadcast a mod b.\n * const a = tf.tensor1d([2, 4, 6, 8]);\n * const b = tf.scalar(5);\n *\n * a.mod(b).print();  // or tf.mod(a, b)\n * ```\n *\n * @param a The first tensor.\n * @param b The second tensor. Must have the same type as `a`.\n *\n * @doc {heading: 'Operations', subheading: 'Arithmetic'}\n */\nfunction mod_<T extends Tensor>(a: Tensor|TensorLike, b: Tensor|TensorLike): T {\n  let $a = convertToTensor(a, 'a', 'mod');\n  let $b = convertToTensor(b, 'b', 'mod');\n  [$a, $b] = makeTypesMatch($a, $b);\n\n  const inputs: ModInputs = {a: $a, b: $b};\n\n  return ENGINE.runKernel(Mod, inputs as {} as NamedTensorMap);\n}\n\nexport const mod = op({mod_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor} from '../tensor';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\nimport {parseAxisParam} from '../util';\n\nimport {expandShapeToKeepDim} from './axis_util';\nimport {cast} from './cast';\nimport {mean} from './mean';\nimport {op} from './operation';\nimport {reshape} from './reshape';\nimport {square} from './square';\nimport {sub} from './sub';\n\n/**\n * Calculates the mean and variance of `x`. The mean and variance are\n * calculated by aggregating the contents of `x` across `axes`. If `x` is\n * 1-D and `axes = [0]` this is just the mean and variance of a vector.\n *\n * @param x The input tensor.\n * @param axis The dimension(s) along with to compute mean and\n *     variance. By default it reduces all dimensions.\n * @param keepDims If true, the moments have the same dimensionality as the\n *     input.\n * @return An object with two keys: `mean` and `variance`.\n *\n * @doc {heading: 'Operations', subheading: 'Normalization'}\n */\nfunction moments_(\n    x: Tensor|TensorLike, axis: number|number[] = null,\n    keepDims = false): {mean: Tensor, variance: Tensor} {\n  x = convertToTensor(x, 'x', 'moments');\n  const axes = parseAxisParam(axis, x.shape);\n  const xMean = mean(x, axes, keepDims);\n  let keepDimsShape = xMean.shape;\n  if (!keepDims) {\n    keepDimsShape = expandShapeToKeepDim(xMean.shape, axes);\n  }\n  const devSquared =\n      square(sub(cast(x, 'float32'), reshape(xMean, keepDimsShape)));\n  const variance = mean(devSquared, axes, keepDims);\n  return {mean: xMean, variance};\n}\n\nexport const moments = op({moments_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {Tensor2D} from '../tensor';\nimport {convertToTensor, convertToTensorArray} from '../tensor_util_env';\nimport {TensorLike} from '../types';\nimport {op} from './operation';\n\n/**\n * @docalias (data: Tensor2D, c: Tensor2D, h: Tensor2D): [Tensor2D, Tensor2D]\n */\nexport type LSTMCellFunc = {\n  (data: Tensor2D, c: Tensor2D, h: Tensor2D): [Tensor2D, Tensor2D];\n};\n\n/**\n * Computes the next states and outputs of a stack of LSTMCells.\n *\n * Each cell output is used as input to the next cell.\n *\n * Returns `[cellState, cellOutput]`.\n *\n * Derived from tf.contrib.rn.MultiRNNCell.\n *\n * @param lstmCells Array of LSTMCell functions.\n * @param data The input to the cell.\n * @param c Array of previous cell states.\n * @param h Array of previous cell outputs.\n *\n * @doc {heading: 'Operations', subheading: 'RNN'}\n */\nfunction multiRNNCell_(\n    lstmCells: LSTMCellFunc[], data: Tensor2D|TensorLike,\n    c: Array<Tensor2D|TensorLike>,\n    h: Array<Tensor2D|TensorLike>): [Tensor2D[], Tensor2D[]] {\n  const $data = convertToTensor(data, 'data', 'multiRNNCell');\n  const $c = convertToTensorArray(c, 'c', 'multiRNNCell');\n  const $h = convertToTensorArray(h, 'h', 'multiRNNCell');\n\n  let input = $data;\n  const newStates = [];\n  for (let i = 0; i < lstmCells.length; i++) {\n    const output = lstmCells[i](input, $c[i], $h[i]);\n    newStates.push(output[0]);\n    newStates.push(output[1]);\n    input = output[1];\n  }\n  const newC: Tensor2D[] = [];\n  const newH: Tensor2D[] = [];\n  for (let i = 0; i < newStates.length; i += 2) {\n    newC.push(newStates[i]);\n    newH.push(newStates[i + 1]);\n  }\n  return [newC, newH];\n}\nexport const multiRNNCell = op({multiRNNCell_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {Multinomial, MultinomialAttrs, MultinomialInputs} from '../kernel_names';\nimport {NamedAttrMap} from '../kernel_registry';\nimport {Tensor1D, Tensor2D} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {op} from './operation';\nimport {reshape} from './reshape';\n\n/**\n * Creates a `tf.Tensor` with values drawn from a multinomial distribution.\n *\n * ```js\n * const probs = tf.tensor([.75, .25]);\n * tf.multinomial(probs, 3).print();\n * ```\n *\n * @param logits 1D array with unnormalized log-probabilities, or\n *     2D array of shape `[batchSize, numOutcomes]`. See the `normalized`\n *     parameter.\n * @param numSamples Number of samples to draw for each row slice.\n * @param seed The seed number.\n * @param normalized Whether the provided `logits` are normalized true\n *     probabilities (sum to 1). Defaults to false.\n * @return 1D array of shape `[numSamples]`, or 2D array of shape\n *     `[batchSize, numSamples]`, depending on the rank of the input.\n *\n * @doc {heading: 'Tensors', subheading: 'Random'}\n */\nfunction multinomial_(\n    logits: Tensor1D|Tensor2D|TensorLike, numSamples: number, seed?: number,\n    normalized = false): Tensor1D|Tensor2D {\n  const $logits = convertToTensor(logits, 'logits', 'multinomial');\n  const numOutcomes = $logits.size;\n  const origRank = $logits.rank;\n  if (numOutcomes < 2) {\n    throw new Error(\n        `Error in multinomial: you need at least 2 outcomes, but got ` +\n        `${numOutcomes}.`);\n  }\n  if (origRank > 2) {\n    throw new Error(`Rank of probabilities must be 1 or 2, but is ${origRank}`);\n  }\n  // TODO(lina128): Investigate correct seed behavior. The code seems not allow\n  // setting see to 0.\n  seed = seed || Math.random();\n\n  // The kernel only accepts (and returns) rank 2 tensors.\n  const logits2D: Tensor2D =\n      origRank === 1 ? reshape($logits, [1, -1]) : $logits as Tensor2D;\n\n  const inputs: MultinomialInputs = {logits: logits2D};\n  const attrs: MultinomialAttrs = {numSamples, seed, normalized};\n\n  // tslint:disable-next-line: no-unnecessary-type-assertion\n  const res = ENGINE.runKernel(\n                  Multinomial, inputs as {} as NamedTensorMap,\n                  attrs as {} as NamedAttrMap) as Tensor2D;\n\n  // tslint:disable-next-line:no-unnecessary-type-assertion\n  return origRank === 1 ? reshape(res, [res.size]) as Tensor1D : res;\n}\n\nexport const multinomial = op({multinomial_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {ENGINE} from '../engine';\nimport {NotEqual, NotEqualInputs} from '../kernel_names';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {makeTypesMatch} from '../tensor_util';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {assertAndGetBroadcastShape} from './broadcast_util';\nimport {op} from './operation';\n\n/**\n * Returns the truth value of (a != b) element-wise. Supports broadcasting.\n *\n * ```js\n * const a = tf.tensor1d([1, 2, 3]);\n * const b = tf.tensor1d([0, 2, 3]);\n *\n * a.notEqual(b).print();\n * ```\n * @param a The first input tensor.\n * @param b The second input tensor. Must have the same dtype as `a`.\n *\n * @doc {heading: 'Operations', subheading: 'Logical'}\n */\nfunction notEqual_<T extends Tensor>(\n    a: Tensor|TensorLike, b: Tensor|TensorLike): T {\n  let $a = convertToTensor(a, 'a', 'notEqual', 'string_or_numeric');\n  let $b = convertToTensor(b, 'b', 'notEqual', 'string_or_numeric');\n  [$a, $b] = makeTypesMatch($a, $b);\n\n  assertAndGetBroadcastShape($a.shape, $b.shape);\n\n  const inputs: NotEqualInputs = {a: $a, b: $b};\n\n  return ENGINE.runKernel(NotEqual, inputs as {} as NamedTensorMap);\n}\n\nexport const notEqual = op({notEqual_});\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {OnesLike, OnesLikeInputs} from '../kernel_names';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {op} from './operation';\n\n/**\n * Creates a `tf.Tensor` with all elements set to 1 with the same shape as the\n * given tensor.\n *\n * ```js\n * const x = tf.tensor([1, 2]);\n * tf.onesLike(x).print();\n * ```\n * @param x A tensor.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nfunction onesLike_<T extends Tensor>(x: T|TensorLike): T {\n  const $x = convertToTensor(x, 'x', 'onesLike');\n\n  const inputs: OnesLikeInputs = {x: $x};\n  return ENGINE.runKernel(OnesLike, inputs as {} as NamedTensorMap);\n}\n\nexport const onesLike = op({onesLike_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {Tensor1D, Tensor2D} from '../tensor';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\nimport * as util from '../util';\n\nimport {matMul} from './mat_mul';\nimport {op} from './operation';\nimport {reshape} from './reshape';\n\n/**\n * Computes the outer product of two vectors, `v1` and `v2`.\n *\n * ```js\n * const a = tf.tensor1d([1, 2, 3]);\n * const b = tf.tensor1d([3, 4, 5]);\n *\n * tf.outerProduct(a, b).print();\n * ```\n * @param v1 The first vector in the outer product operation.\n * @param v2 The second vector in the outer product operation.\n *\n * @doc {heading: 'Operations', subheading: 'Matrices'}\n */\nfunction outerProduct_(\n    v1: Tensor1D|TensorLike, v2: Tensor1D|TensorLike): Tensor2D {\n  const $v1 = convertToTensor(v1, 'v1', 'outerProduct');\n  const $v2 = convertToTensor(v2, 'v2', 'outerProduct');\n\n  util.assert(\n      $v1.rank === 1 && $v2.rank === 1,\n      () => `Error in outerProduct: inputs must be rank 1, but got ranks ` +\n          `${$v1.rank} and ${$v2.rank}.`);\n\n  const v12D = reshape($v1, [-1, 1]);\n  const v22D = reshape($v2, [1, -1]);\n  return matMul(v12D, v22D);\n}\n\nexport const outerProduct = op({outerProduct_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {PadV2, PadV2Attrs, PadV2Inputs} from '../kernel_names';\nimport {NamedAttrMap} from '../kernel_registry';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {op} from './operation';\n\n/**\n * Pads a `tf.Tensor` with a given value and paddings.\n *\n * This operation implements `CONSTANT` mode. For `REFLECT` and `SYMMETRIC`,\n * refer to `tf.mirrorPad`.\n *\n * Also available are stricter rank-specific methods with the same signature\n * as this method that assert that `paddings` is of given length.\n *   - `tf.pad1d`\n *   - `tf.pad2d`\n *   - `tf.pad3d`\n *   - `tf.pad4d`\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3, 4]);\n * x.pad([[1, 2]]).print();\n * ```\n * @param x The tensor to pad.\n * @param paddings An array of length `R` (the rank of the tensor), where\n * each element is a length-2 tuple of ints `[padBefore, padAfter]`,\n * specifying how much to pad along each dimension of the tensor.\n * @param constantValue The pad value to use. Defaults to 0.\n *\n * @doc {heading: 'Tensors', subheading: 'Transformations'}\n */\nfunction pad_<T extends Tensor>(\n    x: T|TensorLike, paddings: Array<[number, number]>, constantValue = 0): T {\n  const $x = convertToTensor(x, 'x', 'pad');\n  if ($x.rank === 0) {\n    throw new Error('pad(scalar) is not defined. Pass non-scalar to pad');\n  }\n\n  const attrs: PadV2Attrs = {paddings, constantValue};\n  const inputs: PadV2Inputs = {x: $x};\n  return ENGINE.runKernel(\n      PadV2, inputs as unknown as NamedTensorMap,\n      attrs as unknown as NamedAttrMap);\n}\n\nexport const pad = op({pad_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {Tensor1D} from '../tensor';\nimport {TensorLike} from '../types';\nimport {assert} from '../util';\nimport {op} from './operation';\nimport {pad} from './pad';\n\n/**\n * Pads a `tf.Tensor1D` with a given value and paddings. See `pad` for details.\n */\nfunction pad1d_(\n    x: Tensor1D|TensorLike, paddings: [number, number],\n    constantValue = 0): Tensor1D {\n  assert(\n      paddings.length === 2,\n      () => 'Invalid number of paddings. Must be length of 2.');\n  return pad(x, [paddings], constantValue);\n}\n\nexport const pad1d = op({pad1d_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {Tensor2D} from '../tensor';\nimport {TensorLike} from '../types';\nimport {assert} from '../util';\nimport {op} from './operation';\nimport {pad} from './pad';\n\n/**\n * Pads a `tf.Tensor2D` with a given value and paddings. See `pad` for details.\n */\nfunction pad2d_(\n    x: Tensor2D|TensorLike, paddings: [[number, number], [number, number]],\n    constantValue = 0): Tensor2D {\n  assert(\n      paddings.length === 2 && paddings[0].length === 2 &&\n          paddings[1].length === 2,\n      () => 'Invalid number of paddings. Must be length of 2 each.');\n  return pad(x, paddings, constantValue);\n}\n\nexport const pad2d = op({pad2d_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {Tensor3D} from '../tensor';\nimport {TensorLike} from '../types';\nimport {assert} from '../util';\nimport {op} from './operation';\nimport {pad} from './pad';\n\n/**\n * Pads a `tf.Tensor3D` with a given value and paddings. See `pad` for details.\n */\nfunction pad3d_(\n    x: Tensor3D|TensorLike,\n    paddings: [[number, number], [number, number], [number, number]],\n    constantValue = 0): Tensor3D {\n  assert(\n      paddings.length === 3 && paddings[0].length === 2 &&\n          paddings[1].length === 2 && paddings[2].length === 2,\n      () => 'Invalid number of paddings. Must be length of 2 each.');\n  return pad(x, paddings, constantValue);\n}\n\nexport const pad3d = op({pad3d_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {Tensor4D} from '../tensor';\nimport {TensorLike} from '../types';\nimport {assert} from '../util';\nimport {op} from './operation';\nimport {pad} from './pad';\n\n/**\n * Pads a `tf.Tensor4D` with a given value and paddings. See `pad` for details.\n */\nfunction pad4d_(\n    x: Tensor4D|TensorLike,\n    paddings:\n        [\n          [number, number], [number, number], [number, number], [number, number]\n        ],\n    constantValue = 0): Tensor4D {\n  assert(\n      paddings.length === 4 && paddings[0].length === 2 &&\n          paddings[1].length === 2 && paddings[2].length === 2 &&\n          paddings[3].length === 2,\n      () => 'Invalid number of paddings. Must be length of 2 each.');\n  return pad(x, paddings, constantValue);\n}\n\nexport const pad4d = op({pad4d_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {SpaceToBatchND, SpaceToBatchNDAttrs, SpaceToBatchNDInputs} from '../kernel_names';\nimport {NamedAttrMap} from '../kernel_registry';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\nimport * as util from '../util';\n\nimport {op} from './operation';\n\n/**\n * This operation divides \"spatial\" dimensions `[1, ..., M]` of the input into\n * a grid of blocks of shape `blockShape`, and interleaves these blocks with\n * the \"batch\" dimension (0) such that in the output, the spatial\n * dimensions `[1, ..., M]` correspond to the position within the grid,\n * and the batch dimension combines both the position within a spatial block\n * and the original batch position. Prior to division into blocks,\n * the spatial dimensions of the input are optionally zero padded\n * according to `paddings`. See below for a precise description.\n *\n * ```js\n * const x = tf.tensor4d([1, 2, 3, 4], [1, 2, 2, 1]);\n * const blockShape = [2, 2];\n * const paddings = [[0, 0], [0, 0]];\n *\n * x.spaceToBatchND(blockShape, paddings).print();\n * ```\n *\n * @param x A `tf.Tensor`. N-D with `x.shape` = `[batch] + spatialShape +\n * remainingShape`, where spatialShape has `M` dimensions.\n * @param blockShape A 1-D array. Must have shape `[M]`, all values must\n * be >= 1.\n * @param paddings A 2-D array. Must have shape `[M, 2]`, all values must be >=\n *     0. `paddings[i] = [padStart, padEnd]` specifies the amount to zero-pad\n * from input dimension `i + 1`, which corresponds to spatial dimension `i`. It\n * is required that\n * `(inputShape[i + 1] + padStart + padEnd) % blockShape[i] === 0`\n *\n * This operation is equivalent to the following steps:\n *\n * 1. Zero-pad the start and end of dimensions `[1, ..., M]` of the input\n * according to `paddings` to produce `padded` of shape paddedShape.\n *\n * 2. Reshape `padded` to `reshapedPadded` of shape:\n * `[batch] + [paddedShape[1] / blockShape[0], blockShape[0], ...,\n * paddedShape[M] / blockShape[M-1], blockShape[M-1]] + remainingShape`\n *\n * 3. Permute dimensions of `reshapedPadded` to produce `permutedReshapedPadded`\n * of shape: `blockShape + [batch] + [paddedShape[1] / blockShape[0], ...,\n * paddedShape[M] / blockShape[M-1]] + remainingShape`\n *\n * 4. Reshape `permutedReshapedPadded` to flatten `blockShape` into the\n * batch dimension, producing an output tensor of shape:\n * `[batch * prod(blockShape)] + [paddedShape[1] / blockShape[0], ...,\n * paddedShape[M] / blockShape[M-1]] + remainingShape`\n *\n * @doc {heading: 'Tensors', subheading: 'Transformations'}\n */\nfunction spaceToBatchND_<T extends Tensor>(\n    x: T|TensorLike, blockShape: number[], paddings: number[][]): T {\n  const $x = convertToTensor(x, 'x', 'spaceToBatchND');\n\n  util.assert(\n      $x.rank >= 1 + blockShape.length,\n      () => `input rank ${$x.rank} should be > than [blockShape] ${\n          blockShape.length}`);\n\n  util.assert(\n      paddings.length === blockShape.length,\n      () => `paddings.shape[0] ${\n          paddings.length} must be equal to [blockShape] ${blockShape.length}`);\n\n  util.assert(\n      $x.shape.reduce(\n          (a, b, i) => {\n            if (i > 0 && i <= blockShape.length) {\n              return a &&\n                  ((b + paddings[i - 1][0] + paddings[i - 1][1]) %\n                       blockShape[i - 1] ===\n                   0);\n            }\n            return a;\n          },\n          true),\n      () => `input spatial dimensions ${$x.shape.slice(1)} with paddings ${\n          paddings.toString()} must be divisible by blockShapes ${\n          blockShape.toString()}`);\n\n  const inputs: SpaceToBatchNDInputs = {x: $x};\n  const attrs: SpaceToBatchNDAttrs = {blockShape, paddings};\n\n  return ENGINE.runKernel(\n      SpaceToBatchND, inputs as {} as NamedTensorMap,\n      attrs as {} as NamedAttrMap);\n}\n\nexport const spaceToBatchND = op({spaceToBatchND_});\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor3D, Tensor4D} from '../tensor';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\nimport * as util from '../util';\n\nimport {avgPool} from './avg_pool';\nimport {batchToSpaceND} from './batch_to_space_nd';\nimport * as conv_util from './conv_util';\nimport {maxPool} from './max_pool';\nimport {op} from './operation';\nimport {reshape} from './reshape';\nimport {spaceToBatchND} from './space_to_batch_nd';\n\n/**\n * Performs an N-D pooling operation\n *\n * @param input The input tensor, of rank 4 or rank 3 of shape\n *     `[batch, height, width, inChannels]`. If rank 3, batch of 1 is assumed.\n * @param windowShape The filter size: `[filterHeight, filterWidth]`. If\n *     `filterSize` is a single number, then `filterHeight == filterWidth`.\n * @param poolingType The type of pooling, either 'max' or 'avg'.\n * @param pad The type of padding algorithm:\n *    - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *    - `valid`: output will be smaller than input if filter is larger\n *       than 1x1.\n *    - For more info, see this guide:\n *     [https://www.tensorflow.org/api_guides/python/nn#Convolution](\n *         https://www.tensorflow.org/api_guides/python/nn#Convolution)\n * @param dilations The dilation rates: `[dilationHeight, dilationWidth]`\n *     in which we sample input values across the height and width dimensions\n *     in dilated pooling. Defaults to `[1, 1]`. If `dilationRate` is a single\n *     number, then `dilationHeight == dilationWidth`. If it is greater than\n *     1, then all values of `strides` must be 1.\n * @param strides The strides of the pooling: `[strideHeight, strideWidth]`. If\n *     `strides` is a single number, then `strideHeight == strideWidth`.\n * @param dimRoundingMode A string from: 'ceil', 'round', 'floor'. If none is\n *     provided, it will default to truncate.\n *\n * @doc {heading: 'Operations', subheading: 'Convolution'}\n */\nfunction pool_<T extends Tensor3D|Tensor4D>(\n    input: T|TensorLike, windowShape: [number, number]|number,\n    poolingType: 'avg'|'max',\n    pad: 'valid'|'same'|number|conv_util.ExplicitPadding,\n    dilations?: [number, number]|number, strides?: [number, number]|number,\n    dimRoundingMode?: 'floor'|'round'|'ceil') {\n  if (dilations == null) {\n    dilations = [1, 1];\n  }\n  if (strides == null) {\n    strides = 1;\n  }\n  if (pad === 0) {\n    pad = 'valid';\n  }\n\n  const $x = convertToTensor(input, 'x', 'maxPool');\n  let x4D = $x as Tensor4D;\n  let reshapedTo4D = false;\n\n  if ($x.rank === 3) {\n    reshapedTo4D = true;\n    x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);\n  }\n\n  util.assert(\n      conv_util.eitherStridesOrDilationsAreOne(strides, dilations),\n      () => 'Error in pool: Either strides or dilations must be 1. ' +\n          `Got strides ${strides} and dilations '${dilations}'`);\n\n  const convInfo = conv_util.computePool2DInfo(\n      x4D.shape, windowShape, strides, dilations, pad);\n  const dilation: [number, number] =\n      [convInfo.dilationHeight, convInfo.dilationWidth];\n\n  // The following implementation does batchToSpace(pool(spaceToBatch(x)))\n  // whenever dilation > 1 since the TF kernels do not support dilation > 1.\n  // tslint:disable-next-line:max-line-length\n  // https://github.com/tensorflow/tensorflow/blob/50f6bb67dc98c9b74630b6047aae7a4f8a40fd02/tensorflow/python/ops/nn_ops.py#L1037\n\n  let basePadding: number[][];\n  if (pad === 'same') {\n    basePadding = withSpaceToBatchBasePaddings(\n        [convInfo.filterHeight, convInfo.filterWidth], dilation);\n  } else {\n    basePadding = [[0, 0], [0, 0]];\n  }\n\n  const isDilationOne = dilation[0] === 1 && dilation[1] === 1;\n  const [adjustedPadding, adjustedCrops] = requiredSpaceToBatchPaddings(\n      [convInfo.inHeight, convInfo.inWidth], dilation, basePadding);\n  const convertedPad = isDilationOne ? pad : 'valid';\n  const convertedX =\n      isDilationOne ? x4D : spaceToBatchND(x4D, dilation, adjustedPadding);\n\n  const forwardOp = poolingType === 'avg' ?\n      () => avgPool(convertedX, windowShape, strides, convertedPad,\n                    dimRoundingMode) :\n      () => maxPool(convertedX, windowShape, strides, convertedPad,\n                    dimRoundingMode);\n  const y = forwardOp();\n\n  const res = isDilationOne ? y : batchToSpaceND(y, dilation, adjustedCrops);\n\n  if (reshapedTo4D) {\n    return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]) as T;\n  }\n\n  return res as T;\n}\n\n// Helper function to compute crops and paddings for pool with dilation > 1.\n// tslint:disable-next-line:max-line-length\n// https://github.com/tensorflow/tensorflow/blob/50f6bb67dc98c9b74630b6047aae7a4f8a40fd02/tensorflow/python/ops/array_ops.py#L2184\nfunction requiredSpaceToBatchPaddings(\n    inputShape: [number, number], blockShape: [number, number],\n    basePadding: number[][]) {\n  const padStart = basePadding.map(b => b[0]);\n  const origPadEnd = basePadding.map(b => b[1]);\n  const fullInputShape = inputShape.concat(padStart, origPadEnd);\n  const padEndExtra = blockShape.map((b, i) => (b - fullInputShape[i] % b) % b);\n  const padEnd = origPadEnd.map((s, i) => s + padEndExtra[i]);\n  const paddings = blockShape.map((_, i) => [padStart[i], padEnd[i]]);\n  const crops = blockShape.map((_, i) => [0, padEndExtra[i]]);\n  return [paddings, crops];\n}\n\n// Helper function to compute base paddings for pool with dilation > 1.\n// tslint:disable-next-line:max-line-length\n// https://github.com/tensorflow/tensorflow/blob/50f6bb67dc98c9b74630b6047aae7a4f8a40fd02/tensorflow/python/ops/nn_ops.py#L524\nfunction withSpaceToBatchBasePaddings(\n    filterShape: [number, number], dilation: [number, number]) {\n  // Spatial dimensions of the filters and the upsampled filters in which we\n  // introduce (rate - 1) zeros between consecutive filter values.\n  const dilatedFilterShape = filterShape.map((s, i) => {\n    return s + (s - 1) * (dilation[i] - 1);\n  });\n  const padExtraShape = dilatedFilterShape.map(s => s - 1);\n\n  // When padding is odd, we pad more at end, following the same\n  // convention as conv2d.\n  const padExtraStart = padExtraShape.map(s => Math.floor(s / 2));\n  const padExtraEnd = padExtraShape.map((s, i) => s - padExtraStart[i]);\n  return padExtraShape.map((_, i) => {\n    return [padExtraStart[i], padExtraEnd[i]];\n  });\n}\n\nexport const pool = op({pool_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {Prelu, PreluInputs} from '../kernel_names';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {op} from './operation';\n\n/**\n * Computes leaky rectified linear element-wise with parametric alphas.\n *\n * `x < 0 ? alpha * x : f(x) = x`\n *\n * ```js\n * const x = tf.tensor1d([-1, 2, -3, 4]);\n * const alpha = tf.scalar(0.1);\n *\n * x.prelu(alpha).print();  // or tf.prelu(x, alpha)\n * ```\n * @param x The input tensor.\n * @param alpha Scaling factor for negative values.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction prelu_<T extends Tensor>(x: T|TensorLike, alpha: T|TensorLike): T {\n  const $x = convertToTensor(x, 'x', 'prelu');\n  const $alpha = convertToTensor(alpha, 'alpha', 'prelu');\n\n  const inputs: PreluInputs = {x: $x, alpha: $alpha};\n  return ENGINE.runKernel(Prelu, inputs as {} as NamedTensorMap);\n}\n\nexport const prelu = op({prelu_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {Prod, ProdAttrs, ProdInputs} from '../kernel_names';\nimport {NamedAttrMap} from '../kernel_registry';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {cast} from './cast';\nimport {op} from './operation';\n\n/**\n * Computes the product of elements across dimensions of a `tf.Tensor`.\n *\n * Reduces the input along the dimensions given in `axes`. Unless `keepDims`\n * is true, the rank of the `tf.Tensor` is reduced by 1 for each entry in\n * `axes`. If `keepDims` is true, the reduced dimensions are retained with\n * length 1. If `axes` has no entries, all dimensions are reduced, and a\n * `tf.Tensor` with a single element is returned.\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3]);\n *\n * x.prod().print();  // or tf.prod(x)\n * ```\n *\n * ```js\n * const x = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n *\n * const axis = 1;\n * x.prod(axis).print();  // or tf.prod(x, axis)\n * ```\n *\n * @param x The input tensor to compute the product over. If the dtype is `bool`\n *   it will be converted to `int32` and the output dtype will be `int32`.\n * @param axis The dimension(s) to reduce. By default it reduces\n *     all dimensions.\n * @param keepDims If true, retains reduced dimensions with size 1.\n *\n * @doc {heading: 'Operations', subheading: 'Reduction'}\n */\nfunction prod_<T extends Tensor>(\n    x: Tensor|TensorLike, axis: number|number[] = null, keepDims = false): T {\n  let $x = convertToTensor(x, 'x', 'prod');\n\n  if ($x.dtype === 'bool') {\n    // bool is not an allowed type for the underlying kernel.\n    $x = cast($x, 'int32');\n  }\n\n  const inputs: ProdInputs = {x: $x};\n  const attrs: ProdAttrs = {axis, keepDims};\n\n  return ENGINE.runKernel(\n      Prod, inputs as {} as NamedTensorMap, attrs as {} as NamedAttrMap);\n}\n\nexport const prod = op({prod_});\n","/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {RaggedGather, RaggedGatherAttrs, RaggedGatherInputs} from '../kernel_names';\nimport {Tensor} from '../tensor';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\nimport {op} from './operation';\n\n/**\n * Gather ragged slices from params axis 0 according to indices.\n *\n * @param paramsNestedSplits: A list of at least 1 Tensor with type 'int32' The\n *     nestedRowSplits tensors that define the row-partitioning for the params\n *     RaggedTensor input.\n * @param paramsDenseValues: A Tensor. The flatValues for the params\n *     RaggedTensor.\n * @param indices: A Tensor. Must be one of type: int32. Indices in the\n *     outermost dimension of params of the values that should be gathered.\n * @param outputRaggedRank: An int that is >= 0. The ragged rank of the output\n *     RaggedTensor. outputNestedSplits will contain this number of rowSplits\n *     tensors. This value should equal indices.shape.ndims + params.raggedRank\n *     - 1.\n * @return A map with the following properties:\n *     - outputNestedSplits: A list of outputRaggedRank Tensor objects with the\n * same type as paramsNestedSplits.\n *     - outputDenseValues: A Tensor. Has the same type as paramsDenseValues.\n * @doc {heading: 'Operations', subheading: 'Ragged'}\n */\n\ninterface RaggedGatherMap {\n  outputNestedSplits: Tensor[];\n  outputDenseValues: Tensor;\n}\n\nfunction raggedGather_(\n    paramsNestedSplits: Tensor[], paramsDenseValues: Tensor|TensorLike,\n    indices: Tensor|TensorLike, outputRaggedRank: number): RaggedGatherMap {\n  const $paramsNestedSplits = paramsNestedSplits.map(\n      (t, i) => convertToTensor(t, `tensors${i}`, 'raggedGather', 'int32'));\n  const $paramsDenseValues =\n      convertToTensor(paramsDenseValues, 'paramsDenseValues', 'raggedGather');\n  const $indices = convertToTensor(indices, 'indices', 'raggedGather', 'int32');\n\n  const inputs: RaggedGatherInputs = {\n    paramsNestedSplits: $paramsNestedSplits,\n    paramsDenseValues: $paramsDenseValues,\n    indices: $indices,\n  };\n  const attrs: RaggedGatherAttrs = {outputRaggedRank};\n\n  const result: Tensor[] =\n      ENGINE.runKernel(RaggedGather, inputs as {}, attrs as {});\n  return {\n    outputNestedSplits: result.slice(0, result.length - 1),\n    outputDenseValues: result[result.length - 1],\n  };\n}\n\nexport const raggedGather = op({raggedGather_});\n","/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {RaggedTensorToTensor, RaggedTensorToTensorAttrs, RaggedTensorToTensorInputs} from '../kernel_names';\nimport {Tensor} from '../tensor';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\nimport {op} from './operation';\n\n/**\n * Create a dense tensor from a ragged tensor, possibly altering its shape.\n *\n * The raggedTensorToTensor op creates a dense tensor from am array of row\n * partition tensors, a value vector, and default values. If the shape is\n * unspecified, the minimal shape required to contain all the elements in the\n * ragged tensor (the natural shape) will be used. If some dimensions are left\n * unspecified, then the size of the natural shape is used in that dimension.\n *\n * The defaultValue will be broadcast to the output shape. After that, the\n * values from the ragged tensor overwrite the default values. Note that the\n * defaultValue must have less dimensions than the value.\n *\n * The row partition tensors are in the order of the dimensions. At present, the\n * types can be: \"ROW_SPLITS\": the row_splits tensor from the ragged tensor.\n *   \"VALUE_ROWIDS\": the value_rowids tensor from the ragged tensor.\n *   \"FIRST_DIM_SIZE\": if value_rowids is used for the first dimension, then it\n * is preceded by \"FIRST_DIM_SIZE\".\n * ```\n * @param shape: A Tensor. Must be one of the following types: 'int32'. The\n *     desired shape of the output tensor. If left unspecified (empty), the\n *     minimal shape required to contain all the elements in the ragged tensor\n *     (the natural shape) will be used. If some dimensions are left\n *     unspecified, then the size of the natural shape is used in that\n *     dimension.\n *\n *     Note that dense dimensions cannot be modified by the shape argument.\n *     Trying to change the size of a dense dimension will cause the op to fail.\n *     Examples: natural shape: [4, 5, 6] shape: -1 output shape: [4, 5, 6]\n *\n *     natural shape: [4, 5, 6] shape: [3, -1, 2] output shape: [3, 5, 2]\n *\n *     natural shape: [4, 5, 6] shape: [3, 7, 2] output shape: [3, 7, 2]\n * @param values: A Tensor. A 1D tensor representing the values of the ragged\n *     tensor.\n * @param defaultValue: A Tensor. Must have the same type as values. The\n *     defaultValue when the shape is larger than the ragged tensor. The\n *     defaultValue is broadcast until it is the shape of the output tensor,\n *     and then overwritten by values in the ragged tensor. The default value\n *     must be compatible with this broadcast operation, and must have fewer\n *     dimensions than the value tensor.\n * @param rowPartitionTensors: A list of at least 1 Tensor objects with the same\n *     type in: 'int32'.\n * @param rowPartitionTypes: A list of strings. The types of the row partition\n *     tensors. At present, these can be:\n *     \"ROW_SPLITS\": the row_splits tensor from the ragged tensor.\n *     \"VALUE_ROWIDS\": the value_rowids tensor from the ragged tensor.\n *     \"FIRST_DIM_SIZE\": if value_rowids is used for the first dimension, then\n *         it is preceeded by \"FIRST_DIM_SIZE\". The tensors are in the order of\n *         the dimensions.\n * @return A Tensor. Has the same type as values.\n * @doc {heading: 'Operations', subheading: 'Ragged'}\n */\nfunction raggedTensorToTensor_(\n    shape: Tensor|TensorLike, values: Tensor|TensorLike,\n    defaultValue: Tensor|TensorLike, rowPartitionTensors: Tensor[],\n    rowPartitionTypes: string[]): Tensor {\n  const $shape =\n      convertToTensor(shape, 'shape', 'raggedTensorToTensor', 'int32');\n  const $values = convertToTensor(values, 'values', 'raggedTensorToTensor');\n  const $defaultValue = convertToTensor(\n      defaultValue, 'defaultValue', 'raggedTensorToTensor', $values.dtype);\n  const $rowPartitionTensors = rowPartitionTensors.map(\n      (t, i) =>\n          convertToTensor(t, `tensors${i}`, 'raggedTensorToTensor', 'int32'));\n\n  const inputs: RaggedTensorToTensorInputs = {\n    shape: $shape,\n    values: $values,\n    defaultValue: $defaultValue,\n    rowPartitionTensors: $rowPartitionTensors\n  };\n  const attrs: RaggedTensorToTensorAttrs = {rowPartitionTypes};\n\n  return ENGINE.runKernel(RaggedTensorToTensor, inputs as {}, attrs as {});\n}\n\nexport const raggedTensorToTensor = op({raggedTensorToTensor_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {Tensor} from '../tensor';\nimport {DataType, Rank, ShapeMap} from '../types';\nimport {sizeFromShape} from '../util';\n\nimport {op} from './operation';\n\n/**\n * Creates a `tf.Tensor` with values sampled from a random number generator\n * function defined by the user.\n *\n * @param shape An array of integers defining the output tensor shape.\n * @param randFunction A random number generator function which is called\n * for each element in the output tensor.\n * @param dtype The data type of the output tensor. Defaults to 'float32'.\n *\n * @doc {heading: 'Tensors', subheading: 'Random'}\n */\nfunction rand_<R extends Rank>(\n    shape: ShapeMap[R], randFunction: () => number,\n    dtype?: DataType): Tensor<R> {\n  const size = sizeFromShape(shape);\n  let values = null;\n  if (dtype == null || dtype === 'float32') {\n    values = new Float32Array(size);\n  } else if (dtype === 'int32') {\n    values = new Int32Array(size);\n  } else if (dtype === 'bool') {\n    values = new Uint8Array(size);\n  } else {\n    throw new Error(`Unknown data type ${dtype}`);\n  }\n  for (let i = 0; i < size; i++) {\n    values[i] = randFunction();\n  }\n  return ENGINE.makeTensor(values, shape, dtype) as Tensor<R>;\n}\n\nexport const rand = op({rand_});\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as seedrandom from 'seedrandom';\n\nimport {expectNumbersClose, testEpsilon} from '../test_util';\nimport {TypedArray} from '../types';\n\nexport interface RandomBase {\n  nextValue(): number;\n}\n\nexport interface RandomGamma {\n  nextValue(): number;\n}\n\nexport interface RandNormalDataTypes {\n  float32: Float32Array;\n  int32: Int32Array;\n}\n\nexport interface RandGammaDataTypes {\n  float32: Float32Array;\n  int32: Int32Array;\n}\n\n// https://en.wikipedia.org/wiki/Marsaglia_polar_method\nexport class MPRandGauss implements RandomBase {\n  private mean: number;\n  private stdDev: number;\n  private nextVal: number;\n  private dtype?: keyof RandNormalDataTypes;\n  private truncated?: boolean;\n  private upper?: number;\n  private lower?: number;\n  private random: seedrandom.prng;\n\n  constructor(\n      mean: number, stdDeviation: number, dtype?: keyof RandNormalDataTypes,\n      truncated?: boolean, seed?: number) {\n    this.mean = mean;\n    this.stdDev = stdDeviation;\n    this.dtype = dtype;\n    this.nextVal = NaN;\n    this.truncated = truncated;\n    if (this.truncated) {\n      this.upper = this.mean + this.stdDev * 2;\n      this.lower = this.mean - this.stdDev * 2;\n    }\n    const seedValue = seed ? seed : Math.random();\n    this.random = seedrandom.alea(seedValue.toString());\n  }\n\n  /** Returns next sample from a Gaussian distribution. */\n  public nextValue(): number {\n    if (!isNaN(this.nextVal)) {\n      const value = this.nextVal;\n      this.nextVal = NaN;\n      return value;\n    }\n\n    let resultX: number, resultY: number;\n    let isValid = false;\n    while (!isValid) {\n      let v1: number, v2: number, s: number;\n      do {\n        v1 = 2 * this.random() - 1;\n        v2 = 2 * this.random() - 1;\n        s = v1 * v1 + v2 * v2;\n      } while (s >= 1 || s === 0);\n\n      const mul = Math.sqrt(-2.0 * Math.log(s) / s);\n      resultX = this.mean + this.stdDev * v1 * mul;\n      resultY = this.mean + this.stdDev * v2 * mul;\n\n      if (!this.truncated || this.isValidTruncated(resultX)) {\n        isValid = true;\n      }\n    }\n\n    if (!this.truncated || this.isValidTruncated(resultY)) {\n      this.nextVal = this.convertValue(resultY);\n    }\n    return this.convertValue(resultX);\n  }\n\n  /** Handles proper rounding for non-floating-point numbers. */\n  private convertValue(value: number): number {\n    if (this.dtype == null || this.dtype === 'float32') {\n      return value;\n    }\n    return Math.round(value);\n  }\n\n  /** Returns true if less than 2-standard-deviations from the mean. */\n  private isValidTruncated(value: number): boolean {\n    return value <= this.upper && value >= this.lower;\n  }\n}\n\n// Marsaglia, George, and Wai Wan Tsang. 2000. \"A Simple Method for Generating\n// Gamma Variables.\"\nexport class RandGamma implements RandomGamma {\n  private alpha: number;\n  private beta: number;\n  private d: number;\n  private c: number;\n  private dtype?: keyof RandGammaDataTypes;\n  private randu: seedrandom.prng;\n  private randn: MPRandGauss;\n\n  constructor(\n      alpha: number, beta: number, dtype: keyof RandGammaDataTypes,\n      seed?: number) {\n    this.alpha = alpha;\n    this.beta = 1 / beta;  // convert rate to scale parameter\n    this.dtype = dtype;\n\n    const seedValue = seed ? seed : Math.random();\n    this.randu = seedrandom.alea(seedValue.toString());\n    this.randn = new MPRandGauss(0, 1, dtype, false, this.randu());\n\n    if (alpha < 1) {\n      this.d = alpha + (2 / 3);\n    } else {\n      this.d = alpha - (1 / 3);\n    }\n    this.c = 1 / Math.sqrt(9 * this.d);\n  }\n\n  /** Returns next sample from a gamma distribution. */\n  public nextValue(): number {\n    let x2: number, v0: number, v1: number, x: number, u: number, v: number;\n    while (true) {\n      do {\n        x = this.randn.nextValue();\n        v = 1 + (this.c * x);\n      } while (v <= 0);\n      v *= v * v;\n      x2 = x * x;\n      v0 = 1 - (0.331 * x2 * x2);\n      v1 = (0.5 * x2) + (this.d * (1 - v + Math.log(v)));\n      u = this.randu();\n      if (u < v0 || Math.log(u) < v1) {\n        break;\n      }\n    }\n    v = (1 / this.beta) * this.d * v;\n    if (this.alpha < 1) {\n      v *= Math.pow(this.randu(), 1 / this.alpha);\n    }\n    return this.convertValue(v);\n  }\n  /** Handles proper rounding for non-floating-point numbers. */\n  private convertValue(value: number): number {\n    if (this.dtype === 'float32') {\n      return value;\n    }\n    return Math.round(value);\n  }\n}\n\nexport class UniformRandom implements RandomBase {\n  private min: number;\n  private range: number;\n  private random: seedrandom.prng;\n  private dtype?: keyof RandNormalDataTypes;\n\n  constructor(\n      min = 0, max = 1, dtype?: keyof RandNormalDataTypes,\n      seed?: string|number) {\n    this.min = min;\n    this.range = max - min;\n    this.dtype = dtype;\n    if (seed == null) {\n      seed = Math.random();\n    }\n    if (typeof seed === 'number') {\n      seed = seed.toString();\n    }\n\n    if (!this.canReturnFloat() && this.range <= 1) {\n      throw new Error(\n          `The difference between ${min} - ${max} <= 1 and dtype is not float`);\n    }\n    this.random = seedrandom.alea(seed);\n  }\n\n  /** Handles proper rounding for non floating point numbers. */\n  private canReturnFloat = () =>\n      (this.dtype == null || this.dtype === 'float32');\n\n  private convertValue(value: number): number {\n    if (this.canReturnFloat()) {\n      return value;\n    }\n    return Math.round(value);\n  }\n\n  nextValue() {\n    return this.convertValue(this.min + this.range * this.random());\n  }\n}\n\nexport function jarqueBeraNormalityTest(values: TypedArray|number[]) {\n  // https://en.wikipedia.org/wiki/Jarque%E2%80%93Bera_test\n  const n = values.length;\n  const s = skewness(values);\n  const k = kurtosis(values);\n  const jb = n / 6 * (Math.pow(s, 2) + 0.25 * Math.pow(k - 3, 2));\n  // JB test requires 2-degress of freedom from Chi-Square @ 0.95:\n  // http://www.itl.nist.gov/div898/handbook/eda/section3/eda3674.htm\n  const CHI_SQUARE_2DEG = 5.991;\n  if (jb > CHI_SQUARE_2DEG) {\n    throw new Error(`Invalid p-value for JB: ${jb}`);\n  }\n}\n\nexport function expectArrayInMeanStdRange(\n    actual: TypedArray|number[], expectedMean: number, expectedStdDev: number,\n    epsilon?: number) {\n  if (epsilon == null) {\n    epsilon = testEpsilon();\n  }\n  const actualMean = mean(actual);\n  expectNumbersClose(actualMean, expectedMean, epsilon);\n  expectNumbersClose(\n      standardDeviation(actual, actualMean), expectedStdDev, epsilon);\n}\n\nfunction mean(values: TypedArray|number[]) {\n  let sum = 0;\n  for (let i = 0; i < values.length; i++) {\n    sum += values[i];\n  }\n  return sum / values.length;\n}\n\nfunction standardDeviation(values: TypedArray|number[], mean: number) {\n  let squareDiffSum = 0;\n  for (let i = 0; i < values.length; i++) {\n    const diff = values[i] - mean;\n    squareDiffSum += diff * diff;\n  }\n  return Math.sqrt(squareDiffSum / values.length);\n}\n\nfunction kurtosis(values: TypedArray|number[]) {\n  // https://en.wikipedia.org/wiki/Kurtosis\n  const valuesMean = mean(values);\n  const n = values.length;\n  let sum2 = 0;\n  let sum4 = 0;\n  for (let i = 0; i < n; i++) {\n    const v = values[i] - valuesMean;\n    sum2 += Math.pow(v, 2);\n    sum4 += Math.pow(v, 4);\n  }\n  return (1 / n) * sum4 / Math.pow((1 / n) * sum2, 2);\n}\n\nfunction skewness(values: TypedArray|number[]) {\n  // https://en.wikipedia.org/wiki/Skewness\n  const valuesMean = mean(values);\n  const n = values.length;\n  let sum2 = 0;\n  let sum3 = 0;\n  for (let i = 0; i < n; i++) {\n    const v = values[i] - valuesMean;\n    sum2 += Math.pow(v, 2);\n    sum3 += Math.pow(v, 3);\n  }\n  return (1 / n) * sum3 / Math.pow((1 / (n - 1)) * sum2, 3 / 2);\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor} from '../tensor';\nimport {Rank, ShapeMap} from '../types';\n\nimport {buffer} from './buffer';\nimport {op} from './operation';\nimport {RandGamma} from './rand_util';\n\n/**\n * Creates a `tf.Tensor` with values sampled from a gamma distribution.\n *\n * ```js\n * tf.randomGamma([2, 2], 1).print();\n * ```\n *\n * @param shape An array of integers defining the output tensor shape.\n * @param alpha The shape parameter of the gamma distribution.\n * @param beta The inverse scale parameter of the gamma distribution. Defaults\n *     to 1.\n * @param dtype The data type of the output. Defaults to float32.\n * @param seed The seed for the random number generator.\n *\n * @doc {heading: 'Tensors', subheading: 'Random'}\n */\nfunction randomGamma_<R extends Rank>(\n    shape: ShapeMap[R], alpha: number, beta = 1,\n    dtype: 'float32'|'int32' = 'float32', seed?: number): Tensor<R> {\n  if (beta == null) {\n    beta = 1;\n  }\n  if (dtype == null) {\n    dtype = 'float32';\n  }\n  if (dtype !== 'float32' && dtype !== 'int32') {\n    throw new Error(`Unsupported data type ${dtype}`);\n  }\n  const rgamma = new RandGamma(alpha, beta, dtype, seed);\n  const res = buffer(shape, dtype);\n  for (let i = 0; i < res.values.length; i++) {\n    res.values[i] = rgamma.nextValue();\n  }\n  return res.toTensor();\n}\n\nexport const randomGamma = op({randomGamma_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor} from '../tensor';\nimport {DataType, Rank, ShapeMap} from '../types';\n\nimport {buffer} from './buffer';\nimport {op} from './operation';\nimport {MPRandGauss} from './rand_util';\n\n/**\n * Creates a `tf.Tensor` with values sampled from a normal distribution.\n *\n * ```js\n * tf.randomNormal([2, 2]).print();\n * ```\n *\n * @param shape An array of integers defining the output tensor shape.\n * @param mean The mean of the normal distribution.\n * @param stdDev The standard deviation of the normal distribution.\n * @param dtype The data type of the output.\n * @param seed The seed for the random number generator.\n *\n * @doc {heading: 'Tensors', subheading: 'Random'}\n */\nfunction randomNormal_<R extends Rank>(\n    shape: ShapeMap[R], mean = 0, stdDev = 1, dtype?: 'float32'|'int32',\n    seed?: number): Tensor<R> {\n  if (dtype != null && (dtype as DataType) === 'bool') {\n    throw new Error(`Unsupported data type ${dtype}`);\n  }\n  const randGauss =\n      new MPRandGauss(mean, stdDev, dtype, false /* truncated */, seed);\n  const res = buffer(shape, dtype);\n  for (let i = 0; i < res.values.length; i++) {\n    res.values[i] = randGauss.nextValue();\n  }\n  return res.toTensor();\n}\n\nexport const randomNormal = op({randomNormal_});\n","/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor} from '../tensor';\nimport {DataType, Rank, ShapeMap} from '../types';\n\nimport {op} from './operation';\nimport {randomNormal} from './random_normal';\n\n/**\n * Creates a `tf.Tensor` with values sampled from a normal distribution.\n *\n * The generated values will have mean 0 and standard deviation 1.\n *\n * ```js\n * tf.randomStandardNormal([2, 2]).print();\n * ```\n *\n * @param shape An array of integers defining the output tensor shape.\n * @param dtype The data type of the output.\n * @param seed The seed for the random number generator.\n *\n * @doc {heading: 'Tensors', subheading: 'Random'}\n */\nfunction randomStandardNormal_<R extends Rank>(\n    shape: ShapeMap[R], dtype?: 'float32'|'int32', seed?: number): Tensor<R> {\n  if (dtype != null && (dtype as DataType) === 'bool') {\n    throw new Error(`Unsupported data type ${dtype}`);\n  }\n  return randomNormal(shape, 0, 1, dtype, seed);\n}\n\nexport const randomStandardNormal = op({randomStandardNormal_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor} from '../tensor';\nimport {DataType, Rank, ShapeMap} from '../types';\n\nimport {buffer} from './buffer';\nimport {op} from './operation';\nimport {UniformRandom} from './rand_util';\n\n/**\n * Creates a `tf.Tensor` with values sampled from a uniform distribution.\n *\n * The generated values follow a uniform distribution in the range [minval,\n * maxval). The lower bound minval is included in the range, while the upper\n * bound maxval is excluded.\n *\n * ```js\n * tf.randomUniform([2, 2]).print();\n * ```\n *\n * @param shape An array of integers defining the output tensor shape.\n * @param minval The lower bound on the range of random values to generate.\n *   Defaults to 0.\n * @param maxval The upper bound on the range of random values to generate.\n *   Defaults to 1.\n * @param dtype The data type of the output tensor. Defaults to 'float32'.\n *\n * @doc {heading: 'Tensors', subheading: 'Random'}\n */\nfunction randomUniform_<R extends Rank>(\n    shape: ShapeMap[R], minval = 0, maxval = 1, dtype: DataType = 'float32',\n    seed?: number|string): Tensor<R> {\n  const res = buffer(shape, dtype);\n  const random = new UniformRandom(minval, maxval, null, seed);\n  for (let i = 0; i < res.values.length; i++) {\n    res.values[i] = random.nextValue();\n  }\n  return res.toTensor();\n}\n\nexport const randomUniform = op({randomUniform_});\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {Range, RangeAttrs} from '../kernel_names';\nimport {NamedAttrMap} from '../kernel_registry';\nimport {Tensor1D} from '../tensor';\n\n/**\n * Creates a new `tf.Tensor1D` filled with the numbers in the range provided.\n *\n * The tensor is a half-open interval meaning it includes start, but\n * excludes stop. Decrementing ranges and negative step values are also\n * supported.\n *\n *\n * ```js\n * tf.range(0, 9, 2).print();\n * ```\n *\n * @param start An integer start value\n * @param stop An integer stop value\n * @param step An integer increment (will default to 1 or -1)\n * @param dtype The data type of the output tensor. Defaults to 'float32'.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nexport function range(\n    start: number, stop: number, step = 1,\n    dtype: 'float32'|'int32' = 'float32'): Tensor1D {\n  if (step === 0) {\n    throw new Error('Cannot have a step of zero');\n  }\n\n  const attrs: RangeAttrs = {start, stop, step, dtype};\n\n  return ENGINE.runKernel(Range, {} /* inputs */, attrs as {} as NamedAttrMap);\n}\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {Reciprocal, ReciprocalInputs} from '../kernel_names';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {op} from './operation';\n\n/**\n * Computes reciprocal of x element-wise: `1 / x`\n *\n * ```js\n * const x = tf.tensor1d([0, 1, 2]);\n *\n * x.reciprocal().print();  // or tf.reciprocal(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction reciprocal_<T extends Tensor>(x: T|TensorLike): T {\n  const $x = convertToTensor(x, 'x', 'reciprocal');\n\n  const inputs: ReciprocalInputs = {x: $x};\n  return ENGINE.runKernel(Reciprocal, inputs as {} as NamedTensorMap);\n}\nexport const reciprocal = op({reciprocal_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {Relu, ReluInputs} from '../kernel_names';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {op} from './operation';\n\n/**\n * Computes rectified linear element-wise: `max(x, 0)`.\n *\n * ```js\n * const x = tf.tensor1d([-1, 2, -3, 4]);\n *\n * x.relu().print();  // or tf.relu(x)\n * ```\n * @param x The input tensor. If the dtype is `bool`, the output dtype will be\n *     `int32`.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction relu_<T extends Tensor>(x: T|TensorLike): T {\n  const $x = convertToTensor(x, 'x', 'relu');\n\n  const inputs: ReluInputs = {x: $x};\n\n  return ENGINE.runKernel(Relu, inputs as {} as NamedTensorMap);\n}\n\nexport const relu = op({relu_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {Relu6, Relu6Inputs} from '../kernel_names';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {op} from './operation';\n\n/**\n * Computes rectified linear 6 element-wise: `min(max(x, 0), 6)`.\n *\n * ```js\n * const x = tf.tensor1d([-1, 2, -3, 8]);\n *\n * x.relu6().print();  // or tf.relu6(x)\n * ```\n * @param x The input tensor. If the dtype is `bool`, the output dtype will be\n *     `int32`.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction relu6_<T extends Tensor>(x: T|TensorLike): T {\n  const $x = convertToTensor(x, 'x', 'relu6');\n\n  const inputs: Relu6Inputs = {x: $x};\n\n  return ENGINE.runKernel(Relu6, inputs as {} as NamedTensorMap);\n}\n\nexport const relu6 = op({relu6_});\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {Reverse, ReverseAttrs, ReverseInputs} from '../kernel_names';\nimport {NamedAttrMap} from '../kernel_registry';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {op} from './operation';\n\n/**\n * Reverses a `tf.Tensor` along a specified axis.\n *\n * Also available are stricter rank-specific methods that assert that `x` is\n * of the given rank:\n *   - `tf.reverse1d`\n *   - `tf.reverse2d`\n *   - `tf.reverse3d`\n *   - `tf.reverse4d`\n *\n * Except `tf.reverse1d` (which does not have axis param), all methods have\n * same signature as this method.\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3, 4]);\n *\n * x.reverse().print();\n * ```\n *\n * ```js\n * const x = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n *\n * const axis = 1;\n * x.reverse(axis).print();\n * ```\n * @param x The input tensor to be reversed.\n * @param axis The set of dimensions to reverse. Must be in the\n *     range [-rank(x), rank(x)). Defaults to all axes.\n *\n * @doc {heading: 'Tensors', subheading: 'Slicing and Joining'}\n */\nfunction reverse_<T extends Tensor>(\n    x: T|TensorLike, axis?: number|number[]): T {\n  const $x = convertToTensor(x, 'x', 'reverse');\n\n  const inputs: ReverseInputs = {x: $x};\n  const attrs: ReverseAttrs = {dims: axis};\n\n  return ENGINE.runKernel(\n      Reverse, inputs as {} as NamedTensorMap, attrs as {} as NamedAttrMap);\n}\n\nexport const reverse = op({reverse_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor1D} from '../tensor';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\nimport * as util from '../util';\nimport {op} from './operation';\nimport {reverse} from './reverse';\n\n/**\n * Reverses a `tf.Tensor1D`.\n *\n * @param x The input tensor.\n */\nfunction reverse1d_(x: Tensor1D|TensorLike): Tensor1D {\n  const $x = convertToTensor(x, 'x', 'reverse');\n  util.assert(\n      $x.rank === 1,\n      () => `Error in reverse1D: x must be rank 1 but got rank ${$x.rank}.`);\n  return reverse($x, 0);\n}\n\nexport const reverse1d = op({reverse1d_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor2D} from '../tensor';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\nimport * as util from '../util';\nimport {op} from './operation';\nimport {reverse} from './reverse';\n\n/**\n * Reverses a `tf.Tensor2D` along a specified axis.\n *\n * @param x The input tensor.\n * @param axis The set of dimensions to reverse. Must be in the\n *     range [-rank(x), rank(x)). Defaults to all axes.\n */\nfunction reverse2d_(x: Tensor2D|TensorLike, axis?: number|number[]): Tensor2D {\n  const $x = convertToTensor(x, 'x', 'reverse');\n  util.assert(\n      $x.rank === 2,\n      () => `Error in reverse2D: x must be rank 2 but got rank ${$x.rank}.`);\n  return reverse($x, axis);\n}\n\nexport const reverse2d = op({reverse2d_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor3D} from '../tensor';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\nimport * as util from '../util';\nimport {op} from './operation';\nimport {reverse} from './reverse';\n\n/**\n * Reverses a `tf.Tensor3D` along a specified axis.\n *\n * @param x The input tensor.\n * @param axis The set of dimensions to reverse. Must be in the\n *     range [-rank(x), rank(x)). Defaults to all axes.\n */\nfunction reverse3d_(x: Tensor3D|TensorLike, axis?: number|number[]): Tensor3D {\n  const $x = convertToTensor(x, 'x', 'reverse');\n  util.assert(\n      $x.rank === 3,\n      () => `Error in reverse3D: x must be rank 3 but got rank ${$x.rank}.`);\n  return reverse($x, axis);\n}\n\nexport const reverse3d = op({reverse3d_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor4D} from '../tensor';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\nimport * as util from '../util';\nimport {op} from './operation';\nimport {reverse} from './reverse';\n\n/**\n * Reverses a `tf.Tensor4D` along a specified axis.\n *\n * @param x The input tensor.\n * @param axis The set of dimensions to reverse. Must be in the\n *     range [-rank(x), rank(x)). Defaults to all axes.\n */\nfunction reverse4d_(x: Tensor4D|TensorLike, axis?: number|number[]): Tensor4D {\n  const $x = convertToTensor(x, 'x', 'reverse');\n  util.assert(\n      $x.rank === 4,\n      () => `Error in reverse4D: x must be rank 4 but got rank ${$x.rank}.`);\n  return reverse($x, axis);\n}\n\nexport const reverse4d = op({reverse4d_});\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {Round, RoundInputs} from '../kernel_names';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {op} from './operation';\n\n/**\n * Computes round of input `tf.Tensor` element-wise: `round(x)`.\n * It implements banker's rounding.\n *\n * ```js\n * const x = tf.tensor1d([.6, 1.1, -3.3]);\n *\n * x.round().print();  // or tf.round(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction round_<T extends Tensor>(x: T|TensorLike): T {\n  const $x = convertToTensor(x, 'x', 'round');\n  const inputs: RoundInputs = {x: $x};\n\n  return ENGINE.runKernel(Round, inputs as {} as NamedTensorMap);\n}\n\nexport const round = op({round_});\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {Rsqrt, RsqrtInputs} from '../kernel_names';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {op} from './operation';\n\n/**\n * Computes reciprocal of square root of the input `tf.Tensor` element-wise:\n * `y = 1 / sqrt(x)`\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 4, -1]);\n *\n * x.rsqrt().print();  // or tf.rsqrt(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction rsqrt_<T extends Tensor>(x: T|TensorLike): T {\n  const $x = convertToTensor(x, 'x', 'rsqrt', 'float32');\n\n  const inputs: RsqrtInputs = {x: $x};\n\n  return ENGINE.runKernel(Rsqrt, inputs as {} as NamedTensorMap);\n}\nexport const rsqrt = op({rsqrt_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {Selu, SeluInputs} from '../kernel_names';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {op} from './operation';\n\n/**\n * Computes scaled exponential linear element-wise.\n *\n * `x < 0 ? scale * alpha * (exp(x) - 1) : scale * x`\n *\n * ```js\n * const x = tf.tensor1d([-1, 2, -3, 4]);\n *\n * x.selu().print();  // or tf.selu(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction selu_<T extends Tensor>(x: T|TensorLike): T {\n  const $x = convertToTensor(x, 'x', 'selu');\n\n  const inputs: SeluInputs = {x: $x};\n\n  return ENGINE.runKernel(Selu, inputs as {} as NamedTensorMap);\n}\n\nexport const selu = op({selu_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {Tensor3D, Tensor4D} from '../tensor';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\nimport * as util from '../util';\n\nimport {conv2d} from './conv2d';\nimport {depthwiseConv2d} from './depthwise_conv2d';\nimport {op} from './operation';\nimport {reshape} from './reshape';\n\n/**\n * 2-D convolution with separable filters.\n *\n * Performs a depthwise convolution that acts separately on channels followed\n * by a pointwise convolution that mixes channels. Note that this is\n * separability between dimensions [1, 2] and 3, not spatial separability\n * between dimensions 1 and 2.\n *\n * See\n * [https://www.tensorflow.org/api_docs/python/tf/nn/separable_conv2d](\n *     https://www.tensorflow.org/api_docs/python/tf/nn/separable_conv2d)\n * for more details.\n *\n * @param x The input tensor, of rank 4 or rank 3, of shape\n *     `[batch, height, width, inChannels]`. If rank 3, batch of 1 is\n * assumed.\n * @param depthwiseFilter The depthwise filter tensor, rank 4, of shape\n *     `[filterHeight, filterWidth, inChannels, channelMultiplier]`. This is\n *     the filter used in the first step.\n * @param pointwiseFilter The pointwise filter tensor, rank 4, of shape\n *     `[1, 1, inChannels * channelMultiplier, outChannels]`. This is\n *     the filter used in the second step.\n * @param strides The strides of the convolution: `[strideHeight,\n * strideWidth]`. If strides is a single number, then `strideHeight ==\n * strideWidth`.\n * @param pad The type of padding algorithm.\n *   - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *   - `valid`: output will be smaller than input if filter is larger\n *       than 1x1.\n *   - For more info, see this guide:\n *     [https://www.tensorflow.org/api_docs/python/tf/nn/convolution](\n *          https://www.tensorflow.org/api_docs/python/tf/nn/convolution)\n * @param dilations The dilation rates: `[dilationHeight, dilationWidth]`\n *     in which we sample input values across the height and width dimensions\n *     in atrous convolution. Defaults to `[1, 1]`. If `rate` is a single\n *     number, then `dilationHeight == dilationWidth`. If it is greater than\n *     1, then all values of `strides` must be 1.\n * @param dataFormat: An optional string from: \"NHWC\", \"NCHW\". Defaults to\n *     \"NHWC\". Specify the data format of the input and output data. With the\n *     default format \"NHWC\", the data is stored in the order of: [batch,\n *     height, width, channels]. Only \"NHWC\" is currently supported.\n *\n * @doc {heading: 'Operations', subheading: 'Convolution'}\n */\nfunction separableConv2d_<T extends Tensor3D|Tensor4D>(\n    x: T|TensorLike, depthwiseFilter: Tensor4D|TensorLike,\n    pointwiseFilter: Tensor4D|TensorLike, strides: [number, number]|number,\n    pad: 'valid'|'same', dilation: [number, number]|number = [1, 1],\n    dataFormat: 'NHWC'|'NCHW' = 'NHWC'): T {\n  const $x = convertToTensor(x, 'x', 'separableConv2d');\n  const $depthwiseFilter =\n      convertToTensor(depthwiseFilter, 'depthwiseFilter', 'separableConv2d');\n  const $pointwiseFilter =\n      convertToTensor(pointwiseFilter, 'pointwiseFilter', 'separableConv2d');\n\n  let x4D = $x as Tensor4D;\n  let reshapedTo4D = false;\n  if ($x.rank === 3) {\n    reshapedTo4D = true;\n    x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);\n  }\n\n  if (dataFormat === 'NCHW') {\n    throw new Error(\n        'separableConv2d currently does not support dataFormat NCHW; only ' +\n        'NHWC is supported');\n  }\n\n  util.assert(\n      x4D.rank === 4,\n      () => `Error in separableConv2d: input must be rank 4, but got ` +\n          `rank ${x4D.rank}.`);\n  util.assert(\n      $depthwiseFilter.rank === 4,\n      () => `Error in separableConv2d: depthwise filter must be rank 4, but ` +\n          `got rank ${$depthwiseFilter.rank}.`);\n  util.assert(\n      $pointwiseFilter.rank === 4,\n      () => `Error in separableConv2d: pointwise filter must be rank 4, but ` +\n          `got rank ${$depthwiseFilter.rank}.`);\n  util.assert(\n      $pointwiseFilter.shape[0] === 1,\n      () =>\n          `Error in separableConv2d: the first dimension of pointwise filter ` +\n          ` must be 1, but got ${$pointwiseFilter.shape[0]}.`);\n  util.assert(\n      $pointwiseFilter.shape[1] === 1,\n      () => `Error in separableConv2d: the second dimension of pointwise ` +\n          `filter must be 1, but got ${$pointwiseFilter.shape[1]}.`);\n\n  const inChannels = $depthwiseFilter.shape[2];\n  const channelMultiplier = $depthwiseFilter.shape[3];\n  util.assert(\n      $pointwiseFilter.shape[2] === inChannels * channelMultiplier,\n      () =>\n          `Error in separableConv2d: the third dimension of pointwise filter ` +\n          `must be ${inChannels * channelMultiplier}, ` +\n          `but got ${$pointwiseFilter.shape[2]}.`);\n\n  const depthwise = depthwiseConv2d(\n      x4D, $depthwiseFilter, strides, pad, dataFormat, dilation);\n  const pointwiseStride = 1;\n  const res =\n      conv2d(depthwise, $pointwiseFilter, pointwiseStride, 'valid', dataFormat);\n\n  if (reshapedTo4D) {\n    return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]) as T;\n  }\n  return res as T;\n}\n\nexport const separableConv2d = op({separableConv2d_});\n","/**\n * @license\n * Copyright 2020 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {Tensor, TensorBuffer} from '../tensor';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\nimport * as util from '../util';\n\n/**\n * Computes the difference between two lists of numbers.\n *\n * Given a Tensor `x` and a Tensor `y`, this operation returns a Tensor `out`\n * that represents all values that are in `x` but not in `y`. The returned\n * Tensor `out` is sorted in the same order that the numbers appear in `x`\n * (duplicates are preserved). This operation also returns a Tensor indices that\n * represents the position of each out element in `x`. In other words:\n *\n * `out[i] = x[idx[i]] for i in [0, 1, ..., out.length - 1]`\n *\n * ```js\n * const x = [1, 2, 3, 4, 5, 6];\n * const y = [1, 3, 5];\n *\n * const [out, indices] = await tf.setdiff1dAsync(x, y);\n * out.print(); // [2, 4, 6]\n * indices.print(); // [1, 3, 5]\n * ```\n *\n * @param x 1-D Tensor. Values to keep.\n * @param y 1-D Tensor. Must have the same type as x. Values to exclude in the\n *     output.\n * @returns Promise of Tensor tuple [out, indices].\n *  out: Tensor with the same type as x.\n *  indices: A Tensor of type int32.\n *\n * @doc {heading: 'Tensors', subheading: 'Transformations'}\n */\nasync function setdiff1dAsync_(\n    x: Tensor|TensorLike, y: Tensor|TensorLike): Promise<[Tensor, Tensor]> {\n  const $x = convertToTensor(x, 'x', 'setdiff1d');\n  const $y = convertToTensor(y, 'y', 'setdiff1d');\n\n  util.assert(\n      $x.dtype === $y.dtype,\n      () => `x and y should have the same dtype, but got x (${\n          $x.dtype}) and y (${$y.dtype}).`);\n\n  util.assert(\n      $x.rank === 1, () => `x should be 1D tensor, but got x (${$x.shape}).`);\n\n  util.assert(\n      $y.rank === 1, () => `y should be 1D tensor, but got y (${$y.shape}).`);\n\n  const xVals = await $x.data();\n  const yVals = await $y.data();\n  const ySet = new Set(yVals);\n\n  let outputSize = 0;\n  for (let i = 0; i < xVals.length; i++) {\n    if (!ySet.has(xVals[i])) {\n      outputSize++;\n    }\n  }\n\n  const buffer = new TensorBuffer([outputSize], $x.dtype);\n  const indices = new TensorBuffer([outputSize], 'int32');\n  for (let i = 0, p = 0; i < xVals.length; i++) {\n    if (!ySet.has(xVals[i])) {\n      buffer.values[p] = xVals[i];\n      indices.values[p] = i;\n      p++;\n    }\n  }\n  return [buffer.toTensor(), indices.toTensor()];\n}\nexport const setdiff1dAsync = setdiff1dAsync_;\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {Sign, SignInputs} from '../kernel_names';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {op} from './operation';\n\n/**\n * Returns an element-wise indication of the sign of a number.\n *\n * ```js\n * const x = tf.tensor1d([.6, 1.1, -3.3, NaN, 0]);\n *\n * x.sign().print();  // or tf.sign(x)\n * ```\n * @param x The input Tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction sign_<T extends Tensor>(x: T|TensorLike): T {\n  const $x = convertToTensor(x, 'x', 'sign');\n  const inputs: SignInputs = {x: $x};\n  return ENGINE.runKernel(Sign, inputs as {} as NamedTensorMap);\n}\nexport const sign = op({sign_});\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {Sin, SinInputs} from '../kernel_names';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {op} from './operation';\n\n/**\n * Computes sin of the input Tensor element-wise: `sin(x)`\n *\n * ```js\n * const x = tf.tensor1d([0, Math.PI / 2, Math.PI * 3 / 4]);\n *\n * x.sin().print();  // or tf.sin(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction sin_<T extends Tensor>(x: T|TensorLike): T {\n  const $x = convertToTensor(x, 'x', 'sin', 'float32');\n\n  const inputs: SinInputs = {x: $x};\n\n  return ENGINE.runKernel(Sin, inputs as {} as NamedTensorMap);\n}\nexport const sin = op({sin_});\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {Sinh, SinhInputs} from '../kernel_names';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {op} from './operation';\n\n/**\n * Computes hyperbolic sin of the input `tf.Tensor` element-wise: `sinh(x)`\n *\n * ```js\n * const x = tf.tensor1d([0, 1, -1, .7]);\n *\n * x.sinh().print();  // or tf.sinh(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction sinh_<T extends Tensor>(x: T|TensorLike): T {\n  const $x = convertToTensor(x, 'x', 'sinh');\n  const inputs: SinhInputs = {x: $x};\n\n  return ENGINE.runKernel(Sinh, inputs as {} as NamedTensorMap);\n}\nexport const sinh = op({sinh_});\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor1D} from '../tensor';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\nimport * as util from '../util';\n\nimport {op} from './operation';\nimport {slice} from './slice';\n\n/**\n * Extracts a 1D slice from 1D array starting at coordinates `begin` and is\n * of length `size`. See `slice` for details.\n */\nfunction slice1d_(\n    x: Tensor1D|TensorLike, begin: number, size: number): Tensor1D {\n  const $x = convertToTensor(x, 'x', 'slice1d');\n  util.assert(\n      $x.rank === 1,\n      () =>\n          `slice1d expects a rank-1 tensor, but got a rank-${$x.rank} tensor`);\n  return slice($x, [begin], [size]);\n}\nexport const slice1d = op({slice1d_});\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor2D} from '../tensor';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\nimport * as util from '../util';\n\nimport {op} from './operation';\nimport {slice} from './slice';\n\n/**\n * Extracts a 2D slice from a 2D array starting at coordinates `begin` and\n * is of size `size`. See `slice` for details.\n */\nfunction slice2d_(\n    x: Tensor2D|TensorLike, begin: [number, number],\n    size: [number, number]): Tensor2D {\n  const $x = convertToTensor(x, 'x', 'slice2d');\n  util.assert(\n      $x.rank === 2,\n      () =>\n          `slice2d expects a rank-2 tensor, but got a rank-${$x.rank} tensor`);\n  return slice($x, begin, size);\n}\nexport const slice2d = op({slice2d_});\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor3D} from '../tensor';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\nimport * as util from '../util';\n\nimport {op} from './operation';\nimport {slice} from './slice';\n\n/**\n * Extracts a 3D slice from a 3D array starting at coordinates `begin` and\n * is of size `size`. See `slice` for details.\n */\nfunction slice3d_(\n    x: Tensor3D|TensorLike, begin: [number, number, number],\n    size: [number, number, number]): Tensor3D {\n  const $x = convertToTensor(x, 'x', 'slice3d');\n  util.assert(\n      $x.rank === 3,\n      () =>\n          `slice3d expects a rank-3 tensor, but got a rank-${$x.rank} tensor`);\n  return slice($x, begin, size);\n}\nexport const slice3d = op({slice3d_});\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor4D} from '../tensor';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\nimport * as util from '../util';\n\nimport {op} from './operation';\nimport {slice} from './slice';\n\n/**\n * Extracts a 4D slice from a 4D array starting at coordinates `begin` and\n * is of size `size`. See `slice` for details.\n */\nfunction slice4d_(\n    x: Tensor4D|TensorLike, begin: [number, number, number, number],\n    size: [number, number, number, number]): Tensor4D {\n  const $x = convertToTensor(x, 'x', 'slice4d');\n  util.assert(\n      $x.rank === 4,\n      () =>\n          `slice4d expects a rank-4 tensor, but got a rank-${$x.rank} tensor`);\n  return slice($x, begin, size);\n}\nexport const slice4d = op({slice4d_});\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {Softmax, SoftmaxAttrs, SoftmaxInputs} from '../kernel_names';\nimport {NamedAttrMap} from '../kernel_registry';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {op} from './operation';\n\n/**\n * Computes the softmax normalized vector given the logits.\n *\n * ```js\n * const a = tf.tensor1d([1, 2, 3]);\n *\n * a.softmax().print();  // or tf.softmax(a)\n * ```\n *\n * ```js\n * const a = tf.tensor2d([2, 4, 6, 1, 2, 3], [2, 3]);\n *\n * a.softmax().print();  // or tf.softmax(a)\n * ```\n *\n * @param logits The logits array.\n * @param dim The dimension softmax would be performed on. Defaults to `-1`\n *     which indicates the last dimension.\n *\n * @doc {heading: 'Operations', subheading: 'Normalization'}\n */\nfunction softmax_<T extends Tensor>(logits: T|TensorLike, dim = -1): T {\n  const $logits = convertToTensor(logits, 'logits', 'softmax', 'float32');\n\n  if (dim === -1) {\n    dim = $logits.rank - 1;\n  }\n  if (dim !== $logits.rank - 1) {\n    throw Error(\n        'Softmax along a non-last dimension is not yet supported. ' +\n        `Logits was rank ${$logits.rank} and dim was ${dim}`);\n  }\n\n  const inputs: SoftmaxInputs = {logits: $logits};\n  const attrs: SoftmaxAttrs = {dim};\n\n  return ENGINE.runKernel(\n      Softmax, inputs as {} as NamedTensorMap, attrs as {} as NamedAttrMap);\n}\n\nexport const softmax = op({softmax_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../../engine';\nimport {FFT, FFTInputs} from '../../kernel_names';\nimport {Tensor} from '../../tensor';\nimport {NamedTensorMap} from '../../tensor_types';\nimport {assert} from '../../util';\nimport {op} from '../operation';\n\n/**\n * Fast Fourier transform.\n *\n * Computes the 1-dimensional discrete Fourier transform over the inner-most\n * dimension of input.\n *\n * ```js\n * const real = tf.tensor1d([1, 2, 3]);\n * const imag = tf.tensor1d([1, 2, 3]);\n * const x = tf.complex(real, imag);\n *\n * x.fft().print();  // tf.spectral.fft(x).print();\n * ```\n * @param input The complex input to compute an fft over.\n *\n * @doc {heading: 'Operations', subheading: 'Spectral', namespace: 'spectral'}\n */\nfunction fft_(input: Tensor): Tensor {\n  assert(\n      input.dtype === 'complex64',\n      () => `The dtype for tf.spectral.fft() must be complex64 ` +\n          `but got ${input.dtype}.`);\n\n  const inputs: FFTInputs = {input};\n\n  return ENGINE.runKernel(FFT, inputs as {} as NamedTensorMap);\n}\n\nexport const fft = op({fft_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../../engine';\nimport {IFFT, IFFTInputs} from '../../kernel_names';\nimport {Tensor} from '../../tensor';\nimport {NamedTensorMap} from '../../tensor_types';\nimport {assert} from '../../util';\nimport {op} from '../operation';\n\n/**\n * Inverse fast Fourier transform.\n *\n * Computes the inverse 1-dimensional discrete Fourier transform over the\n * inner-most dimension of input.\n *\n * ```js\n * const real = tf.tensor1d([1, 2, 3]);\n * const imag = tf.tensor1d([1, 2, 3]);\n * const x = tf.complex(real, imag);\n *\n * x.ifft().print();  // tf.spectral.ifft(x).print();\n * ```\n * @param input The complex input to compute an ifft over.\n *\n * @doc {heading: 'Operations', subheading: 'Spectral', namespace: 'spectral'}\n */\nfunction ifft_(input: Tensor): Tensor {\n  assert(\n      input.dtype === 'complex64',\n      () => `The dtype for tf.spectral.ifft() must be complex64 ` +\n          `but got ${input.dtype}.`);\n\n  const inputs: IFFTInputs = {input};\n\n  return ENGINE.runKernel(IFFT, inputs as {} as NamedTensorMap);\n}\n\nexport const ifft = op({ifft_});\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor, Tensor2D} from '../../tensor';\nimport {complex} from '../complex';\nimport {concat} from '../concat';\nimport {imag} from '../imag';\nimport {mul} from '../mul';\nimport {op} from '../operation';\nimport {real} from '../real';\nimport {reshape} from '../reshape';\nimport {reverse} from '../reverse';\nimport {scalar} from '../scalar';\nimport {slice} from '../slice';\n\nimport {ifft} from './ifft';\n\n/**\n * Inversed real value input fast Fourier transform.\n *\n * Computes the 1-dimensional inversed discrete Fourier transform over the\n * inner-most dimension of the real input.\n *\n * ```js\n * const real = tf.tensor1d([1, 2, 3]);\n * const imag = tf.tensor1d([0, 0, 0]);\n * const x = tf.complex(real, imag);\n *\n * x.irfft().print();\n * ```\n * @param input The real value input to compute an irfft over.\n *\n * @doc {heading: 'Operations', subheading: 'Spectral', namespace: 'spectral'}\n */\nfunction irfft_(input: Tensor): Tensor {\n  const innerDimensionSize = input.shape[input.shape.length - 1];\n  const batch = input.size / innerDimensionSize;\n  let ret: Tensor;\n  if (innerDimensionSize <= 2) {\n    const complexInput = reshape(input, [batch, innerDimensionSize]);\n    ret = ifft(complexInput);\n  } else {\n    // The length of unique components of the DFT of a real-valued signal\n    // is 2 * (input_len - 1)\n    const outputShape = [batch, 2 * (innerDimensionSize - 1)];\n    const realInput = reshape(real(input), [batch, innerDimensionSize]);\n    const imagInput = reshape(imag(input), [batch, innerDimensionSize]);\n\n    const realConjugate =\n        reverse(slice(realInput, [0, 1], [batch, innerDimensionSize - 2]), 1);\n    const imagConjugate: Tensor2D = mul(\n        reverse(slice(imagInput, [0, 1], [batch, innerDimensionSize - 2]), 1),\n        scalar(-1));\n\n    const r = concat([realInput, realConjugate], 1);\n    const i = concat([imagInput, imagConjugate], 1);\n    const complexInput =\n        reshape(complex(r, i), [outputShape[0], outputShape[1]]);\n    ret = ifft(complexInput);\n  }\n  ret = real(ret);\n  // reshape the result if the input is 3D tensor.\n  if (input.rank === 3 && input.shape[0] !== 0) {\n    const temp = ret;\n    const batch = input.shape[0];\n    ret = reshape(ret, [batch, ret.shape[0] / batch, ret.shape[1]]);\n    temp.dispose();\n  }\n  return ret;\n}\n\nexport const irfft = op({irfft_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {ENGINE} from '../engine';\nimport {SplitV, SplitVAttrs, SplitVInputs} from '../kernel_names';\nimport {NamedAttrMap} from '../kernel_registry';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {op} from './operation';\n\n/**\n * Splits a `tf.Tensor` into sub tensors.\n *\n * If `numOrSizeSplits` is a number, splits `x` along dimension `axis`\n * into `numOrSizeSplits` smaller tensors.\n * Requires that `numOrSizeSplits` evenly divides `x.shape[axis]`.\n *\n * If `numOrSizeSplits` is a number array, splits `x` into\n * `numOrSizeSplits.length` pieces. The shape of the `i`-th piece has the\n * same size as `x` except along dimension `axis` where the size is\n * `numOrSizeSplits[i]`.\n *\n * ```js\n * const x = tf.tensor2d([1, 2, 3, 4, 5, 6, 7, 8], [2, 4]);\n * const [a, b] = tf.split(x, 2, 1);\n * a.print();\n * b.print();\n *\n * const [c, d, e] = tf.split(x, [1, 2, 1], 1);\n * c.print();\n * d.print();\n * e.print();\n * ```\n *\n * @param x The input tensor to split.\n * @param numOrSizeSplits Either an integer indicating the number of\n * splits along the axis or an array of integers containing the sizes of\n * each output tensor along the axis. If a number then it must evenly divide\n * `x.shape[axis]`; otherwise the sum of sizes must match `x.shape[axis]`.\n * Can contain one -1 indicating that dimension is to be inferred.\n * @param axis The dimension along which to split. Defaults to 0 (the first\n * dim).\n *\n * @doc {heading: 'Tensors', subheading: 'Slicing and Joining'}\n */\nfunction split_<T extends Tensor>(\n    x: Tensor|TensorLike, numOrSizeSplits: number[]|number, axis = 0): T[] {\n  const $x = convertToTensor(x, 'x', 'split');\n\n  const inputs: SplitVInputs = {x: $x};\n  const attr: SplitVAttrs = {numOrSizeSplits, axis};\n\n  return ENGINE.runKernel(\n             SplitV, inputs as {} as NamedTensorMap,\n             attr as {} as NamedAttrMap) as {} as T[];\n}\n\nexport const split = op({split_});\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor} from '../../tensor';\nimport {assert} from '../../util';\nimport {complex} from '../complex';\nimport {concat} from '../concat';\nimport {imag} from '../imag';\nimport {op} from '../operation';\nimport {real} from '../real';\nimport {reshape} from '../reshape';\nimport {slice} from '../slice';\nimport {split} from '../split';\nimport {zeros} from '../zeros';\nimport {zerosLike} from '../zeros_like';\n\nimport {fft} from './fft';\n\n/**\n * Real value input fast Fourier transform.\n *\n * Computes the 1-dimensional discrete Fourier transform over the\n * inner-most dimension of the real input.\n *\n * ```js\n * const real = tf.tensor1d([1, 2, 3]);\n *\n * real.rfft().print();\n * ```\n * @param input The real value input to compute an rfft over.\n *\n * @doc {heading: 'Operations', subheading: 'Spectral', namespace: 'spectral'}\n */\nfunction rfft_(input: Tensor, fftLength?: number): Tensor {\n  assert(\n      input.dtype === 'float32',\n      () => `The dtype for rfft() must be real value but got ${input.dtype}`);\n\n  let innerDimensionSize = input.shape[input.shape.length - 1];\n  const batch = input.size / innerDimensionSize;\n\n  let adjustedInput: Tensor;\n  if (fftLength != null && fftLength < innerDimensionSize) {\n    // Need to crop\n    const begin = input.shape.map(v => 0);\n    const size = input.shape.map(v => v);\n    size[input.shape.length - 1] = fftLength;\n    adjustedInput = slice(input, begin, size);\n    innerDimensionSize = fftLength;\n  } else if (fftLength != null && fftLength > innerDimensionSize) {\n    // Need to pad with zeros\n    const zerosShape = input.shape.map(v => v);\n    zerosShape[input.shape.length - 1] = fftLength - innerDimensionSize;\n    adjustedInput = concat([input, zeros(zerosShape)], input.shape.length - 1);\n    innerDimensionSize = fftLength;\n  } else {\n    adjustedInput = input;\n  }\n\n  // Complement the input with zero imaginary numbers.\n  const zerosInput = zerosLike(adjustedInput);\n  const complexInput =\n      reshape(complex(adjustedInput, zerosInput), [batch, innerDimensionSize]);\n\n  const ret = fft(complexInput);\n\n  // Exclude complex conjugations. These conjugations are put symmetrically.\n  const half = Math.floor(innerDimensionSize / 2) + 1;\n  const realValues = real(ret);\n  const imagValues = imag(ret);\n  const realComplexConjugate = split(\n      realValues, [half, innerDimensionSize - half],\n      realValues.shape.length - 1);\n  const imagComplexConjugate = split(\n      imagValues, [half, innerDimensionSize - half],\n      imagValues.shape.length - 1);\n\n  const outputShape = adjustedInput.shape.slice();\n  outputShape[adjustedInput.shape.length - 1] = half;\n\n  return reshape(\n      complex(realComplexConjugate[0], imagComplexConjugate[0]), outputShape);\n}\n\nexport const rfft = op({rfft_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {SquaredDifference, SquaredDifferenceInputs} from '../kernel_names';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {makeTypesMatch} from '../tensor_util';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {assertAndGetBroadcastShape} from './broadcast_util';\nimport {op} from './operation';\n\n/**\n * Returns (a - b) * (a - b) element-wise.\n * Supports broadcasting.\n *\n * ```js\n * const a = tf.tensor1d([1, 4, 3, 16]);\n * const b = tf.tensor1d([1, 2, 9, 4]);\n *\n * a.squaredDifference(b).print();  // or tf.squaredDifference(a, b)\n * ```\n *\n * ```js\n * // Broadcast squared difference  a with b.\n * const a = tf.tensor1d([2, 4, 6, 8]);\n * const b = tf.scalar(5);\n *\n * a.squaredDifference(b).print();  // or tf.squaredDifference(a, b)\n * ```\n *\n * @param a The first tensor.\n * @param b The second tensor. Must have the same type as `a`.\n *\n * @doc {heading: 'Operations', subheading: 'Arithmetic'}\n */\nfunction squaredDifference_<T extends Tensor>(\n    a: Tensor|TensorLike, b: Tensor|TensorLike): T {\n  let $a = convertToTensor(a, 'a', 'squaredDifference');\n  let $b = convertToTensor(b, 'b', 'squaredDifference');\n  [$a, $b] = makeTypesMatch($a, $b);\n\n  assertAndGetBroadcastShape($a.shape, $b.shape);\n\n  const inputs: SquaredDifferenceInputs = {a: $a, b: $b};\n  const attrs = {};\n\n  return ENGINE.runKernel(\n      SquaredDifference, inputs as unknown as NamedTensorMap, attrs);\n}\n\nexport const squaredDifference = op({squaredDifference_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor} from '../tensor';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\nimport {squeezeShape} from '../util';\n\nimport {op} from './operation';\nimport {reshape} from './reshape';\n\n/**\n * Removes dimensions of size 1 from the shape of a `tf.Tensor`.\n *\n * ```js\n * const x = tf.tensor([1, 2, 3, 4], [1, 1, 4]);\n * x.squeeze().print();\n * ```\n *\n * @param x The input tensor to be squeezed.\n * @param axis An optional list of numbers. If specified, only\n *     squeezes the dimensions listed. The dimension index starts at 0. It\n * is an error to squeeze a dimension that is not 1.\n *\n * @doc {heading: 'Tensors', subheading: 'Transformations'}\n */\nfunction squeeze_<T extends Tensor>(x: Tensor|TensorLike, axis?: number[]): T {\n  const $x = convertToTensor(x, 'x', 'squeeze', 'string_or_numeric');\n  return reshape($x, squeezeShape($x.shape, axis).newShape) as T;\n}\n\nexport const squeeze = op({squeeze_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {Pack, PackAttrs, PackInputs} from '../kernel_names';\nimport {NamedAttrMap} from '../kernel_registry';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensorArray} from '../tensor_util_env';\nimport {TensorLike} from '../types';\nimport * as util from '../util';\n\nimport {op} from './operation';\n\n/**\n * Stacks a list of rank-`R` `tf.Tensor`s into one rank-`(R+1)` `tf.Tensor`.\n *\n * ```js\n * const a = tf.tensor1d([1, 2]);\n * const b = tf.tensor1d([3, 4]);\n * const c = tf.tensor1d([5, 6]);\n * tf.stack([a, b, c]).print();\n * ```\n *\n * @param tensors A list of tensor objects with the same shape and dtype.\n * @param axis The axis to stack along. Defaults to 0 (the first dim).\n *\n * @doc {heading: 'Tensors', subheading: 'Slicing and Joining'}\n */\nfunction stack_<T extends Tensor>(\n    tensors: Array<T|TensorLike>, axis = 0): Tensor {\n  const $tensors =\n      convertToTensorArray(tensors, 'tensors', 'stack', 'string_or_numeric');\n\n  util.assert(\n      $tensors.length >= 1, () => 'Pass at least one tensor to tf.stack');\n\n  if ($tensors.length > 0) {\n    util.assert(\n        axis <= $tensors[0].rank, () => 'Axis must be <= rank of the tensor');\n  }\n\n  const inputs: PackInputs = $tensors;\n  const attrs: PackAttrs = {axis};\n\n  return ENGINE.runKernel(\n      Pack, inputs as {} as NamedTensorMap, attrs as {} as NamedAttrMap);\n}\n\nexport const stack = op({stack_});\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {Step, StepAttrs, StepInputs} from '../kernel_names';\nimport {NamedAttrMap} from '../kernel_registry';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {op} from './operation';\n\n/**\n * Computes step of the input `tf.Tensor` element-wise: `x > 0 ? 1 : alpha * x`\n *\n * ```js\n * const x = tf.tensor1d([0, 2, -1, -3]);\n *\n * x.step(.5).print();  // or tf.step(x, .5)\n * ```\n * @param x The input tensor.\n * @param alpha The gradient when input is negative.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction step_<T extends Tensor>(x: T|TensorLike, alpha = 0.0): T {\n  const $x = convertToTensor(x, 'x', 'step');\n\n  const inputs: StepInputs = {x: $x};\n  const attrs: StepAttrs = {alpha};\n\n  return ENGINE.runKernel(\n      Step, inputs as {} as NamedTensorMap, attrs as {} as NamedAttrMap);\n}\nexport const step = op({step_});\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {StridedSlice, StridedSliceAttrs, StridedSliceInputs} from '../kernel_names';\nimport {NamedAttrMap} from '../kernel_registry';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {op} from './operation';\n\n/**\n * Extracts a strided slice of a tensor.\n *\n * Roughly speaking, this op extracts a slice of size (end-begin)/stride from\n * the given input tensor (x). Starting at the location specified by begin the\n * slice continues by adding stride to the index until all dimensions are not\n * less than end. Note that a stride can be negative, which causes a reverse\n * slice.\n *\n * ```js\n * const t = tf.tensor3d([1, 1, 1 ,2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6],\n *    [3, 2, 3]);\n * t.stridedSlice([1, 0, 0], [2, 1, 3], [1, 1, 1]).print()  // [[[3, 3, 3]]]\n * t.stridedSlice([1, 0, 0], [2, 2, 3], [1, 1, 1]).print()  // [[[3, 3, 3],\n *                                                     // [4, 4, 4]]]\n * t.stridedSlice([1, -1, 0], [2, -3, 3], [1, -1, 1]).print() // [[[4, 4, 4],\n *                                                     // [3, 3, 3]]]\n * ```\n *\n * @param x The tensor to stride slice.\n * @param begin The coordinates to start the slice from.\n * @param end: The coordinates to end the slice at.\n * @param strides: The size of the slice.\n * @param beginMask: If the ith bit of beginMask is set, begin[i] is ignored\n *      and the fullest possible range in that dimension is used instead.\n * @param endMask: If the ith bit of endMask is set, end[i] is ignored\n *      and the fullest possible range in that dimension is used instead.\n * @param shrinkAxisMask: a bitmask where bit i implies that\n * the ith specification should shrink the dimensionality. begin and end must\n * imply a slice of size 1 in the dimension.\n *\n * @doc {heading: 'Operations', subheading: 'Slicing and Joining'}\n */\nfunction stridedSlice_(\n    x: Tensor|TensorLike, begin: number[], end: number[], strides?: number[],\n    beginMask = 0, endMask = 0, ellipsisMask = 0, newAxisMask = 0,\n    shrinkAxisMask = 0): Tensor {\n  const $x = convertToTensor(x, 'x', 'stridedSlice', 'string_or_numeric');\n\n  const inputs: StridedSliceInputs = {x: $x};\n  const attrs: StridedSliceAttrs = {\n    begin,\n    end,\n    strides,\n    beginMask,\n    endMask,\n    ellipsisMask,\n    newAxisMask,\n    shrinkAxisMask\n  };\n\n  return ENGINE.runKernel(\n      StridedSlice, inputs as {} as NamedTensorMap,\n      attrs as {} as NamedAttrMap);\n}\n\nexport const stridedSlice = op({stridedSlice_});\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {Tan, TanInputs} from '../kernel_names';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {op} from './operation';\n\n/**\n * Computes tan of the input `tf.Tensor` element-wise, `tan(x)`\n *\n * ```js\n * const x = tf.tensor1d([0, Math.PI / 2, Math.PI * 3 / 4]);\n *\n * x.tan().print();  // or tf.tan(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction tan_<T extends Tensor>(x: T|TensorLike): T {\n  const $x = convertToTensor(x, 'x', 'tan', 'float32');\n\n  const inputs: TanInputs = {x: $x};\n\n  return ENGINE.runKernel(Tan, inputs as {} as NamedTensorMap);\n}\nexport const tan = op({tan_});\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor1D} from '../tensor';\nimport {inferShape} from '../tensor_util_env';\nimport {TensorLike1D} from '../types';\nimport {DataType} from '../types';\nimport {assertNonNull} from '../util';\nimport {makeTensor} from './tensor_ops_util';\n\n/**\n * Creates rank-1 `tf.Tensor` with the provided values, shape and dtype.\n *\n * The same functionality can be achieved with `tf.tensor`, but in general\n * we recommend using `tf.tensor1d` as it makes the code more readable.\n *\n * ```js\n * tf.tensor1d([1, 2, 3]).print();\n * ```\n *\n * @param values The values of the tensor. Can be array of numbers,\n *     or a `TypedArray`.\n * @param dtype The data type.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nexport function tensor1d(values: TensorLike1D, dtype?: DataType): Tensor1D {\n  assertNonNull(values);\n  const inferredShape = inferShape(values, dtype);\n  if (inferredShape.length !== 1) {\n    throw new Error('tensor1d() requires values to be a flat/TypedArray');\n  }\n  const shape: number[] = null;\n  return makeTensor(values, shape, inferredShape, dtype) as Tensor1D;\n}\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor2D} from '../tensor';\nimport {inferShape} from '../tensor_util_env';\nimport {TensorLike2D} from '../types';\nimport {DataType} from '../types';\nimport {assertNonNull} from '../util';\nimport {makeTensor} from './tensor_ops_util';\n\n/**\n * Creates rank-2 `tf.Tensor` with the provided values, shape and dtype.\n *\n * The same functionality can be achieved with `tf.tensor`, but in general\n * we recommend using `tf.tensor2d` as it makes the code more readable.\n *\n *  ```js\n * // Pass a nested array.\n * tf.tensor2d([[1, 2], [3, 4]]).print();\n * ```\n * ```js\n * // Pass a flat array and specify a shape.\n * tf.tensor2d([1, 2, 3, 4], [2, 2]).print();\n * ```\n *\n * @param values The values of the tensor. Can be nested array of numbers,\n *     or a flat array, or a `TypedArray`.\n * @param shape The shape of the tensor. If not provided, it is inferred from\n *     `values`.\n * @param dtype The data type.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nexport function tensor2d(\n    values: TensorLike2D, shape?: [number, number],\n    dtype?: DataType): Tensor2D {\n  assertNonNull(values);\n  if (shape != null && shape.length !== 2) {\n    throw new Error('tensor2d() requires shape to have two numbers');\n  }\n  const inferredShape = inferShape(values, dtype);\n  if (inferredShape.length !== 2 && inferredShape.length !== 1) {\n    throw new Error(\n        'tensor2d() requires values to be number[][] or flat/TypedArray');\n  }\n  if (inferredShape.length === 1 && shape == null) {\n    throw new Error(\n        'tensor2d() requires shape to be provided when `values` ' +\n        'are a flat/TypedArray');\n  }\n  return makeTensor(values, shape, inferredShape, dtype) as Tensor2D;\n}\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor4D} from '../tensor';\nimport {inferShape} from '../tensor_util_env';\nimport {TensorLike4D} from '../types';\nimport {DataType} from '../types';\nimport {assertNonNull} from '../util';\nimport {makeTensor} from './tensor_ops_util';\n\n/**\n * Creates rank-4 `tf.Tensor` with the provided values, shape and dtype.\n *\n * The same functionality can be achieved with `tf.tensor`, but in general\n * we recommend using `tf.tensor4d` as it makes the code more readable.\n *\n *  ```js\n * // Pass a nested array.\n * tf.tensor4d([[[[1], [2]], [[3], [4]]]]).print();\n * ```\n * ```js\n * // Pass a flat array and specify a shape.\n * tf.tensor4d([1, 2, 3, 4], [1, 2, 2, 1]).print();\n * ```\n *\n * @param values The values of the tensor. Can be nested array of numbers,\n *     or a flat array, or a `TypedArray`.\n * @param shape The shape of the tensor. Optional. If not provided,\n *   it is inferred from `values`.\n * @param dtype The data type.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nexport function tensor4d(\n    values: TensorLike4D, shape?: [number, number, number, number],\n    dtype?: DataType): Tensor4D {\n  assertNonNull(values);\n  if (shape != null && shape.length !== 4) {\n    throw new Error('tensor4d() requires shape to have four numbers');\n  }\n  const inferredShape = inferShape(values, dtype);\n  if (inferredShape.length !== 4 && inferredShape.length !== 1) {\n    throw new Error(\n        'tensor4d() requires values to be number[][][][] or flat/TypedArray');\n  }\n  if (inferredShape.length === 1 && shape == null) {\n    throw new Error(\n        'tensor4d() requires shape to be provided when `values` ' +\n        'are a flat array');\n  }\n  return makeTensor(values, shape, inferredShape, dtype) as Tensor4D;\n}\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor5D} from '../tensor';\nimport {inferShape} from '../tensor_util_env';\nimport {TensorLike5D} from '../types';\nimport {DataType} from '../types';\nimport {assertNonNull} from '../util';\nimport {makeTensor} from './tensor_ops_util';\n\n/**\n * Creates rank-5 `tf.Tensor` with the provided values, shape and dtype.\n *\n * The same functionality can be achieved with `tf.tensor`, but in general\n * we recommend using `tf.tensor5d` as it makes the code more readable.\n *\n *  ```js\n * // Pass a nested array.\n * tf.tensor5d([[[[[1],[2]],[[3],[4]]],[[[5],[6]],[[7],[8]]]]]).print();\n * ```\n * ```js\n * // Pass a flat array and specify a shape.\n * tf.tensor5d([1, 2, 3, 4, 5, 6, 7, 8], [1, 2, 2, 2, 1]).print();\n * ```\n *\n * @param values The values of the tensor. Can be nested array of numbers,\n *     or a flat array, or a `TypedArray`.\n * @param shape The shape of the tensor. Optional. If not provided,\n *   it is inferred from `values`.\n * @param dtype The data type.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nexport function tensor5d(\n    values: TensorLike5D, shape?: [number, number, number, number, number],\n    dtype?: DataType): Tensor5D {\n  assertNonNull(values);\n  if (shape != null && shape.length !== 5) {\n    throw new Error('tensor5d() requires shape to have five numbers');\n  }\n  const inferredShape = inferShape(values, dtype);\n  if (inferredShape.length !== 5 && inferredShape.length !== 1) {\n    throw new Error(\n        'tensor5d() requires values to be ' +\n        'number[][][][][] or flat/TypedArray');\n  }\n  if (inferredShape.length === 1 && shape == null) {\n    throw new Error(\n        'tensor5d() requires shape to be provided when `values` ' +\n        'are a flat array');\n  }\n  return makeTensor(values, shape, inferredShape, dtype) as Tensor5D;\n}\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor6D} from '../tensor';\nimport {inferShape} from '../tensor_util_env';\nimport {TensorLike6D} from '../types';\nimport {DataType} from '../types';\nimport {assertNonNull} from '../util';\nimport {makeTensor} from './tensor_ops_util';\n\n/**\n * Creates rank-6 `tf.Tensor` with the provided values, shape and dtype.\n *\n * The same functionality can be achieved with `tf.tensor`, but in general\n * we recommend using `tf.tensor6d` as it makes the code more readable.\n *\n *  ```js\n * // Pass a nested array.\n * tf.tensor6d([[[[[[1],[2]],[[3],[4]]],[[[5],[6]],[[7],[8]]]]]]).print();\n * ```\n * ```js\n * // Pass a flat array and specify a shape.\n * tf.tensor6d([1, 2, 3, 4, 5, 6, 7, 8], [1, 1, 2, 2, 2, 1]).print();\n * ```\n *\n * @param values The values of the tensor. Can be nested array of numbers,\n *     or a flat array, or a `TypedArray`.\n * @param shape The shape of the tensor. Optional. If not provided,\n *   it is inferred from `values`.\n * @param dtype The data type.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nexport function tensor6d(\n    values: TensorLike6D,\n    shape?: [number, number, number, number, number, number],\n    dtype?: DataType): Tensor6D {\n  assertNonNull(values);\n  if (shape != null && shape.length !== 6) {\n    throw new Error('tensor6d() requires shape to have six numbers');\n  }\n  const inferredShape = inferShape(values, dtype);\n  if (inferredShape.length !== 6 && inferredShape.length !== 1) {\n    throw new Error(\n        'tensor6d() requires values to be number[][][][][][] or ' +\n        'flat/TypedArray');\n  }\n  if (inferredShape.length === 1 && shape == null) {\n    throw new Error(\n        'tensor6d() requires shape to be provided when `values` ' +\n        'are a flat array');\n  }\n  shape = shape ||\n      inferredShape as [number, number, number, number, number, number];\n  return makeTensor(values, shape, inferredShape, dtype) as Tensor6D;\n}\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {TopK, TopKAttrs, TopKInputs} from '../kernel_names';\nimport {NamedAttrMap} from '../kernel_registry';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {op} from './operation';\n\n/**\n * Finds the values and indices of the `k` largest entries along the last\n * dimension.\n *\n * If the input is a vector (rank=1), finds the k largest entries in the vector\n * and outputs their values and indices as vectors. Thus values[j] is the j-th\n * largest entry in input, and its index is indices[j].\n * For higher rank inputs, computes the top k entries along the last dimension.\n *\n * If two elements are equal, the lower-index element appears first.\n *\n * ```js\n * const a = tf.tensor2d([[1, 5], [4, 3]]);\n * const {values, indices} = tf.topk(a);\n * values.print();\n * indices.print();\n * ```\n * @param x 1-D or higher `tf.Tensor` with last dimension being at least `k`.\n * @param k Number of top elements to look for along the last dimension.\n * @param sorted If true, the resulting `k` elements will be sorted by the\n *     values in descending order.\n *\n * @doc {heading: 'Operations', subheading: 'Evaluation'}\n */\nfunction topk_<T extends Tensor>(\n    x: T|TensorLike, k = 1, sorted = true): {values: T, indices: T} {\n  const $x = convertToTensor(x, 'x', 'topk');\n  if ($x.rank === 0) {\n    throw new Error('topk() expects the input to be of rank 1 or higher');\n  }\n  const lastDim = $x.shape[$x.shape.length - 1];\n\n  if (k < 0) {\n    throw new Error(`'k' passed to topk() must be >= 0 but got ${k}`);\n  }\n\n  if (k > lastDim) {\n    throw new Error(\n        `'k' passed to topk() must be <= the last dimension (${lastDim}) ` +\n        `but got ${k}`);\n  }\n\n  const inputs: TopKInputs = {x: $x};\n  const attrs: TopKAttrs = {k, sorted};\n\n  const [values, indices] = ENGINE.runKernel(\n      TopK, inputs as {} as NamedTensorMap, attrs as {} as NamedAttrMap);\n\n  return {values, indices} as {values: T, indices: T};\n}\n\nexport const topk = op({topk_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor} from '../tensor';\nimport {DataType, Rank, ShapeMap} from '../types';\n\nimport {buffer} from './buffer';\nimport {op} from './operation';\nimport {MPRandGauss} from './rand_util';\n\n/**\n * Creates a `tf.Tensor` with values sampled from a truncated normal\n * distribution.\n *\n * ```js\n * tf.truncatedNormal([2, 2]).print();\n * ```\n *\n * The generated values follow a normal distribution with specified mean and\n * standard deviation, except that values whose magnitude is more than 2\n * standard deviations from the mean are dropped and re-picked.\n *\n * @param shape An array of integers defining the output tensor shape.\n * @param mean The mean of the normal distribution.\n * @param stdDev The standard deviation of the normal distribution.\n * @param dtype The data type of the output tensor.\n * @param seed The seed for the random number generator.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nfunction truncatedNormal_<R extends Rank>(\n    shape: ShapeMap[R], mean = 0, stdDev = 1, dtype?: 'float32'|'int32',\n    seed?: number): Tensor<R> {\n  if (dtype != null && (dtype as DataType) === 'bool') {\n    throw new Error(`Unsupported data type $ { dtype }`);\n  }\n  const randGauss =\n      new MPRandGauss(mean, stdDev, dtype, true /* truncated */, seed);\n  const res = buffer(shape, dtype);\n  for (let i = 0; i < res.values.length; i++) {\n    res.values[i] = randGauss.nextValue();\n  }\n  return res.toTensor();\n}\n\nexport const truncatedNormal = op({truncatedNormal_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {Unique, UniqueAttrs, UniqueInputs} from '../kernel_names';\nimport {NamedAttrMap} from '../kernel_registry';\nimport {Tensor, Tensor1D} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\nimport {assert} from '../util';\n\nimport {op} from './operation';\n\n/**\n * Finds unique elements along an axis of a tensor.\n *\n * It returns a tensor `values` containing all of the unique elements along the\n * `axis` of the given tensor `x` in the same order that they occur along the\n * `axis` in `x`; `x` does not need to be sorted. It also returns a tensor\n * `indices` the same size as the number of the elements in `x` along the `axis`\n * dimension. It contains the index in the unique output `values`.\n *\n * ```js\n * // A 1-D tensor\n * const a = tf.tensor1d([1, 1, 2, 4, 4, 4, 7, 8, 8]);\n * const {values, indices} = tf.unique(a);\n * values.print();   // [1, 2, 4, 7, 8,]\n * indices.print();  // [0, 0, 1, 2, 2, 2, 3, 4, 4]\n * ```\n *\n * ```js\n * // A 2-D tensor with axis=0\n * //\n * // 'a' is: [[1, 0, 0],\n * //          [1, 0, 0],\n * //          [2, 0, 0]]\n * const a = tf.tensor2d([[1, 0, 0], [1, 0, 0], [2, 0, 0]]);\n * const {values, indices} = tf.unique(a, 0)\n * values.print();   // [[1, 0, 0],\n *                   //  [2, 0, 0]]\n * indices.print();  // [0, 0, 1]\n * ```\n *\n * ```js\n * // A 2-D tensor with axis=1\n * //\n * // 'a' is: [[1, 0, 0],\n * //          [1, 0, 0],\n * //          [2, 0, 0]]\n * const a = tf.tensor2d([[1, 0, 0], [1, 0, 0], [2, 0, 0]]);\n * const {values, indices} = tf.unique(a, 1)\n * values.print();   // [[1, 0],\n *                   //  [1, 0],\n *                   //  [2, 0]]\n * indices.print();  // [0, 1, 1]\n * ```\n * @param x A tensor (int32, string, bool).\n * @param axis The axis of the tensor to find the unique elements.\n * @returns [uniqueElements, indices] (see above for details)\n *\n * @doc {heading: 'Operations', subheading: 'Evaluation'}\n */\nfunction unique_<T extends Tensor>(\n    x: T|TensorLike, axis = 0): {values: T, indices: Tensor1D} {\n  const $x = convertToTensor(x, 'x', 'unique', 'string_or_numeric');\n  assert($x.rank > 0, () => 'The input tensor must be at least 1D');\n\n  const inputs: UniqueInputs = {x: $x};\n  const attrs: UniqueAttrs = {axis};\n  const [values, indices] = ENGINE.runKernel(\n                                Unique, inputs as {} as NamedTensorMap,\n                                attrs as {} as NamedAttrMap) as [T, Tensor1D];\n  return {values, indices};\n}\n\nexport const unique = op({unique_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {UnsortedSegmentSum, UnsortedSegmentSumAttrs, UnsortedSegmentSumInputs} from '../kernel_names';\nimport {NamedAttrMap} from '../kernel_registry';\nimport {Tensor, Tensor1D} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\nimport {assert, isInt} from '../util';\n\nimport {op} from './operation';\n\n/**\n * Computes the sum along segments of a `tf.Tensor`.\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3, 4]);\n * const segmentIds = tf.tensor1d([1, 2, 0, 1], 'int32');\n * const numSegments = 3;\n *\n * x.unsortedSegmentSum(segmentIds, numSegments).print()\n * //or tf.unsortedSegmentSum(x, segmentIds, numSegments)\n * ```\n * @param x The `tf.Tensor` that will be summed along its segments.\n * @param segmentIds A `tf.Tensor1D` whose rank is equal to the rank of `x`'s\n * dimension along the `axis`.  Maps each element of `x` to a segment.\n * @param numSegments The number of distinct `segmentIds`.\n *\n * @doc {heading: 'Operations', subheading: 'Segment'}\n */\nfunction unsortedSegmentSum_<T extends Tensor>(\n    x: T|TensorLike, segmentIds: Tensor1D|TensorLike, numSegments: number): T {\n  const $x = convertToTensor(x, 'x', 'unsortedSegmentSum');\n  const $segmentIds =\n      convertToTensor(segmentIds, 'segmentIds', 'unsortedSegmentSum', 'int32');\n  assert(isInt(numSegments), () => 'numSegments must be of dtype int');\n\n  const inputs: UnsortedSegmentSumInputs = {x: $x, segmentIds: $segmentIds};\n  const attrs: UnsortedSegmentSumAttrs = {numSegments};\n\n  return ENGINE.runKernel(\n      UnsortedSegmentSum, inputs as {} as NamedTensorMap,\n      attrs as {} as NamedAttrMap);\n}\n\nexport const unsortedSegmentSum = op({unsortedSegmentSum_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {Unpack, UnpackAttrs, UnpackInputs} from '../kernel_names';\nimport {NamedAttrMap} from '../kernel_registry';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\nimport * as util from '../util';\n\nimport {op} from './operation';\n\n/**\n * Unstacks a `tf.Tensor` of rank-`R` into a list of rank-`(R-1)` `tf.Tensor`s.\n *\n * ```js\n * const a = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n *\n * tf.unstack(a).forEach(tensor => tensor.print());\n * ```\n *\n * @param x A tensor object.\n * @param axis The axis to unstack along. Defaults to 0 (the first dim).\n *\n * @doc {heading: 'Tensors', subheading: 'Slicing and Joining'}\n */\nfunction unstack_(x: Tensor|TensorLike, axis = 0): Tensor[] {\n  const $x = convertToTensor(x, 'x', 'unstack', 'string_or_numeric');\n  util.assert(\n      axis >= -$x.shape.length && axis < $x.shape.length,\n      () =>\n          `Axis = ${axis} is not in [-${$x.shape.length}, ${$x.shape.length})`);\n\n  const inputs: UnpackInputs = {value: $x};\n  const attrs: UnpackAttrs = {axis};\n\n  return ENGINE.runKernel(\n      Unpack, inputs as {} as NamedTensorMap, attrs as {} as NamedAttrMap);\n}\n\nexport const unstack = op({unstack_});\n","/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor} from '../tensor';\nimport {TensorLike} from '../types';\nimport {searchSorted} from './search_sorted';\n\n/**\n * Searches for where a value would go in a sorted sequence.\n *\n * This is not a method for checking containment (like javascript in).\n *\n * The typical use case for this operation is \"binning\", \"bucketing\", or\n * \"discretizing\". The values are assigned to bucket-indices based on the edges\n * listed in 'sortedSequence'. This operation returns the bucket-index for each\n * value.\n *\n * The index returned corresponds to the first edge greater than the value.\n *\n * The axis is not settable for this operation. It always operates on the\n * innermost dimension (axis=-1). The operation will accept any number of outer\n * dimensions.\n *\n * Note: This operation assumes that 'upperBound' is sorted along the\n * innermost axis, maybe using 'sort(..., axis=-1)'. If the sequence is not\n * sorted no error is raised and the content of the returned tensor is not well\n * defined.\n *\n * ```js\n * const seq = tf.tensor1d([0, 3, 9, 10, 10]);\n * const values = tf.tensor1d([0, 4, 10]);\n * const result = tf.upperBound(seq, values);\n * result.print(); // [1, 2, 5]\n * ```\n * @param sortedSequence: N-D. Sorted sequence.\n * @param values: N-D. Search values.\n * @return An N-D int32 tensor the size of values containing the result of\n *     applying upper bound to each value. The result is not a global index to\n *     the entire Tensor, but the index in the last dimension.\n * @doc {heading: 'Operations', subheading: 'Evaluation'}\n */\nexport function upperBound(\n    sortedSequence: Tensor|TensorLike, values: Tensor|TensorLike): Tensor {\n  return searchSorted(sortedSequence, values, 'right');\n}\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {Tensor, Variable} from '../tensor';\nimport {DataType, Rank} from '../types';\n\n/**\n * Creates a new variable with the provided initial value.\n * ```js\n * const x = tf.variable(tf.tensor([1, 2, 3]));\n * x.assign(tf.tensor([4, 5, 6]));\n *\n * x.print();\n * ```\n *\n * @param initialValue Initial value for the tensor.\n * @param trainable If true, optimizers are allowed to update it.\n * @param name Name of the variable. Defaults to a unique id.\n * @param dtype If set, initialValue will be converted to the given type.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nexport function variable<R extends Rank>(\n    initialValue: Tensor<R>, trainable = true, name?: string,\n    dtype?: DataType): Variable<R> {\n  return ENGINE.makeVariable(initialValue, trainable, name, dtype) as\n      Variable<R>;\n}\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n/** An implementation of the Where kernel shared between cpu and webgl */\n\nimport {buffer} from '../ops/buffer';\nimport {Tensor2D} from '../tensor';\nimport {TypedArray} from '../types';\n\nexport function whereImpl(condShape: number[], condVals: TypedArray): Tensor2D {\n  const indices = [];\n  for (let i = 0; i < condVals.length; i++) {\n    if (condVals[i]) {\n      indices.push(i);\n    }\n  }\n\n  const inBuffer = buffer(condShape, 'int32');\n\n  const out = buffer([indices.length, condShape.length], 'int32');\n  for (let i = 0; i < indices.length; i++) {\n    const loc = inBuffer.indexToLoc(indices[i]);\n    const offset = i * condShape.length;\n    out.values.set(loc, offset);\n  }\n  return out.toTensor() as Tensor2D;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {whereImpl} from '../backends/where_impl';\nimport {Tensor, Tensor2D} from '../tensor';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\n/**\n * Returns the coordinates of true elements of condition.\n *\n * The coordinates are returned in a 2-D tensor where the first dimension (rows)\n * represents the number of true elements, and the second dimension (columns)\n * represents the coordinates of the true elements. Keep in mind, the shape of\n * the output tensor can vary depending on how many true values there are in\n * input. Indices are output in row-major order. The resulting tensor has the\n * shape `[numTrueElems, condition.rank]`.\n *\n * This is analogous to calling the python `tf.where(cond)` without an x or y.\n *\n * ```js\n * const cond = tf.tensor1d([false, false, true], 'bool');\n * const result = await tf.whereAsync(cond);\n * result.print();\n * ```\n *\n * @doc {heading: 'Operations', subheading: 'Logical'}\n */\nasync function whereAsync_(condition: Tensor|TensorLike): Promise<Tensor2D> {\n  const $condition =\n      convertToTensor(condition, 'condition', 'whereAsync', 'bool');\n  const vals = await $condition.data();\n  const res = whereImpl($condition.shape, vals);\n  if (condition !== $condition) {\n    $condition.dispose();\n  }\n  return res;\n}\n\nexport const whereAsync = whereAsync_;\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor} from '../tensor';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\nimport * as util from '../util';\n\nimport {gather} from './gather';\nimport {reshape} from './reshape';\nimport {squeeze} from './squeeze';\nimport {whereAsync} from './where_async';\n\n/**\n * Apply boolean mask to tensor.\n *\n * ```js\n * const tensor = tf.tensor2d([1, 2, 3, 4, 5, 6], [3, 2]);\n * const mask = tf.tensor1d([1, 0, 1], 'bool');\n * const result = await tf.booleanMaskAsync(tensor, mask);\n * result.print();\n * ```\n *\n * @param tensor N-D tensor.\n * @param mask K-D boolean tensor, K <= N and K must be known statically.\n * @param axis A 0-D int Tensor representing the axis in tensor to mask from.\n *     By default, axis is 0 which will mask from the first dimension.\n *     Otherwise K + axis <= N.\n *\n * @doc {heading: 'Tensors', subheading: 'Slicing and Joining'}\n */\nasync function booleanMaskAsync_(\n    tensor: Tensor|TensorLike, mask: Tensor|TensorLike,\n    axis?: number): Promise<Tensor> {\n  const $tensor = convertToTensor(tensor, 'tensor', 'boolMask');\n  const $mask = convertToTensor(mask, 'mask', 'boolMask', 'bool');\n\n  const axisFrom = axis == null ? 0 : axis;\n  const maskDim = $mask.rank;\n  const tensorShape = $tensor.shape;\n\n  util.assert(maskDim > 0, () => 'mask cannot be scalar');\n  util.assertShapesMatch(\n      tensorShape.slice(axisFrom, axisFrom + maskDim), $mask.shape,\n      `mask's shape must match the first K dimensions of tensor's shape,`);\n\n  let leadingSize = 1;\n  for (let i = axisFrom; i < axisFrom + maskDim; i++) {\n    leadingSize *= tensorShape[i];\n  }\n  const targetTensorShape =\n      tensorShape.slice(0, axisFrom)\n          .concat([leadingSize], tensorShape.slice(axisFrom + maskDim));\n  const reshapedTensor = reshape($tensor, targetTensorShape);\n  const reshapedMask = reshape($mask, [-1]);\n  const positivePositions = await whereAsync(reshapedMask);\n  const indices = squeeze(positivePositions, [1]);\n\n  const res = gather(reshapedTensor, indices, axisFrom);\n\n  // Ensure no memory leak.\n  if (tensor !== $tensor) {\n    $tensor.dispose();\n  }\n  if (mask !== $mask) {\n    $mask.dispose();\n  }\n  indices.dispose();\n  reshapedTensor.dispose();\n  reshapedMask.dispose();\n  positivePositions.dispose();\n\n  return res;\n}\n\nexport const booleanMaskAsync = booleanMaskAsync_;\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Scalar, Tensor} from '../tensor';\nimport {assertTypesMatch} from '../tensor_util';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\nimport * as util from '../util';\n\nimport {add} from './add';\nimport {div} from './div';\nimport {mul} from './mul';\nimport {op} from './operation';\nimport {pow} from './pow';\nimport {scalar} from './scalar';\nimport {sub} from './sub';\n\n/**\n * Compute the moving average of a variable.\n *\n * Without zeroDebias, the moving average operation is defined by:\n *   `v += delta`\n * where\n *   `delta = (1 - decay) * (x - v)`\n *\n * With zeroDebias (default), the `delta` term is scaled to debias the\n * effect of the (assumed) zero-initialization of `v`.\n *   `delta /= (1 - decay ^ step)`\n *\n * For more details on the zero-debiasing algorithm, see:\n *   https://arxiv.org/abs/1412.6980\n *\n * Note that this function is completely stateless and does not keep track of\n * step count. The step count needs to be maintained by the caller and passed\n * in as `step`.\n *\n * @param v The current moving average value.\n * @param x New input value, must have the same shape and dtype as `v`.\n * @param decay The decay factor. Typical values are 0.95 and 0.99.\n * @param step Step count.\n * @param zeroDebias: Whether zeroDebias is to be performed (default: `true`).\n * @returns The new moving average value.\n *\n * @doc {heading: 'Operations', subheading: 'Moving Average'}\n */\nfunction movingAverage_<T extends Tensor>(\n    v: T|TensorLike, x: T|TensorLike, decay: number|Scalar,\n    step?: number|Scalar, zeroDebias = true): T {\n  const $v = convertToTensor(v, 'v', 'movingAverage');\n  const $x = convertToTensor(x, 'x', 'movingAverage');\n  const $decay = convertToTensor(decay, 'decay', 'movingAverage');\n\n  assertTypesMatch($v, $x);\n  util.assert(\n      util.arraysEqual($v.shape, $x.shape), () => 'Shape mismatch in v and x');\n\n  const one = scalar(1);\n  const oneMinusDecay = sub(one, $decay);\n\n  let update = mul(sub($x, $v), oneMinusDecay);\n  if (zeroDebias) {\n    util.assert(\n        step != null, () => 'When using zeroDebias: true, step is required.');\n    const $step = convertToTensor(step, 'step', 'movingAverage');\n    update = div(update, sub(one, pow($decay, $step)));\n  }\n  return add($v, update);\n}\n\nexport const movingAverage = op({movingAverage_});\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {ScatterNd, ScatterNdAttrs, ScatterNdInputs} from '../kernel_names';\nimport {NamedAttrMap} from '../kernel_registry';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {Rank, ShapeMap, TensorLike} from '../types';\n\nimport {op} from './operation';\nimport * as scatter_nd_util from './scatter_nd_util';\n\n/**\n * Creates a new tensor by applying sparse updates to individual\n * values or slices within a zero tensor of the given shape tensor according to\n * indices. This operator is the inverse of the `tf.gatherND` operator which\n * extracts values or slices from a given tensor.\n *\n * ```js\n * const indices = tf.tensor2d([4, 3, 1, 7], [4, 1], 'int32');\n * const updates = tf.tensor1d([9, 10, 11, 12]);\n * const shape = [8];\n * tf.scatterND(indices, updates, shape).print() //[0, 11, 0, 10, 9, 0, 0, 12]\n * ```\n *\n * @param indices The tensor contains the indices into the output tensor.\n * @param updates The tensor contains the value for the indices.\n * @param shape: The shape of the output tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Slicing and Joining'}\n */\nfunction scatterND_<R extends Rank>(\n    indices: Tensor|TensorLike, updates: Tensor|TensorLike,\n    shape: ShapeMap[R]): Tensor<R> {\n  const $indices = convertToTensor(indices, 'indices', 'scatterND', 'int32');\n  const $updates = convertToTensor(updates, 'updates', 'scatterND');\n  scatter_nd_util.validateInput($updates, $indices, shape);\n\n  const inputs: ScatterNdInputs = {indices: $indices, updates: $updates};\n  const attrs: ScatterNdAttrs = {shape};\n\n  // tslint:disable-next-line: no-unnecessary-type-assertion\n  return ENGINE.runKernel(\n             ScatterNd, inputs as {} as NamedTensorMap,\n             attrs as {} as NamedAttrMap) as Tensor<R>;\n}\n\nexport const scatterND = op({scatterND_});\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {SparseToDense, SparseToDenseAttrs, SparseToDenseInputs} from '../kernel_names';\nimport {NamedAttrMap} from '../kernel_registry';\nimport * as sparse_to_dense from '../ops/sparse_to_dense_util';\nimport {Scalar, Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {Rank, ScalarLike, ShapeMap, TensorLike} from '../types';\n\nimport {op} from './operation';\n\n/**\n * Converts a sparse representation into a dense tensor.\n *\n * Builds an array dense with shape outputShape such that:\n *\n * // If sparseIndices is scalar\n * dense[i] = (i == sparseIndices ? sparseValues : defaultValue)\n *\n * // If sparseIndices is a vector, then for each i\n * dense[sparseIndices[i]] = sparseValues[i]\n *\n * // If sparseIndices is an n by d matrix, then for each i in [0, n)\n * dense[sparseIndices[i][0], ..., sparseIndices[i][d-1]] = sparseValues[i]\n * All other values in dense are set to defaultValue. If sparseValues is a\n * scalar, all sparse indices are set to this single value.\n *\n * If indices are repeated the final value is summed over all values for those\n * indices.\n *\n * ```js\n * const indices = tf.tensor1d([4, 5, 6, 1, 2, 3], 'int32');\n * const values = tf.tensor1d([10, 11, 12, 13, 14, 15], 'float32');\n * const shape = [8];\n * tf.sparseToDense(indices, values, shape).print();\n * ```\n *\n * @param sparseIndices A 0-D, 1-D, or 2-D Tensor of type int32.\n * sparseIndices[i] contains the complete index where sparseValues[i] will be\n * placed.\n * @param sparseValues A 0-D or 1-D Tensor. Values\n * corresponding to each row of sparseIndices, or a scalar value to be used for\n * all sparse indices.\n * @param outputShape Shape of the dense output tensor. The type is inferred.\n * @param defaultValue Scalar. Value to set for indices not specified in\n * sparseIndices. Defaults to zero.\n *\n * @doc {heading: 'Operations', subheading: 'Normalization'}\n */\nfunction sparseToDense_<R extends Rank>(\n    sparseIndices: Tensor|TensorLike, sparseValues: Tensor|TensorLike,\n    outputShape: ShapeMap[R], defaultValue: Scalar|ScalarLike = 0): Tensor<R> {\n  const $sparseIndices =\n      convertToTensor(sparseIndices, 'sparseIndices', 'sparseToDense', 'int32');\n  const $sparseValues = convertToTensor(\n      sparseValues, 'sparseValues', 'sparseToDense', 'string_or_numeric');\n  const $defaultValue = convertToTensor(\n      defaultValue, 'defaultValue', 'sparseToDense', $sparseValues.dtype);\n\n  sparse_to_dense.validateInput(\n      $sparseIndices, $sparseValues, outputShape, $defaultValue);\n\n  const inputs: SparseToDenseInputs = {\n    sparseIndices: $sparseIndices,\n    sparseValues: $sparseValues,\n    defaultValue: $defaultValue\n  };\n\n  const attrs: SparseToDenseAttrs = {outputShape};\n\n  return ENGINE.runKernel(\n      SparseToDense, inputs as {} as NamedTensorMap,\n      attrs as {} as NamedAttrMap);\n}\n\nexport const sparseToDense = op({sparseToDense_});\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {Tensor} from '../tensor';\n\n/**\n * Validate sparseToDense inputs.\n *\n * @param sparseIndices A 0-D, 1-D, or 2-D Tensor of type int32.\n * sparseIndices[i] contains the complete index where sparseValues[i] will be\n * placed.\n * @param sparseValues A 0-D or 1-D Tensor. Values\n * corresponding to each row of sparseIndices, or a scalar value to be used for\n * all sparse indices.\n * @param outputShape number[]. Shape of the dense output tensor.\n * @param validateIndices boolean. indice validation is not supported, error\n * will be thrown if it is set.\n */\nexport function validateInput(\n    sparseIndices: Tensor, sparseValues: Tensor, outputShape: number[],\n    defaultValues: Tensor) {\n  if (sparseIndices.dtype !== 'int32') {\n    throw new Error(\n        'tf.sparseToDense() expects the indices to be int32 type,' +\n        ` but the dtype was ${sparseIndices.dtype}.`);\n  }\n  if (sparseIndices.rank > 2) {\n    throw new Error(\n        'sparseIndices should be a scalar, vector, or matrix,' +\n        ` but got shape ${sparseIndices.shape}.`);\n  }\n\n  const numElems = sparseIndices.rank > 0 ? sparseIndices.shape[0] : 1;\n  const numDims = sparseIndices.rank > 1 ? sparseIndices.shape[1] : 1;\n\n  if (outputShape.length !== numDims) {\n    throw new Error(\n        'outputShape has incorrect number of elements:,' +\n        ` ${outputShape.length}, should be: ${numDims}.`);\n  }\n\n  const numValues = sparseValues.size;\n  if (!(sparseValues.rank === 0 ||\n        sparseValues.rank === 1 && numValues === numElems)) {\n    throw new Error(\n        'sparseValues has incorrect shape ' +\n        `${sparseValues.shape}, should be [] or [${numElems}]`);\n  }\n\n  if (sparseValues.dtype !== defaultValues.dtype) {\n    throw new Error('sparseValues.dtype must match defaultValues.dtype');\n  }\n}\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {ENGINE} from '../engine';\nimport {GatherNd, GatherNdInputs} from '../kernel_names';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\nimport {op} from './operation';\n\n/**\n * Gather slices from input tensor into a Tensor with shape specified by\n * `indices`.\n *\n * `indices` is a K-dimensional integer tensor, best thought of as a\n * (K-1)-dimensional tensor of indices into input, where each element defines a\n * slice of input:\n * output[\\\\(i_0, ..., i_{K-2}\\\\)] = input[indices[\\\\(i_0, ..., i_{K-2}\\\\)]]\n *\n * Whereas in `tf.gather`, `indices` defines slices into the first dimension of\n * input, in `tf.gatherND`, `indices` defines slices into the first N dimensions\n * of input, where N = indices.shape[-1].\n *\n * The last dimension of indices can be at most the rank of input:\n * indices.shape[-1] <= input.rank\n *\n * The last dimension of `indices` corresponds to elements\n * (if indices.shape[-1] == input.rank) or slices\n * (if indices.shape[-1] < input.rank) along dimension indices.shape[-1] of\n * input.\n * The output tensor has shape\n * indices.shape[:-1] + input.shape[indices.shape[-1]:]\n *\n * Note that on CPU, if an out of bound index is found, an error is returned. On\n * GPU, if an out of bound index is found, a 0 is stored in the corresponding\n * output value.\n *\n * ```js\n * const indices = tf.tensor2d([0, 1, 1, 0], [2,2], 'int32');\n * const input = tf.tensor2d([9, 10, 11, 12], [2, 2]);\n * tf.gatherND(input, indices).print() // [10, 11]\n * ```\n *\n * @param x The tensor from which to gather values.\n * @param indices Index tensor, must be of type int32.\n *\n * @doc {heading: 'Operations', subheading: 'Slicing and Joining'}\n */\nfunction gatherND_(x: Tensor|TensorLike, indices: Tensor|TensorLike): Tensor {\n  const $indices = convertToTensor(indices, 'indices', 'gatherND', 'int32');\n  const $x = convertToTensor(x, 'x', 'gatherND', 'string_or_numeric');\n\n  const inputs: GatherNdInputs = {params: $x, indices: $indices};\n\n  return ENGINE.runKernel(GatherNd, inputs as {} as NamedTensorMap);\n}\n\nexport const gatherND = op({gatherND_});\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor} from '../tensor';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\nimport * as util from '../util';\n\nimport {add} from './add';\nimport {div} from './div';\nimport {getNoiseShape} from './dropout_util';\nimport {floor} from './floor';\nimport {mul} from './mul';\nimport {op} from './operation';\nimport {randomUniform} from './random_uniform';\n\n/**\n * Computes dropout.\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 2, 1]);\n * const rate = 0.75;\n * const output = tf.dropout(x, rate);\n * output.print();\n * ```\n *\n * @param x A floating point Tensor or TensorLike.\n * @param rate A float in the range [0, 1). The probability that each element\n *   of x is discarded.\n * @param noiseShape An array of numbers of type int32, representing the\n * shape for randomly generated keep/drop flags. If the noiseShape has null\n * value, it will be automatically replaced with the x's relative dimension\n * size. Optional.\n * @param seed Used to create random seeds. Optional.\n * @returns A Tensor of the same shape of x.\n *\n * @doc {heading: 'Operations', subheading: 'Dropout'}\n */\nfunction dropout_(\n    x: Tensor|TensorLike, rate: number, noiseShape?: number[],\n    seed?: number|string): Tensor {\n  const $x = convertToTensor(x, 'x', 'dropout');\n\n  util.assert(\n      $x.dtype === 'float32',\n      () => `x has to be a floating point tensor since it's going to be ` +\n          `scaled, but got a ${$x.dtype} tensor instead.`);\n  util.assert(\n      rate >= 0 && rate < 1,\n      () => `rate must be a float in the range [0, 1), but got ${rate}.`);\n\n  if (rate === 0) {\n    return x instanceof Tensor ? $x.clone() : $x;\n  }\n\n  const $noiseShape = getNoiseShape($x, noiseShape);\n  const keepProb = 1 - rate;\n  const multiplier = div(\n      floor(add(randomUniform($noiseShape, 0, 1, 'float32', seed), keepProb)),\n      keepProb);\n\n  return mul($x, multiplier);\n}\n\nexport const dropout = op({dropout_});\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor} from '../tensor';\nimport * as util from '../util';\n\n/**\n * Normalize noise shape based on provided tensor and noise shape.\n *\n * @param x Tensor.\n * @param noiseShape The shape for the randomly generated keep/drop flags, as\n *   an array of numbers. Optional.\n * @returns Normalized noise shape.\n */\nexport function getNoiseShape(x: Tensor, noiseShape?: number[]): number[] {\n  if (noiseShape == null) {\n    return x.shape.slice();\n  }\n  if (util.arraysEqual(x.shape, noiseShape)) {\n    return noiseShape;\n  }\n  if (x.shape.length === noiseShape.length) {\n    const newDimension: number[] = [];\n    for (let i = 0; i < x.shape.length; i++) {\n      if (noiseShape[i] == null && x.shape[i] != null) {\n        newDimension.push(x.shape[i]);\n      } else {\n        newDimension.push(noiseShape[i]);\n      }\n    }\n    return newDimension;\n  }\n\n  return noiseShape;\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor1D} from '../tensor';\nimport {tensor1d} from './tensor1d';\n\nexport function enclosingPowerOfTwo(value: number) {\n  // Return 2**N for integer N such that 2**N >= value.\n  return Math.floor(Math.pow(2, Math.ceil(Math.log(value) / Math.log(2.0))));\n}\n\nexport function cosineWindow(\n    windowLength: number, a: number, b: number): Tensor1D {\n  const even = 1 - windowLength % 2;\n  const newValues = new Float32Array(windowLength);\n  for (let i = 0; i < windowLength; ++i) {\n    const cosArg = (2.0 * Math.PI * i) / (windowLength + even - 1);\n    newValues[i] = a - b * Math.cos(cosArg);\n  }\n  return tensor1d(newValues, 'float32');\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor} from '../tensor';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\nimport {assert, assertShapesMatch, getTypedArrayFromDType} from '../util';\nimport {tensor} from './tensor';\n\n/**\n * Returns whether the targets are in the top K predictions.\n *\n * ```js\n * const predictions = tf.tensor2d([[20, 10, 40, 30], [30, 50, -20, 10]]);\n * const targets = tf.tensor1d([2, 0]);\n * const precision = await tf.inTopKAsync(predictions, targets);\n * precision.print();\n * ```\n * @param predictions 2-D or higher `tf.Tensor` with last dimension being\n *     at least `k`.\n * @param targets 1-D or higher `tf.Tensor`.\n * @param k Optional Number of top elements to look at for computing precision,\n *     default to 1.\n *\n * @doc {heading: 'Operations', subheading: 'Evaluation'}\n */\nasync function inTopKAsync_<T extends Tensor, U extends Tensor>(\n    predictions: T|TensorLike, targets: U|TensorLike, k = 1): Promise<U> {\n  const $predictions = convertToTensor(predictions, 'predictions', 'inTopK');\n  const $targets = convertToTensor(targets, 'targets', 'inTopK');\n\n  assert(\n      $predictions.rank > 1,\n      () => 'inTopK() expects the predictions to be of rank 2 or higher, ' +\n          `but got ${$predictions.rank}`);\n  assert(\n      $predictions.rank - 1 === $targets.rank,\n      () => `predictions rank should be 1 larger than ` +\n          `targets rank, but got predictions rank ` +\n          `${$predictions.rank} and targets rank ${$targets.rank}`);\n  assertShapesMatch(\n      $predictions.shape.slice(0, $predictions.shape.length - 1),\n      $targets.shape,\n      `predictions's shape should be align with the targets' shape, ` +\n          'except the last dimension.');\n  const lastDim = $predictions.shape[$predictions.shape.length - 1];\n  assert(\n      k > 0 && k <= lastDim,\n      () => `'k' passed to inTopK() must be > 0 && <= the predictions last ` +\n          `dimension (${lastDim}), but got ${k}`);\n\n  const predictionsVals = await $predictions.data();\n  const targetsVals = await $targets.data();\n\n  // Reshape predictionsVals into a 2d tensor [batch, lastDim]\n  // and look up topK along lastDim.\n  const [batch, size] = [predictionsVals.length / lastDim, lastDim];\n  const precision = getTypedArrayFromDType('bool', batch);\n\n  for (let b = 0; b < batch; b++) {\n    const offset = b * size;\n    const vals = predictionsVals.subarray(offset, offset + size);\n    const valAndInd: Array<{value: number, index: number}> = [];\n    for (let i = 0; i < vals.length; i++) {\n      valAndInd.push({value: vals[i], index: i});\n    }\n    valAndInd.sort((a, b) => b.value - a.value);\n\n    precision[b] = 0;\n    for (let i = 0; i < k; i++) {\n      if (valAndInd[i].index === targetsVals[b]) {\n        precision[b] = 1;\n        break;\n      }\n    }\n  }\n\n  if (predictions !== $predictions) {\n    $predictions.dispose();\n  }\n  if (targets !== $targets) {\n    $targets.dispose();\n  }\n\n  // Output precision has the same shape as targets.\n  return tensor(precision, $targets.shape, 'bool') as U;\n}\n\nexport const inTopKAsync = inTopKAsync_;\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {ENGINE} from '../engine';\nimport {Conv2DBackpropFilter, Conv2DBackpropFilterAttrs, Conv2DBackpropFilterInputs} from '../kernel_names';\nimport {NamedAttrMap} from '../kernel_registry';\nimport {Tensor3D, Tensor4D} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport * as util from '../util';\n\nimport * as conv_util from './conv_util';\nimport {op} from './operation';\nimport {reshape} from './reshape';\n\n/**\n * Computes the derivative of the filter of a 2D convolution.\n *\n * @param x The input tensor, of rank 4 or rank 3 of shape\n *     [batch, height, width, inChannels]. If rank 3, batch of 1 is assumed.\n * @param dy The dy image, of rank 4 or rank 3, of shape\n *     [batch, height, width, outDepth]. If rank 3, batch of 1 is assumed.\n * @param filterShape The shape of the filter, length 4,\n *     [filterHeight, filterWidth, inDepth, outDepth].\n * @param strides The strides of the convolution: [strideHeight,\n * strideWidth].\n * @param pad A string from: 'same', 'valid'. The type of padding algorithm\n *     used in the forward prop of the op.\n * @param dataFormat: An optional string from: \"NHWC\", \"NCHW\". Defaults to\n *     \"NHWC\". Specify the data format of the input and output data. With the\n *     default format \"NHWC\", the data is stored in the order of: [batch,\n *     height, width, channels].\n * @param dimRoundingMode A string from: 'ceil', 'round', 'floor'. If none is\n *     provided, it will default to truncate.\n */\nfunction conv2DBackpropFilter_<T extends Tensor3D|Tensor4D>(\n    x: T, dy: T, filterShape: [number, number, number, number],\n    strides: [number, number]|number,\n    pad: 'valid'|'same'|number|conv_util.ExplicitPadding,\n    dataFormat: 'NHWC'|'NCHW' = 'NHWC',\n    dimRoundingMode?: 'floor'|'round'|'ceil'): Tensor4D {\n  let x4D = x as Tensor4D;\n  if (x.rank === 3) {\n    x4D = reshape(x, [1, x.shape[0], x.shape[1], x.shape[2]]);\n  }\n  let dy4D = dy as Tensor4D;\n  if (dy4D.rank === 3) {\n    dy4D = reshape(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2]]);\n  }\n  util.assert(\n      x4D.rank === 4,\n      () => `Error in conv2dDerFilter: input must be rank 4, but got shape ` +\n          `${x4D.shape}.`);\n  util.assert(\n      dy4D.rank === 4,\n      () => `Error in conv2dDerFilter: dy must be rank 4, but got shape ` +\n          `${dy4D.shape}.`);\n  util.assert(\n      filterShape.length === 4,\n      () => `Error in conv2dDerFilter: filterShape must be length 4, but got ` +\n          `${filterShape}.`);\n  const inDepth = dataFormat === 'NHWC' ? x4D.shape[3] : x4D.shape[1];\n  const outDepth = dataFormat === 'NHWC' ? dy4D.shape[3] : dy4D.shape[1];\n  util.assert(\n      inDepth === filterShape[2],\n      () => `Error in conv2dDerFilter: depth of input ${inDepth}) must ` +\n          `match input depth in filter (${filterShape[2]}.`);\n  util.assert(\n      outDepth === filterShape[3],\n      () => `Error in conv2dDerFilter: depth of dy (${outDepth}) must ` +\n          `match output depth for filter (${filterShape[3]}).`);\n  conv_util.checkPadOnDimRoundingMode('conv2dDerFilter', pad, dimRoundingMode);\n  const inputs: Conv2DBackpropFilterInputs = {x: x4D, dy: dy4D};\n  const attrs: Conv2DBackpropFilterAttrs =\n      {strides, pad, dataFormat, dimRoundingMode, filterShape};\n\n  // tslint:disable-next-line: no-unnecessary-type-assertion\n  return ENGINE.runKernel(\n             Conv2DBackpropFilter, inputs as {} as NamedTensorMap,\n             attrs as {} as NamedAttrMap) as Tensor4D;\n}\n\nexport const conv2DBackpropFilter = op({conv2DBackpropFilter_});\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor} from '../tensor';\n\nimport * as broadcast_util from './broadcast_util';\nimport {elu} from './elu';\nimport {Activation} from './fused_types';\nimport {leakyRelu} from './leaky_relu';\nimport {mul} from './mul';\nimport {prelu} from './prelu';\nimport {relu} from './relu';\nimport {relu6} from './relu6';\nimport {reshape} from './reshape';\nimport {sigmoid} from './sigmoid';\nimport {step} from './step';\nimport {sum} from './sum';\n\n// Returns gradient for fused activation.\nexport function getFusedDyActivation(\n    dy: Tensor, y: Tensor, activation: Activation): Tensor {\n  if (activation == null || activation === 'linear') {\n    return dy;\n  }\n  if (activation === 'relu') {\n    return mul(dy, step(y));\n  }\n  throw new Error(\n      `Cannot compute gradient for fused activation ${activation}.`);\n}\n\n// Returns gradient for fused bias.\nexport function getFusedBiasGradient(\n    bias: Tensor, dyActivation: Tensor): Tensor {\n  let res = dyActivation;\n  const reduceAxes =\n      broadcast_util.getReductionAxes(bias.shape, dyActivation.shape);\n  if (reduceAxes.length > 0) {\n    res = sum(res, reduceAxes);\n  }\n  return reshape(res, bias.shape);\n}\n\nexport function applyActivation(\n    x: Tensor, activation: Activation, preluActivationWeights?: Tensor,\n    leakyreluAlpha?: number): Tensor {\n  if (activation === 'linear') {\n    return x;\n  } else if (activation === 'relu') {\n    return relu(x);\n  } else if (activation === 'elu') {\n    return elu(x);\n  } else if (activation === 'relu6') {\n    return relu6(x);\n  } else if (activation === 'prelu') {\n    return prelu(x, preluActivationWeights);\n  } else if (activation === 'leakyrelu') {\n    return leakyRelu(x, leakyreluAlpha);\n  } else if (activation === 'sigmoid') {\n    return sigmoid(x);\n  }\n  throw new Error(`Unknown fused activation ${activation}.`);\n}\n\n// Whether we should call fused ops.\nexport const shouldFuse = (gradientDepth: number, activation: Activation) => {\n  const gradientMode = gradientDepth > 0;\n  return !gradientMode || activation === 'linear';\n};\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../../engine';\nimport {customGrad} from '../../gradients';\nimport {FusedConv2D, FusedConv2DAttrs, FusedConv2DInputs} from '../../kernel_names';\nimport {NamedAttrMap} from '../../kernel_registry';\nimport {Tensor, Tensor3D, Tensor4D} from '../../tensor';\nimport {GradSaveFunc, NamedTensorMap} from '../../tensor_types';\nimport {makeTypesMatch} from '../../tensor_util';\nimport {convertToTensor} from '../../tensor_util_env';\nimport {TensorLike} from '../../types';\nimport * as util from '../../util';\nimport {add} from '../add';\nimport * as broadcast_util from '../broadcast_util';\nimport {conv2d as unfusedConv2d} from '../conv2d';\nimport {conv2DBackpropFilter} from '../conv2d_backprop_filter';\nimport {conv2DBackpropInput} from '../conv2d_backprop_input';\nimport * as conv_util from '../conv_util';\nimport {Activation} from '../fused_types';\nimport {applyActivation, getFusedBiasGradient, getFusedDyActivation, shouldFuse} from '../fused_util';\nimport {op} from '../operation';\nimport {reshape} from '../reshape';\n\n/**\n * Computes a 2D convolution over the input x, optionally fused with adding a\n * bias and applying an activation.\n *\n * ```js\n * const inputDepth = 2;\n * const inShape = [2, 2, 2, inputDepth];\n * const outputDepth = 2;\n * const fSize = 1;\n * const pad = 0;\n * const strides = 1;\n *\n * const x = tf.tensor4d( [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15,\n * 16], inShape);\n * const w = tf.tensor4d([-1, 1, -2, 0.5], [fSize, fSize, inputDepth,\n * outputDepth]);\n *\n * tf.fused.conv2d({ x, filter: w, strides, pad, dataFormat: 'NHWC',\n * dilations: [1, 1], bias: tf.scalar(5), activation: 'relu' }).print();\n * ```\n *\n * @param obj An object with the following properties:\n * @param x The input tensor, of rank 4 or rank 3, of shape\n *     `[batch, height, width, inChannels]`. If rank 3, batch of 1 is\n * assumed.\n * @param filter The filter, rank 4, of shape\n *     `[filterHeight, filterWidth, inDepth, outDepth]`.\n * @param strides The strides of the convolution: `[strideHeight,\n * strideWidth]`.\n * @param pad The type of padding algorithm.\n *   - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *   - `valid` output will be smaller than input if filter is larger\n *       than 1x1.\n *   - For more info, see this guide:\n *     [https://www.tensorflow.org/api_docs/python/tf/nn/convolution](\n *          https://www.tensorflow.org/api_docs/python/tf/nn/convolution)\n * @param dataFormat An optional string from: \"NHWC\", \"NCHW\". Defaults to\n *     \"NHWC\". Specify the data format of the input and output data. With the\n *     default format \"NHWC\", the data is stored in the order of: [batch,\n *     height, width, channels]. Only \"NHWC\" is currently supported.\n * @param dilations The dilation rates: `[dilationHeight, dilationWidth]`\n *     in which we sample input values across the height and width dimensions\n *     in atrous convolution. Defaults to `[1, 1]`. If `dilations` is a single\n *     number, then `dilationHeight == dilationWidth`. If it is greater than\n *     1, then all values of `strides` must be 1.\n * @param dimRoundingMode A string from: 'ceil', 'round', 'floor'. If none is\n *     provided, it will default to truncate.\n * @param bias Tensor to be added to the result.\n * @param activation Name of activation kernel (defaults to `linear`) to be\n *     applied\n *      after biasAdd.\n * @param preluActivationWeights Tensor of prelu weights to be applied as part\n *     of a `prelu` activation, typically the same shape as `x`.\n * @param leakyreluAlpha Optional. Alpha to be applied as part of a `leakyrelu`\n *     activation.\n */\nfunction fusedConv2d_<T extends Tensor3D|Tensor4D>({\n  x,\n  filter,\n  strides,\n  pad,\n  dataFormat = 'NHWC',\n  dilations = [1, 1],\n  dimRoundingMode,\n  bias,\n  activation = 'linear',\n  preluActivationWeights,\n  leakyreluAlpha\n}: {\n  x: T|TensorLike,\n  filter: Tensor4D|TensorLike,\n  strides: [number, number]|number,\n  pad: 'valid'|'same'|number|conv_util.ExplicitPadding,\n  dataFormat?: 'NHWC'|'NCHW',\n  dilations?: [number, number]|number,\n  dimRoundingMode?: 'floor'|'round'|'ceil',\n  bias?: Tensor|TensorLike,\n  activation?: Activation,\n  preluActivationWeights?: Tensor,\n  leakyreluAlpha?: number\n}): T {\n  activation = activation || 'linear';\n\n  if (shouldFuse(ENGINE.state.gradientDepth, activation) === false) {\n    // TODO: Transpose bias and preluActivationWeights properly for NCHW\n    // format before computation.\n    util.assert(\n        dataFormat === 'NHWC',\n        () => `Error in fused conv2d: got dataFormat of ${dataFormat} but ` +\n            `only NHWC is currently supported for the case of gradient depth ` +\n            `is 0 and the activation is not linear.`);\n\n    let result = unfusedConv2d(\n        x, filter, strides, pad, dataFormat, dilations, dimRoundingMode);\n    if (bias != null) {\n      result = add(result, bias);\n    }\n\n    return applyActivation(\n               result, activation, preluActivationWeights, leakyreluAlpha) as T;\n  }\n\n  const $x = convertToTensor(x, 'x', 'conv2d', 'float32');\n  const $filter = convertToTensor(filter, 'filter', 'conv2d', 'float32');\n\n  let x4D = $x as Tensor4D;\n  let reshapedTo4D = false;\n\n  if ($x.rank === 3) {\n    reshapedTo4D = true;\n    x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);\n  }\n  util.assert(\n      x4D.rank === 4,\n      () => `Error in fused conv2d: input must be rank 4, but got rank ` +\n          `${x4D.rank}.`);\n  util.assert(\n      $filter.rank === 4,\n      () => `Error in fused conv2d: filter must be rank 4, but got rank ` +\n          `${$filter.rank}.`);\n  conv_util.checkPadOnDimRoundingMode('fused conv2d', pad, dimRoundingMode);\n  const inputChannels = dataFormat === 'NHWC' ? x4D.shape[3] : x4D.shape[1];\n  util.assert(\n      $filter.shape[2] === inputChannels,\n      () => `Error in conv2d: depth of input (${inputChannels}) must match ` +\n          `input depth for filter ${$filter.shape[2]}.`);\n  util.assert(\n      conv_util.eitherStridesOrDilationsAreOne(strides, dilations),\n      () => 'Error in conv2D: Either strides or dilations must be 1. ' +\n          `Got strides ${strides} and dilations '${dilations}'`);\n\n  const convInfo = conv_util.computeConv2DInfo(\n      x4D.shape, $filter.shape, strides, dilations, pad, dimRoundingMode);\n\n  let $bias: Tensor;\n  if (bias != null) {\n    $bias = convertToTensor(bias, 'bias', 'fused conv2d');\n    [$bias] = makeTypesMatch($bias, $x);\n\n    // According to TensorFlow, the bias is supposed be a 1-D tensor or a\n    // scalar.\n    //\n    // 3-D or 4-D bias is not disabled for NHWC format, because they are\n    // currently being used in some cases. For examplem in our code base,\n    // https://github.com/tensorflow/tfjs/blob/b53bd47e880367ae57493f0ea628abaf08db2d5d/tfjs-core/src/ops/fused/fused_conv2d_test.ts#L1972.\n    if (dataFormat === 'NHWC') {\n      broadcast_util.assertAndGetBroadcastShape(convInfo.outShape, $bias.shape);\n    } else {\n      util.assert(\n          $bias.shape.length <= 1,\n          () => `Error in fused conv2d: only supports scalar or 1-D Tensor ` +\n              `bias for NCHW format but got the bias of ` +\n              `rank-${$bias.shape.length}.`);\n\n      util.assert(\n          $bias.shape.length === 0 || $bias.shape[0] === convInfo.outChannels ||\n              $bias.shape[0] === 1,\n          () => `Error in fused conv2d: bias shape (${$bias.shape}) is not ` +\n              `compatible with the number of output channels ` +\n              `(${convInfo.outChannels})`);\n    }\n  }\n\n  let $preluActivationWeights: Tensor;\n  if (preluActivationWeights != null) {\n    // PReLU's activation weights could be a scalar, a 1-D tensor or a 3-D\n    // tensor.\n    const alphaShape = preluActivationWeights.shape;\n    util.assert(\n        alphaShape.length <= 1 || alphaShape.length === 3,\n        () => `Error in fused conv2d: only supports scalar, 1-D Tensor or ` +\n            `3-D Tensor PReLU activation weights but got a tensor of ` +\n            `rank-${alphaShape.length}.`);\n\n    if (alphaShape.length === 1) {\n      // Whether the data format is NCHW or NHWC, the 1-D PReLU activation\n      // weights tensor should be aligned with the output channels of conv2d\n      // result.\n      util.assert(\n          alphaShape[0] === 1 || alphaShape[0] === convInfo.outChannels,\n          () => `Error in fused conv2d: PReLU activation weights ` +\n              `(${alphaShape}) is not compatible with the number of output ` +\n              `channels (${convInfo.outChannels}).`);\n    } else if (alphaShape.length === 3) {\n      // Whether the data format is NCHW or NHWC, the PReLU activation weights\n      // tensor should has the compatible shape with the result of conv2d.\n      try {\n        broadcast_util.assertAndGetBroadcastShape(\n            alphaShape, convInfo.outShape);\n      } catch (e) {\n        const errMsg =\n            `Error in fused conv2d: PReLU activation weights (${alphaShape}) ` +\n            `is not compatible with the output shape of the conv2d ` +\n            `(${convInfo.outShape}).`;\n        throw Error(errMsg);\n      }\n    }\n\n    $preluActivationWeights = convertToTensor(\n        preluActivationWeights, 'prelu weights', 'fused conv2d');\n  }\n\n  const grad = (dy: Tensor4D, saved: Tensor[]) => {\n    util.assert(\n        dataFormat === 'NHWC',\n        () => `Error in gradient of fused conv2D: got dataFormat of ${\n            dataFormat} but only NHWC is currently supported.`);\n\n    const [$filter, x4D, y, $bias] =\n        saved as [Tensor4D, Tensor4D, Tensor4D, Tensor];\n\n    const dyActivation = getFusedDyActivation(dy, y, activation) as Tensor4D;\n\n    util.assert(\n        conv_util.tupleValuesAreOne(dilations),\n        () => 'Error in gradient of fused conv2D: ' +\n            `dilation rates greater than 1 ` +\n            `are not yet supported in gradients. Got dilations '${dilations}'`);\n\n    const xDer =\n        conv2DBackpropInput(x4D.shape, dyActivation, $filter, strides, pad);\n    const filterDer =\n        conv2DBackpropFilter(x4D, dyActivation, $filter.shape, strides, pad);\n    const der: Tensor[] = [xDer, filterDer];\n\n    if ($bias != null) {\n      const biasDer = getFusedBiasGradient($bias, dyActivation);\n      der.push(biasDer);\n    }\n    return der;\n  };\n\n  const inputs: FusedConv2DInputs = {\n    x: x4D,\n    filter: $filter,\n    bias: $bias,\n    preluActivationWeights: $preluActivationWeights\n  };\n\n  const attrs: FusedConv2DAttrs = {\n    strides,\n    pad,\n    dataFormat,\n    dilations,\n    dimRoundingMode,\n    activation,\n    leakyreluAlpha\n  };\n\n  // Depending on the the params passed in we will have different number of\n  // inputs and thus a a different number of elements in the gradient.\n  if (bias == null) {\n    const customOp =\n        customGrad((x4D: Tensor4D, filter: Tensor4D, save: GradSaveFunc) => {\n          let res: Tensor4D|Tensor3D =\n              // tslint:disable-next-line: no-unnecessary-type-assertion\n              ENGINE.runKernel(\n                  FusedConv2D, inputs as {} as NamedTensorMap,\n                  attrs as {} as NamedAttrMap);\n\n          save([filter, x4D, res]);\n\n          if (reshapedTo4D) {\n            // tslint:disable-next-line: no-unnecessary-type-assertion\n            res = reshape(res, [res.shape[1], res.shape[2], res.shape[3]]) as\n                Tensor3D;\n          }\n\n          return {value: res, gradFunc: grad};\n        });\n    return customOp(x4D, $filter) as T;\n  } else {\n    const customOpWithBias = customGrad(\n        (x4D: Tensor4D, filter: Tensor4D, bias: Tensor, save: GradSaveFunc) => {\n          let res: Tensor4D|Tensor3D = ENGINE.runKernel(\n              FusedConv2D, inputs as {} as NamedTensorMap,\n              attrs as {} as NamedAttrMap);\n\n          save([filter, x4D, res, bias]);\n\n          if (reshapedTo4D) {\n            // tslint:disable-next-line: no-unnecessary-type-assertion\n            res = reshape(res, [res.shape[1], res.shape[2], res.shape[3]]) as\n                Tensor3D;\n          }\n\n          return {value: res, gradFunc: grad};\n        });\n\n    return customOpWithBias(x4D, $filter, $bias) as T;\n  }\n}\nexport const conv2d = op({fusedConv2d_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {ENGINE} from '../engine';\nimport {DepthwiseConv2dNativeBackpropFilter, DepthwiseConv2dNativeBackpropFilterAttrs, DepthwiseConv2dNativeBackpropFilterInputs} from '../kernel_names';\nimport {NamedAttrMap} from '../kernel_registry';\nimport {Tensor3D, Tensor4D} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\n\nimport {ExplicitPadding} from './conv_util';\nimport {op} from './operation';\nimport {reshape} from './reshape';\n\nfunction depthwiseConv2dNativeBackpropFilter_<T extends Tensor3D|Tensor4D>(\n    x: T, dy: T, filterShape: [number, number, number, number],\n    strides: [number, number]|number,\n    pad: 'valid'|'same'|number|ExplicitPadding,\n    dilations: [number, number]|number = [1, 1],\n    dimRoundingMode?: 'floor'|'round'|'ceil'): Tensor4D {\n  let x4D = x as Tensor4D;\n  if (x.rank === 3) {\n    x4D = reshape(x, [1, x.shape[0], x.shape[1], x.shape[2]]);\n  }\n  let dy4D = dy as Tensor4D;\n  if (dy4D.rank === 3) {\n    dy4D = reshape(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2]]);\n  }\n\n  const inputs: DepthwiseConv2dNativeBackpropFilterInputs = {x: x4D, dy: dy4D};\n  const attrs: DepthwiseConv2dNativeBackpropFilterAttrs =\n      {strides, pad, dimRoundingMode, dilations, filterShape};\n\n  // tslint:disable-next-line: no-unnecessary-type-assertion\n  return ENGINE.runKernel(\n             DepthwiseConv2dNativeBackpropFilter,\n             inputs as {} as NamedTensorMap, attrs as {} as NamedAttrMap) as\n      Tensor4D;\n}\n\nexport const depthwiseConv2dNativeBackpropFilter =\n    op({depthwiseConv2dNativeBackpropFilter_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {ENGINE} from '../engine';\nimport {DepthwiseConv2dNativeBackpropInput, DepthwiseConv2dNativeBackpropInputAttrs, DepthwiseConv2dNativeBackpropInputInputs} from '../kernel_names';\nimport {NamedAttrMap} from '../kernel_registry';\nimport {Tensor3D, Tensor4D} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\n\nimport {ExplicitPadding} from './conv_util';\nimport {op} from './operation';\nimport {reshape} from './reshape';\n\nfunction depthwiseConv2dNativeBackpropInput_<T extends Tensor3D|Tensor4D>(\n    xShape: [number, number, number, number], dy: T, filter: Tensor4D,\n    strides: [number, number]|number,\n    pad: 'valid'|'same'|number|ExplicitPadding,\n    dilations: [number, number]|number = [1, 1],\n    dimRoundingMode?: 'floor'|'round'|'ceil'): T {\n  let dy4D = dy as Tensor4D;\n  let reshapedTo4D = false;\n  if (dy.rank === 3) {\n    reshapedTo4D = true;\n    dy4D = reshape(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2]]);\n  }\n\n  const inputs: DepthwiseConv2dNativeBackpropInputInputs = {dy: dy4D, filter};\n  const attrs: DepthwiseConv2dNativeBackpropInputAttrs =\n      {strides, pad, dimRoundingMode, dilations, inputShape: xShape};\n\n  const res =\n      // tslint:disable-next-line: no-unnecessary-type-assertion\n      ENGINE.runKernel(\n          DepthwiseConv2dNativeBackpropInput, inputs as {} as NamedTensorMap,\n          attrs as {} as NamedAttrMap) as T;\n\n  if (reshapedTo4D) {\n    return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]) as T;\n  }\n  return res;\n}\n\nexport const depthwiseConv2dNativeBackpropInput =\n    op({depthwiseConv2dNativeBackpropInput_});\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../../engine';\nimport {customGrad} from '../../gradients';\nimport {FusedDepthwiseConv2D, FusedDepthwiseConv2DAttrs, FusedDepthwiseConv2DInputs} from '../../kernel_names';\nimport {NamedAttrMap} from '../../kernel_registry';\nimport {Tensor, Tensor3D, Tensor4D} from '../../tensor';\nimport {GradSaveFunc, NamedTensorMap} from '../../tensor_types';\nimport {makeTypesMatch} from '../../tensor_util';\nimport {convertToTensor} from '../../tensor_util_env';\nimport {TensorLike} from '../../types';\nimport * as util from '../../util';\nimport {add} from '../add';\nimport * as broadcast_util from '../broadcast_util';\nimport * as conv_util from '../conv_util';\nimport {depthwiseConv2d as unfusedDepthwiseConv2d} from '../depthwise_conv2d';\nimport {depthwiseConv2dNativeBackpropFilter} from '../depthwise_conv2d_native_backprop_filter';\nimport {depthwiseConv2dNativeBackpropInput} from '../depthwise_conv2d_native_backprop_input';\nimport {Activation} from '../fused_types';\nimport {applyActivation, getFusedBiasGradient, getFusedDyActivation, shouldFuse} from '../fused_util';\nimport {op} from '../operation';\nimport {reshape} from '../reshape';\n\n/**\n * Computes depthwise 2D convolution, optionally fused with adding a\n * bias and applying an activation.\n *\n * Given a 4D `input` array and a `filter` array of shape\n * `[filterHeight, filterWidth, inChannels, channelMultiplier]` containing\n * `inChannels` convolutional filters of depth 1, this op applies a\n * different filter to each input channel (expanding from 1 channel to\n * `channelMultiplier` channels for each), then concatenates the results\n * together. The output has `inChannels * channelMultiplier` channels.\n *\n * See\n * [https://www.tensorflow.org/api_docs/python/tf/nn/depthwise_conv2d](\n *     https://www.tensorflow.org/api_docs/python/tf/nn/depthwise_conv2d)\n * for more details.\n *\n * @param obj An object with the following properties:\n * @param x The input tensor, of rank 4 or rank 3, of shape\n *     `[batch, height, width, inChannels]`. If rank 3, batch of 1 is\n * assumed.\n * @param filter The filter tensor, rank 4, of shape\n *     `[filterHeight, filterWidth, inChannels, channelMultiplier]`.\n * @param strides The strides of the convolution: `[strideHeight,\n * strideWidth]`. If strides is a single number, then `strideHeight ==\n * strideWidth`.\n * @param pad The type of padding algorithm.\n *   - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *   - `valid`: output will be smaller than input if filter is larger\n *       than 1x1.\n *   - For more info, see this guide:\n *     [https://www.tensorflow.org/api_docs/python/tf/nn/convolution](\n *          https://www.tensorflow.org/api_docs/python/tf/nn/convolution)\n * @param dilations The dilation rates: `[dilationHeight, dilationWidth]`\n *     in which we sample input values across the height and width dimensions\n *     in atrous convolution. Defaults to `[1, 1]`. If `rate` is a single\n *     number, then `dilationHeight == dilationWidth`. If it is greater than\n *     1, then all values of `strides` must be 1.\n * @param dataFormat: An optional string from: \"NHWC\", \"NCHW\". Defaults to\n *     \"NHWC\". Specify the data format of the input and output data. With the\n *     default format \"NHWC\", the data is stored in the order of: [batch,\n *     height, width, channels]. Only \"NHWC\" is currently supported.\n * @param dimRoundingMode A string from: 'ceil', 'round', 'floor'. If none is\n *     provided, it will default to truncate.\n * @param bias Tensor to be added to the result.\n * @param activation Name of activation kernel (defaults to `linear`).\n * @param preluActivationWeights Tensor of prelu weights to be applied as part\n *     of a `prelu` activation, typically the same shape as `x`.\n * @param leakyreluAlpha Optional. Alpha to be applied as part of a `leakyrelu`\n *     activation.\n */\nfunction fusedDepthwiseConv2d_<T extends Tensor3D|Tensor4D>({\n  x,\n  filter,\n  strides,\n  pad,\n  dataFormat = 'NHWC',\n  dilations = [1, 1],\n  dimRoundingMode,\n  bias,\n  activation = 'linear',\n  preluActivationWeights,\n  leakyreluAlpha\n}: {\n  x: T|TensorLike,\n  filter: Tensor4D|TensorLike,\n  strides: [number, number]|number,\n  pad: 'valid'|'same'|number,\n  dataFormat?: 'NHWC'|'NCHW',\n  dilations?: [number, number]|number,\n  dimRoundingMode?: 'floor'|'round'|'ceil',\n  bias?: Tensor|TensorLike,\n  activation?: Activation,\n  preluActivationWeights?: Tensor,\n  leakyreluAlpha?: number\n}): T {\n  if (shouldFuse(ENGINE.state.gradientDepth, activation) === false) {\n    let result = unfusedDepthwiseConv2d(\n        x, filter, strides, pad, dataFormat, dilations, dimRoundingMode);\n    if (bias != null) {\n      result = add(result, bias);\n    }\n\n    return applyActivation(\n               result, activation, preluActivationWeights, leakyreluAlpha) as T;\n  }\n\n  const $x = convertToTensor(x, 'x', 'depthwiseConv2d', 'float32');\n  const $filter =\n      convertToTensor(filter, 'filter', 'depthwiseConv2d', 'float32');\n\n  let x4D = $x as Tensor4D;\n  let reshapedTo4D = false;\n  if ($x.rank === 3) {\n    reshapedTo4D = true;\n    x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);\n  }\n  util.assert(\n      x4D.rank === 4,\n      () => `Error in fused depthwiseConv2d: input must be rank 4, but got ` +\n          `rank ${x4D.rank}.`);\n  util.assert(\n      $filter.rank === 4,\n      () => `Error in fused depthwiseConv2d: filter must be rank 4, ` +\n          `but got rank ${$filter.rank}.`);\n  util.assert(\n      x4D.shape[3] === $filter.shape[2],\n      () => `Error in fused depthwiseConv2d: number of input channels ` +\n          `(${x4D.shape[3]}) must match the inChannels dimension in ` +\n          `filter ${$filter.shape[2]}.`);\n  if (dilations == null) {\n    dilations = [1, 1];\n  }\n  util.assert(\n      conv_util.eitherStridesOrDilationsAreOne(strides, dilations),\n      () =>\n          'Error in fused depthwiseConv2d: Either strides or dilations must ' +\n          `be 1. Got strides ${strides} and dilations '${dilations}'`);\n  conv_util.checkPadOnDimRoundingMode(\n      'fused depthwiseConv2d', pad, dimRoundingMode);\n  const convInfo = conv_util.computeConv2DInfo(\n      x4D.shape, $filter.shape, strides, dilations, pad, dimRoundingMode,\n      true /* depthwise */);\n\n  let $bias: Tensor;\n  if (bias != null) {\n    $bias = convertToTensor(bias, 'bias', 'fused conv2d');\n    [$bias] = makeTypesMatch($bias, $x);\n\n    broadcast_util.assertAndGetBroadcastShape(convInfo.outShape, $bias.shape);\n  }\n\n  let $preluActivationWeights: Tensor;\n  if (preluActivationWeights != null) {\n    $preluActivationWeights = convertToTensor(\n        preluActivationWeights, 'prelu weights', 'fused depthwiseConv2d');\n  }\n\n  const grad = (dy: Tensor4D, saved: Tensor[]) => {\n    util.assert(\n        conv_util.tupleValuesAreOne(dilations),\n        () => 'Error in gradient of fused depthwiseConv2d: dilation rates ' +\n            `greater than 1 are not yet supported. Got dilations ` +\n            `'${dilations}'`);\n    const [$filter, x4D, y, bias] = saved;\n\n    const dyActivation = getFusedDyActivation(dy, y, activation) as Tensor4D;\n\n    const xDer = depthwiseConv2dNativeBackpropInput(\n        (x4D as Tensor4D).shape, dyActivation, $filter as Tensor4D, strides,\n        pad, dilations, dimRoundingMode);\n    const filterDer = depthwiseConv2dNativeBackpropFilter(\n        x4D as Tensor4D, dyActivation, ($filter as Tensor4D).shape, strides,\n        pad, dilations, dimRoundingMode);\n\n    if (bias != null) {\n      const biasDer = getFusedBiasGradient($bias, dyActivation);\n      return [xDer, filterDer, biasDer];\n    }\n    return [xDer, filterDer];\n  };\n\n  const inputs: FusedDepthwiseConv2DInputs = {\n    x: x4D,\n    filter: $filter,\n    bias: $bias,\n    preluActivationWeights: $preluActivationWeights\n  };\n  const attrs: FusedDepthwiseConv2DAttrs = {\n    strides,\n    pad,\n    dataFormat,\n    dilations,\n    dimRoundingMode,\n    activation,\n    leakyreluAlpha\n  };\n\n  // Depending on the the params passed in we will have different number of\n  // inputs and thus a a different number of elements in the gradient.\n  if (bias == null) {\n    const customOp =\n        customGrad((x4D: Tensor4D, filter: Tensor4D, save: GradSaveFunc) => {\n          // tslint:disable-next-line: no-unnecessary-type-assertion\n          let res: Tensor4D|Tensor3D = ENGINE.runKernel(\n              FusedDepthwiseConv2D, inputs as {} as NamedTensorMap,\n              attrs as {} as NamedAttrMap);\n\n          save([filter, x4D, res]);\n\n          if (reshapedTo4D) {\n            // tslint:disable-next-line: no-unnecessary-type-assertion\n            res = reshape(res, [res.shape[1], res.shape[2], res.shape[3]]) as\n                Tensor3D;\n          }\n\n          return {value: res, gradFunc: grad};\n        });\n    return customOp(x4D, $filter) as T;\n  } else {\n    const customOpWithBias = customGrad(\n        (x4D: Tensor4D, filter: Tensor4D, bias: Tensor, save: GradSaveFunc) => {\n          // tslint:disable-next-line: no-unnecessary-type-assertion\n          let res: Tensor4D|Tensor3D = ENGINE.runKernel(\n              FusedDepthwiseConv2D, inputs as {} as NamedTensorMap,\n              attrs as {} as NamedAttrMap);\n\n          save([filter, x4D, res, bias]);\n\n          if (reshapedTo4D) {\n            // tslint:disable-next-line: no-unnecessary-type-assertion\n            res = reshape(res, [res.shape[1], res.shape[2], res.shape[3]]) as\n                Tensor3D;\n          }\n\n          return {value: res, gradFunc: grad};\n        });\n\n    return customOpWithBias(x4D, $filter, $bias) as T;\n  }\n}\nexport const depthwiseConv2d = op({fusedDepthwiseConv2d_});\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../../engine';\nimport {customGrad} from '../../gradients';\nimport {_FusedMatMul, _FusedMatMulAttrs, _FusedMatMulInputs} from '../../kernel_names';\nimport {NamedAttrMap} from '../../kernel_registry';\nimport {Tensor, Tensor3D} from '../../tensor';\nimport {GradSaveFunc, NamedTensorMap} from '../../tensor_types';\nimport {makeTypesMatch} from '../../tensor_util';\nimport {convertToTensor} from '../../tensor_util_env';\nimport {TensorLike} from '../../types';\nimport * as util from '../../util';\n\nimport {add} from '../add';\nimport * as broadcast_util from '../broadcast_util';\nimport {Activation} from '../fused_types';\nimport {applyActivation, getFusedBiasGradient, getFusedDyActivation, shouldFuse} from '../fused_util';\nimport {matMul as unfusedMatMul} from '../mat_mul';\nimport {op} from '../operation';\nimport {reshape} from '../reshape';\n\n/**\n * Computes the dot product of two matrices with optional activation and bias.\n *\n * ```js\n * const a = tf.tensor2d([-1, -2], [1, 2]);\n * const b = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n * const bias = tf.tensor2d([1, 2], [1, 2]);\n *\n * tf.fused.matMul({a, b, bias, activation: 'relu'}).print();\n * ```\n *\n * @param obj An object with the following properties:\n * - `a` First matrix in dot product operation.\n * - `b` Second matrix in dot product operation.\n * - `transposeA` If true, `a` is transposed before multiplication.\n * - `transposeB` If true, `b` is transposed before multiplication.\n * - `bias` Matrix to be added to the result.\n * - `activation` Name of activation kernel (defaults to `linear`).\n * - `preluActivationWeights` Tensor of prelu weights.\n * - `leakyreluAlpha` Alpha of leakyrelu.\n */\nfunction fusedMatMul_({\n  a,\n  b,\n  transposeA = false,\n  transposeB = false,\n  bias,\n  activation = 'linear',\n  preluActivationWeights,\n  leakyreluAlpha = 0.2,\n}: {\n  a: Tensor|TensorLike,\n  b: Tensor|TensorLike,\n  transposeA?: boolean,\n  transposeB?: boolean,\n  bias?: Tensor|TensorLike,\n  activation?: Activation,\n  preluActivationWeights?: Tensor\n  leakyreluAlpha?: number\n}): Tensor {\n    if (shouldFuse(ENGINE.state.gradientDepth, activation) === false) {\n      let result = unfusedMatMul(a, b, transposeA, transposeB);\n      if (bias != null) {\n        result = add(result, bias);\n      }\n\n      return applyActivation(\n                 result, activation, preluActivationWeights, leakyreluAlpha);\n    }\n\n    let $a = convertToTensor(a, 'a', 'fused matMul');\n    let $b = convertToTensor(b, 'b', 'fused matMul');\n    [$a, $b] = makeTypesMatch($a, $b);\n\n    const innerShapeA =\n        transposeA ? $a.shape[$a.rank - 2] : $a.shape[$a.rank - 1];\n    const innerShapeB =\n        transposeB ? $b.shape[$b.rank - 1] : $b.shape[$b.rank - 2];\n\n    const outerShapeA =\n        transposeA ? $a.shape[$a.rank - 1] : $a.shape[$a.rank - 2];\n    const outerShapeB =\n        transposeB ? $b.shape[$b.rank - 2] : $b.shape[$b.rank - 1];\n\n    const outerDimsA = $a.shape.slice(0, -2);\n    const outerDimsB = $b.shape.slice(0, -2);\n    const batchDimA = util.sizeFromShape(outerDimsA);\n    const batchDimB = util.sizeFromShape(outerDimsB);\n\n    util.assert(\n        innerShapeA === innerShapeB,\n        () => `Error in fused matMul: inner shapes (${innerShapeA}) and (` +\n            `${innerShapeB}) of Tensors with shapes ${$a.shape} and ` +\n            `${$b.shape} and transposeA=${transposeA}` +\n            ` and transposeB=${transposeB} must match.`);\n\n    const outShapeOuterDims = broadcast_util.assertAndGetBroadcastShape(\n        $a.shape.slice(0, -2), $b.shape.slice(0, -2));\n    const outShape = outShapeOuterDims.concat([outerShapeA, outerShapeB]);\n\n    const a3D: Tensor3D = transposeA ?\n        reshape($a, [batchDimA, innerShapeA, outerShapeA]) :\n        reshape($a, [batchDimA, outerShapeA, innerShapeA]);\n    const b3D: Tensor3D = transposeB ?\n        reshape($b, [batchDimB, outerShapeB, innerShapeB]) :\n        reshape($b, [batchDimB, innerShapeB, outerShapeB]);\n\n    let $bias: Tensor;\n    if (bias != null) {\n      $bias = convertToTensor(bias, 'bias', 'fused matMul');\n      [$bias] = makeTypesMatch($bias, $a);\n\n      broadcast_util.assertAndGetBroadcastShape(outShape, $bias.shape);\n    }\n\n    let $preluActivationWeights: Tensor;\n    if (preluActivationWeights != null) {\n      $preluActivationWeights = convertToTensor(\n          preluActivationWeights, 'prelu weights', 'fused matMul');\n    }\n\n    const grad = (dy: Tensor3D, saved: Tensor[]) => {\n      const [a3D, b3D, y, $bias] = saved;\n      // we reshape dy because the result of the forward is not\n      // necessarily going to be a 3d tensor due to a reshape done at the end of\n      // the customOp.\n      const dyActivation =\n          getFusedDyActivation(reshape(dy, y.shape), y, activation);\n      let aDer: Tensor;\n      let bDer: Tensor;\n\n      if (!transposeA && !transposeB) {\n        aDer = unfusedMatMul(dyActivation, b3D, false, true);\n        bDer = unfusedMatMul(a3D, dyActivation, true, false);\n      } else if (!transposeA && transposeB) {\n        aDer = unfusedMatMul(dyActivation, b3D, false, false);\n        bDer = unfusedMatMul(dyActivation, a3D, true, false);\n      } else if (transposeA && !transposeB) {\n        aDer = unfusedMatMul(b3D, dyActivation, false, true);\n        bDer = unfusedMatMul(a3D, dyActivation, false, false);\n      } else {\n        aDer = unfusedMatMul(b3D, dyActivation, true, true);\n        bDer = unfusedMatMul(dyActivation, a3D, true, true);\n      }\n\n      if (bias != null) {\n        const biasDer = getFusedBiasGradient($bias, dyActivation);\n        return [aDer, bDer, biasDer];\n      } else {\n        return [aDer, bDer];\n      }\n    };\n\n    const inputs: _FusedMatMulInputs = {\n      a: a3D,\n      b: b3D,\n      bias: $bias,\n      preluActivationWeights: $preluActivationWeights\n    };\n    const attrs: _FusedMatMulAttrs =\n        {transposeA, transposeB, activation, leakyreluAlpha};\n\n    // Depending on the the params passed in we will have different number of\n    // inputs and thus a a different number of elements in the gradient.\n    if (bias == null) {\n      const customOp =\n          customGrad((a3D: Tensor3D, b3D: Tensor3D, save: GradSaveFunc) => {\n            const res =\n                // tslint:disable-next-line: no-unnecessary-type-assertion\n                ENGINE.runKernel(\n                    _FusedMatMul, inputs as {} as NamedTensorMap,\n                    attrs as {} as NamedAttrMap) as Tensor;\n\n            save([a3D, b3D, res]);\n\n            return {value: reshape(res, outShape), gradFunc: grad};\n          });\n      return customOp(a3D, b3D);\n    } else {\n      const customOpWithBias = customGrad(\n          (a3D: Tensor3D, b3D: Tensor3D, $bias: Tensor, save: GradSaveFunc) => {\n            const res =\n                // tslint:disable-next-line: no-unnecessary-type-assertion\n                ENGINE.runKernel(\n                    _FusedMatMul, inputs as {} as NamedTensorMap,\n                    attrs as {} as NamedAttrMap) as Tensor;\n\n            save([a3D, b3D, res, $bias]);\n\n            return {value: reshape(res, outShape), gradFunc: grad};\n          });\n\n      return customOpWithBias(a3D, b3D, $bias);\n    }\n  }\n\n  export const matMul = op({fusedMatMul_});\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor1D} from '../../tensor';\nimport {op} from '../operation';\nimport {cosineWindow} from '../signal_ops_util';\n\n/**\n * Generate a hamming window.\n *\n * See: https://en.wikipedia.org/wiki/Window_function#Hann_and_Hamming_windows\n *\n * ```js\n * tf.signal.hammingWindow(10).print();\n * ```\n * @param The length of window\n *\n * @doc {heading: 'Operations', subheading: 'Signal', namespace: 'signal'}\n */\nfunction hammingWindow_(windowLength: number): Tensor1D {\n  return cosineWindow(windowLength, 0.54, 0.46);\n}\nexport const hammingWindow = op({hammingWindow_});\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor1D} from '../../tensor';\nimport {op} from '../operation';\nimport {cosineWindow} from '../signal_ops_util';\n\n/**\n * Generate a Hann window.\n *\n * See: https://en.wikipedia.org/wiki/Window_function#Hann_and_Hamming_windows\n *\n * ```js\n * tf.signal.hannWindow(10).print();\n * ```\n * @param The length of window\n *\n * @doc {heading: 'Operations', subheading: 'Signal', namespace: 'signal'}\n */\nfunction hannWindow_(windowLength: number): Tensor1D {\n  return cosineWindow(windowLength, 0.5, 0.5);\n}\n\nexport const hannWindow = op({hannWindow_});\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor, Tensor1D} from '../../tensor';\nimport {concat} from '../concat';\nimport {fill} from '../fill';\nimport {op} from '../operation';\nimport {reshape} from '../reshape';\nimport {slice} from '../slice';\nimport {tensor2d} from '../tensor2d';\n\n/**\n * Expands input into frames of frameLength.\n * Slides a window size with frameStep.\n *\n * ```js\n * tf.signal.frame([1, 2, 3], 2, 1).print();\n * ```\n * @param signal The input tensor to be expanded\n * @param frameLength Length of each frame\n * @param frameStep The frame hop size in samples.\n * @param padEnd Whether to pad the end of signal with padValue.\n * @param padValue A number to use where the input signal does\n *     not exist when padEnd is True.\n *\n * @doc {heading: 'Operations', subheading: 'Signal', namespace: 'signal'}\n */\nfunction frame_(\n    signal: Tensor1D, frameLength: number, frameStep: number, padEnd = false,\n    padValue = 0): Tensor {\n  let start = 0;\n  const output: Tensor[] = [];\n  while (start + frameLength <= signal.size) {\n    output.push(slice(signal, start, frameLength));\n    start += frameStep;\n  }\n\n  if (padEnd) {\n    while (start < signal.size) {\n      const padLen = (start + frameLength) - signal.size;\n      const pad = concat([\n        slice(signal, start, frameLength - padLen), fill([padLen], padValue)\n      ]);\n      output.push(pad);\n      start += frameStep;\n    }\n  }\n\n  if (output.length === 0) {\n    return tensor2d([], [0, frameLength]);\n  }\n\n  return reshape(concat(output), [output.length, frameLength]);\n}\nexport const frame = op({frame_});\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor, Tensor1D} from '../../tensor';\nimport {mul} from '../mul';\nimport {op} from '../operation';\nimport {enclosingPowerOfTwo} from '../signal_ops_util';\nimport {rfft} from '../spectral/rfft';\n\nimport {frame} from './frame';\nimport {hannWindow} from './hann_window';\n\n/**\n * Computes the Short-time Fourier Transform of signals\n * See: https://en.wikipedia.org/wiki/Short-time_Fourier_transform\n *\n * ```js\n * const input = tf.tensor1d([1, 1, 1, 1, 1])\n * tf.signal.stft(input, 3, 1).print();\n * ```\n * @param signal 1-dimensional real value tensor.\n * @param frameLength The window length of samples.\n * @param frameStep The number of samples to step.\n * @param fftLength The size of the FFT to apply.\n * @param windowFn A callable that takes a window length and returns 1-d tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Signal', namespace: 'signal'}\n */\nfunction stft_(\n    signal: Tensor1D, frameLength: number, frameStep: number,\n    fftLength?: number,\n    windowFn: (length: number) => Tensor1D = hannWindow): Tensor {\n  if (fftLength == null) {\n    fftLength = enclosingPowerOfTwo(frameLength);\n  }\n  const framedSignal = frame(signal, frameLength, frameStep);\n  const windowedSignal = mul(framedSignal, windowFn(frameLength));\n  return rfft(windowedSignal, fftLength);\n}\nexport const stft = op({stft_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../../engine';\nimport {CropAndResize, CropAndResizeAttrs, CropAndResizeInputs} from '../../kernel_names';\nimport {NamedAttrMap} from '../../kernel_registry';\nimport {Tensor1D, Tensor2D, Tensor4D} from '../../tensor';\nimport {NamedTensorMap} from '../../tensor_types';\nimport {convertToTensor} from '../../tensor_util_env';\nimport {TensorLike} from '../../types';\nimport * as util from '../../util';\n\nimport {op} from '../operation';\n\n/**\n * Extracts crops from the input image tensor and resizes them using bilinear\n * sampling or nearest neighbor sampling (possibly with aspect ratio change)\n * to a common output size specified by cropSize.\n *\n * @param image 4d tensor of shape `[batch,imageHeight,imageWidth, depth]`,\n *     where imageHeight and imageWidth must be positive, specifying the\n *     batch of images from which to take crops\n * @param boxes 2d float32 tensor of shape `[numBoxes, 4]`. Each entry is\n *     `[y1, x1, y2, x2]`, where `(y1, x1)` and `(y2, x2)` are the normalized\n *     coordinates of the box in the `boxInd[i]`th image in the batch\n * @param boxInd 1d int32 tensor of shape `[numBoxes]` with values in range\n *     `[0, batch)` that specifies the image that the `i`-th box refers to.\n * @param cropSize 1d int32 tensor of 2 elements `[cropHeigh, cropWidth]`\n *     specifying the size to which all crops are resized to.\n * @param method Optional string from `'bilinear' | 'nearest'`,\n *     defaults to bilinear, which specifies the sampling method for resizing\n * @param extrapolationValue A threshold for deciding when to remove boxes based\n *     on score. Defaults to 0.\n * @return A 4D tensor of the shape `[numBoxes,cropHeight,cropWidth,depth]`\n *\n * @doc {heading: 'Operations', subheading: 'Images', namespace: 'image'}\n */\nfunction cropAndResize_(\n    image: Tensor4D|TensorLike,\n    boxes: Tensor2D|TensorLike,\n    boxInd: Tensor1D|TensorLike,\n    cropSize: [number, number],\n    method: 'bilinear'|'nearest' = 'bilinear',\n    extrapolationValue = 0,\n    ): Tensor4D {\n  const $image = convertToTensor(image, 'image', 'cropAndResize');\n  const $boxes = convertToTensor(boxes, 'boxes', 'cropAndResize', 'float32');\n  const $boxInd = convertToTensor(boxInd, 'boxInd', 'cropAndResize', 'int32');\n\n  const numBoxes = $boxes.shape[0];\n\n  util.assert(\n      $image.rank === 4,\n      () => 'Error in cropAndResize: image must be rank 4,' +\n          `but got rank ${$image.rank}.`);\n  util.assert(\n      $boxes.rank === 2 && $boxes.shape[1] === 4,\n      () => `Error in cropAndResize: boxes must be have size [${numBoxes},4] ` +\n          `but had shape ${$boxes.shape}.`);\n  util.assert(\n      $boxInd.rank === 1 && $boxInd.shape[0] === numBoxes,\n      () => `Error in cropAndResize: boxInd must be have size [${numBoxes}] ` +\n          `but had shape ${$boxes.shape}.`);\n  util.assert(\n      cropSize.length === 2,\n      () => `Error in cropAndResize: cropSize must be of length 2, but got ` +\n          `length ${cropSize.length}.`);\n  util.assert(\n      cropSize[0] >= 1 && cropSize[1] >= 1,\n      () => `cropSize must be atleast [1,1], but was ${cropSize}`);\n  util.assert(\n      method === 'bilinear' || method === 'nearest',\n      () => `method must be bilinear or nearest, but was ${method}`);\n\n  const inputs:\n      CropAndResizeInputs = {image: $image, boxes: $boxes, boxInd: $boxInd};\n  const attrs: CropAndResizeAttrs = {method, extrapolationValue, cropSize};\n  const res = ENGINE.runKernel(\n      CropAndResize, inputs as {} as NamedTensorMap,\n      attrs as {} as NamedAttrMap);\n  return res as Tensor4D;\n}\n\nexport const cropAndResize = op({cropAndResize_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../../engine';\nimport {FlipLeftRight, FlipLeftRightInputs} from '../../kernel_names';\nimport {Tensor4D} from '../../tensor';\nimport {NamedTensorMap} from '../../tensor_types';\nimport {convertToTensor} from '../../tensor_util_env';\nimport {TensorLike} from '../../types';\nimport * as util from '../../util';\nimport {op} from '../operation';\n\n/**\n * Flips the image left to right. Currently available in the CPU, WebGL, and\n * WASM backends.\n *\n * @param image 4d tensor of shape `[batch, imageHeight, imageWidth, depth]`.\n */\n/** @doc {heading: 'Operations', subheading: 'Images', namespace: 'image'} */\nfunction flipLeftRight_(image: Tensor4D|TensorLike): Tensor4D {\n  const $image = convertToTensor(image, 'image', 'flipLeftRight', 'float32');\n\n  util.assert(\n      $image.rank === 4,\n      () => 'Error in flipLeftRight: image must be rank 4,' +\n          `but got rank ${$image.rank}.`);\n\n  const inputs: FlipLeftRightInputs = {image: $image};\n  const res =\n      ENGINE.runKernel(FlipLeftRight, inputs as {} as NamedTensorMap, {});\n  return res as Tensor4D;\n}\n\nexport const flipLeftRight = op({flipLeftRight_});\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor2D, Tensor3D, Tensor4D, Tensor5D, Tensor6D} from '../../tensor';\nimport {convertToTensor} from '../../tensor_util_env';\nimport {TensorLike} from '../../types';\nimport * as util from '../../util';\n\nimport {op} from '../operation';\nimport {tile} from '../tile';\n\n/**\n * Converts images from grayscale to RGB format.\n *\n * @param image A grayscale tensor to convert. The `image`'s last dimension must\n *     be size 1 with at least a two-dimensional shape.\n *\n * @doc {heading: 'Operations', subheading: 'Images', namespace: 'image'}\n */\nfunction grayscaleToRGB_<T extends Tensor2D|Tensor3D|Tensor4D|Tensor5D|\n                         Tensor6D>(image: T|TensorLike): T {\n  const $image = convertToTensor(image, 'image', 'grayscaleToRGB');\n\n  const lastDimsIdx = $image.rank - 1;\n  const lastDims = $image.shape[lastDimsIdx];\n\n  util.assert(\n      $image.rank >= 2,\n      () => 'Error in grayscaleToRGB: images must be at least rank 2, ' +\n          `but got rank ${$image.rank}.`);\n\n  util.assert(\n      lastDims === 1,\n      () => 'Error in grayscaleToRGB: last dimension of a grayscale image ' +\n          `should be size 1, but got size ${lastDims}.`);\n\n  const reps = new Array($image.rank);\n\n  reps.fill(1, 0, lastDimsIdx);\n  reps[lastDimsIdx] = 3;\n\n  return tile($image, reps);\n}\n\nexport const grayscaleToRGB = op({grayscaleToRGB_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../../engine';\nimport {RotateWithOffset, RotateWithOffsetAttrs, RotateWithOffsetInputs} from '../../kernel_names';\nimport {NamedAttrMap} from '../../kernel_registry';\nimport {Tensor4D} from '../../tensor';\nimport {NamedTensorMap} from '../../tensor_types';\nimport {convertToTensor} from '../../tensor_util_env';\nimport {TensorLike} from '../../types';\nimport * as util from '../../util';\n\nimport {op} from '../operation';\n\n/**\n * Rotates the input image tensor counter-clockwise with an optional offset\n * center of rotation. Currently available in the CPU, WebGL, and WASM backends.\n *\n * @param image 4d tensor of shape `[batch, imageHeight, imageWidth, depth]`.\n * @param radians The amount of rotation.\n * @param fillValue The value to fill in the empty space leftover\n *     after rotation. Can be either a single grayscale value (0-255), or an\n *     array of three numbers `[red, green, blue]` specifying the red, green,\n *     and blue channels. Defaults to `0` (black).\n * @param center The center of rotation. Can be either a single value (0-1), or\n *     an array of two numbers `[centerX, centerY]`. Defaults to `0.5` (rotates\n *     the image around its center).\n *\n * @doc {heading: 'Operations', subheading: 'Images', namespace: 'image'}\n */\nfunction rotateWithOffset_(\n    image: Tensor4D|TensorLike, radians: number,\n    fillValue: number|[number, number, number] = 0,\n    center: number|[number, number] = 0.5): Tensor4D {\n  const $image = convertToTensor(image, 'image', 'rotateWithOffset', 'float32');\n\n  util.assert(\n      $image.rank === 4,\n      () => 'Error in rotateWithOffset: image must be rank 4,' +\n          `but got rank ${$image.rank}.`);\n\n  const inputs: RotateWithOffsetInputs = {image: $image};\n  const attrs: RotateWithOffsetAttrs = {radians, fillValue, center};\n  const res = ENGINE.runKernel(\n      RotateWithOffset, inputs as {} as NamedTensorMap,\n      attrs as {} as NamedAttrMap);\n  return res as Tensor4D;\n}\n\nexport const rotateWithOffset = op({rotateWithOffset_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor1D, Tensor2D} from '../tensor';\nimport * as util from '../util';\n\nfunction nonMaxSuppSanityCheck(\n    boxes: Tensor2D, scores: Tensor1D, maxOutputSize: number,\n    iouThreshold: number, scoreThreshold: number, softNmsSigma?: number): {\n  maxOutputSize: number,\n  iouThreshold: number,\n  scoreThreshold: number,\n  softNmsSigma: number\n} {\n  if (iouThreshold == null) {\n    iouThreshold = 0.5;\n  }\n  if (scoreThreshold == null) {\n    scoreThreshold = Number.NEGATIVE_INFINITY;\n  }\n  if (softNmsSigma == null) {\n    softNmsSigma = 0.0;\n  }\n\n  const numBoxes = boxes.shape[0];\n  maxOutputSize = Math.min(maxOutputSize, numBoxes);\n\n  util.assert(\n      0 <= iouThreshold && iouThreshold <= 1,\n      () => `iouThreshold must be in [0, 1], but was '${iouThreshold}'`);\n  util.assert(\n      boxes.rank === 2,\n      () => `boxes must be a 2D tensor, but was of rank '${boxes.rank}'`);\n  util.assert(\n      boxes.shape[1] === 4,\n      () =>\n          `boxes must have 4 columns, but 2nd dimension was ${boxes.shape[1]}`);\n  util.assert(scores.rank === 1, () => 'scores must be a 1D tensor');\n  util.assert(\n      scores.shape[0] === numBoxes,\n      () => `scores has incompatible shape with boxes. Expected ${numBoxes}, ` +\n          `but was ${scores.shape[0]}`);\n  util.assert(\n      0 <= softNmsSigma && softNmsSigma <= 1,\n      () => `softNmsSigma must be in [0, 1], but was '${softNmsSigma}'`);\n  return {maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma};\n}\n\nexport {nonMaxSuppSanityCheck};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../../engine';\nimport {NonMaxSuppressionV3} from '../../kernel_names';\nimport {Tensor1D, Tensor2D} from '../../tensor';\nimport {convertToTensor} from '../../tensor_util_env';\nimport {TensorLike} from '../../types';\nimport {nonMaxSuppSanityCheck} from '../nonmax_util';\nimport {op} from '../operation';\n\n/**\n * Performs non maximum suppression of bounding boxes based on\n * iou (intersection over union).\n *\n * @param boxes a 2d tensor of shape `[numBoxes, 4]`. Each entry is\n *     `[y1, x1, y2, x2]`, where `(y1, x1)` and `(y2, x2)` are the corners of\n *     the bounding box.\n * @param scores a 1d tensor providing the box scores of shape `[numBoxes]`.\n * @param maxOutputSize The maximum number of boxes to be selected.\n * @param iouThreshold A float representing the threshold for deciding whether\n *     boxes overlap too much with respect to IOU. Must be between [0, 1].\n *     Defaults to 0.5 (50% box overlap).\n * @param scoreThreshold A threshold for deciding when to remove boxes based\n *     on score. Defaults to -inf, which means any score is accepted.\n * @return A 1D tensor with the selected box indices.\n *\n * @doc {heading: 'Operations', subheading: 'Images', namespace: 'image'}\n */\nfunction nonMaxSuppression_(\n    boxes: Tensor2D|TensorLike, scores: Tensor1D|TensorLike,\n    maxOutputSize: number, iouThreshold = 0.5,\n    scoreThreshold = Number.NEGATIVE_INFINITY): Tensor1D {\n  const $boxes =\n      convertToTensor(boxes, 'boxes', 'nonMaxSuppression', 'float32');\n  const $scores =\n      convertToTensor(scores, 'scores', 'nonMaxSuppression', 'float32');\n\n  const inputs = nonMaxSuppSanityCheck(\n      $boxes, $scores, maxOutputSize, iouThreshold, scoreThreshold);\n  maxOutputSize = inputs.maxOutputSize;\n  iouThreshold = inputs.iouThreshold;\n  scoreThreshold = inputs.scoreThreshold;\n\n  const attrs = {maxOutputSize, iouThreshold, scoreThreshold};\n  return ENGINE.runKernel(\n      NonMaxSuppressionV3, {boxes: $boxes, scores: $scores}, attrs);\n}\n\nexport const nonMaxSuppression = op({nonMaxSuppression_});\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n/**\n * Inserts a value into a sorted array. This method allows duplicate, meaning it\n * allows inserting duplicate value, in which case, the element will be inserted\n * at the lowest index of the value.\n * @param arr The array to modify.\n * @param element The element to insert.\n * @param comparator Optional. If no comparator is specified, elements are\n * compared using array_util.defaultComparator, which is suitable for Strings\n * and Numbers in ascending arrays. If the array contains multiple instances of\n * the target value, the left-most instance will be returned. To provide a\n * comparator, it should take 2 arguments to compare and return a negative,\n * zero, or a positive number.\n */\nexport function binaryInsert<T>(\n    arr: T[], element: T, comparator?: (a: T, b: T) => number) {\n  const index = binarySearch(arr, element, comparator);\n  const insertionPoint = index < 0 ? -(index + 1) : index;\n  arr.splice(insertionPoint, 0, element);\n}\n\n/**\n * Searches the array for the target using binary search, returns the index\n * of the found element, or position to insert if element not found. If no\n * comparator is specified, elements are compared using array_\n * util.defaultComparator, which is suitable for Strings and Numbers in\n * ascending arrays. If the array contains multiple instances of the target\n * value, the left-most instance will be returned.\n * @param arr The array to be searched in.\n * @param target The target to be searched for.\n * @param comparator Should take 2 arguments to compare and return a negative,\n *    zero, or a positive number.\n * @return Lowest index of the target value if found, otherwise the insertion\n *    point where the target should be inserted, in the form of\n *    (-insertionPoint - 1).\n */\nexport function binarySearch<T>(\n    arr: T[], target: T, comparator?: (a: T, b: T) => number) {\n  return binarySearch_(arr, target, comparator || defaultComparator);\n}\n\n/**\n * Compares its two arguments for order.\n * @param a The first element to be compared.\n * @param b The second element to be compared.\n * @return A negative number, zero, or a positive number as the first\n *     argument is less than, equal to, or greater than the second.\n */\nfunction defaultComparator<T>(a: T, b: T): number {\n  return a > b ? 1 : a < b ? -1 : 0;\n}\n\nfunction binarySearch_<T>(\n    arr: T[], target: T, comparator: (a: T, b: T) => number) {\n  let left = 0;\n  let right = arr.length;\n  let middle = 0;\n  let found = false;\n  while (left < right) {\n    middle = left + ((right - left) >>> 1);\n    const compareResult = comparator(target, arr[middle]);\n    if (compareResult > 0) {\n      left = middle + 1;\n    } else {\n      right = middle;\n      // If compareResult is 0, the value is found. We record it is found,\n      // and then keep looking because there may be duplicate.\n      found = !compareResult;\n    }\n  }\n\n  return found ? left : -left - 1;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {TypedArray} from '../types';\nimport {binaryInsert} from './non_max_suppression_util';\n\n/**\n * Implementation of the NonMaxSuppression kernel shared between webgl and cpu.\n */\ninterface Candidate {\n  score: number;\n  boxIndex: number;\n  suppressBeginIndex: number;\n}\n\ninterface NonMaxSuppressionResult {\n  selectedIndices: number[];\n  selectedScores?: number[];\n  validOutputs?: number;\n}\n\nexport function nonMaxSuppressionV3Impl(\n    boxes: TypedArray, scores: TypedArray, maxOutputSize: number,\n    iouThreshold: number, scoreThreshold: number): NonMaxSuppressionResult {\n  return nonMaxSuppressionImpl_(\n      boxes, scores, maxOutputSize, iouThreshold, scoreThreshold,\n      0 /* softNmsSigma */);\n}\n\nexport function nonMaxSuppressionV4Impl(\n    boxes: TypedArray, scores: TypedArray, maxOutputSize: number,\n    iouThreshold: number, scoreThreshold: number,\n    padToMaxOutputSize: boolean): NonMaxSuppressionResult {\n  return nonMaxSuppressionImpl_(\n      boxes, scores, maxOutputSize, iouThreshold, scoreThreshold,\n      0 /* softNmsSigma */, false /* returnScoresTensor */,\n      padToMaxOutputSize /* padToMaxOutputSize */, true\n      /* returnValidOutputs */);\n}\n\nexport function nonMaxSuppressionV5Impl(\n    boxes: TypedArray, scores: TypedArray, maxOutputSize: number,\n    iouThreshold: number, scoreThreshold: number,\n    softNmsSigma: number): NonMaxSuppressionResult {\n  return nonMaxSuppressionImpl_(\n      boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma,\n      true /* returnScoresTensor */);\n}\n\nfunction nonMaxSuppressionImpl_(\n    boxes: TypedArray, scores: TypedArray, maxOutputSize: number,\n    iouThreshold: number, scoreThreshold: number, softNmsSigma: number,\n    returnScoresTensor = false, padToMaxOutputSize = false,\n    returnValidOutputs = false): NonMaxSuppressionResult {\n  // The list is sorted in ascending order, so that we can always pop the\n  // candidate with the largest score in O(1) time.\n  const candidates = [];\n\n  for (let i = 0; i < scores.length; i++) {\n    if (scores[i] > scoreThreshold) {\n      candidates.push({score: scores[i], boxIndex: i, suppressBeginIndex: 0});\n    }\n  }\n\n  candidates.sort(ascendingComparator);\n\n  // If softNmsSigma is 0, the outcome of this algorithm is exactly same as\n  // before.\n  const scale = softNmsSigma > 0 ? (-0.5 / softNmsSigma) : 0.0;\n\n  const selectedIndices: number[] = [];\n  const selectedScores: number[] = [];\n\n  while (selectedIndices.length < maxOutputSize && candidates.length > 0) {\n    const candidate = candidates.pop();\n    const {score: originalScore, boxIndex, suppressBeginIndex} = candidate;\n\n    if (originalScore < scoreThreshold) {\n      break;\n    }\n\n    // Overlapping boxes are likely to have similar scores, therefore we\n    // iterate through the previously selected boxes backwards in order to\n    // see if candidate's score should be suppressed. We use\n    // suppressBeginIndex to track and ensure a candidate can be suppressed\n    // by a selected box no more than once. Also, if the overlap exceeds\n    // iouThreshold, we simply ignore the candidate.\n    let ignoreCandidate = false;\n    for (let j = selectedIndices.length - 1; j >= suppressBeginIndex; --j) {\n      const iou = intersectionOverUnion(boxes, boxIndex, selectedIndices[j]);\n\n      if (iou >= iouThreshold) {\n        ignoreCandidate = true;\n        break;\n      }\n\n      candidate.score =\n          candidate.score * suppressWeight(iouThreshold, scale, iou);\n\n      if (candidate.score <= scoreThreshold) {\n        break;\n      }\n    }\n\n    // At this point, if `candidate.score` has not dropped below\n    // `scoreThreshold`, then we know that we went through all of the\n    // previous selections and can safely update `suppressBeginIndex` to the\n    // end of the selected array. Then we can re-insert the candidate with\n    // the updated score and suppressBeginIndex back in the candidate list.\n    // If on the other hand, `candidate.score` has dropped below the score\n    // threshold, we will not add it back to the candidates list.\n    candidate.suppressBeginIndex = selectedIndices.length;\n\n    if (!ignoreCandidate) {\n      // Candidate has passed all the tests, and is not suppressed, so\n      // select the candidate.\n      if (candidate.score === originalScore) {\n        selectedIndices.push(boxIndex);\n        selectedScores.push(candidate.score);\n      } else if (candidate.score > scoreThreshold) {\n        // Candidate's score is suppressed but is still high enough to be\n        // considered, so add back to the candidates list.\n        binaryInsert(candidates, candidate, ascendingComparator);\n      }\n    }\n  }\n\n  // NonMaxSuppressionV4 feature: padding output to maxOutputSize.\n  const validOutputs = selectedIndices.length;\n  const elemsToPad = maxOutputSize - validOutputs;\n\n  if (padToMaxOutputSize && elemsToPad > 0) {\n    selectedIndices.push(...new Array(elemsToPad).fill(0));\n    selectedScores.push(...new Array(elemsToPad).fill(0.0));\n  }\n\n  const result: NonMaxSuppressionResult = {selectedIndices};\n\n  if (returnScoresTensor) {\n    result['selectedScores'] = selectedScores;\n  }\n\n  if (returnValidOutputs) {\n    result['validOutputs'] = validOutputs;\n  }\n\n  return result;\n}\n\nfunction intersectionOverUnion(boxes: TypedArray, i: number, j: number) {\n  const iCoord = boxes.subarray(i * 4, i * 4 + 4);\n  const jCoord = boxes.subarray(j * 4, j * 4 + 4);\n  const yminI = Math.min(iCoord[0], iCoord[2]);\n  const xminI = Math.min(iCoord[1], iCoord[3]);\n  const ymaxI = Math.max(iCoord[0], iCoord[2]);\n  const xmaxI = Math.max(iCoord[1], iCoord[3]);\n  const yminJ = Math.min(jCoord[0], jCoord[2]);\n  const xminJ = Math.min(jCoord[1], jCoord[3]);\n  const ymaxJ = Math.max(jCoord[0], jCoord[2]);\n  const xmaxJ = Math.max(jCoord[1], jCoord[3]);\n  const areaI = (ymaxI - yminI) * (xmaxI - xminI);\n  const areaJ = (ymaxJ - yminJ) * (xmaxJ - xminJ);\n  if (areaI <= 0 || areaJ <= 0) {\n    return 0.0;\n  }\n  const intersectionYmin = Math.max(yminI, yminJ);\n  const intersectionXmin = Math.max(xminI, xminJ);\n  const intersectionYmax = Math.min(ymaxI, ymaxJ);\n  const intersectionXmax = Math.min(xmaxI, xmaxJ);\n  const intersectionArea = Math.max(intersectionYmax - intersectionYmin, 0.0) *\n      Math.max(intersectionXmax - intersectionXmin, 0.0);\n  return intersectionArea / (areaI + areaJ - intersectionArea);\n}\n\n// A Gaussian penalty function, this method always returns values in [0, 1].\n// The weight is a function of similarity, the more overlap two boxes are, the\n// smaller the weight is, meaning highly overlapping boxe will be significantly\n// penalized. On the other hand, a non-overlapping box will not be penalized.\nfunction suppressWeight(iouThreshold: number, scale: number, iou: number) {\n  const weight = Math.exp(scale * iou * iou);\n  return iou <= iouThreshold ? weight : 0.0;\n}\n\nfunction ascendingComparator(c1: Candidate, c2: Candidate) {\n  // For objects with same scores, we make the object with the larger index go\n  // first. In an array that pops from the end, this means that the object with\n  // the smaller index will be popped first. This ensures the same output as\n  // the TensorFlow python version.\n  return (c1.score - c2.score) ||\n      ((c1.score === c2.score) && (c2.boxIndex - c1.boxIndex));\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {nonMaxSuppressionV3Impl} from '../../backends/non_max_suppression_impl';\nimport {Tensor1D, Tensor2D} from '../../tensor';\nimport {convertToTensor} from '../../tensor_util_env';\nimport {TensorLike} from '../../types';\nimport {nonMaxSuppSanityCheck} from '../nonmax_util';\nimport {tensor1d} from '../tensor1d';\n\n/**\n * Performs non maximum suppression of bounding boxes based on\n * iou (intersection over union).\n *\n * This is the async version of `nonMaxSuppression`\n *\n * @param boxes a 2d tensor of shape `[numBoxes, 4]`. Each entry is\n *     `[y1, x1, y2, x2]`, where `(y1, x1)` and `(y2, x2)` are the corners of\n *     the bounding box.\n * @param scores a 1d tensor providing the box scores of shape `[numBoxes]`.\n * @param maxOutputSize The maximum number of boxes to be selected.\n * @param iouThreshold A float representing the threshold for deciding whether\n *     boxes overlap too much with respect to IOU. Must be between [0, 1].\n *     Defaults to 0.5 (50% box overlap).\n * @param scoreThreshold A threshold for deciding when to remove boxes based\n *     on score. Defaults to -inf, which means any score is accepted.\n * @return A 1D tensor with the selected box indices.\n *\n * @doc {heading: 'Operations', subheading: 'Images', namespace: 'image'}\n */\nasync function nonMaxSuppressionAsync_(\n    boxes: Tensor2D|TensorLike, scores: Tensor1D|TensorLike,\n    maxOutputSize: number, iouThreshold = 0.5,\n    scoreThreshold = Number.NEGATIVE_INFINITY): Promise<Tensor1D> {\n  const $boxes = convertToTensor(boxes, 'boxes', 'nonMaxSuppressionAsync');\n  const $scores = convertToTensor(scores, 'scores', 'nonMaxSuppressionAsync');\n\n  const inputs = nonMaxSuppSanityCheck(\n      $boxes, $scores, maxOutputSize, iouThreshold, scoreThreshold);\n  maxOutputSize = inputs.maxOutputSize;\n  iouThreshold = inputs.iouThreshold;\n  scoreThreshold = inputs.scoreThreshold;\n\n  const boxesAndScores = await Promise.all([$boxes.data(), $scores.data()]);\n  const boxesVals = boxesAndScores[0];\n  const scoresVals = boxesAndScores[1];\n\n  // We call a cpu based impl directly with the typedarray data  here rather\n  // than a kernel because all kernels are synchronous (and thus cannot await\n  // .data()).\n  const {selectedIndices} = nonMaxSuppressionV3Impl(\n      boxesVals, scoresVals, maxOutputSize, iouThreshold, scoreThreshold);\n  if ($boxes !== boxes) {\n    $boxes.dispose();\n  }\n  if ($scores !== scores) {\n    $scores.dispose();\n  }\n\n  return tensor1d(selectedIndices, 'int32');\n}\n\nexport const nonMaxSuppressionAsync = nonMaxSuppressionAsync_;\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../../engine';\nimport {NonMaxSuppressionV5, NonMaxSuppressionV5Attrs, NonMaxSuppressionV5Inputs} from '../../kernel_names';\nimport {NamedAttrMap} from '../../kernel_registry';\nimport {Tensor, Tensor1D, Tensor2D} from '../../tensor';\nimport {NamedTensorMap} from '../../tensor_types';\nimport {convertToTensor} from '../../tensor_util_env';\nimport {TensorLike} from '../../types';\n\nimport {nonMaxSuppSanityCheck} from '../nonmax_util';\nimport {op} from '../operation';\n\n/**\n * Performs non maximum suppression of bounding boxes based on\n * iou (intersection over union).\n *\n * This op also supports a Soft-NMS mode (cf.\n * Bodla et al, https://arxiv.org/abs/1704.04503) where boxes reduce the score\n * of other overlapping boxes, therefore favoring different regions of the image\n * with high scores. To enable this Soft-NMS mode, set the `softNmsSigma`\n * parameter to be larger than 0.\n *\n * @param boxes a 2d tensor of shape `[numBoxes, 4]`. Each entry is\n *     `[y1, x1, y2, x2]`, where `(y1, x1)` and `(y2, x2)` are the corners of\n *     the bounding box.\n * @param scores a 1d tensor providing the box scores of shape `[numBoxes]`.\n * @param maxOutputSize The maximum number of boxes to be selected.\n * @param iouThreshold A float representing the threshold for deciding whether\n *     boxes overlap too much with respect to IOU. Must be between [0, 1].\n *     Defaults to 0.5 (50% box overlap).\n * @param scoreThreshold A threshold for deciding when to remove boxes based\n *     on score. Defaults to -inf, which means any score is accepted.\n * @param softNmsSigma A float representing the sigma parameter for Soft NMS.\n *     When sigma is 0, it falls back to nonMaxSuppression.\n * @return A map with the following properties:\n *     - selectedIndices: A 1D tensor with the selected box indices.\n *     - selectedScores: A 1D tensor with the corresponding scores for each\n *       selected box.\n *\n * @doc {heading: 'Operations', subheading: 'Images', namespace: 'image'}\n */\nfunction nonMaxSuppressionWithScore_(\n    boxes: Tensor2D|TensorLike, scores: Tensor1D|TensorLike,\n    maxOutputSize: number, iouThreshold = 0.5,\n    scoreThreshold = Number.NEGATIVE_INFINITY,\n    softNmsSigma = 0.0): NamedTensorMap {\n  const $boxes = convertToTensor(boxes, 'boxes', 'nonMaxSuppression');\n  const $scores = convertToTensor(scores, 'scores', 'nonMaxSuppression');\n\n  const params = nonMaxSuppSanityCheck(\n      $boxes, $scores, maxOutputSize, iouThreshold, scoreThreshold,\n      softNmsSigma);\n  maxOutputSize = params.maxOutputSize;\n  iouThreshold = params.iouThreshold;\n  scoreThreshold = params.scoreThreshold;\n  softNmsSigma = params.softNmsSigma;\n\n  const inputs: NonMaxSuppressionV5Inputs = {boxes: $boxes, scores: $scores};\n  const attrs: NonMaxSuppressionV5Attrs =\n      {maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma};\n\n  // tslint:disable-next-line: no-unnecessary-type-assertion\n  const result = ENGINE.runKernel(\n                     NonMaxSuppressionV5, inputs as {} as NamedTensorMap,\n                     attrs as {} as NamedAttrMap) as Tensor[];\n\n  return {selectedIndices: result[0], selectedScores: result[1]};\n}\n\nexport const nonMaxSuppressionWithScore = op({nonMaxSuppressionWithScore_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {nonMaxSuppressionV5Impl} from '../../backends/non_max_suppression_impl';\nimport {Tensor1D, Tensor2D} from '../../tensor';\nimport {NamedTensorMap} from '../../tensor_types';\nimport {convertToTensor} from '../../tensor_util_env';\nimport {TensorLike} from '../../types';\nimport {nonMaxSuppSanityCheck} from '../nonmax_util';\nimport {tensor1d} from '../tensor1d';\n\n/**\n * Asynchronously performs non maximum suppression of bounding boxes based on\n * iou (intersection over union).\n *\n * This op also supports a Soft-NMS mode (cf.\n * Bodla et al, https://arxiv.org/abs/1704.04503) where boxes reduce the score\n * of other overlapping boxes, therefore favoring different regions of the image\n * with high scores. To enable this Soft-NMS mode, set the `softNmsSigma`\n * parameter to be larger than 0.\n *\n * @param boxes a 2d tensor of shape `[numBoxes, 4]`. Each entry is\n *     `[y1, x1, y2, x2]`, where `(y1, x1)` and `(y2, x2)` are the corners of\n *     the bounding box.\n * @param scores a 1d tensor providing the box scores of shape `[numBoxes]`.\n * @param maxOutputSize The maximum number of boxes to be selected.\n * @param iouThreshold A float representing the threshold for deciding whether\n *     boxes overlap too much with respect to IOU. Must be between [0, 1].\n *     Defaults to 0.5 (50% box overlap).\n * @param scoreThreshold A threshold for deciding when to remove boxes based\n *     on score. Defaults to -inf, which means any score is accepted.\n * @param softNmsSigma A float representing the sigma parameter for Soft NMS.\n *     When sigma is 0, it falls back to nonMaxSuppression.\n * @return A map with the following properties:\n *     - selectedIndices: A 1D tensor with the selected box indices.\n *     - selectedScores: A 1D tensor with the corresponding scores for each\n *       selected box.\n *\n * @doc {heading: 'Operations', subheading: 'Images', namespace: 'image'}\n */\nasync function nonMaxSuppressionWithScoreAsync_(\n    boxes: Tensor2D|TensorLike, scores: Tensor1D|TensorLike,\n    maxOutputSize: number, iouThreshold = 0.5,\n    scoreThreshold = Number.NEGATIVE_INFINITY,\n    softNmsSigma = 0.0): Promise<NamedTensorMap> {\n  const $boxes = convertToTensor(boxes, 'boxes', 'nonMaxSuppressionAsync');\n  const $scores = convertToTensor(scores, 'scores', 'nonMaxSuppressionAsync');\n\n  const params = nonMaxSuppSanityCheck(\n      $boxes, $scores, maxOutputSize, iouThreshold, scoreThreshold,\n      softNmsSigma);\n  maxOutputSize = params.maxOutputSize;\n  iouThreshold = params.iouThreshold;\n  scoreThreshold = params.scoreThreshold;\n  softNmsSigma = params.softNmsSigma;\n\n  const boxesAndScores = await Promise.all([$boxes.data(), $scores.data()]);\n  const boxesVals = boxesAndScores[0];\n  const scoresVals = boxesAndScores[1];\n\n  // We call a cpu based impl directly with the typedarray data  here rather\n  // than a kernel because all kernels are synchronous (and thus cannot await\n  // .data()).\n  const {selectedIndices, selectedScores} = nonMaxSuppressionV5Impl(\n      boxesVals, scoresVals, maxOutputSize, iouThreshold, scoreThreshold,\n      softNmsSigma);\n\n  if ($boxes !== boxes) {\n    $boxes.dispose();\n  }\n  if ($scores !== scores) {\n    $scores.dispose();\n  }\n\n  return {\n    selectedIndices: tensor1d(selectedIndices, 'int32'),\n    selectedScores: tensor1d(selectedScores)\n  };\n}\n\nexport const nonMaxSuppressionWithScoreAsync = nonMaxSuppressionWithScoreAsync_;\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../../engine';\nimport {NonMaxSuppressionV4, NonMaxSuppressionV4Attrs, NonMaxSuppressionV4Inputs} from '../../kernel_names';\nimport {NamedAttrMap} from '../../kernel_registry';\nimport {Tensor, Tensor1D, Tensor2D} from '../../tensor';\nimport {NamedTensorMap} from '../../tensor_types';\nimport {convertToTensor} from '../../tensor_util_env';\nimport {TensorLike} from '../../types';\n\nimport {nonMaxSuppSanityCheck} from '../nonmax_util';\nimport {op} from '../operation';\n\n/**\n * Asynchronously performs non maximum suppression of bounding boxes based on\n * iou (intersection over union), with an option to pad results.\n *\n * @param boxes a 2d tensor of shape `[numBoxes, 4]`. Each entry is\n *     `[y1, x1, y2, x2]`, where `(y1, x1)` and `(y2, x2)` are the corners of\n *     the bounding box.\n * @param scores a 1d tensor providing the box scores of shape `[numBoxes]`.\n * @param maxOutputSize The maximum number of boxes to be selected.\n * @param iouThreshold A float representing the threshold for deciding whether\n *     boxes overlap too much with respect to IOU. Must be between [0, 1].\n *     Defaults to 0.5 (50% box overlap).\n * @param scoreThreshold A threshold for deciding when to remove boxes based\n *     on score. Defaults to -inf, which means any score is accepted.\n * @param padToMaxOutputSize Defaults to false. If true, size of output\n *     `selectedIndices` is padded to maxOutputSize.\n * @return A map with the following properties:\n *     - selectedIndices: A 1D tensor with the selected box indices.\n *     - validOutputs: A scalar denoting how many elements in `selectedIndices`\n *       are valid. Valid elements occur first, then padding.\n *\n * @doc {heading: 'Operations', subheading: 'Images', namespace: 'image'}\n */\nfunction nonMaxSuppressionPadded_(\n    boxes: Tensor2D|TensorLike, scores: Tensor1D|TensorLike,\n    maxOutputSize: number, iouThreshold = 0.5,\n    scoreThreshold = Number.NEGATIVE_INFINITY,\n    padToMaxOutputSize = false): NamedTensorMap {\n  const $boxes = convertToTensor(boxes, 'boxes', 'nonMaxSuppression');\n  const $scores = convertToTensor(scores, 'scores', 'nonMaxSuppression');\n\n  const params = nonMaxSuppSanityCheck(\n      $boxes, $scores, maxOutputSize, iouThreshold, scoreThreshold,\n      null /* softNmsSigma */);\n  const $maxOutputSize = params.maxOutputSize;\n  const $iouThreshold = params.iouThreshold;\n  const $scoreThreshold = params.scoreThreshold;\n\n  const inputs: NonMaxSuppressionV4Inputs = {boxes: $boxes, scores: $scores};\n  const attrs: NonMaxSuppressionV4Attrs = {\n    maxOutputSize: $maxOutputSize,\n    iouThreshold: $iouThreshold,\n    scoreThreshold: $scoreThreshold,\n    padToMaxOutputSize\n  };\n\n  // tslint:disable-next-line: no-unnecessary-type-assertion\n  const result = ENGINE.runKernel(\n                     NonMaxSuppressionV4, inputs as {} as NamedTensorMap,\n                     attrs as {} as NamedAttrMap) as Tensor[];\n\n  return {selectedIndices: result[0], validOutputs: result[1]};\n}\n\nexport const nonMaxSuppressionPadded = op({nonMaxSuppressionPadded_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {nonMaxSuppressionV4Impl} from '../../backends/non_max_suppression_impl';\nimport {Tensor1D, Tensor2D} from '../../tensor';\nimport {NamedTensorMap} from '../../tensor_types';\nimport {convertToTensor} from '../../tensor_util_env';\nimport {TensorLike} from '../../types';\nimport {nonMaxSuppSanityCheck} from '../nonmax_util';\nimport {scalar} from '../scalar';\nimport {tensor1d} from '../tensor1d';\n\n/**\n * Asynchronously performs non maximum suppression of bounding boxes based on\n * iou (intersection over union), with an option to pad results.\n *\n * @param boxes a 2d tensor of shape `[numBoxes, 4]`. Each entry is\n *     `[y1, x1, y2, x2]`, where `(y1, x1)` and `(y2, x2)` are the corners of\n *     the bounding box.\n * @param scores a 1d tensor providing the box scores of shape `[numBoxes]`.\n * @param maxOutputSize The maximum number of boxes to be selected.\n * @param iouThreshold A float representing the threshold for deciding whether\n *     boxes overlap too much with respect to IOU. Must be between [0, 1].\n *     Defaults to 0.5 (50% box overlap).\n * @param scoreThreshold A threshold for deciding when to remove boxes based\n *     on score. Defaults to -inf, which means any score is accepted.\n * @param padToMaxOutputSize Defaults to false. If true, size of output\n *     `selectedIndices` is padded to maxOutputSize.\n * @return A map with the following properties:\n *     - selectedIndices: A 1D tensor with the selected box indices.\n *     - validOutputs: A scalar denoting how many elements in `selectedIndices`\n *       are valid. Valid elements occur first, then padding.\n *\n * @doc {heading: 'Operations', subheading: 'Images', namespace: 'image'}\n */\nasync function nonMaxSuppressionPaddedAsync_(\n    boxes: Tensor2D|TensorLike, scores: Tensor1D|TensorLike,\n    maxOutputSize: number, iouThreshold = 0.5,\n    scoreThreshold = Number.NEGATIVE_INFINITY,\n    padToMaxOutputSize = false): Promise<NamedTensorMap> {\n  const $boxes = convertToTensor(boxes, 'boxes', 'nonMaxSuppressionAsync');\n  const $scores = convertToTensor(scores, 'scores', 'nonMaxSuppressionAsync');\n\n  const params = nonMaxSuppSanityCheck(\n      $boxes, $scores, maxOutputSize, iouThreshold, scoreThreshold,\n      null /* softNmsSigma */);\n  const $maxOutputSize = params.maxOutputSize;\n  const $iouThreshold = params.iouThreshold;\n  const $scoreThreshold = params.scoreThreshold;\n\n  const [boxesVals, scoresVals] =\n      await Promise.all([$boxes.data(), $scores.data()]);\n\n  // We call a cpu based impl directly with the typedarray data here rather\n  // than a kernel because all kernels are synchronous (and thus cannot await\n  // .data()).\n  const {selectedIndices, validOutputs} = nonMaxSuppressionV4Impl(\n      boxesVals, scoresVals, $maxOutputSize, $iouThreshold, $scoreThreshold,\n      padToMaxOutputSize);\n\n  if ($boxes !== boxes) {\n    $boxes.dispose();\n  }\n  if ($scores !== scores) {\n    $scores.dispose();\n  }\n\n  return {\n    selectedIndices: tensor1d(selectedIndices, 'int32'),\n    validOutputs: scalar(validOutputs, 'int32')\n  };\n}\n\nexport const nonMaxSuppressionPaddedAsync = nonMaxSuppressionPaddedAsync_;\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../../engine';\nimport {ResizeBilinear, ResizeBilinearAttrs, ResizeBilinearInputs} from '../../kernel_names';\nimport {NamedAttrMap} from '../../kernel_registry';\nimport {Tensor3D, Tensor4D} from '../../tensor';\nimport {NamedTensorMap} from '../../tensor_types';\nimport {convertToTensor} from '../../tensor_util_env';\nimport {TensorLike} from '../../types';\nimport * as util from '../../util';\n\nimport {op} from '../operation';\nimport {reshape} from '../reshape';\n\n/**\n * Bilinear resize a single 3D image or a batch of 3D images to a new shape.\n *\n * @param images The images, of rank 4 or rank 3, of shape\n *     `[batch, height, width, inChannels]`. If rank 3, batch of 1 is assumed.\n * @param size The new shape `[newHeight, newWidth]` to resize the\n *     images to. Each channel is resized individually.\n * @param alignCorners Defaults to `false`. If true, rescale\n *     input by `(new_height - 1) / (height - 1)`, which exactly aligns the 4\n *     corners of images and resized images. If false, rescale by\n *     `new_height / height`. Treat similarly the width dimension.\n * @param halfPixelCenters Defaults to `false`. Whether to assume pixel centers\n *     are at 0.5, which would make the floating point coordinates of the top\n *     left pixel 0.5, 0.5.\n *\n * @doc {heading: 'Operations', subheading: 'Images', namespace: 'image'}\n */\nfunction resizeBilinear_<T extends Tensor3D|Tensor4D>(\n    images: T|TensorLike, size: [number, number], alignCorners = false,\n    halfPixelCenters = false): T {\n  const $images = convertToTensor(images, 'images', 'resizeBilinear');\n\n  util.assert(\n      $images.rank === 3 || $images.rank === 4,\n      () => `Error in resizeBilinear: x must be rank 3 or 4, but got ` +\n          `rank ${$images.rank}.`);\n  util.assert(\n      size.length === 2,\n      () => `Error in resizeBilinear: new shape must 2D, but got shape ` +\n          `${size}.`);\n  util.assert(\n      halfPixelCenters === false || alignCorners === false,\n      () => `Error in resizeBilinear: If halfPixelCenters is true, ` +\n          `alignCorners must be false.`);\n\n  let batchImages = $images as Tensor4D;\n  let reshapedTo4D = false;\n  if ($images.rank === 3) {\n    reshapedTo4D = true;\n    batchImages = reshape(\n        $images, [1, $images.shape[0], $images.shape[1], $images.shape[2]]);\n  }\n\n  const [] = size;\n\n  const inputs: ResizeBilinearInputs = {images: batchImages};\n  const attrs: ResizeBilinearAttrs = {alignCorners, halfPixelCenters, size};\n\n  // tslint:disable-next-line: no-unnecessary-type-assertion\n  const res = ENGINE.runKernel(\n                  ResizeBilinear, inputs as {} as NamedTensorMap,\n                  attrs as {} as NamedAttrMap) as T;\n\n  if (reshapedTo4D) {\n    return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]) as T;\n  }\n  return res;\n}\n\nexport const resizeBilinear = op({resizeBilinear_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../../engine';\nimport {ResizeNearestNeighbor, ResizeNearestNeighborAttrs, ResizeNearestNeighborInputs} from '../../kernel_names';\nimport {NamedAttrMap} from '../../kernel_registry';\nimport {Tensor3D, Tensor4D} from '../../tensor';\nimport {NamedTensorMap} from '../../tensor_types';\nimport {convertToTensor} from '../../tensor_util_env';\nimport {TensorLike} from '../../types';\nimport * as util from '../../util';\n\nimport {op} from '../operation';\nimport {reshape} from '../reshape';\n\n/**\n * NearestNeighbor resize a batch of 3D images to a new shape.\n *\n * @param images The images, of rank 4 or rank 3, of shape\n *     `[batch, height, width, inChannels]`. If rank 3, batch of 1 is assumed.\n * @param size The new shape `[newHeight, newWidth]` to resize the\n *     images to. Each channel is resized individually.\n * @param alignCorners Defaults to False. If true, rescale\n *     input by `(new_height - 1) / (height - 1)`, which exactly aligns the 4\n *     corners of images and resized images. If false, rescale by\n *     `new_height / height`. Treat similarly the width dimension.\n * @param halfPixelCenters Defaults to `false`. Whether to assume pixels are of\n *      half the actual dimensions, and yield more accurate resizes. This flag\n *      would also make the floating point coordinates of the top left pixel\n *      0.5, 0.5.\n *\n * @doc {heading: 'Operations', subheading: 'Images', namespace: 'image'}\n */\nfunction resizeNearestNeighbor_<T extends Tensor3D|Tensor4D>(\n    images: T|TensorLike, size: [number, number], alignCorners = false,\n    halfPixelCenters = false): T {\n  const $images = convertToTensor(images, 'images', 'resizeNearestNeighbor');\n\n  util.assert(\n      $images.rank === 3 || $images.rank === 4,\n      () => `Error in resizeNearestNeighbor: x must be rank 3 or 4, but got ` +\n          `rank ${$images.rank}.`);\n  util.assert(\n      size.length === 2,\n      () =>\n          `Error in resizeNearestNeighbor: new shape must 2D, but got shape ` +\n          `${size}.`);\n  util.assert(\n      $images.dtype === 'float32' || $images.dtype === 'int32',\n      () => '`images` must have `int32` or `float32` as dtype');\n  util.assert(\n      halfPixelCenters === false || alignCorners === false,\n      () => `Error in resizeNearestNeighbor: If halfPixelCenters is true, ` +\n          `alignCorners must be false.`);\n  let batchImages = $images as Tensor4D;\n  let reshapedTo4D = false;\n  if ($images.rank === 3) {\n    reshapedTo4D = true;\n    batchImages = reshape(\n        $images, [1, $images.shape[0], $images.shape[1], $images.shape[2]]);\n  }\n  const [] = size;\n\n  const inputs: ResizeNearestNeighborInputs = {images: batchImages};\n  const attrs:\n      ResizeNearestNeighborAttrs = {alignCorners, halfPixelCenters, size};\n\n  // tslint:disable-next-line: no-unnecessary-type-assertion\n  const res = ENGINE.runKernel(\n                  ResizeNearestNeighbor, inputs as {} as NamedTensorMap,\n                  attrs as {} as NamedAttrMap) as T;\n\n  if (reshapedTo4D) {\n    return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]) as T;\n  }\n  return res;\n}\n\nexport const resizeNearestNeighbor = op({resizeNearestNeighbor_});\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport { Tensor1D, Tensor3D } from '../../tensor';\nimport { tensor1d } from '../tensor1d';\nimport { TensorLike } from '../../types';\nimport { op } from '../operation';\nimport { cast } from '../cast';\nimport { split } from '../split';\nimport { bincount } from '../bincount';\nimport { lessEqual } from '../less_equal';\nimport { greater } from '../greater';\nimport { sum } from '../sum';\nimport { add } from '../add';\nimport { mul } from '../mul';\nimport { div } from '../div';\nimport { sub } from '../sub';\nimport { round } from '../round';\nimport { where } from '../where';\nimport { fill } from '../fill';\nimport {slice} from '../slice';\nimport { range } from '../range';\nimport { tensor } from '../tensor';\nimport * as util from '../../util';\nimport { convertToTensor } from '../../tensor_util_env';\n\n/**\n * Performs image binarization with corresponding threshold\n * (depends on the method)value, which creates a binary image from a grayscale.\n * @param image 3d tensor of shape [imageHeight,imageWidth, depth],\n * where imageHeight and imageWidth must be positive.The image color\n * range should be [0, 255].\n * @param method Optional string from `'binary' | 'otsu'`\n * which specifies the method for thresholding. Defaults to 'binary'.\n * @param inverted Optional boolean whichspecifies\n * if colours should be inverted. Defaults to false.\n * @param threshValue Optional number which defines threshold value from 0 to 1.\n * Defaults to 0.5.\n * @return A 3d tensor of shape [imageHeight,imageWidth, depth], which\n * contains binarized image.\n */\n\nfunction threshold_(\n    image: Tensor3D | TensorLike,\n    method = 'binary',\n    inverted = false,\n    threshValue = 0.5\n): Tensor3D {\n    const $image = convertToTensor(image, 'image', 'threshold');\n\n    /* 0.2989, 0.5870, 0.1140 are represent luma coefficients in CCIR601.\n\tReference for converting between RGB and grayscale: https://en.wikipedia.org/wiki/Luma_%28video%29  */\n\n    const RED_INTENCITY_COEF = 0.2989;\n    const GREEN_INTENCITY_COEF = 0.5870;\n    const BLUE_INTENCITY_COEF = 0.1140;\n    const totalPixelsInImage = $image.shape[0] * $image.shape[1];\n\n    let $threshold = mul(tensor1d([threshValue]), 255);\n    let r, g, b, grayscale;\n\n    util.assert(\n        $image.rank === 3,\n        () => 'Error in threshold: image must be rank 3,' +\n            `but got rank ${$image.rank}.`);\n\n    util.assert(\n        $image.shape[2] === 3 || $image.shape[2]=== 1,\n        () => 'Error in threshold: ' +\n            'image color channel must be equal to 3 or 1' +\n            `but got ${$image.shape[2]}.`);\n\n    util.assert(\n      $image.dtype === 'int32' || $image.dtype === 'float32',\n      () => 'Error in dtype: image dtype must be int32 or float32,' +\n          `but got dtype ${$image.dtype}.`);\n\n    util.assert(\n      method === 'otsu' || method === 'binary',\n      () => `Method must be binary or otsu, but was ${method}`);\n\n    if ($image.shape[2] === 3) {\n        [r, g, b] = split($image, [1, 1, 1], -1);\n        const $r = mul(r,RED_INTENCITY_COEF);\n        const $g = mul(g,GREEN_INTENCITY_COEF);\n        const $b = mul(b,BLUE_INTENCITY_COEF);\n        grayscale = add(add($r, $g), $b);\n    } else {\n        grayscale = image;\n    }\n\n    if (method === 'otsu') {\n        const $histogram = bincount(cast(round(grayscale), 'int32') as Tensor1D,\n            tensor([]),\n            256);\n        $threshold = otsu($histogram, totalPixelsInImage);\n    }\n\n    const invCondition = inverted ?\n        lessEqual(grayscale, $threshold) : greater(grayscale, $threshold);\n\n    const result = cast(mul(invCondition,255), 'int32');\n\n    return result as Tensor3D;\n}\n\nfunction otsu(histogram: Tensor1D, total: number):Tensor1D {\n\n    let bestThresh = tensor1d([-1]);\n    let bestInBetVar = tensor1d([0]);\n    let cInBetVar = tensor1d([0]);\n    let classFirst, classSecond, meanFirst,\n        meanSec, weightForeground, weightBack;\n\n    for (let index = 0; index < histogram.size-1; index++) {\n\n        classFirst = slice(histogram, 0, index + 1);\n\n        classSecond = slice(histogram,index + 1);\n\n        weightForeground = div(sum(classFirst),total);\n\n        weightBack = div(sum(classSecond),total);\n\n        const meanFirstDivA = sum(mul(classFirst, range(0, classFirst.size)));\n\n        meanFirst = div(meanFirstDivA, sum(classFirst) );\n\n        const meanSecFill = fill(classSecond.shape, classFirst.size);\n        const meanSecAdd = add(range(0,classSecond.size),meanSecFill);\n        const meanSecMul = mul(classSecond, (meanSecAdd));\n        meanSec = div(sum(meanSecMul), sum(classSecond));\n\n        const cInBetVarSubA = sub(meanFirst, meanSec);\n        const cInBetVarSubB = sub(meanFirst, meanSec);\n        const cInBetVarMul = mul(weightForeground, weightBack);\n        cInBetVar = mul(mul(cInBetVarMul,cInBetVarSubA), cInBetVarSubB);\n\n        const condition = greater(cInBetVar, bestInBetVar);\n\n        bestInBetVar = where(condition, cInBetVar, bestInBetVar);\n\n        bestThresh = where(condition, tensor1d([index]), bestThresh);\n\n    }\n    return bestThresh;\n}\n\nexport const threshold = op({ threshold_ });\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {ENGINE} from '../../engine';\nimport {Transform, TransformAttrs, TransformInputs} from '../../kernel_names';\nimport {NamedAttrMap} from '../../kernel_registry';\nimport {Tensor2D, Tensor4D} from '../../tensor';\nimport {NamedTensorMap} from '../../tensor_types';\nimport {convertToTensor} from '../../tensor_util_env';\nimport {TensorLike} from '../../types';\nimport * as util from '../../util';\n\nimport {op} from '../operation';\n\n/**\n * Applies the given transform(s) to the image(s).\n *\n * @param image 4d tensor of shape `[batch, imageHeight, imageWidth, depth]`.\n * @param transforms Projective transform matrix/matrices. A tensor1d of length\n *     8 or tensor of size N x 8. If one row of transforms is [a0, a1, a2, b0,\n *     b1, b2, c0, c1], then it maps the output point (x, y) to a transformed\n *     input point (x', y') = ((a0 x + a1 y + a2) / k, (b0 x + b1 y + b2) / k),\n *     where k = c0 x + c1 y + 1. The transforms are inverted compared to the\n *     transform mapping input points to output points.\n * @param interpolation Interpolation mode.\n *     Supported values: 'nearest', 'bilinear'. Default to 'nearest'.\n * @param fillMode Points outside the boundaries of the input are filled\n *     according to the given mode, one of 'constant', 'reflect', 'wrap',\n *     'nearest'. Default to 'constant'.\n *     'reflect': (d c b a | a b c d | d c b a ) The input is extended by\n *     reflecting about the edge of the last pixel.\n *     'constant': (k k k k | a b c d | k k k k) The input is extended by\n *     filling all values beyond the edge with the same constant value k.\n *     'wrap': (a b c d | a b c d | a b c d) The input is extended by\n *     wrapping around to the opposite edge.\n *     'nearest': (a a a a | a b c d | d d d d) The input is extended by\n *     the nearest pixel.\n * @param fillValue A float represents the value to be filled outside the\n *     boundaries when fillMode is 'constant'.\n * @param Output dimension after the transform, [height, width]. If undefined,\n *     output is the same size as input image.\n *\n * @doc {heading: 'Operations', subheading: 'Images', namespace: 'image'}\n */\nfunction transform_(\n    image: Tensor4D|TensorLike, transforms: Tensor2D|TensorLike,\n    interpolation: 'nearest'|'bilinear' = 'nearest',\n    fillMode: 'constant'|'reflect'|'wrap'|'nearest' = 'constant', fillValue = 0,\n    outputShape?: [number, number]): Tensor4D {\n  const $image = convertToTensor(image, 'image', 'transform', 'float32');\n  const $transforms =\n      convertToTensor(transforms, 'transforms', 'transform', 'float32');\n\n  util.assert(\n      $image.rank === 4,\n      () => 'Error in transform: image must be rank 4,' +\n          `but got rank ${$image.rank}.`);\n\n  util.assert(\n      $transforms.rank === 2 &&\n          ($transforms.shape[0] === $image.shape[0] ||\n           $transforms.shape[0] === 1) &&\n          $transforms.shape[1] === 8,\n      () => `Error in transform: Input transform should be batch x 8 or 1 x 8`);\n\n  util.assert(\n      outputShape == null || outputShape.length === 2,\n      () =>\n          'Error in transform: outputShape must be [height, width] or null, ' +\n          `but got ${outputShape}.`);\n\n  const inputs: TransformInputs = {image: $image, transforms: $transforms};\n  const attrs:\n      TransformAttrs = {interpolation, fillMode, fillValue, outputShape};\n\n  return ENGINE.runKernel(\n      Transform, inputs as {} as NamedTensorMap, attrs as {} as NamedAttrMap);\n}\n\nexport const transform = op({transform_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor} from '../../tensor';\nimport {convertToTensor} from '../../tensor_util_env';\nimport {TensorLike} from '../../types';\nimport {assert} from '../../util';\n\nimport {greaterEqual} from '../greater_equal';\nimport {lessEqual} from '../less_equal';\nimport {logicalAnd} from '../logical_and';\nimport {op} from '../operation';\nimport {range} from '../range';\nimport {reshape} from '../reshape';\nimport {scalar} from '../scalar';\nimport {stack} from '../stack';\nimport {sub} from '../sub';\nimport {unstack} from '../unstack';\nimport {where} from '../where';\nimport {zeros} from '../zeros';\n\n/**\n * Copy a tensor setting everything outside a central band in each innermost\n * matrix to zero.\n *\n * The band part is computed as follows: Assume input has `k` dimensions\n * `[I, J, K, ..., M, N]`, then the output is a tensor with the same shape where\n * `band[i, j, k, ..., m, n] = in_band(m, n) * input[i, j, k, ..., m, n]`.\n * The indicator function\n * `in_band(m, n) = (num_lower < 0 || (m-n) <= num_lower)`\n * `&& (num_upper < 0 || (n-m) <= num_upper)`\n *\n * ```js\n * const x = tf.tensor2d([[ 0,  1,  2, 3],\n *                        [-1,  0,  1, 2],\n *                        [-2, -1,  0, 1],\n *                        [-3, -2, -1, 0]]);\n * let y = tf.linalg.bandPart(x, 1, -1);\n * y.print(); // [[ 0,  1,  2, 3],\n *            //  [-1,  0,  1, 2],\n *            //  [ 0, -1,  0, 1],\n *            //  [ 0, 0 , -1, 0]]\n * let z = tf.linalg.bandPart(x, 2, 1);\n * z.print(); // [[ 0,  1,  0, 0],\n *            //  [-1,  0,  1, 0],\n *            //  [-2, -1,  0, 1],\n *            //  [ 0, -2, -1, 0]]\n * ```\n *\n * @param x Rank `k` tensor\n * @param numLower Number of subdiagonals to keep.\n *   If negative, keep entire lower triangle.\n * @param numUpper Number of subdiagonals to keep.\n *   If negative, keep entire upper triangle.\n * @returns Rank `k` tensor of the same shape as input.\n *   The extracted banded tensor.\n *\n * @doc {heading:'Operations', subheading:'Linear Algebra', namespace:'linalg'}\n */\nfunction bandPart_<T extends Tensor>(\n    a: T|TensorLike, numLower: number, numUpper: number): T {\n  assert(\n      numLower % 1 === 0,\n      () => `bandPart(): numLower must be an integer, got ${numLower}.`);\n  assert(\n      numUpper % 1 === 0,\n      () => `bandPart(): numUpper must be an integer, got ${numUpper}.`);\n\n  const $a = convertToTensor(a, 'a', 'bandPart');\n\n  assert(\n      $a.rank >= 2,\n      () => `bandPart(): Rank must be at least 2, got ${$a.rank}.`);\n\n  const shape = $a.shape;\n  const [M, N] = $a.shape.slice(-2);\n\n  if (!(numLower <= M)) {\n    throw new Error(\n        `bandPart(): numLower (${numLower})` +\n        ` must not be greater than the number of rows (${M}).`);\n  }\n  if (!(numUpper <= N)) {\n    throw new Error(\n        `bandPart(): numUpper (${numUpper})` +\n        ` must not be greater than the number of columns (${N}).`);\n  }\n\n  if (numLower < 0) {\n    numLower = M;\n  }\n  if (numUpper < 0) {\n    numUpper = N;\n  }\n\n  const i = reshape(range(0, M, 1, 'int32'), [-1, 1]);\n  const j = range(0, N, 1, 'int32');\n  const ij = sub(i, j);\n\n  const inBand = logicalAnd(\n      lessEqual(ij, scalar(+numLower, 'int32')),\n      greaterEqual(ij, scalar(-numUpper, 'int32')));\n\n  const zero = zeros([M, N], $a.dtype);\n\n  return reshape(\n             stack(unstack(reshape($a, [-1, M, N]))\n                       .map(mat => where(inBand, mat, zero))),\n             shape) as T;\n}\n\nexport const bandPart = op({bandPart_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../../engine';\nimport {Tensor1D, Tensor2D} from '../../tensor';\nimport {assert} from '../../util';\n\nimport {div} from '../div';\nimport {mul} from '../mul';\nimport {norm} from '../norm';\nimport {op} from '../operation';\nimport {split} from '../split';\nimport {squeeze} from '../squeeze';\nimport {stack} from '../stack';\nimport {sub} from '../sub';\nimport {sum} from '../sum';\n\n/**\n * Gram-Schmidt orthogonalization.\n *\n * ```js\n * const x = tf.tensor2d([[1, 2], [3, 4]]);\n * let y = tf.linalg.gramSchmidt(x);\n * y.print();\n * console.log('Orthogonalized:');\n * y.dot(y.transpose()).print();  // should be nearly the identity matrix.\n * console.log('First row direction maintained:');\n * const data = await y.array();\n * console.log(data[0][1] / data[0][0]);  // should be nearly 2.\n * ```\n *\n * @param xs The vectors to be orthogonalized, in one of the two following\n *   formats:\n *   - An Array of `tf.Tensor1D`.\n *   - A `tf.Tensor2D`, i.e., a matrix, in which case the vectors are the rows\n *     of `xs`.\n *   In each case, all the vectors must have the same length and the length\n *   must be greater than or equal to the number of vectors.\n * @returns The orthogonalized and normalized vectors or matrix.\n *   Orthogonalization means that the vectors or the rows of the matrix\n *   are orthogonal (zero inner products). Normalization means that each\n *   vector or each row of the matrix has an L2 norm that equals `1`.\n *\n * @doc {heading:'Operations', subheading:'Linear Algebra', namespace:'linalg'}\n */\nfunction gramSchmidt_(xs: Tensor1D[]|Tensor2D): Tensor1D[]|Tensor2D {\n  let inputIsTensor2D: boolean;\n  if (Array.isArray(xs)) {\n    inputIsTensor2D = false;\n    assert(\n        xs != null && xs.length > 0,\n        () => 'Gram-Schmidt process: input must not be null, undefined, or ' +\n            'empty');\n    const dim = xs[0].shape[0];\n    for (let i = 1; i < xs.length; ++i) {\n      assert(\n          xs[i].shape[0] === dim,\n          () =>\n              'Gram-Schmidt: Non-unique lengths found in the input vectors: ' +\n              `(${(xs as Tensor1D[])[i].shape[0]} vs. ${dim})`);\n    }\n  } else {\n    inputIsTensor2D = true;\n    xs = split(xs, xs.shape[0], 0).map(x => squeeze(x, [0]));\n  }\n\n  assert(\n      xs.length <= xs[0].shape[0],\n      () => `Gram-Schmidt: Number of vectors (${\n                (xs as Tensor1D[]).length}) exceeds ` +\n          `number of dimensions (${(xs as Tensor1D[])[0].shape[0]}).`);\n\n  const ys: Tensor1D[] = [];\n  const xs1d = xs;\n  for (let i = 0; i < xs.length; ++i) {\n    ys.push(ENGINE.tidy(() => {\n      let x = xs1d[i];\n      if (i > 0) {\n        for (let j = 0; j < i; ++j) {\n          const proj = mul(sum(mul(ys[j], x)), ys[j]);\n          x = sub(x, proj);\n        }\n      }\n      return div(x, norm(x, 'euclidean'));\n    }));\n  }\n\n  if (inputIsTensor2D) {\n    return stack(ys, 0) as Tensor2D;\n  } else {\n    return ys;\n  }\n}\n\nexport const gramSchmidt = op({gramSchmidt_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {ENGINE} from '../../engine';\nimport {dispose} from '../../globals';\nimport {Tensor, Tensor2D} from '../../tensor';\nimport {assert} from '../../util';\n\nimport {clone} from '../clone';\nimport {concat} from '../concat';\nimport {div} from '../div';\nimport {eye} from '../eye';\nimport {greater} from '../greater';\nimport {matMul} from '../mat_mul';\nimport {mul} from '../mul';\nimport {neg} from '../neg';\nimport {norm} from '../norm';\nimport {op} from '../operation';\nimport {reshape} from '../reshape';\nimport {slice} from '../slice';\nimport {stack} from '../stack';\nimport {sub} from '../sub';\nimport {tensor2d} from '../tensor2d';\nimport {transpose} from '../transpose';\nimport {unstack} from '../unstack';\nimport {where} from '../where';\n\n/**\n * Compute QR decomposition of m-by-n matrix using Householder transformation.\n *\n * Implementation based on\n *   [http://www.cs.cornell.edu/~bindel/class/cs6210-f09/lec18.pdf]\n * (http://www.cs.cornell.edu/~bindel/class/cs6210-f09/lec18.pdf)\n *\n * ```js\n * const a = tf.tensor2d([[1, 2], [3, 4]]);\n * let [q, r] = tf.linalg.qr(a);\n * console.log('Q');\n * q.print();\n * console.log('R');\n * r.print();\n * console.log('Orthogonalized');\n * q.dot(q.transpose()).print()  // should be nearly the identity matrix.\n * console.log('Reconstructed');\n * q.dot(r).print(); // should be nearly [[1, 2], [3, 4]];\n * ```\n *\n * @param x The `tf.Tensor` to be QR-decomposed. Must have rank >= 2. Suppose\n *   it has the shape `[..., M, N]`.\n * @param fullMatrices An optional boolean parameter. Defaults to `false`.\n *   If `true`, compute full-sized `Q`. If `false` (the default),\n *   compute only the leading N columns of `Q` and `R`.\n * @returns An `Array` of two `tf.Tensor`s: `[Q, R]`. `Q` is a unitary matrix,\n *   i.e., its columns all have unit norm and are mutually orthogonal.\n *   If `M >= N`,\n *     If `fullMatrices` is `false` (default),\n *       - `Q` has a shape of `[..., M, N]`,\n *       - `R` has a shape of `[..., N, N]`.\n *     If `fullMatrices` is `true` (default),\n *       - `Q` has a shape of `[..., M, M]`,\n *       - `R` has a shape of `[..., M, N]`.\n *   If `M < N`,\n *     - `Q` has a shape of `[..., M, M]`,\n *     - `R` has a shape of `[..., M, N]`.\n * @throws If the rank of `x` is less than 2.\n *\n * @doc {heading:'Operations',\n *       subheading:'Linear Algebra',\n *       namespace:'linalg'}\n */\nfunction qr_(x: Tensor, fullMatrices = false): [Tensor, Tensor] {\n  assert(\n      x.rank >= 2,\n      () => `qr() requires input tensor to have a rank >= 2, but got rank ${\n          x.rank}`);\n\n  if (x.rank === 2) {\n    return qr2d(x as Tensor2D, fullMatrices);\n  } else {\n    // Rank > 2.\n    // TODO(cais): Below we split the input into individual 2D tensors,\n    //   perform QR decomposition on them and then stack the results back\n    //   together. We should explore whether this can be parallelized.\n    const outerDimsProd = x.shape.slice(0, x.shape.length - 2)\n                              .reduce((value, prev) => value * prev);\n    const x2ds = unstack(\n        reshape(\n            x,\n            [\n              outerDimsProd, x.shape[x.shape.length - 2],\n              x.shape[x.shape.length - 1]\n            ]),\n        0);\n    const q2ds: Tensor2D[] = [];\n    const r2ds: Tensor2D[] = [];\n    x2ds.forEach(x2d => {\n      const [q2d, r2d] = qr2d(x2d as Tensor2D, fullMatrices);\n      q2ds.push(q2d);\n      r2ds.push(r2d);\n    });\n    const q = reshape(stack(q2ds, 0), x.shape);\n    const r = reshape(stack(r2ds, 0), x.shape);\n    return [q, r];\n  }\n}\n\nfunction qr2d(x: Tensor2D, fullMatrices = false): [Tensor2D, Tensor2D] {\n  return ENGINE.tidy(() => {\n    assert(\n        x.shape.length === 2,\n        () => `qr2d() requires a 2D Tensor, but got a ${\n            x.shape.length}D Tensor.`);\n\n    const m = x.shape[0];\n    const n = x.shape[1];\n\n    let q = eye(m);    // Orthogonal transform so far.\n    let r = clone(x);  // Transformed matrix so far.\n\n    const one2D = tensor2d([[1]], [1, 1]);\n    let w: Tensor2D = clone(one2D);\n\n    const iters = m >= n ? n : m;\n    for (let j = 0; j < iters; ++j) {\n      // This tidy within the for-loop ensures we clean up temporary\n      // tensors as soon as they are no longer needed.\n      const rTemp = r;\n      const wTemp = w;\n      const qTemp = q;\n      [w, r, q] = ENGINE.tidy((): [Tensor2D, Tensor2D, Tensor2D] => {\n        // Find H = I - tau * w * w', to put zeros below R(j, j).\n        const rjEnd1 = slice(r, [j, j], [m - j, 1]);\n        const normX = norm(rjEnd1);\n        const rjj = slice(r, [j, j], [1, 1]);\n\n        // The sign() function returns 0 on 0, which causes division by zero.\n        const s = where(greater(rjj, 0), tensor2d([[-1]]), tensor2d([[1]]));\n\n        const u1 = sub(rjj, mul(s, normX));\n        const wPre = div(rjEnd1, u1);\n        if (wPre.shape[0] === 1) {\n          w = clone(one2D);\n        } else {\n          w = concat(\n              [\n                one2D,\n                slice(wPre, [1, 0], [wPre.shape[0] - 1, wPre.shape[1]]) as\n                    Tensor2D\n              ],\n              0);\n        }\n        const tau = neg(div(matMul(s, u1), normX)) as Tensor2D;\n\n        // -- R := HR, Q := QH.\n        const rjEndAll = slice(r, [j, 0], [m - j, n]);\n        const tauTimesW: Tensor2D = mul(tau, w);\n        const wT: Tensor2D = transpose(w);\n        if (j === 0) {\n          r = sub(rjEndAll, matMul(tauTimesW, matMul(wT, rjEndAll)));\n        } else {\n          const rTimesTau: Tensor2D =\n              sub(rjEndAll, matMul(tauTimesW, matMul(wT, rjEndAll)));\n          r = concat([slice(r, [0, 0], [j, n]), rTimesTau], 0);\n        }\n        const tawTimesWT: Tensor2D = transpose(tauTimesW);\n        const qAllJEnd = slice(q, [0, j], [m, q.shape[1] - j]);\n        if (j === 0) {\n          q = sub(qAllJEnd, matMul(matMul(qAllJEnd, w), tawTimesWT));\n        } else {\n          const qTimesTau: Tensor2D =\n              sub(qAllJEnd, matMul(matMul(qAllJEnd, w), tawTimesWT));\n          q = concat([slice(q, [0, 0], [m, j]), qTimesTau], 1);\n        }\n        return [w, r, q];\n      });\n      dispose([rTemp, wTemp, qTemp]);\n    }\n\n    if (!fullMatrices && m > n) {\n      q = slice(q, [0, 0], [m, n]);\n      r = slice(r, [0, 0], [n, n]);\n    }\n\n    return [q, r];\n  }) as [Tensor2D, Tensor2D];\n}\n\nexport const qr = op({qr_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nexport enum Reduction {\n  NONE,\n  MEAN,\n  SUM,\n  SUM_BY_NONZERO_WEIGHTS\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {Tensor} from '../../tensor';\nimport {convertToTensor} from '../../tensor_util_env';\nimport {TensorLike} from '../../types';\n\nimport {cast} from '../cast';\nimport {div} from '../div';\nimport {Reduction} from '../loss_ops_utils';\nimport {mean} from '../mean';\nimport {mul} from '../mul';\nimport {notEqual} from '../not_equal';\nimport {ones} from '../ones';\nimport {op} from '../operation';\nimport {scalar} from '../scalar';\nimport {sum} from '../sum';\n\n/**\n * Computes the weighted loss between two tensors.\n *\n * @param losses Tensor of shape `[batch_size, d1, ..., dN]`.\n * @param weights Tensor whose rank is either 0, or the same rank as\n *    `losses`, and must be broadcastable to `losses` (i.e., all\n *    dimensions must be either `1`, or the same as the corresponding\n *    `losses` dimension).\n *\n * @doc {heading: 'Training', subheading: 'Losses', namespace: 'losses'}\n */\nfunction computeWeightedLoss_<T extends Tensor, O extends Tensor>(\n    losses: T|TensorLike, weights?: Tensor|TensorLike,\n    reduction = Reduction.SUM_BY_NONZERO_WEIGHTS): O {\n  const $losses = convertToTensor(losses, 'losses', 'computeWeightedLoss');\n  let $weights: Tensor = null;\n  if (weights != null) {\n    $weights = convertToTensor(weights, 'weights', 'computeWeightedLoss');\n  }\n\n  const weightedLoss = ($weights == null) ? $losses : mul($losses, $weights);\n\n  if (reduction === Reduction.NONE) {\n    return weightedLoss as O;\n  }\n  if (reduction === Reduction.SUM) {\n    return sum(weightedLoss);\n  }\n  if (reduction === Reduction.MEAN) {\n    if ($weights == null) {\n      return mean(weightedLoss);\n    } else {\n      const broadcastFactor = $losses.size / $weights.size;\n      const result = div(sum(weightedLoss), sum($weights));\n      return broadcastFactor > 1 ? div(result, scalar(broadcastFactor)) :\n                                   result as O;\n    }\n  }\n  if (reduction === Reduction.SUM_BY_NONZERO_WEIGHTS) {\n    if ($weights == null) {\n      return div(sum(weightedLoss), scalar($losses.size));\n    } else {\n      const broadcastedWeights = mul($weights, ones($losses.shape));\n\n      const numNonZeros =\n          cast(sum(notEqual(broadcastedWeights, scalar(0))), 'float32');\n      return div(sum(weightedLoss), numNonZeros);\n    }\n  }\n\n  throw Error(`Unknown reduction: ${reduction}`);\n}\nexport const computeWeightedLoss = op({computeWeightedLoss_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor} from '../../tensor';\nimport {convertToTensor} from '../../tensor_util_env';\nimport {TensorLike} from '../../types';\nimport {assertShapesMatch} from '../../util';\nimport {abs} from '../abs';\nimport {Reduction} from '../loss_ops_utils';\nimport {op} from '../operation';\nimport {sub} from '../sub';\n\nimport {computeWeightedLoss} from './compute_weighted_loss';\n\n/**\n * Computes the absolute difference loss between two tensors.\n *\n * @param labels The ground truth output tensor, same dimensions as\n *    'predictions'.\n * @param predictions The predicted outputs.\n * @param weights Tensor whose rank is either 0, or the same rank as\n *    `labels`, and must be broadcastable to `labels` (i.e., all dimensions\n *    must be either `1`, or the same as the corresponding `losses`\n *    dimension).\n * @param reduction Type of reduction to apply to loss. Should be of type\n *    `Reduction`\n *\n * @doc {heading: 'Training', subheading: 'Losses', namespace: 'losses'}\n */\nfunction absoluteDifference_<T extends Tensor, O extends Tensor>(\n    labels: T|TensorLike, predictions: T|TensorLike,\n    weights?: Tensor|TensorLike,\n    reduction = Reduction.SUM_BY_NONZERO_WEIGHTS): O {\n  const $labels = convertToTensor(labels, 'labels', 'absoluteDifference');\n  const $predictions =\n      convertToTensor(predictions, 'predictions', 'absoluteDifference');\n  let $weights: Tensor = null;\n  if (weights != null) {\n    $weights = convertToTensor(weights, 'weights', 'absoluteDifference');\n  }\n  assertShapesMatch(\n      $labels.shape, $predictions.shape, 'Error in absoluteDifference: ');\n\n  const losses = abs(sub($labels, $predictions));\n  return computeWeightedLoss(losses, $weights, reduction);\n}\n\nexport const absoluteDifference = op({absoluteDifference_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {Tensor} from '../../tensor';\nimport {convertToTensor} from '../../tensor_util_env';\nimport {TensorLike} from '../../types';\nimport {assertShapesMatch} from '../../util';\nimport {Reduction} from '../loss_ops_utils';\nimport {mul} from '../mul';\nimport {op} from '../operation';\nimport {scalar} from '../scalar';\nimport {sub} from '../sub';\nimport {sum} from '../sum';\n\nimport {computeWeightedLoss} from './compute_weighted_loss';\n\n/**\n * Computes the cosine distance loss between two tensors.\n *\n * @param labels The ground truth output tensor, same dimensions as\n *    'predictions'.\n * @param predictions The predicted outputs.\n * @param axis The dimension along which the cosine distance is computed.\n * @param weights Tensor whose rank is either 0, or the same rank as\n *    `labels`, and must be broadcastable to `labels` (i.e., all dimensions\n *    must be either `1`, or the same as the corresponding `losses`\n *    dimension).\n * @param reduction Type of reduction to apply to loss. Should be of type\n *    `Reduction`\n *\n * @doc {heading: 'Training', subheading: 'Losses', namespace: 'losses'}\n */\nfunction cosineDistance_<T extends Tensor, O extends Tensor>(\n    labels: T|TensorLike, predictions: T|TensorLike, axis: number,\n    weights?: Tensor|TensorLike,\n    reduction = Reduction.SUM_BY_NONZERO_WEIGHTS): O {\n  const $labels = convertToTensor(labels, 'labels', 'cosineDistance');\n  const $predictions =\n      convertToTensor(predictions, 'predictions', 'cosineDistance');\n  let $weights: Tensor = null;\n  if (weights != null) {\n    $weights = convertToTensor(weights, 'weights', 'cosineDistance');\n  }\n  assertShapesMatch(\n      $labels.shape, $predictions.shape, 'Error in cosineDistance: ');\n\n  const one = scalar(1);\n  const losses = sub(one, sum(mul($labels, $predictions), axis, true));\n  return computeWeightedLoss(losses, $weights, reduction);\n}\nexport const cosineDistance = op({cosineDistance_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {Tensor} from '../../tensor';\nimport {convertToTensor} from '../../tensor_util_env';\nimport {TensorLike} from '../../types';\nimport {assertShapesMatch} from '../../util';\nimport {Reduction} from '../loss_ops_utils';\nimport {mul} from '../mul';\nimport {op} from '../operation';\nimport {relu} from '../relu';\nimport {scalar} from '../scalar';\nimport {sub} from '../sub';\n\nimport {computeWeightedLoss} from './compute_weighted_loss';\n\n/**\n * Computes the Hinge loss between two tensors.\n *\n * @param labels The ground truth output tensor, same dimensions as\n *    'predictions'.\n * @param predictions The predicted outputs.\n * @param weights Tensor whose rank is either 0, or the same rank as\n *    `labels`, and must be broadcastable to `labels` (i.e., all dimensions\n *    must be either `1`, or the same as the corresponding `losses`\n *    dimension).\n * @param reduction Type of reduction to apply to loss. Should be of type\n *    `Reduction`\n *\n * @doc {heading: 'Training', subheading: 'Losses', namespace: 'losses'}\n */\nfunction hingeLoss_<T extends Tensor, O extends Tensor>(\n    labels: T|TensorLike, predictions: T|TensorLike,\n    weights?: Tensor|TensorLike,\n    reduction = Reduction.SUM_BY_NONZERO_WEIGHTS): O {\n  let $labels = convertToTensor(labels, 'labels', 'hingeLoss');\n  const $predictions = convertToTensor(predictions, 'predictions', 'hingeLoss');\n  let $weights: Tensor = null;\n  if (weights != null) {\n    $weights = convertToTensor(weights, 'weights', 'hingeLoss');\n  }\n  assertShapesMatch($labels.shape, $predictions.shape, 'Error in hingeLoss: ');\n\n  const one = scalar(1);\n  // Convert binary labels to (-1, 1)\n  $labels = sub(mul(scalar(2), $labels), one);\n  const losses = relu(sub(one, mul($labels, $predictions)));\n  return computeWeightedLoss(losses, $weights, reduction);\n}\nexport const hingeLoss = op({hingeLoss_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor} from '../../tensor';\nimport {convertToTensor} from '../../tensor_util_env';\nimport {TensorLike} from '../../types';\nimport {assertShapesMatch} from '../../util';\nimport {abs} from '../abs';\nimport {add} from '../add';\nimport {Reduction} from '../loss_ops_utils';\nimport {minimum} from '../minimum';\nimport {mul} from '../mul';\nimport {op} from '../operation';\nimport {scalar} from '../scalar';\nimport {square} from '../square';\nimport {sub} from '../sub';\n\nimport {computeWeightedLoss} from './compute_weighted_loss';\n\n/**\n * Computes the Huber loss between two tensors.\n *\n * @param labels The ground truth output tensor, same dimensions as\n *    'predictions'.\n * @param predictions The predicted outputs.\n * @param weights Tensor whose rank is either 0, or the same rank as\n *    `labels`, and must be broadcastable to `labels` (i.e., all dimensions\n *    must be either `1`, or the same as the corresponding `losses`\n *    dimension).\n * @param delta Point where Huber loss changes from quadratic to linear.\n * @param reduction Type of reduction to apply to loss. Should be of type\n *    `Reduction`.\n *\n * @doc {heading: 'Training', subheading: 'Losses', namespace: 'losses'}\n */\nfunction huberLoss_<T extends Tensor, O extends Tensor>(\n    labels: T|TensorLike, predictions: T|TensorLike,\n    weights?: Tensor|TensorLike, delta = 1.0,\n    reduction = Reduction.SUM_BY_NONZERO_WEIGHTS): O {\n  const $labels = convertToTensor(labels, 'labels', 'huberLoss');\n  const $predictions = convertToTensor(predictions, 'predictions', 'huberLoss');\n  let $weights: Tensor = null;\n  if (weights != null) {\n    $weights = convertToTensor(weights, 'weights', 'huberLoss');\n  }\n  assertShapesMatch($labels.shape, $predictions.shape, 'Error in huberLoss: ');\n\n  const deltaScalar = scalar(delta);\n  const error = abs(sub($predictions, $labels));\n  const quadratic = minimum(error, deltaScalar);\n  const linear = sub(error, quadratic);\n\n  const losses =\n      add(mul(scalar(0.5), square(quadratic)), mul(deltaScalar, linear));\n  return computeWeightedLoss(losses, $weights, reduction);\n}\nexport const huberLoss = op({huberLoss_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor} from '../../tensor';\nimport {convertToTensor} from '../../tensor_util_env';\nimport {TensorLike} from '../../types';\nimport {assertShapesMatch} from '../../util';\nimport {add} from '../add';\nimport {log} from '../log';\nimport {Reduction} from '../loss_ops_utils';\nimport {mul} from '../mul';\nimport {neg} from '../neg';\nimport {op} from '../operation';\nimport {scalar} from '../scalar';\nimport {sub} from '../sub';\n\nimport {computeWeightedLoss} from './compute_weighted_loss';\n\n/**\n * Computes the log loss between two tensors.\n *\n * @param labels The ground truth output tensor, same dimensions as\n *    'predictions'.\n * @param predictions The predicted outputs.\n * @param weights Tensor whose rank is either 0, or the same rank as\n *    `labels`, and must be broadcastable to `labels` (i.e., all dimensions\n *    must be either `1`, or the same as the corresponding `losses`\n *    dimension).\n * @param epsilon A small increment to avoid taking log of zero\n * @param reduction Type of reduction to apply to loss. Should be of type\n *    `Reduction`\n *\n * @doc {heading: 'Training', subheading: 'Losses', namespace: 'losses'}\n */\nfunction logLoss_<T extends Tensor, O extends Tensor>(\n    labels: T|TensorLike, predictions: T|TensorLike,\n    weights?: Tensor|TensorLike, epsilon = 1e-7,\n    reduction = Reduction.SUM_BY_NONZERO_WEIGHTS): O {\n  const $labels = convertToTensor(labels, 'labels', 'logLoss');\n  const $predictions = convertToTensor(predictions, 'predictions', 'logLoss');\n  let $weights: Tensor = null;\n  if (weights != null) {\n    $weights = convertToTensor(weights, 'weights', 'logLoss');\n  }\n  assertShapesMatch($labels.shape, $predictions.shape, 'Error in logLoss: ');\n\n  const one = scalar(1);\n  const epsilonScalar = scalar(epsilon);\n\n  const l1 = neg(mul($labels, log(add($predictions, epsilonScalar))));\n  const l2 =\n      mul(sub(one, $labels), log(add(sub(one, $predictions), epsilonScalar)));\n  const losses = sub(l1, l2);\n  return computeWeightedLoss(losses, $weights, reduction);\n}\nexport const logLoss = op({logLoss_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor} from '../../tensor';\nimport {convertToTensor} from '../../tensor_util_env';\nimport {TensorLike} from '../../types';\nimport {assertShapesMatch} from '../../util';\nimport {Reduction} from '../loss_ops_utils';\nimport {op} from '../operation';\nimport {squaredDifference} from '../squared_difference';\n\nimport {computeWeightedLoss} from './compute_weighted_loss';\n\n/**\n * Computes the mean squared error between two tensors.\n *\n * @param labels The ground truth output tensor, same dimensions as\n *    'predictions'.\n * @param predictions The predicted outputs.\n * @param weights Tensor whose rank is either 0, or the same rank as\n *    `labels`, and must be broadcastable to `labels` (i.e., all dimensions\n *    must be either `1`, or the same as the corresponding `losses`\n *    dimension).\n * @param reduction Type of reduction to apply to loss. Should be of type\n *    `Reduction`\n *\n * @doc {heading: 'Training', subheading: 'Losses', namespace: 'losses'}\n */\nfunction meanSquaredError_<T extends Tensor, O extends Tensor>(\n    labels: T|TensorLike, predictions: T|TensorLike,\n    weights?: Tensor|TensorLike,\n    reduction = Reduction.SUM_BY_NONZERO_WEIGHTS): O {\n  const $labels = convertToTensor(labels, 'labels', 'meanSquaredError');\n  const $predictions =\n      convertToTensor(predictions, 'predictions', 'meanSquaredError');\n  let $weights: Tensor = null;\n  if (weights != null) {\n    $weights = convertToTensor(weights, 'weights', 'meanSquaredError');\n  }\n  assertShapesMatch(\n      $labels.shape, $predictions.shape, 'Error in meanSquaredError: ');\n\n  const losses = squaredDifference($labels, $predictions);\n  return computeWeightedLoss(losses, $weights, reduction);\n}\nexport const meanSquaredError = op({meanSquaredError_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor} from '../../tensor';\nimport {convertToTensor} from '../../tensor_util_env';\nimport {TensorLike} from '../../types';\nimport {assertShapesMatch} from '../../util';\nimport {abs} from '../abs';\nimport {add} from '../add';\nimport {exp} from '../exp';\nimport {log1p} from '../log1p';\nimport {Reduction} from '../loss_ops_utils';\nimport {mul} from '../mul';\nimport {neg} from '../neg';\nimport {op} from '../operation';\nimport {relu} from '../relu';\nimport {scalar} from '../scalar';\nimport {sub} from '../sub';\n\nimport {computeWeightedLoss} from './compute_weighted_loss';\n\nfunction sigmoidCrossEntropyWithLogits_<T extends Tensor, O extends Tensor>(\n    labels: T|TensorLike, logits: T|TensorLike): O {\n  const $labels =\n      convertToTensor(labels, 'labels', 'sigmoidCrossEntropyWithLogits');\n  const $logits =\n      convertToTensor(logits, 'logits', 'sigmoidCrossEntropyWithLogits');\n  assertShapesMatch(\n      $labels.shape, $logits.shape, 'Error in sigmoidCrossEntropyWithLogits: ');\n\n  /**\n   * Implementation Details:\n   *\n   * For brevity, let `x = logits`, `z = labels`.  The logistic loss is\n   *     z * -log(sigmoid(x)) + (1 - z) * -log(1 - sigmoid(x))\n   *   = z * -log(1 / (1 + exp(-x))) + (1 - z) * -log(exp(-x) / (1 + exp(-x)))\n   *   = z * log(1 + exp(-x)) + (1 - z) * (-log(exp(-x)) + log(1 + exp(-x)))\n   *   = z * log(1 + exp(-x)) + (1 - z) * (x + log(1 + exp(-x))\n   *   = (1 - z) * x + log(1 + exp(-x))\n   *   = x - x * z + log(1 + exp(-x))\n   *\n   *   For x < 0, to avoid overflow in exp(-x), we reformulate the above\n   *     x - x * z + log(1 + exp(-x))\n   *   = log(exp(x)) - x * z + log(1 + exp(-x))\n   *   = - x * z + log(1 + exp(x))\n   *\n   * Hence, to ensure stability and avoid overflow, the implementation uses\n   * this equivalent formulation:\n   *     max(x, 0) - x * z + log(1 + exp(-abs(x)))\n   */\n  const maxOutput = relu($logits);\n  const outputXTarget = mul($logits, $labels);\n  const sigmoidOutput = log1p(exp(neg(abs($logits))));\n\n  return add(sub(maxOutput, outputXTarget), sigmoidOutput);\n}\n\n/**\n * Computes the sigmoid cross entropy loss between two tensors.\n *\n * If labelSmoothing is nonzero, smooth the labels towards 1/2:\n *\n *   newMulticlassLabels = multiclassLabels * (1 - labelSmoothing)\n *                         + 0.5 * labelSmoothing\n *\n * @param multiClassLabels The ground truth output tensor of shape\n * [batch_size, num_classes], same dimensions as 'predictions'.\n * @param logits The predicted outputs.\n * @param weights Tensor whose rank is either 0, or the same rank as\n *    `labels`, and must be broadcastable to `labels` (i.e., all dimensions\n *    must be either `1`, or the same as the corresponding `losses`\n *    dimension).\n * @param labelSmoothing If greater than 0, then smooth the labels.\n * @param reduction Type of reduction to apply to loss. Should be of type\n *    `Reduction`\n *\n * @doc { heading: 'Training', subheading: 'Losses', namespace: 'losses' }\n */\nfunction sigmoidCrossEntropy_<T extends Tensor, O extends Tensor>(\n    multiClassLabels: T|TensorLike, logits: T|TensorLike,\n    weights?: Tensor|TensorLike, labelSmoothing = 0,\n    reduction = Reduction.SUM_BY_NONZERO_WEIGHTS): O {\n  let $multiClassLabels = convertToTensor(\n      multiClassLabels, 'multiClassLabels', 'sigmoidCrossEntropy');\n  const $logits = convertToTensor(logits, 'logits', 'sigmoidCrossEntropy');\n  let $weights: Tensor = null;\n  if (weights != null) {\n    $weights = convertToTensor(weights, 'weights', 'sigmoidCrossEntropy');\n  }\n  assertShapesMatch(\n      $multiClassLabels.shape, $logits.shape, 'Error in sigmoidCrossEntropy: ');\n\n  if (labelSmoothing > 0) {\n    const labelSmoothingScalar = scalar(labelSmoothing);\n    const one = scalar(1);\n    const half = scalar(0.5);\n\n    $multiClassLabels =\n        add(mul($multiClassLabels, sub(one, labelSmoothingScalar)),\n            mul(half, labelSmoothingScalar));\n  }\n  const losses = sigmoidCrossEntropyWithLogits_($multiClassLabels, $logits);\n\n  return computeWeightedLoss(losses, $weights, reduction);\n}\n\nexport const sigmoidCrossEntropy = op({sigmoidCrossEntropy_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {customGrad} from '../../gradients';\nimport {Tensor} from '../../tensor';\nimport {GradSaveFunc} from '../../tensor_types';\nimport {convertToTensor} from '../../tensor_util_env';\nimport {TensorLike} from '../../types';\nimport {assertShapesMatch} from '../../util';\nimport {add} from '../add';\nimport {expandShapeToKeepDim} from '../axis_util';\nimport {cast} from '../cast';\nimport {div} from '../div';\nimport {exp} from '../exp';\nimport {logSumExp} from '../log_sum_exp';\nimport {Reduction} from '../loss_ops_utils';\nimport {mul} from '../mul';\nimport {neg} from '../neg';\nimport {op} from '../operation';\nimport {reshape} from '../reshape';\nimport {scalar} from '../scalar';\nimport {sub} from '../sub';\nimport {sum} from '../sum';\n\nimport {computeWeightedLoss} from './compute_weighted_loss';\n\n/**\n * Computes softmax cross entropy between logits and labels.\n *\n * Measures the probability error in discrete classification tasks in which\n * the classes are mutually exclusive (each entry is in exactly one class).\n * For example, each CIFAR-10 image is labeled with one and only one label: an\n * image can be a dog or a truck, but not both.\n *\n * `NOTE`: While the classes are mutually exclusive, their probabilities need\n * not be. All that is required is that each row of labels is a valid\n * probability distribution. If they are not, the computation of the gradient\n * will be incorrect.\n *\n * `WARNING`: This op expects unscaled logits, since it performs a softmax on\n * logits internally for efficiency. Do not call this op with the output of\n * softmax, as it will produce incorrect results.\n *\n * logits and labels must have the same shape, e.g. [batch_size, num_classes]\n * and the same dtype.\n * @param labels The labels array.\n * @param logits The logits array.\n * @param dim The dimension softmax would be performed on. Defaults to `-1`\n *     which indicates the last dimension.\n */\nfunction softmaxCrossEntropyWithLogits_<T extends Tensor, O extends Tensor>(\n    labels: T, logits: T, dim = -1): O {\n  if (dim === -1) {\n    dim = logits.rank - 1;\n  }\n\n  if (dim !== logits.rank - 1) {\n    throw Error(\n        `Softmax cross entropy along a non-last dimension is not yet ` +\n        `supported. Labels / logits was rank ${logits.rank} ` +\n        `and dim was ${dim}`);\n  }\n  // Use a custom gradient for numerical stability.\n  const customOp =\n      customGrad((labels: Tensor, logits: Tensor, save: GradSaveFunc) => {\n        // Reference:\n        //   1. http://cs231n.github.io/linear-classify/#softmax\n        //   2. https://blog.feedly.com/tricks-of-the-trade-logsumexp/\n        const keepDims = true;\n        const lse = logSumExp(logits, [dim], keepDims);\n        const logResult = sub(cast(logits, 'float32'), lse);\n        save([labels, logResult]);\n\n        const costVector = neg(mul(logResult, labels));\n        const value: O = sum(costVector, [dim]);\n\n        const gradFunc = (dy: O, saved: Tensor[]) => {\n          const [labels, logResult] = saved;\n          const dyShape = expandShapeToKeepDim(dy.shape, [dim]);\n          return [\n            mul(reshape(dy, dyShape),\n                sub(cast(labels, 'float32'), exp(logResult))),\n            mul(reshape(dy, dyShape),\n                sub(exp(logResult), cast(labels, 'float32'))),\n          ];\n        };\n        return {value, gradFunc};\n      });\n\n  return customOp(labels, logits);\n}\n\n/**\n * Computes the softmax cross entropy loss between two tensors.\n *\n * If labelSmoothing is nonzero, smooth the labels towards 1/2:\n *\n *   newOnehotLabels = onehotLabels * (1 - labelSmoothing)\n *                         + labelSmoothing / numClasses\n *\n * @param onehotLabels One hot encoded labels\n *    [batch_size, num_classes], same dimensions as 'predictions'.\n * @param logits The predicted outputs.\n * @param weights Tensor whose rank is either 0, or 1, and must be\n *    broadcastable to `loss`  of shape [batch_size]\n * @param labelSmoothing If greater than 0, then smooth the labels.\n * @param reduction Type of reduction to apply to loss. Should be of type\n *    `Reduction`\n *\n * @doc { heading: 'Training', subheading: 'Losses', namespace: 'losses' }\n */\nfunction softmaxCrossEntropy_<T extends Tensor, O extends Tensor>(\n    onehotLabels: T|TensorLike, logits: T|TensorLike,\n    weights?: Tensor|TensorLike, labelSmoothing = 0,\n    reduction = Reduction.SUM_BY_NONZERO_WEIGHTS): O {\n  let $onehotLabels =\n      convertToTensor(onehotLabels, 'onehotLabels', 'softmaxCrossEntropy');\n  const $logits = convertToTensor(logits, 'logits', 'softmaxCrossEntropy');\n  let $weights: Tensor = null;\n\n  if (weights != null) {\n    $weights = convertToTensor(weights, 'weights', 'softmaxCrossEntropy');\n  }\n\n  assertShapesMatch(\n      $onehotLabels.shape, $logits.shape, 'Error in softmaxCrossEntropy: ');\n\n  if (labelSmoothing > 0) {\n    const labelSmoothingScalar = scalar(labelSmoothing);\n    const one = scalar(1);\n    const numClasses = scalar($onehotLabels.shape[1]);\n\n    $onehotLabels =\n        add(mul($onehotLabels, sub(one, labelSmoothingScalar)),\n            div(labelSmoothingScalar, numClasses));\n  }\n\n  const losses = softmaxCrossEntropyWithLogits_($onehotLabels, $logits);\n\n  return computeWeightedLoss(losses, $weights, reduction);\n}\n\nexport const softmaxCrossEntropy = op({softmaxCrossEntropy_});\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../../engine';\nimport {SparseFillEmptyRows, SparseFillEmptyRowsInputs} from '../../kernel_names';\nimport {Scalar, Tensor, Tensor1D, Tensor2D} from '../../tensor';\nimport {NamedTensorMap} from '../../tensor_types';\nimport {convertToTensor} from '../../tensor_util_env';\nimport {ScalarLike, TensorLike} from '../../types';\nimport {op} from '../operation';\n\n/**\n * The input SparseTensor is represented via the map of inputs {`indices`,\n * `values`, `denseShape`}. The output SparseTensor has the same `denseShape`\n * but with indices `outputIndices` and values `outputValues`. This op inserts a\n * single entry for every row that doesn't have any values. The index is created\n * as `[row, 0, ..., 0]` and the inserted value is `defaultValue`.\n *\n * For example, suppose `spInput` has shape [5, 6] and non-empty values:\n * [0, 1]: a\n * [0, 3]: b\n * [2, 0]: c\n * [3, 1]: d\n *\n * Rows 1 and 4 are empty, so the output will be of shape [5, 6] with values:\n * [0, 1]: a\n * [0, 3]: b\n * [1, 0]: `defaultValue`\n * [2, 0]: c\n * [3, 1]: d\n * [4, 0]: `defaultValue`\n *\n * The output SparseTensor will be in row-major order and will have the same\n * shape as the input.\n *\n * This op also returns an indicator vector shaped [dense_shape[0]] such that\n * emptyRowIndicator[i] = True iff row i was an empty row.\n *\n * And a reverse index map vector shaped [indices.shape[0]] that is used during\n * backpropagation, reverseIndexMap[i] = outi s.t. indices[i, j] ==\n * outputIndices[outi, j] for all j\n *\n * ```js\n * const result = tf.sparse.sparseFillEmptyRows(\n *   [[0, 0], [1, 0], [1, 3], [1, 4], [3, 2], [3, 3]],\n *   [0, 10, 13, 14, 32, 33], [5, 6], -1);\n * console.log(result);\n * result['outputIndices'].print(); // [[0, 0], [1, 0], [1, 3], [1, 4],\n *                                  //  [2, 0], [3, 2], [3, 3], [4, 0]]\n * result['outputValues'].print(); // [0, 10, 13, 14,-1, 32, 33, -1]\n * result['emptyRowIndicator'].print(); // [false, false, true, false, true]\n * result['reverseIndexMap'].print(); // [0, 1, 2, 3, 5, 6]\n * ```\n * @param indices: 2-D. The indices of the sparse tensor.\n * @param values: 1-D. The values of the sparse tensor.\n * @param denseShape: 1-D. The shape of the sparse tensor.\n * @param defaultValue: 0-D. Default value to insert into location [row, 0, ...,\n *     0] for rows missing from the input sparse tensor.\n * @return A map with the following properties:\n *     - outputIndices\n *     - outputValues: 1-D. The values of the filled sparse tensor.\n *     - emptyRowIndicator: 1-D. Whether the dense row was missing in the input\n * sparse tensor.\n *     - reverseIndexMap: 1-D. A map from the input indices to the output\n * indices.\n * @doc {heading: 'Operations', subheading: 'Sparse'}\n */\nfunction sparseFillEmptyRows_(\n    indices: Tensor2D|TensorLike, values: Tensor1D|TensorLike,\n    denseShape: Tensor1D|TensorLike,\n    defaultValue: Scalar|ScalarLike): NamedTensorMap {\n  const $indices =\n      convertToTensor(indices, 'indices', 'sparseFillEmptyRows', 'int32');\n  const $values = convertToTensor(values, 'values', 'sparseFillEmptyRows');\n  const $denseShape =\n      convertToTensor(denseShape, 'denseShape', 'sparseFillEmptyRows', 'int32');\n  const $defaultValue = convertToTensor(\n      defaultValue, 'defaultValue', 'sparseFillEmptyRows', $values.dtype);\n\n  if ($indices.rank !== 2) {\n    throw new Error(`Indices should be Tensor2D but received shape\n        ${$indices.shape}`);\n  }\n  if ($values.rank !== 1) {\n    throw new Error(\n        `Values should be Tensor1D but received shape ${$values.shape}`);\n  }\n  if ($denseShape.rank !== 1) {\n    throw new Error(`Dense shape should be Tensor1D but received shape ${\n        $denseShape.shape}`);\n  }\n  if ($defaultValue.rank !== 0) {\n    throw new Error(`Default value should be a scalar but received shape ${\n        $defaultValue.shape}`);\n  }\n\n  const inputs: SparseFillEmptyRowsInputs = {\n    indices: $indices,\n    values: $values,\n    denseShape: $denseShape,\n    defaultValue: $defaultValue\n  };\n\n  const result: Tensor[] = ENGINE.runKernel(SparseFillEmptyRows, inputs as {});\n  return {\n    outputIndices: result[0],\n    outputValues: result[1],\n    emptyRowIndicator: result[2],\n    reverseIndexMap: result[3]\n  };\n}\n\nexport const sparseFillEmptyRows = op({sparseFillEmptyRows_});\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../../engine';\nimport {SparseReshape, SparseReshapeInputs} from '../../kernel_names';\nimport {Tensor, Tensor1D, Tensor2D} from '../../tensor';\nimport {NamedTensorMap} from '../../tensor_types';\nimport {convertToTensor} from '../../tensor_util_env';\nimport {TensorLike} from '../../types';\nimport {op} from '../operation';\n\n/**\n * This operation has the same semantics as reshape on the represented dense\n * tensor. The `inputIndices` are recomputed based on the requested `newShape`.\n * If one component of `newShape` is the special value -1, the size of that\n * dimension is computed so that the total dense size remains constant. At most\n * one component of `newShape` can be -1. The number of dense elements implied\n * by `newShape` must be the same as the number of dense elements originally\n * implied by `inputShape`. Reshaping does not affect the order of values in the\n * SparseTensor. If the input tensor has rank R_in and N non-empty values, and\n * `newShape` has length R_out, then `inputIndices` has shape [N, R_in],\n * `inputShape` has length R_in, `outputIndices` has shape [N, R_out], and\n * `outputShape` has length R_out.\n *\n * ```js\n * const result = tf.sparse.sparseReshape(\n *   [[0, 0, 0], [0, 0, 1], [0, 1, 0], [1, 0, 0], [1, 2, 3]],\n *   [2, 3, 6], [9, -1]);\n * console.log(result);\n * result['outputIndices'].print(); //[[0, 0], [0, 1], [1, 2], [4, 2], [8, 1]]\n * result['outputShape'].print(); // [9, 4]\n * ```\n * @param inputIndices: 2-D. N x R_in matrix with the indices of non-empty\n * values in a SparseTensor.\n * @param inputShape: 1-D. R_in Tensor1D with the input SparseTensor's dense\n * shape.\n * @param newShape: 1-D. R_out Tensor1D with the requested new dense shape.\n * @return A map with the following properties:\n *     - outputIndices: 2-D. N x R_out matrix with the updated indices of\n *       non-empty values in the output SparseTensor.\n *     - outputShape: 1-D. R_out vector with the full dense shape of the output\n *       SparseTensor. This is the same as newShape but with any -1 dimensions\n *        filled in.\n * @doc {heading: 'Operations', subheading: 'Sparse'}\n */\nfunction sparseReshape_(\n    inputIndices: Tensor2D|TensorLike, inputShape: Tensor1D|TensorLike,\n    newShape: Tensor1D|TensorLike): NamedTensorMap {\n  const $inputIndices =\n      convertToTensor(inputIndices, 'inputIndices', 'sparseReshape', 'int32');\n  const $inputShape =\n      convertToTensor(inputShape, 'inputShape', 'sparseReshape', 'int32');\n  const $newShape =\n      convertToTensor(newShape, 'newShape', 'sparseReshape', 'int32');\n\n  if ($inputIndices.rank !== 2) {\n    throw new Error(`Input indices should be Tensor2D but received shape\n        ${$inputIndices.shape}`);\n  }\n  if ($inputShape.rank !== 1) {\n    throw new Error(`Input shape should be Tensor1D but received shape ${\n        $inputShape.shape}`);\n  }\n  if ($newShape.rank !== 1) {\n    throw new Error(\n        `New shape should be Tensor1D but received shape ${$newShape.shape}`);\n  }\n\n  const inputs: SparseReshapeInputs = {\n    inputIndices: $inputIndices,\n    inputShape: $inputShape,\n    newShape: $newShape\n  };\n  const result: Tensor[] = ENGINE.runKernel(SparseReshape, inputs as {});\n  return {outputIndices: result[0], outputShape: result[1]};\n}\n\nexport const sparseReshape = op({sparseReshape_});\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../../engine';\nimport {SparseSegmentMean, SparseSegmentMeanInputs} from '../../kernel_names';\nimport {Tensor, Tensor1D} from '../../tensor';\nimport {convertToTensor} from '../../tensor_util_env';\nimport {TensorLike} from '../../types';\nimport {op} from '../operation';\n\n/**\n * Computes the mean along sparse segments of a tensor.\n *\n * ```js\n * const c = tf.tensor2d([[1,2,3,4], [-1,-2,-3,-4], [6,7,8,9]]);\n * // Select two rows, one segment.\n * const result1 = tf.sparse.sparseSegmentMean(c,\n *                                           tf.tensor1d([0, 1], 'int32'),\n *                                           tf.tensor1d([0, 0], 'int32'));\n * result1.print(); // [[0, 0, 0, 0]]\n *\n * // Select two rows, two segments.\n * const result2 = tf.sparse.sparseSegmentMean(c,\n *                                             tf.tensor1d([0, 1], 'int32'),\n *                                             tf.tensor1d([0, 1], 'int32'));\n * result2.print(); // [[1, 2, 3, 4], [-1, -2, -3, -4]]\n *\n * // Select all rows, two segments.\n * const result3 = tf.sparse.sparseSegmentMean(c,\n *                                             tf.tensor1d([0, 1, 2], 'int32'),\n *                                             tf.tensor1d([0, 1, 1], 'int32'));\n * result3.print(); // [[1.0, 2.0, 3.0, 4.0], [2.5, 2.5, 2.5, 2.5]]\n * ```\n * @param data: A Tensor of at least one dimension with data that will be\n *     assembled in the output.\n * @param indices: A 1-D Tensor with indices into data. Has same rank as\n *     segmentIds.\n * @param segmentIds: A 1-D Tensor with indices into the output Tensor. Values\n *     should be sorted and can be repeated.\n * @return Has same shape as data, except for dimension 0 which has equal to\n *         the number of segments.\n *\n * @doc {heading: 'Operations', subheading: 'Sparse'}\n */\nfunction sparseSegmentMean_(\n    data: Tensor|TensorLike, indices: Tensor1D|TensorLike,\n    segmentIds: Tensor1D|TensorLike): Tensor {\n  const $data = convertToTensor(data, 'data', 'sparseSegmentMean');\n  const $indices =\n      convertToTensor(indices, 'indices', 'sparseSegmentMean', 'int32');\n  const $segmentIds =\n      convertToTensor(segmentIds, 'segmentIds', 'sparseSegmentMean', 'int32');\n\n  if ($data.rank < 1) {\n    throw new Error(\n        `Data should be at least 1 dimensional but received scalar`);\n  }\n  if ($indices.rank !== 1) {\n    throw new Error(`Indices should be Tensor1D but received shape\n          ${$indices.shape}`);\n  }\n  if ($segmentIds.rank !== 1) {\n    throw new Error(`Segment ids should be Tensor1D but received shape\n          ${$segmentIds.shape}`);\n  }\n\n  const inputs: SparseSegmentMeanInputs = {\n    data: $data,\n    indices: $indices,\n    segmentIds: $segmentIds\n  };\n\n  return ENGINE.runKernel(SparseSegmentMean, inputs as {});\n}\n\nexport const sparseSegmentMean = op({sparseSegmentMean_});\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../../engine';\nimport {SparseSegmentSum, SparseSegmentSumInputs} from '../../kernel_names';\nimport {Tensor, Tensor1D} from '../../tensor';\nimport {convertToTensor} from '../../tensor_util_env';\nimport {TensorLike} from '../../types';\nimport {op} from '../operation';\n\n/**\n * Computes the sum along sparse segments of a tensor.\n *\n * ```js\n * const c = tf.tensor2d([[1,2,3,4], [-1,-2,-3,-4], [5,6,7,8]]);\n * // Select two rows, one segment.\n * const result1 = tf.sparse.sparseSegmentSum(c,\n *                                           tf.tensor1d([0, 1], 'int32'),\n *                                           tf.tensor1d([0, 0], 'int32'));\n * result1.print(); // [[0, 0, 0, 0]]\n *\n * // Select two rows, two segments.\n * const result2 = tf.sparse.sparseSegmentSum(c,\n *                                           tf.tensor1d([0, 1], 'int32'),\n *                                           tf.tensor1d([0, 1], 'int32'));\n * result2.print(); // [[1, 2, 3, 4], [-1, -2, -3, -4]]\n *\n * // Select all rows, two segments.\n * const result3 = tf.sparse.sparseSegmentSum(c,\n *                                           tf.tensor1d([0, 1, 2], 'int32'),\n *                                           tf.tensor1d([0, 0, 1], 'int32'));\n * result3.print(); // [[0, 0, 0, 0], [5, 6, 7, 8]]\n * ```\n * @param data: A Tensor of at least one dimension with data that will be\n *     assembled in the output.\n * @param indices: A 1-D Tensor with indices into data. Has same rank as\n *     segmentIds.\n * @param segmentIds: A 1-D Tensor with indices into the output Tensor. Values\n *     should be sorted and can be repeated.\n * @return Has same shape as data, except for dimension 0 which has equal to\n *         the number of segments.\n *\n * @doc {heading: 'Operations', subheading: 'Sparse'}\n */\nfunction sparseSegmentSum_(\n    data: Tensor|TensorLike, indices: Tensor1D|TensorLike,\n    segmentIds: Tensor1D|TensorLike): Tensor {\n  const $data = convertToTensor(data, 'data', 'sparseSegmentSum');\n  const $indices =\n      convertToTensor(indices, 'indices', 'sparseSegmentSum', 'int32');\n  const $segmentIds =\n      convertToTensor(segmentIds, 'segmentIds', 'sparseSegmentSum', 'int32');\n\n  if ($data.rank < 1) {\n    throw new Error(\n        `Data should be at least 1 dimensional but received scalar`);\n  }\n  if ($indices.rank !== 1) {\n    throw new Error(`Indices should be Tensor1D but received shape\n         ${$indices.shape}`);\n  }\n  if ($segmentIds.rank !== 1) {\n    throw new Error(`Segment ids should be Tensor1D but received shape\n         ${$segmentIds.shape}`);\n  }\n\n  const inputs: SparseSegmentSumInputs = {\n    data: $data,\n    indices: $indices,\n    segmentIds: $segmentIds\n  };\n\n  return ENGINE.runKernel(SparseSegmentSum, inputs as {});\n}\n\nexport const sparseSegmentSum = op({sparseSegmentSum_});\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../../engine';\nimport {StringNGrams, StringNGramsAttrs, StringNGramsInputs} from '../../kernel_names';\nimport {Tensor, Tensor1D} from '../../tensor';\nimport {NamedTensorMap} from '../../tensor_types';\nimport {convertToTensor} from '../../tensor_util_env';\nimport {TensorLike} from '../../types';\nimport {op} from '../operation';\n\n/**\n * Creates ngrams from ragged string data.\n *\n * This op accepts a ragged tensor with 1 ragged dimension containing only\n * strings and outputs a ragged tensor with 1 ragged dimension containing ngrams\n * of that string, joined along the innermost axis.\n *\n * ```js\n * const result = tf.string.stringNGrams(\n *   ['a', 'b', 'c', 'd'], tf.tensor1d([0, 2, 4], 'int32'),\n *   '|', [1, 2], 'LP', 'RP', -1, false);\n * result['nGrams'].print(); // ['a', 'b', 'LP|a', 'a|b', 'b|RP',\n *                           //  'c', 'd', 'LP|c', 'c|d', 'd|RP']\n * result['nGramsSplits'].print(); // [0, 5, 10]\n * ```\n * @param data: The values tensor of the ragged string tensor to make ngrams out\n *     of. Must be a 1D string tensor.\n * @param dataSplits: The splits tensor of the ragged string tensor to make\n *     ngrams out of.\n * @param separator: The string to append between elements of the token. Use \"\"\n *     for no separator.\n * @param nGramWidths: The sizes of the ngrams to create.\n * @param leftPad: The string to use to pad the left side of the ngram sequence.\n *     Only used if pad_width !== 0.\n * @param rightPad: The string to use to pad the right side of the ngram\n *     sequence. Only used if pad_width !== 0.\n * @param padWidth: The number of padding elements to add to each side of each\n *     sequence. Note that padding will never be greater than `nGramWidths`-1\n *     regardless of this value. If `padWidth`=-1, then add max(`nGramWidths`)-1\n *     elements.\n * @param preserveShortSequences: If true, then ensure that at least one ngram\n *     is generated for each input sequence. In particular, if an input sequence\n *     is shorter than min(ngramWidth) + 2*padWidth, then generate a single\n *     ngram containing the entire sequence. If false, then no ngrams are\n *     generated for these short input sequences.\n * @return A map with the following properties:\n *     - nGrams: The values tensor of the output ngrams ragged tensor.\n *     - nGramsSplits: The splits tensor of the output ngrams ragged tensor.\n *\n * @doc {heading: 'Operations', subheading: 'String'}\n */\nfunction stringNGrams_(\n    data: Tensor1D|TensorLike, dataSplits: Tensor|TensorLike, separator: string,\n    nGramWidths: number[], leftPad: string, rightPad: string, padWidth: number,\n    preserveShortSequences: boolean): NamedTensorMap {\n  const $data = convertToTensor(data, 'data', 'stringNGrams', 'string');\n  if ($data.dtype !== 'string') {\n    throw new Error('Data must be of datatype string');\n  }\n  if ($data.shape.length !== 1) {\n    throw new Error(`Data must be a vector, saw: ${$data.shape}`);\n  }\n\n  const $dataSplits = convertToTensor(dataSplits, 'dataSplits', 'stringNGrams');\n  if ($dataSplits.dtype !== 'int32') {\n    throw new Error('Data splits must be of datatype int32');\n  }\n\n  const attrs: StringNGramsAttrs = {\n    separator,\n    nGramWidths,\n    leftPad,\n    rightPad,\n    padWidth,\n    preserveShortSequences\n  };\n\n  const inputs: StringNGramsInputs = {data: $data, dataSplits: $dataSplits};\n  const result: Tensor[] =\n      ENGINE.runKernel(StringNGrams, inputs as {}, attrs as {});\n  return {nGrams: result[0], nGramsSplits: result[1]};\n}\n\nexport const stringNGrams = op({stringNGrams_});\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../../engine';\nimport {StringSplit, StringSplitAttrs, StringSplitInputs} from '../../kernel_names';\nimport {Scalar, Tensor, Tensor1D} from '../../tensor';\nimport {NamedTensorMap} from '../../tensor_types';\nimport {convertToTensor} from '../../tensor_util_env';\nimport {ScalarLike, TensorLike} from '../../types';\nimport {op} from '../operation';\n\n/**\n * Split elements of `input` based on `delimiter` into a SparseTensor .\n *\n * Let N be the size of source (typically N will be the batch size). Split each\n * element of `input` based on `delimiter` and return a SparseTensor containing\n * the splitted tokens. Empty tokens are ignored if `skipEmpty` is set to True.\n *\n * `delimiter` can be empty, or a string of split characters. If `delimiter` is\n * an empty string, each element of `input` is split into individual\n * character strings. Otherwise every character of `delimiter` is a potential\n * split point.\n *\n * ```js\n * const result = tf.string.stringSplit(['hello world',  'a b c'], ' ');\n * result['indices'].print(); // [[0, 0], [0, 1], [1, 0], [1, 1], [1, 2]]\n * result['values'].print(); // ['hello', 'world', 'a', 'b', 'c']\n * result['shape'].print(); // [2, 3]\n * ```\n * @param input: 1-D. Strings to split.\n * @param delimiter: 0-D. Delimiter characters, or empty string.\n * @param skipEmpty: Optional. If true, skip the empty strings from the result.\n *     Defaults to true.\n * @return A map with the following properties:\n *     - indices: A dense matrix of int32 representing the indices of the sparse\n *       tensor.\n *     - values: A vector of strings corresponding to the splited values.\n *     - shape: a length-2 vector of int32 representing the shape of the sparse\n * tensor, where the first value is N and the second value is the maximum number\n * of tokens in a single input entry.\n *\n * @doc {heading: 'Operations', subheading: 'String'}\n */\nfunction stringSplit_(\n    input: Tensor1D|TensorLike, delimiter: Scalar|ScalarLike,\n    skipEmpty = true): NamedTensorMap {\n  const $input = convertToTensor(input, 'input', 'stringSplit', 'string');\n  const $delimiter =\n      convertToTensor(delimiter, 'delimiter', 'stringSplit', 'string');\n\n  if ($input.rank !== 1) {\n    throw new Error(\n        `Input should be Tensor1D but received shape ${$input.shape}`);\n  }\n  if ($delimiter.rank !== 0) {\n    throw new Error(\n        `Delimiter should be a scalar but received shape ${$delimiter.shape}`);\n  }\n\n  const attrs: StringSplitAttrs = {skipEmpty};\n  const inputs: StringSplitInputs = {input: $input, delimiter: $delimiter};\n  const result: Tensor[] =\n      ENGINE.runKernel(StringSplit, inputs as {}, attrs as {});\n  return {indices: result[0], values: result[1], shape: result[2]};\n}\n\nexport const stringSplit = op({stringSplit_});\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../../engine';\nimport {StringToHashBucketFast, StringToHashBucketFastAttrs, StringToHashBucketFastInputs} from '../../kernel_names';\nimport {Tensor} from '../../tensor';\nimport {convertToTensor} from '../../tensor_util_env';\nimport {TensorLike} from '../../types';\nimport {op} from '../operation';\n\n/**\n * Converts each string in the input Tensor to its hash mod by a number of\n * buckets.\n *\n * The hash function is deterministic on the content of the string within the\n * process and will never change. However, it is not suitable for cryptography.\n * This function may be used when CPU time is scarce and inputs are trusted or\n * unimportant. There is a risk of adversaries constructing inputs that all hash\n * to the same bucket.\n *\n * ```js\n * const result = tf.string.stringToHashBucketFast(\n *   ['Hello', 'TensorFlow', '2.x'], 3);\n * result.print(); // [0, 2, 2]\n * ```\n * @param input: The strings to assign a hash bucket.\n * @param numBuckets: The number of buckets.\n * @return A Tensor of the same shape as the input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'String'}\n */\nfunction stringToHashBucketFast_(\n    input: Tensor|TensorLike, numBuckets: number): Tensor {\n  const $input =\n      convertToTensor(input, 'input', 'stringToHashBucketFast', 'string');\n  const attrs: StringToHashBucketFastAttrs = {numBuckets};\n\n  if (numBuckets <= 0) {\n    throw new Error(`Number of buckets must be at least 1`);\n  }\n\n  const inputs: StringToHashBucketFastInputs = {input: $input};\n  return ENGINE.runKernel(StringToHashBucketFast, inputs as {}, attrs as {});\n}\n\nexport const stringToHashBucketFast = op({stringToHashBucketFast_});\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n// Modularized ops.\nexport {abs} from './abs';\nexport {acos} from './acos';\nexport {acosh} from './acosh';\nexport {add} from './add';\nexport {addN} from './add_n';\nexport {all} from './all';\nexport {any} from './any';\nexport {argMax} from './arg_max';\nexport {argMin} from './arg_min';\nexport {asin} from './asin';\nexport {asinh} from './asinh';\nexport {atan} from './atan';\nexport {atan2} from './atan2';\nexport {atanh} from './atanh';\nexport {avgPool} from './avg_pool';\nexport {avgPool3d} from './avg_pool_3d';\nexport {basicLSTMCell} from './basic_lstm_cell';\nexport {batchToSpaceND} from './batch_to_space_nd';\nexport {batchNorm} from './batchnorm';\nexport {batchNorm2d} from './batchnorm2d';\nexport {batchNorm3d} from './batchnorm3d';\nexport {batchNorm4d} from './batchnorm4d';\nexport {bincount} from './bincount';\nexport {broadcastArgs} from './broadcast_args';\nexport {broadcastTo} from './broadcast_to';\nexport {buffer} from './buffer';\nexport {cast} from './cast';\nexport {ceil} from './ceil';\nexport {clipByValue} from './clip_by_value';\nexport {clone} from './clone';\nexport {complex} from './complex';\nexport {concat} from './concat';\nexport {concat1d} from './concat_1d';\nexport {concat2d} from './concat_2d';\nexport {concat3d} from './concat_3d';\nexport {concat4d} from './concat_4d';\nexport {conv1d} from './conv1d';\nexport {conv2d} from './conv2d';\nexport {conv2dTranspose} from './conv2d_transpose';\nexport {conv3d} from './conv3d';\nexport {conv3dTranspose} from './conv3d_transpose';\nexport {cos} from './cos';\nexport {cosh} from './cosh';\nexport {cumprod} from './cumprod';\nexport {cumsum} from './cumsum';\nexport {denseBincount} from './dense_bincount';\nexport {depthToSpace} from './depth_to_space';\nexport {depthwiseConv2d} from './depthwise_conv2d';\nexport {diag} from './diag';\nexport {dilation2d} from './dilation2d';\nexport {div} from './div';\nexport {divNoNan} from './div_no_nan';\nexport {dot} from './dot';\nexport {einsum} from './einsum';\nexport {elu} from './elu';\nexport {equal} from './equal';\nexport {erf} from './erf';\nexport {euclideanNorm} from './euclidean_norm';\nexport {exp} from './exp';\nexport {expandDims} from './expand_dims';\nexport {expm1} from './expm1';\nexport {eye} from './eye';\nexport {fill} from './fill';\nexport {floor} from './floor';\nexport {floorDiv} from './floorDiv';\nexport {gather} from './gather';\nexport {greater} from './greater';\nexport {greaterEqual} from './greater_equal';\nexport {imag} from './imag';\nexport {isFinite} from './is_finite';\nexport {isInf} from './is_inf';\nexport {isNaN} from './is_nan';\nexport {leakyRelu} from './leaky_relu';\nexport {less} from './less';\nexport {lessEqual} from './less_equal';\nexport {linspace} from './linspace';\nexport {localResponseNormalization} from './local_response_normalization';\nexport {log} from './log';\nexport {log1p} from './log1p';\nexport {logSigmoid} from './log_sigmoid';\nexport {logSoftmax} from './log_softmax';\nexport {logSumExp} from './log_sum_exp';\nexport {logicalAnd} from './logical_and';\nexport {logicalNot} from './logical_not';\nexport {logicalOr} from './logical_or';\nexport {logicalXor} from './logical_xor';\nexport {lowerBound} from './lower_bound';\nexport {matMul} from './mat_mul';\nexport {max} from './max';\nexport {maxPool} from './max_pool';\nexport {maxPool3d} from './max_pool_3d';\nexport {maxPoolWithArgmax} from './max_pool_with_argmax';\nexport {maximum} from './maximum';\nexport {mean} from './mean';\nexport {meshgrid} from './meshgrid';\nexport {min} from './min';\nexport {minimum} from './minimum';\nexport {mirrorPad} from './mirror_pad';\nexport {mod} from './mod';\nexport {moments} from './moments';\nexport {mul} from './mul';\nexport {LSTMCellFunc, multiRNNCell} from './multi_rnn_cell';\nexport {multinomial} from './multinomial';\nexport {neg} from './neg';\nexport {notEqual} from './not_equal';\nexport {oneHot} from './one_hot';\nexport {ones} from './ones';\nexport {onesLike} from './ones_like';\nexport {outerProduct} from './outer_product';\nexport {pad} from './pad';\nexport {pad1d} from './pad1d';\nexport {pad2d} from './pad2d';\nexport {pad3d} from './pad3d';\nexport {pad4d} from './pad4d';\nexport {pool} from './pool';\nexport {pow} from './pow';\nexport {prelu} from './prelu';\nexport {print} from './print';\nexport {prod} from './prod';\nexport {raggedGather} from './ragged_gather';\nexport {raggedTensorToTensor} from './ragged_tensor_to_tensor';\nexport {rand} from './rand';\nexport {randomGamma} from './random_gamma';\nexport {randomNormal} from './random_normal';\nexport {randomStandardNormal} from './random_standard_normal';\nexport {randomUniform} from './random_uniform';\nexport {range} from './range';\nexport {real} from './real';\nexport {reciprocal} from './reciprocal';\nexport {relu} from './relu';\nexport {relu6} from './relu6';\nexport {reshape} from './reshape';\nexport {reverse} from './reverse';\nexport {reverse1d} from './reverse_1d';\nexport {reverse2d} from './reverse_2d';\nexport {reverse3d} from './reverse_3d';\nexport {reverse4d} from './reverse_4d';\nexport {round} from './round';\nexport {rsqrt} from './rsqrt';\nexport {scalar} from './scalar';\nexport {selu} from './selu';\nexport {separableConv2d} from './separable_conv2d';\nexport {setdiff1dAsync} from './setdiff1d_async';\nexport {sigmoid} from './sigmoid';\nexport {sign} from './sign';\nexport {sin} from './sin';\nexport {sinh} from './sinh';\nexport {slice} from './slice';\nexport {slice1d} from './slice1d';\nexport {slice2d} from './slice2d';\nexport {slice3d} from './slice3d';\nexport {slice4d} from './slice4d';\nexport {softmax} from './softmax';\nexport {softplus} from './softplus';\nexport {spaceToBatchND} from './space_to_batch_nd';\nexport {fft} from './spectral/fft';\nexport {ifft} from './spectral/ifft';\nexport {irfft} from './spectral/irfft';\nexport {rfft} from './spectral/rfft';\nexport {split} from './split';\nexport {sqrt} from './sqrt';\nexport {square} from './square';\nexport {squaredDifference} from './squared_difference';\nexport {squeeze} from './squeeze';\nexport {stack} from './stack';\nexport {step} from './step';\nexport {stridedSlice} from './strided_slice';\nexport {sub} from './sub';\nexport {sum} from './sum';\nexport {tan} from './tan';\nexport {tanh} from './tanh';\nexport {tensor} from './tensor';\nexport {tensor1d} from './tensor1d';\nexport {tensor2d} from './tensor2d';\nexport {tensor3d} from './tensor3d';\nexport {tensor4d} from './tensor4d';\nexport {tensor5d} from './tensor5d';\nexport {tensor6d} from './tensor6d';\nexport {tile} from './tile';\nexport {topk} from './topk';\nexport {truncatedNormal} from './truncated_normal';\nexport {unique} from './unique';\nexport {unsortedSegmentSum} from './unsorted_segment_sum';\nexport {unstack} from './unstack';\nexport {upperBound} from './upper_bound';\nexport {variable} from './variable';\nexport {where} from './where';\nexport {whereAsync} from './where_async';\nexport {zeros} from './zeros';\nexport {zerosLike} from './zeros_like';\n\nexport * from './boolean_mask';\nexport * from './transpose';\nexport * from './norm';\nexport * from './moving_average';\nexport * from './scatter_nd';\nexport * from './search_sorted';\nexport * from './sparse_to_dense';\nexport * from './gather_nd';\nexport * from './dropout';\nexport * from './signal_ops_util';\nexport * from './in_top_k';\n\nexport {op, OP_SCOPE_SUFFIX} from './operation';\n\nimport {rfft} from './spectral/rfft';\nimport {fft} from './spectral/fft';\nimport {ifft} from './spectral/ifft';\nimport {irfft} from './spectral/irfft';\nconst spectral = {\n  fft,\n  ifft,\n  rfft,\n  irfft\n};\n\nimport * as fused from './fused_ops';\n\nimport {hammingWindow} from './signal/hamming_window';\nimport {hannWindow} from './signal/hann_window';\nimport {frame} from './signal/frame';\nimport {stft} from './signal/stft';\nconst signal = {\n  hammingWindow,\n  hannWindow,\n  frame,\n  stft,\n};\n\n// Image Ops namespace\nimport {cropAndResize} from './image/crop_and_resize';\nimport {flipLeftRight} from './image/flip_left_right';\nimport {grayscaleToRGB} from './image/grayscale_to_rgb';\nimport {rotateWithOffset} from './image/rotate_with_offset';\nimport {nonMaxSuppression} from './image/non_max_suppression';\nimport {nonMaxSuppressionAsync} from './image/non_max_suppression_async';\nimport {nonMaxSuppressionWithScore} from './image/non_max_suppression_with_score';\nimport {nonMaxSuppressionWithScoreAsync} from './image/non_max_suppression_with_score_async';\nimport {nonMaxSuppressionPadded} from './image/non_max_suppression_padded';\nimport {nonMaxSuppressionPaddedAsync} from './image/non_max_suppression_padded_async';\nimport {resizeBilinear} from './image/resize_bilinear';\nimport {resizeNearestNeighbor} from './image/resize_nearest_neighbor';\nimport {threshold} from './image/threshold';\nimport {transform} from './image/transform';\nconst image = {\n  flipLeftRight,\n  grayscaleToRGB,\n  resizeNearestNeighbor,\n  resizeBilinear,\n  rotateWithOffset,\n  cropAndResize,\n  nonMaxSuppression,\n  nonMaxSuppressionAsync,\n  nonMaxSuppressionWithScore,\n  nonMaxSuppressionWithScoreAsync,\n  nonMaxSuppressionPadded,\n  nonMaxSuppressionPaddedAsync,\n  threshold,\n  transform\n};\n\n// linalg namespace\nimport {bandPart} from './linalg/band_part';\nimport {gramSchmidt} from './linalg/gram_schmidt';\nimport {qr} from './linalg/qr';\nconst linalg = {\n  bandPart,\n  gramSchmidt,\n  qr\n};\n\n// losses namespace;\nimport {absoluteDifference} from './losses/absolute_difference';\nimport {computeWeightedLoss} from './losses/compute_weighted_loss';\nimport {cosineDistance} from './losses/cosine_distance';\nimport {hingeLoss} from './losses/hinge_loss';\nimport {huberLoss} from './losses/huber_loss';\nimport {logLoss} from './losses/log_loss';\nimport {meanSquaredError} from './losses/mean_squared_error';\nimport {sigmoidCrossEntropy} from './losses/sigmoid_cross_entropy';\nimport {softmaxCrossEntropy} from './losses/softmax_cross_entropy';\nconst losses = {\n  absoluteDifference,\n  computeWeightedLoss,\n  cosineDistance,\n  hingeLoss,\n  huberLoss,\n  logLoss,\n  meanSquaredError,\n  sigmoidCrossEntropy,\n  softmaxCrossEntropy\n};\n\nimport {sparseFillEmptyRows} from './sparse/sparse_fill_empty_rows';\nimport {sparseReshape} from './sparse/sparse_reshape';\nimport {sparseSegmentMean} from './sparse/sparse_segment_mean';\nimport {sparseSegmentSum} from './sparse/sparse_segment_sum';\nconst sparse = {\n  sparseFillEmptyRows,\n  sparseReshape,\n  sparseSegmentMean,\n  sparseSegmentSum\n};\n\nimport {stringNGrams} from './string/string_n_grams';\nimport {stringSplit} from './string/string_split';\nimport {stringToHashBucketFast} from './string/string_to_hash_bucket_fast';\n// tslint:disable-next-line:variable-name\nconst string = {\n  stringNGrams,\n  stringSplit,\n  stringToHashBucketFast\n};\n\n// Second level exports.\nexport {image, linalg, losses, spectral, fused, signal, sparse, string};\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n// So typings can propagate.\nimport {AdadeltaOptimizer} from './optimizers/adadelta_optimizer';\nimport {AdagradOptimizer} from './optimizers/adagrad_optimizer';\nimport {AdamOptimizer} from './optimizers/adam_optimizer';\nimport {AdamaxOptimizer} from './optimizers/adamax_optimizer';\nimport {MomentumOptimizer} from './optimizers/momentum_optimizer';\nimport {OptimizerConstructors} from './optimizers/optimizer_constructors';\nimport {RMSPropOptimizer} from './optimizers/rmsprop_optimizer';\nimport {SGDOptimizer} from './optimizers/sgd_optimizer';\n\n// tslint:disable-next-line:no-unused-expression\n[MomentumOptimizer, SGDOptimizer, AdadeltaOptimizer, AdagradOptimizer,\n RMSPropOptimizer, AdamaxOptimizer, AdamOptimizer];\n\nexport const train = {\n  sgd: OptimizerConstructors.sgd,\n  momentum: OptimizerConstructors.momentum,\n  adadelta: OptimizerConstructors.adadelta,\n  adagrad: OptimizerConstructors.adagrad,\n  rmsprop: OptimizerConstructors.rmsprop,\n  adamax: OptimizerConstructors.adamax,\n  adam: OptimizerConstructors.adam\n};\n","/**\n * @license\n * Copyright 2017 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nconst delayCallback: Function = (() => {\n  if (typeof requestAnimationFrame !== 'undefined') {\n    return requestAnimationFrame;\n  } else if (typeof setImmediate !== 'undefined') {\n    return setImmediate;\n  }\n  return (f: Function) => f();  // no delays\n})();\n\n/**\n * Returns a promise that resolves when a requestAnimationFrame has completed.\n *\n * On Node.js this uses setImmediate instead of requestAnimationFrame.\n *\n * This is simply a sugar method so that users can do the following:\n * `await tf.nextFrame();`\n *\n * @doc {heading: 'Performance', subheading: 'Timing'}\n */\nfunction nextFrame(): Promise<void> {\n  return new Promise<void>(resolve => delayCallback(() => resolve()));\n}\n\nexport {nextFrame};\n","/**\n * @license\n * Copyright 2017 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as util from '../util';\n\nexport function assertParamsConsistent(shapes: number[][], axis: number) {\n  const rank = shapes[0].length;\n  shapes.forEach((shape, i) => {\n    util.assert(\n        shape.length === rank,\n        () =>\n            `Error in concat${rank}D: rank of tensors[${i}] must be the same ` +\n            `as the rank of the rest (${rank})`);\n  });\n\n  util.assert(\n      axis >= 0 && axis < rank,\n      () => `Error in concat${rank}D: axis must be between 0 and ${rank - 1}.`);\n\n  const firstShape = shapes[0];\n  shapes.forEach((shape, i) => {\n    for (let r = 0; r < rank; r++) {\n      util.assert(\n          (r === axis) || (shape[r] === firstShape[r]),\n          () => `Error in concat${rank}D: Shape of tensors[${i}] (${shape}) ` +\n              `does not match the shape of the rest (${firstShape}) ` +\n              `along the non-concatenated axis ${i}.`);\n    }\n  });\n}\n\nexport function computeOutShape(shapes: number[][], axis: number): number[] {\n  const outputShape = shapes[0].slice();\n  for (let i = 1; i < shapes.length; i++) {\n    outputShape[axis] += shapes[i][axis];\n  }\n  return outputShape;\n}\n","/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nexport enum RowPartitionType {\n  FIRST_DIM_SIZE,\n  VALUE_ROWIDS,\n  ROW_LENGTHS,\n  ROW_SPLITS,\n  ROW_LIMITS,\n  ROW_STARTS\n}\n\nexport function combineRaggedTensorToTensorShapes(\n    raggedRank: number, shape: number[], valueShape: number[]) {\n  // Test for consistency of valueShape and shape specified.\n  // If shape is unspecified and valueShape is specified, then copy\n  // over the size from the valueShape dimension.\n\n  let outputShape: number[] = new Array();\n  if (valueShape == null && shape == null) {\n    return outputShape;\n  }\n\n  if (shape == null) {\n    // Here, value_shape must be of known size.\n    while (outputShape.length < raggedRank + valueShape.length) {\n      outputShape.push(-1);\n    }\n  } else {\n    outputShape = shape.slice();\n  }\n  if (valueShape == null) {\n    return outputShape;\n  }\n  // At this point, valueShape and output_shape have known ranks.\n  if (raggedRank + valueShape.length !== outputShape.length) {\n    throw new Error(\n        `rt input.shape and shape=${shape} are incompatible: rt input.rank = ${\n            raggedRank +\n            valueShape.length}, but shape.rank = ${outputShape.length}`);\n  }\n\n  for (let i = 1; i < valueShape.length; ++i) {\n    const valueDim = valueShape[i];\n    const outputShapeDimIndex =\n        outputShape[outputShape.length - valueShape.length + i];\n    const outputShapeDim = outputShape[outputShapeDimIndex];\n\n    if (valueDim >= 0) {\n      if (outputShapeDim >= 0) {\n        if (outputShapeDim !== valueDim) {\n          throw new Error(`rt input.shape and shape=${\n              shape} are incompatible: rt input.shape[${i + raggedRank}] = ${\n              valueDim} but shape[${i + raggedRank}] = ${outputShapeDim}`);\n        }\n      } else {\n        outputShape[outputShapeDimIndex] = valueDim;\n      }\n    }\n  }\n  return outputShape;\n}\n\nexport function getRowPartitionTypesHelper(rowPartitionTypeStrings: string[]) {\n  const stringToType = {\n    'FIRST_DIM_SIZE': RowPartitionType.FIRST_DIM_SIZE,\n    'VALUE_ROWIDS': RowPartitionType.VALUE_ROWIDS,\n    'ROW_LENGTHS': RowPartitionType.ROW_LENGTHS,\n    'ROW_SPLITS': RowPartitionType.ROW_SPLITS,\n    'ROW_LIMITS': RowPartitionType.ROW_LIMITS,\n    'ROW_STARTS': RowPartitionType.ROW_STARTS\n  };\n\n  const result: RowPartitionType[] = [];\n  for (const typeStr of rowPartitionTypeStrings) {\n    if (typeStr in stringToType) {\n      result.push(stringToType[typeStr as keyof typeof stringToType]);\n    } else {\n      break;\n    }\n  }\n\n  return result;\n}\n\nexport function getRaggedRank(rowPartitionTypes: RowPartitionType[]) {\n  if (rowPartitionTypes.length === 0) {\n    return 0;\n  }\n  if (rowPartitionTypes[0] === RowPartitionType.FIRST_DIM_SIZE) {\n    return rowPartitionTypes.length - 1;\n  }\n  return rowPartitionTypes.length;\n}\n\nexport function validateDefaultValueShape(\n    defaultValueShape: number[], valueShape: number[]) {\n  if (defaultValueShape == null || valueShape == null) {\n    return;\n  }\n\n  const defaultNDims = defaultValueShape.length;\n  const valuesNDims = valueShape.length;\n  if (defaultNDims >= valuesNDims) {\n    throw new Error(`defaultValue.shape=${\n        defaultValueShape} and ragged tensor flatValues.shape=${\n        valueShape}, are incompatible: defaultValue.rank = ${\n        defaultNDims} must be less than ragged tensor input flatValues.rank = ${\n        valuesNDims})`);\n  }\n  for (let i = 0; i < Math.min(defaultNDims, valuesNDims - 1); ++i) {\n    const defaultDim = defaultValueShape[i];\n    const valueDim = valueShape[i + 1];\n    if (defaultDim >= 0 && valueDim >= 0 && defaultDim !== 1 &&\n        defaultDim !== valueDim) {\n      throw new Error(`defaultValue.shape=${\n          defaultValueShape}, and ragged tensor input flatValues.shape=${\n          valueShape} are incompatible: defaultValue.shape[${\n          i - defaultValueShape.length}] = ${\n          defaultDim} but ragged tensor input.flatValues.shape[${\n          i - defaultValueShape.length}] = ${valueDim}`);\n    }\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n/**\n * Inputs of size above this threshold will be parallelized by calling multiple\n * shader programs.\n */\nimport {nearestDivisor} from '../util';\n\nexport const PARALLELIZE_THRESHOLD = 30;\n\nexport interface ReduceInfo {\n  windowSize: number;\n  batchSize: number;\n  inSize: number;\n  outSize: number;\n}\n\nexport function computeOptimalWindowSize(inSize: number): number {\n  if (inSize <= PARALLELIZE_THRESHOLD) {\n    return inSize;\n  }\n  return nearestDivisor(inSize, Math.floor(Math.sqrt(inSize)));\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n// Returns the image center in pixels.\nexport function getImageCenter(\n    center: number|[number, number], imageHeight: number,\n    imageWidth: number): [number, number] {\n  const centerX =\n      imageWidth * (typeof center === 'number' ? center : center[0]);\n  const centerY =\n      imageHeight * (typeof center === 'number' ? center : center[1]);\n  return [centerX, centerY];\n}\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n/**\n * Gets the new shape of the input Tensor after it's been reshaped\n * to:\n * [blockShape[0], ..., blockShape[M-1], batch / prod(blockShape),\n * inputShape[1], ..., inputShape[N-1]]\n *\n * See step 1: https://www.tensorflow.org/api_docs/python/tf/batch_to_space_nd\n */\nexport function getReshaped(\n    inputShape: number[], blockShape: number[], prod: number,\n    batchToSpace = true): number[] {\n  let reshaped: number[] = [];\n  if (batchToSpace) {\n    reshaped = reshaped.concat(blockShape.slice(0));\n    reshaped.push(inputShape[0] / prod);\n    reshaped = reshaped.concat(inputShape.slice(1));\n  } else {\n    reshaped = reshaped.concat(inputShape[0]);\n    const spatialLength = blockShape.length;\n    for (let i = 0; i < spatialLength; ++i) {\n      reshaped =\n          reshaped.concat([inputShape[i + 1] / blockShape[i], blockShape[i]]);\n    }\n    reshaped = reshaped.concat(inputShape.slice(spatialLength + 1));\n  }\n  return reshaped;\n}\n\n/**\n * Gets the permutation that will transpose the dimensions of the\n * reshaped tensor to shape:\n *\n * [batch / prod(block_shape),inputShape[1], blockShape[0], ...,\n * inputShape[M], blockShape[M-1],inputShape[M+1], ..., inputShape[N-1]]\n *\n * see step 2: https://www.tensorflow.org/api_docs/python/tf/batch_to_space_nd\n */\nexport function getPermuted(\n    reshapedRank: number, blockShapeRank: number,\n    batchToSpace = true): number[] {\n  const permuted = [];\n  if (batchToSpace) {\n    permuted.push(blockShapeRank);\n    for (let i = blockShapeRank + 1; i < reshapedRank; ++i) {\n      if (i <= 2 * blockShapeRank) {\n        permuted.push(i);\n        permuted.push(i - (blockShapeRank + 1));\n      } else {\n        permuted.push(i);\n      }\n    }\n  } else {\n    const permutedBeforeBatch = [];\n    const permutedAfterBatch = [];\n    for (let i = 1; i < reshapedRank; ++i) {\n      if (i >= blockShapeRank * 2 + 1 || i % 2 === 1) {\n        permutedAfterBatch.push(i);\n      } else {\n        permutedBeforeBatch.push(i);\n      }\n    }\n    permuted.push(...permutedBeforeBatch);\n    permuted.push(0);\n    permuted.push(...permutedAfterBatch);\n  }\n  return permuted;\n}\n\n/**\n * Gets the shape of the reshaped and permuted input Tensor before any cropping\n * is applied.  The new shape will be:\n *\n * [batch / prod(blockShape),inputShape[1] * blockShape[0], ...,\n * inputShape[M] * blockShape[M-1],inputShape[M+1], ..., inputShape[N-1]]\n *\n * See step 3: https://www.tensorflow.org/api_docs/python/tf/batch_to_space_nd\n */\nexport function getReshapedPermuted(\n    inputShape: number[], blockShape: number[], prod: number,\n    batchToSpace = true): number[] {\n  const reshapedPermuted = [];\n\n  if (batchToSpace) {\n    reshapedPermuted.push(inputShape[0] / prod);\n  } else {\n    reshapedPermuted.push(inputShape[0] * prod);\n  }\n\n  for (let i = 1; i < inputShape.length; ++i) {\n    if (i <= blockShape.length) {\n      if (batchToSpace) {\n        reshapedPermuted.push(blockShape[i - 1] * inputShape[i]);\n      } else {\n        reshapedPermuted.push(inputShape[i] / blockShape[i - 1]);\n      }\n    } else {\n      reshapedPermuted.push(inputShape[i]);\n    }\n  }\n\n  return reshapedPermuted;\n}\n\n/**\n * Converts the crops argument into the beginning coordinates of a slice\n * operation.\n */\nexport function getSliceBeginCoords(\n    crops: number[][], blockShape: number): number[] {\n  const sliceBeginCoords = [0];\n  for (let i = 0; i < blockShape; ++i) {\n    sliceBeginCoords.push(crops[i][0]);\n  }\n  return sliceBeginCoords;\n}\n\n/**\n * Converts the crops argument into the size of a slice operation.  When\n * combined with getSliceBeginCoords this function allows the reshaped and\n * permuted Tensor to be cropped to its final output shape of:\n *\n * inputShape[1] * blockShape[0] - crops[0,0] - crops[0,1], ...,\n * inputShape[M] * blockShape[M-1] -crops[M-1,0] -\n * crops[M-1,1],inputShape[M+1], ..., inputShape[N-1]]\n *\n * See step 4: https://www.tensorflow.org/api_docs/python/tf/batch_to_space_nd\n */\nexport function getSliceSize(\n    uncroppedShape: number[], crops: number[][], blockShape: number): number[] {\n  const sliceSize = uncroppedShape.slice(0, 1);\n  for (let i = 0; i < blockShape; ++i) {\n    sliceSize.push(uncroppedShape[i + 1] - crops[i][0] - crops[i][1]);\n  }\n\n  return sliceSize;\n}\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nexport const SELU_SCALEALPHA = 1.7580993408473768599402175208123;\nexport const SELU_SCALE = 1.0507009873554804934193349852946;\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nexport const ERF_P = 0.3275911;\nexport const ERF_A1 = 0.254829592;\nexport const ERF_A2 = -0.284496736;\nexport const ERF_A3 = 1.421413741;\nexport const ERF_A4 = -1.453152027;\nexport const ERF_A5 = 1.061405429;\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {TypedArray} from '../types';\n/**\n * Merges real and imaginary Float32Arrays into a single complex Float32Array.\n *\n * The memory layout is interleaved as follows:\n * real: [r0, r1, r2]\n * imag: [i0, i1, i2]\n * complex: [r0, i0, r1, i1, r2, i2]\n *\n * This is the inverse of splitRealAndImagArrays.\n *\n * @param real The real values of the complex tensor values.\n * @param imag The imag values of the complex tensor values.\n * @returns A complex tensor as a Float32Array with merged values.\n */\nexport function mergeRealAndImagArrays(\n    real: Float32Array, imag: Float32Array): Float32Array {\n  if (real.length !== imag.length) {\n    throw new Error(\n        `Cannot merge real and imag arrays of different lengths. real:` +\n        `${real.length}, imag: ${imag.length}.`);\n  }\n  const result = new Float32Array(real.length * 2);\n  for (let i = 0; i < result.length; i += 2) {\n    result[i] = real[i / 2];\n    result[i + 1] = imag[i / 2];\n  }\n  return result;\n}\n\n/**\n * Splits a complex Float32Array into real and imag parts.\n *\n * The memory layout is interleaved as follows:\n * complex: [r0, i0, r1, i1, r2, i2]\n * real: [r0, r1, r2]\n * imag: [i0, i1, i2]\n *\n * This is the inverse of mergeRealAndImagArrays.\n *\n * @param complex The complex tensor values.\n * @returns An object with real and imag Float32Array components of the complex\n *     tensor.\n */\nexport function splitRealAndImagArrays(complex: Float32Array):\n    {real: Float32Array, imag: Float32Array} {\n  const real = new Float32Array(complex.length / 2);\n  const imag = new Float32Array(complex.length / 2);\n  for (let i = 0; i < complex.length; i += 2) {\n    real[i / 2] = complex[i];\n    imag[i / 2] = complex[i + 1];\n  }\n  return {real, imag};\n}\n\n/**\n * Extracts even indexed complex values in the given array.\n * @param complex The complex tensor values\n */\nexport function complexWithEvenIndex(complex: Float32Array):\n    {real: Float32Array, imag: Float32Array} {\n  const len = Math.ceil(complex.length / 4);\n  const real = new Float32Array(len);\n  const imag = new Float32Array(len);\n  for (let i = 0; i < complex.length; i += 4) {\n    real[Math.floor(i / 4)] = complex[i];\n    imag[Math.floor(i / 4)] = complex[i + 1];\n  }\n  return {real, imag};\n}\n\n/**\n * Extracts odd indexed comple values in the given array.\n * @param complex The complex tensor values\n */\nexport function complexWithOddIndex(complex: Float32Array):\n    {real: Float32Array, imag: Float32Array} {\n  const len = Math.floor(complex.length / 4);\n  const real = new Float32Array(len);\n  const imag = new Float32Array(len);\n  for (let i = 2; i < complex.length; i += 4) {\n    real[Math.floor(i / 4)] = complex[i];\n    imag[Math.floor(i / 4)] = complex[i + 1];\n  }\n  return {real, imag};\n}\n\n/**\n * Get the map representing a complex value in the given array.\n * @param complex The complex tensor values.\n * @param index An index of the target complex value.\n */\nexport function getComplexWithIndex(\n    complex: Float32Array, index: number): {real: number, imag: number} {\n  const real = complex[index * 2];\n  const imag = complex[index * 2 + 1];\n  return {real, imag};\n}\n\n/**\n * Insert a given complex value into the TypedArray.\n * @param data The array in which the complex value is inserted.\n * @param c The complex value to be inserted.\n * @param index An index of the target complex value.\n */\nexport function assignToTypedArray(\n    data: TypedArray, real: number, imag: number, index: number) {\n  data[index * 2] = real;\n  data[index * 2 + 1] = imag;\n}\n\n/**\n * Make the list of exponent terms used by FFT.\n */\nexport function exponents(\n    n: number, inverse: boolean): {real: Float32Array, imag: Float32Array} {\n  const real = new Float32Array(n / 2);\n  const imag = new Float32Array(n / 2);\n  for (let i = 0; i < Math.ceil(n / 2); i++) {\n    const x = (inverse ? 2 : -2) * Math.PI * (i / n);\n    real[i] = Math.cos(x);\n    imag[i] = Math.sin(x);\n  }\n  return {real, imag};\n}\n\n/**\n * Make the exponent term used by FFT.\n */\nexport function exponent(\n    k: number, n: number, inverse: boolean): {real: number, imag: number} {\n  const x = (inverse ? 2 : -2) * Math.PI * (k / n);\n  const real = Math.cos(x);\n  const imag = Math.sin(x);\n  return {real, imag};\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n/**\n * Utility functions for computing einsum (tensor contraction and summation\n * based on Einstein summation.)\n */\n\nimport {Tensor} from '../tensor';\nimport {assert} from '../util_base';\n\nconst ARROW = '->';\nconst ARROW_REGEX = /->/g;\nconst COMMA = ',';\nconst ELLIPSIS = '...';\n\n/**\n * Parse an equation for einsum.\n *\n * @param equation The einsum equation (e.g., \"ij,jk->ik\").\n * @param numTensors Number of tensors provided along with `equation`. Used to\n *   check matching number of input tensors.\n * @returns An object consisting of the following fields:\n *   - allDims: all dimension names as strings.\n *   - summedDims: a list of all dimensions being summed over, as indices to\n *     the elements of `allDims`.\n *   - idDims: indices of the dimensions in each input tensor, as indices to\n *     the elements of `allDims.\n */\nexport function decodeEinsumEquation(equation: string, numTensors: number): {\n  allDims: string[],\n  summedDims: number[],\n  idDims: number[][],\n} {\n  equation = equation.replace(/\\s/g, '');  // Remove witespace in equation.\n  const numArrows =\n      (equation.length - equation.replace(ARROW_REGEX, '').length) /\n      ARROW.length;\n  if (numArrows < 1) {\n    throw new Error('Equations without an arrow are not supported.');\n  } else if (numArrows > 1) {\n    throw new Error(`Equation must contain exactly one arrow (\"${ARROW}\").`);\n  }\n  const [inputString, outputString] = equation.split(ARROW);\n  assert(\n      inputString.indexOf(ELLIPSIS) === -1,\n      () => `The ellipsis notation (\"${ELLIPSIS}\") is not supported yet.`);\n  const inputTerms = inputString.split(COMMA);\n  const numInputs = inputTerms.length;\n  if (numTensors !== numInputs) {\n    throw new Error(\n        `Expected ${numInputs} input tensors, received ${numTensors}`);\n  }\n  if (numInputs > 2) {\n    throw new Error(\n        'Support for more than 2 input tensors is not implemented yet.');\n  }\n\n  const allDims: string[] = [];\n  for (let i = 0; i < outputString.length; ++i) {\n    const dimName = outputString[i];\n    if (!inputTerms.some(inputTerm => inputTerm.indexOf(dimName) !== -1)) {\n      throw new Error(\n          `Output subscripts contain the label ${dimName} ` +\n          `not present in the input subscripts.`);\n    }\n    if (allDims.indexOf(dimName) === -1) {\n      allDims.push(dimName);\n    }\n  }\n  for (let i = 0; i < inputString.length; ++i) {\n    const dimName = inputString[i];\n    if (allDims.indexOf(dimName) === -1 && dimName !== COMMA) {\n      allDims.push(dimName);\n    }\n  }\n\n  const idDims: number[][] = new Array<number[]>(inputTerms.length);\n  for (let i = 0; i < numInputs; ++i) {\n    if (new Set(inputTerms[i].split('')).size !== inputTerms[i].length) {\n      throw new Error(\n          `Found duplicate axes in input component ${inputTerms[i]}. ` +\n          `Support for duplicate axes in input is not implemented yet.`);\n    }\n    idDims[i] = [];\n    for (let j = 0; j < inputTerms[i].length; ++j) {\n      idDims[i].push(allDims.indexOf(inputTerms[i][j]));\n    }\n  }\n\n  const numDims = allDims.length;          // Number of unique dimensions.\n  const numOutDims = outputString.length;  // Number of output dimensions.\n  const summedDims: number[] = [];         // Dimensions being summed over.\n  for (let i = numOutDims; i < numDims; ++i) {\n    summedDims.push(i);\n  }\n  return {allDims, summedDims, idDims};\n}\n\n/**\n * Get the permutation for a given input tensor.\n *\n * @param nDims Total number of dimension of all tensors involved in the einsum\n *   operation.\n * @param idDims Dimension indices involve in the tensor in question.\n * @returns An object consisting of the following fields:\n *   - permutationIndices: Indices to permute the axes of the tensor with.\n *   - expandDims: Indices to the dimension that need to be expanded from the\n *     tensor after permutation.\n */\nexport function getEinsumPermutation(nDims: number, idDims: number[]):\n    {permutationIndices: number[], expandDims: number[]} {\n  let permutationIndices: number[] = new Array<number>(nDims);\n  permutationIndices.fill(-1);\n  for (let i = 0; i < idDims.length; ++i) {\n    permutationIndices[idDims[i]] = i;\n  }\n  const expandDims: number[] = [];\n  for (let i = 0; i < nDims; ++i) {\n    if (permutationIndices[i] === -1) {\n      expandDims.push(i);\n    }\n  }\n  permutationIndices = permutationIndices.filter(d => d !== -1);\n  return {permutationIndices, expandDims};\n}\n\n/**\n * Checks that the dimension sizes from different input tensors match the\n * equation.\n */\nexport function checkEinsumDimSizes(\n    nDims: number, idDims: number[][], tensors: Tensor[]) {\n  const dimSizes: number[] = new Array<number>(nDims);\n  for (let i = 0; i < tensors.length; ++i) {\n    const shape: number[] = tensors[i].shape;\n    for (let j = 0; j < idDims[i].length; ++j) {\n      if (dimSizes[idDims[i][j]] === undefined) {\n        dimSizes[idDims[i][j]] = shape[j];\n      } else {\n        assert(\n            dimSizes[idDims[i][j]] === shape[j],\n            () => `Expected dimension ${dimSizes[idDims[i][j]]} at axis ${j} ` +\n                `of input shaped ${JSON.stringify(shape)}, ` +\n                `but got dimension ${shape[j]}`);\n      }\n    }\n  }\n}\n\n/**\n * Gets path of computation for einsum.\n *\n * @param summedDims indices to the dimensions being summed over.\n * @param idDims A look up table for the dimensions present in each input\n *     tensor. Each consituent array contains indices for the dimensions in the\n *     corresponding input tensor.\n *\n * @return A map with two fields:\n *   - path: The path of computation, with each element indicating the dimension\n *     being summed over after the element-wise multiplication in that step.\n *   - steps: With the same length as `path`. Each element contains the indices\n *     to the input tensors being used for element-wise multiplication in the\n *     corresponding step.\n */\nexport function getEinsumComputePath(summedDims: number[], idDims: number[][]):\n    {path: number[], steps: number[][]} {\n  const path: number[] = summedDims;\n  const steps: number[][] = [];\n  let nSteps = 0;\n  if (summedDims.length === 0) {\n    // Einsum that involes no summing: e.g., transpose and outer product.\n    path.push(-1);\n  }\n  nSteps = summedDims.length + 1;\n  for (let i = 0; i < nSteps; ++i) {\n    steps.push([]);\n  }\n  const computedTermIndices: number[] = [];\n  for (let i = 0; i < path.length; ++i) {\n    const summedDim = path[i];\n    const termIndices = findTermsWithDim(idDims, summedDim);\n    for (const termIndex of termIndices) {\n      if (computedTermIndices.indexOf(termIndex) === -1) {\n        steps[i].push(termIndex);\n        computedTermIndices.push(termIndex);\n      }\n    }\n  }\n  return {path, steps};\n}\n\n/** Determines if an axes permutation is the identity permutation. */\nexport function isIdentityPermutation(perm: number[]): boolean {\n  return perm.every((dim: number, index: number) => dim === index);\n}\n\nfunction findTermsWithDim(idDims: number[][], dim: number): number[] {\n  const termIndices: number[] = [];\n  for (let i = 0; i < idDims.length; ++i) {\n    if (idDims[i].length === 0 || idDims[i].indexOf(dim) !== -1 || dim === -1) {\n      termIndices.push(i);\n    }\n  }\n  return termIndices;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {TensorInfo} from '../kernel_registry';\nimport {Tensor} from '../tensor';\nimport {assert} from '../util';\n\n/**\n * Prepare the split size array. When the input is a number, the axis is evenly\n * divided among the split size. When the input contains the negative value, the\n * rest of the axis is allocated toward that.\n */\nexport function prepareSplitSize(\n    x: Tensor|TensorInfo, numOrSizeSplits: number[]|number,\n    axis = 0): number[] {\n  let splitSizes = [];\n  if (typeof (numOrSizeSplits) === 'number') {\n    assert(\n        x.shape[axis] % numOrSizeSplits === 0,\n        () => 'Number of splits must evenly divide the axis.');\n    splitSizes =\n        new Array(numOrSizeSplits).fill(x.shape[axis] / numOrSizeSplits);\n  } else {\n    const numOfNegs = numOrSizeSplits.reduce((count, value) => {\n      if (value === -1) {\n        count += 1;\n      }\n      return count;\n    }, 0);\n    assert(\n        numOfNegs <= 1,\n        () => 'There should be only one negative value in split array.');\n    const negIndex = numOrSizeSplits.indexOf(-1);\n    // Allow the number of split array to be -1, which indicates the rest\n    // of dimension is allocated to that split.\n    if (negIndex !== -1) {\n      const total = numOrSizeSplits.reduce((a, b) => b > 0 ? a + b : a);\n      numOrSizeSplits[negIndex] = x.shape[axis] - total;\n    }\n    assert(\n        x.shape[axis] === numOrSizeSplits.reduce((a, b) => a + b),\n        () => 'The sum of sizes must match the size of the axis dimension.');\n    splitSizes = numOrSizeSplits;\n  }\n\n  return splitSizes;\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n/**\n * Generates sparse fill empty rows indices, dense shape mismatch error message.\n *\n * @param indicesLength The first dimension of indices.\n */\nexport function getSparseFillEmptyRowsIndicesDenseShapeMismatch(\n    indicesLength: number) {\n  return `Received SparseTensor with denseShape[0] = 0 but\n  indices.shape[0] = ${indicesLength}`;\n}\n\n/**\n * Generates sparse fill empty rows negative index error message.\n *\n * @param index The index with a negative value.\n * @param value The negative value.\n */\nexport function getSparseFillEmptyRowsNegativeIndexErrorMessage(\n    index: number, value: number) {\n  return `indices(${index}, 0) is invalid: ${value} < 0`;\n}\n\n/**\n * Generates sparse fill empty rows out of range index error message.\n *\n * @param index The index with an out of range value.\n * @param value The out of range value.\n * @param limit The upper limit for indices.\n */\nexport function getSparseFillEmptyRowsOutOfRangeIndexErrorMessage(\n    index: number, value: number, limit: number) {\n  return `indices(${index}, 0) is invalid: ${value} >= ${limit}`;\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {sizeFromShape} from '../../util';\n\n/**\n * Generates sparse reshape multiple negative 1 output dimension error message.\n *\n * @param dim1 The first dimension with a negative 1 value.\n * @param dim2 The second dimension with a negative 1 value.\n */\nexport function getSparseReshapeMultipleNegativeOneOutputDimErrorMessage(\n    dim1: number, dim2: number) {\n  return `only one output dimension may be -1, not both ${dim1} and ${dim2}`;\n}\n\n/**\n * Generates sparse reshape negative output dimension error message.\n *\n * @param dim The dimension with a negative value.\n * @param value The negative value.\n */\nexport function getSparseReshapeNegativeOutputDimErrorMessage(\n    dim: number, value: number) {\n  return `size ${dim} must be non-negative, not ${value}`;\n}\n\n/**\n * Generates sparse reshape empty tensor zero output dimension error message.\n *\n */\nexport function getSparseReshapeEmptyTensorZeroOutputDimErrorMessage() {\n  return 'reshape cannot infer the missing input size for an empty tensor ' +\n      'unless all specified input sizes are non-zero';\n}\n\n/**\n * Generates sparse reshape input output multiple mismatch error message.\n *\n * @param inputShape the input shape.\n * @param outputShape the requested output shape.\n */\nexport function getSparseReshapeInputOutputMultipleErrorMessage(\n    inputShape: number[], outputShape: number[]) {\n  const inputSize = sizeFromShape(inputShape);\n  const outputSize = sizeFromShape(outputShape);\n  return `Input to reshape is a SparseTensor with ${inputSize}\n  dense values, but the requested shape requires a multiple of ${\n      outputSize}. inputShape=${inputShape} outputShape= ${outputShape}`;\n}\n\n/**\n * Generates sparse reshape input output inequality error message.\n *\n * @param inputShape the input shape.\n * @param outputShape the requested output shape.\n */\nexport function getSparseReshapeInputOutputMismatchErrorMessage(\n    inputShape: number[], outputShape: number[]) {\n  const inputSize = sizeFromShape(inputShape);\n  const outputSize = sizeFromShape(outputShape);\n  return `Input to reshape is a tensor with ${\n      inputSize} dense values, but the requested shape has ${\n      outputSize}. inputShape=${inputShape} outputShape=${outputShape}`;\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n/**\n * Generates sparse segment reduction negative segment ids error message.\n *\n */\nexport function getSparseSegmentReductionNegativeSegmentIdsErrorMessage() {\n  return `segment ids must be >= 0`;\n}\n\n/**\n * Generates sparse segment reduction non increasing segment ids error message.\n *\n */\nexport function getSparseSegmentReductionNonIncreasingSegmentIdsErrorMessage() {\n  return `segment ids are not increasing`;\n}\n\n/**\n * Generates sparse segment reduction segment id out of range error message.\n *\n * @param segmentId The segment id index that is out of range.\n * @param outputRows Upper bound of valid segment id values.\n */\nexport function getSparseSegmentReductionSegmentIdOutOfRangeErrorMessage(\n    segmentId: number, outputRows: number) {\n  return `Segment id ${segmentId} out of range [0, ${\n      outputRows}), possibly because segmentIds input is not sorted.`;\n}\n\n/**\n * Generates sparse segment reduction input indice out of range error message.\n *\n * @param index The index that holds the out of range value.\n * @param indexValue The value that is out of range.\n * @param inputRows Upper bound of valid index values.\n */\nexport function getSparseSegmentReductionIndicesOutOfRangeErrorMessage(\n    index: number, indexValue: number, inputRows: number) {\n  return `Bad: indices[${index}] == ${indexValue} out of range [0, ${\n      inputRows})`;\n}\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {TensorInfo} from '../kernel_registry';\nimport {nearestDivisor} from '../util';\n\nimport {PARALLELIZE_THRESHOLD} from './reduce_util';\n\nexport interface SegOpInfo {\n  windowSize: number;\n  batchSize: number;\n  inSize: number;\n  numSegments: number;\n}\n\nexport function segOpComputeOptimalWindowSize(\n    inSize: number, numSegments: number): number {\n  let done = false;\n  let res;\n\n  if (inSize <= PARALLELIZE_THRESHOLD) {\n    res = inSize;\n    done = true;\n  } else {\n    res = nearestDivisor(inSize, Math.floor(Math.sqrt(inSize)));\n  }\n\n  while (!done) {\n    if (res > numSegments || res === inSize) {\n      done = true;\n    } else {\n      res = nearestDivisor(inSize, res + 1);\n    }\n  }\n  return res;\n}\n\nexport function computeOutShape(\n    aShape: number[], axis: number, numSegments: number): number[] {\n  const outShape = [];\n  const rank = aShape.length;\n  for (let dim = 0; dim < rank; dim++) {\n    if (dim !== axis) {\n      outShape.push(aShape[dim]);\n    } else {\n      outShape.push(numSegments);\n    }\n  }\n  return outShape;\n}\n\nexport interface GatherOpShapeInfo {\n  batchSize: number;\n  sliceSize: number;\n  outerSize: number;\n  dimSize: number;\n  outputShape: number[];\n}\n\nexport function collectGatherOpShapeInfo(\n    x: TensorInfo, indices: TensorInfo, axis: number,\n    batchDims: number): GatherOpShapeInfo {\n  const indicesRank = indices.shape.length;\n  const xRank = x.shape.length;\n\n  if (batchDims !== 0) {\n    if (batchDims < -indicesRank || batchDims > indicesRank) {\n      throw new Error(`Expect batchDims in the range of [-${indicesRank}, ${\n          indicesRank}], but got ${batchDims}`);\n    }\n  }\n\n  if (batchDims < 0) {\n    batchDims += indicesRank;\n  }\n\n  if (batchDims > xRank) {\n    throw new Error(`batchDims (${batchDims}) must be less than rank(x) (\n    ${xRank}).`);\n  }\n\n  if (axis < batchDims) {\n    throw new Error(`batchDims (${\n        batchDims}) must be less than or equal to axis (${axis}).`);\n  }\n\n  for (let i = 0; i < batchDims; ++i) {\n    if (x.shape[i] !== indices.shape[i]) {\n      throw new Error(\n          `x.shape[${i}]: ${x.shape[i]} should be equal to indices.shape[${\n              i}]: ${indices.shape[i]}.`);\n    }\n  }\n  const dimSize = x.shape[axis];\n\n  const outputShape: number[] = [];\n  let batchSize = 1;\n  let outerSize = 1;\n  let sliceSize = 1;\n\n  for (let i = 0; i < batchDims; ++i) {\n    outputShape.push(x.shape[i]);\n    batchSize *= x.shape[i];\n  }\n\n  for (let i = batchDims; i < axis; i++) {\n    outputShape.push(x.shape[i]);\n    outerSize *= x.shape[i];\n  }\n\n  for (let i = batchDims; i < indicesRank; i++) {\n    outputShape.push(indices.shape[i]);\n  }\n\n  for (let i = axis + 1; i < xRank; i++) {\n    outputShape.push(x.shape[i]);\n    sliceSize *= x.shape[i];\n  }\n\n  return {batchSize, sliceSize, outerSize, dimSize, outputShape};\n}\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {decodeString, encodeString} from '../util';\n\n// Utilities needed by backend consumers of tf-core.\nexport * from '../ops/axis_util';\nexport * from '../ops/broadcast_util';\nexport * from '../ops/concat_util';\nexport * from '../ops/conv_util';\nexport * from '../ops/fused_util';\nexport * from '../ops/fused_types';\nexport * from '../ops/ragged_to_dense_util';\nexport * from '../ops/reduce_util';\n\nimport * as slice_util from '../ops/slice_util';\nexport {slice_util};\n\nexport {BackendValues, TypedArray, upcastType, PixelData} from '../types';\nexport {MemoryInfo, TimingInfo} from '../engine';\nexport * from '../ops/rotate_util';\nexport * from '../ops/array_ops_util';\nexport * from '../ops/gather_nd_util';\nexport * from '../ops/scatter_nd_util';\nexport * from '../ops/selu_util';\nexport * from '../ops/fused_util';\nexport * from '../ops/erf_util';\nexport * from '../log';\nexport * from '../backends/complex_util';\nexport * from '../backends/einsum_util';\nexport * from '../ops/split_util';\nexport * from '../ops/sparse/sparse_fill_empty_rows_util';\nexport * from '../ops/sparse/sparse_reshape_util';\nexport * from '../ops/sparse/sparse_segment_reduction_util';\n\nimport * as segment_util from '../ops/segment_util';\nexport {segment_util};\n\nexport function fromUint8ToStringArray(vals: Uint8Array[]) {\n  try {\n    // Decode the bytes into string.\n    return vals.map(val => decodeString(val));\n  } catch (err) {\n    throw new Error(\n        `Failed to decode encoded string bytes into utf-8, error: ${err}`);\n  }\n}\n\nexport function fromStringArrayToUint8(strings: string[]) {\n  return strings.map(s => encodeString(s));\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *\n * =============================================================================\n */\n\n/* tslint:disable */\n\n/** Properties of an Any. */\nexport declare interface IAny {\n  /** Any typeUrl */\n  typeUrl?: (string|null);\n\n  /** Any value */\n  value?: (Uint8Array|null);\n}\n\n/** DataType enum. */\nexport enum DataType {\n  // Not a legal value for DataType.  Used to indicate a DataType field\n  // has not been set.\n  DT_INVALID = 0,\n\n  // Data types that all computation devices are expected to be\n  // capable to support.\n  DT_FLOAT = 1,\n  DT_DOUBLE = 2,\n  DT_INT32 = 3,\n  DT_UINT8 = 4,\n  DT_INT16 = 5,\n  DT_INT8 = 6,\n  DT_STRING = 7,\n  DT_COMPLEX64 = 8,  // Single-precision complex\n  DT_INT64 = 9,\n  DT_BOOL = 10,\n  DT_QINT8 = 11,     // Quantized int8\n  DT_QUINT8 = 12,    // Quantized uint8\n  DT_QINT32 = 13,    // Quantized int32\n  DT_BFLOAT16 = 14,  // Float32 truncated to 16 bits.  Only for cast ops.\n  DT_QINT16 = 15,    // Quantized int16\n  DT_QUINT16 = 16,   // Quantized uint16\n  DT_UINT16 = 17,\n  DT_COMPLEX128 = 18,  // Double-precision complex\n  DT_HALF = 19,\n  DT_RESOURCE = 20,\n  DT_VARIANT = 21,  // Arbitrary C++ data types\n  DT_UINT32 = 22,\n  DT_UINT64 = 23,\n\n  // Do not use!  These are only for parameters.  Every enum above\n  // should have a corresponding value below (verified by types_test).\n  DT_FLOAT_REF = 101,\n  DT_DOUBLE_REF = 102,\n  DT_INT32_REF = 103,\n  DT_UINT8_REF = 104,\n  DT_INT16_REF = 105,\n  DT_INT8_REF = 106,\n  DT_STRING_REF = 107,\n  DT_COMPLEX64_REF = 108,\n  DT_INT64_REF = 109,\n  DT_BOOL_REF = 110,\n  DT_QINT8_REF = 111,\n  DT_QUINT8_REF = 112,\n  DT_QINT32_REF = 113,\n  DT_BFLOAT16_REF = 114,\n  DT_QINT16_REF = 115,\n  DT_QUINT16_REF = 116,\n  DT_UINT16_REF = 117,\n  DT_COMPLEX128_REF = 118,\n  DT_HALF_REF = 119,\n  DT_RESOURCE_REF = 120,\n  DT_VARIANT_REF = 121,\n  DT_UINT32_REF = 122,\n  DT_UINT64_REF = 123,\n}\n\n/** Properties of a TensorShape. */\nexport declare interface ITensorShape {\n  /** TensorShape dim */\n  dim?: (TensorShape.IDim[]|null);\n\n  /** TensorShape unknownRank */\n  unknownRank?: (boolean|null);\n}\n\nexport namespace TensorShape {\n  /** Properties of a Dim. */\n  export declare interface IDim {\n    /** Dim size */\n    size?: (number|string|null);\n\n    /** Dim name */\n    name?: (string|null);\n  }\n}\n\n/** Properties of a Tensor. */\nexport declare interface ITensor {\n  /** Tensor dtype */\n  dtype?: (DataType|null);\n\n  /** Tensor tensorShape */\n  tensorShape?: (ITensorShape|null);\n\n  /** Tensor versionNumber */\n  versionNumber?: (number|null);\n\n  /** Tensor tensorContent */\n  tensorContent?: (Uint8Array|null);\n\n  /** Tensor floatVal */\n  floatVal?: (number[]|null);\n\n  /** Tensor doubleVal */\n  doubleVal?: (number[]|null);\n\n  /** Tensor intVal */\n  intVal?: (number[]|null);\n\n  /** Tensor stringVal */\n  stringVal?: (Uint8Array[]|null);\n\n  /** Tensor scomplexVal */\n  scomplexVal?: (number[]|null);\n\n  /** Tensor int64Val */\n  int64Val?: ((number | string)[]|null);\n\n  /** Tensor boolVal */\n  boolVal?: (boolean[]|null);\n\n  /** Tensor uint32Val */\n  uint32Val?: (number[]|null);\n\n  /** Tensor uint64Val */\n  uint64Val?: ((number | string)[]|null);\n}\n\n/** Properties of an AttrValue. */\nexport declare interface IAttrValue {\n  /** AttrValue list */\n  list?: (AttrValue.IListValue|null);\n\n  /** AttrValue s */\n  s?: (string|null);\n\n  /** AttrValue i */\n  i?: (number|string|null);\n\n  /** AttrValue f */\n  f?: (number|null);\n\n  /** AttrValue b */\n  b?: (boolean|null);\n\n  /** AttrValue type */\n  type?: (DataType|null);\n\n  /** AttrValue shape */\n  shape?: (ITensorShape|null);\n\n  /** AttrValue tensor */\n  tensor?: (ITensor|null);\n\n  /** AttrValue placeholder */\n  placeholder?: (string|null);\n\n  /** AttrValue func */\n  func?: (INameAttrList|null);\n}\n\nexport namespace AttrValue {\n  /** Properties of a ListValue. */\n  export declare interface IListValue {\n    /** ListValue s */\n    s?: (string[]|null);\n\n    /** ListValue i */\n    i?: ((number | string)[]|null);\n\n    /** ListValue f */\n    f?: (number[]|null);\n\n    /** ListValue b */\n    b?: (boolean[]|null);\n\n    /** ListValue type */\n    type?: (DataType[]|null);\n\n    /** ListValue shape */\n    shape?: (ITensorShape[]|null);\n\n    /** ListValue tensor */\n    tensor?: (ITensor[]|null);\n\n    /** ListValue func */\n    func?: (INameAttrList[]|null);\n  }\n}\n\n/** Properties of a NameAttrList. */\nexport declare interface INameAttrList {\n  /** NameAttrList name */\n  name?: (string|null);\n\n  /** NameAttrList attr */\n  attr?: ({[k: string]: IAttrValue}|null);\n}\n\n/** Properties of a NodeDef. */\nexport declare interface INodeDef {\n  /** NodeDef name */\n  name?: (string|null);\n\n  /** NodeDef op */\n  op?: (string|null);\n\n  /** NodeDef input */\n  input?: (string[]|null);\n\n  /** NodeDef device */\n  device?: (string|null);\n\n  /** NodeDef attr */\n  attr?: ({[k: string]: IAttrValue}|null);\n}\n\n/** Properties of a VersionDef. */\nexport declare interface IVersionDef {\n  /** VersionDef producer */\n  producer?: (number|null);\n\n  /** VersionDef minConsumer */\n  minConsumer?: (number|null);\n\n  /** VersionDef badConsumers */\n  badConsumers?: (number[]|null);\n}\n\n/** Properties of a GraphDef. */\nexport declare interface IGraphDef {\n  /** GraphDef node */\n  node?: (INodeDef[]|null);\n\n  /** GraphDef versions */\n  versions?: (IVersionDef|null);\n\n  /** GraphDef library */\n  library?: (IFunctionDefLibrary|null);\n}\n\n/** Properties of a CollectionDef. */\nexport declare interface ICollectionDef {\n  /** CollectionDef nodeList */\n  nodeList?: (CollectionDef.INodeList|null);\n\n  /** CollectionDef bytesList */\n  bytesList?: (CollectionDef.IBytesList|null);\n\n  /** CollectionDef int64List */\n  int64List?: (CollectionDef.IInt64List|null);\n\n  /** CollectionDef floatList */\n  floatList?: (CollectionDef.IFloatList|null);\n\n  /** CollectionDef anyList */\n  anyList?: (CollectionDef.IAnyList|null);\n}\n\nexport namespace CollectionDef {\n  /** Properties of a NodeList. */\n  export declare interface INodeList {\n    /** NodeList value */\n    value?: (string[]|null);\n  }\n\n  /** Properties of a BytesList. */\n  export declare interface IBytesList {\n    /** BytesList value */\n    value?: (Uint8Array[]|null);\n  }\n\n  /** Properties of an Int64List. */\n  export declare interface IInt64List {\n    /** Int64List value */\n    value?: ((number | string)[]|null);\n  }\n\n  /** Properties of a FloatList. */\n  export declare interface IFloatList {\n    /** FloatList value */\n    value?: (number[]|null);\n  }\n\n  /** Properties of an AnyList. */\n  export declare interface IAnyList {\n    /** AnyList value */\n    value?: (IAny[]|null);\n  }\n}\n\n/** Properties of a SaverDef. */\nexport declare interface ISaverDef {\n  /** SaverDef filenameTensorName */\n  filenameTensorName?: (string|null);\n\n  /** SaverDef saveTensorName */\n  saveTensorName?: (string|null);\n\n  /** SaverDef restoreOpName */\n  restoreOpName?: (string|null);\n\n  /** SaverDef maxToKeep */\n  maxToKeep?: (number|null);\n\n  /** SaverDef sharded */\n  sharded?: (boolean|null);\n\n  /** SaverDef keepCheckpointEveryNHours */\n  keepCheckpointEveryNHours?: (number|null);\n\n  /** SaverDef version */\n  version?: (SaverDef.CheckpointFormatVersion|null);\n}\n\nexport namespace SaverDef {\n  /** CheckpointFormatVersion enum. */\n  export enum CheckpointFormatVersion {'LEGACY' = 0, 'V1' = 1, 'V2' = 2}\n}\n\n/** Properties of a TensorInfo. */\nexport declare interface ITensorInfo {\n  /** TensorInfo name */\n  name?: (string|null);\n\n  /** TensorInfo cooSparse */\n  cooSparse?: (TensorInfo.ICooSparse|null);\n\n  /** TensorInfo dtype */\n  dtype?: (DataType|null);\n\n  /** TensorInfo tensorShape */\n  tensorShape?: (ITensorShape|null);\n}\n\nexport namespace TensorInfo {\n  /** Properties of a CooSparse. */\n  export declare interface ICooSparse {\n    /** CooSparse valuesTensorName */\n    valuesTensorName?: (string|null);\n\n    /** CooSparse indicesTensorName */\n    indicesTensorName?: (string|null);\n\n    /** CooSparse denseShapeTensorName */\n    denseShapeTensorName?: (string|null);\n  }\n}\n\n/** Properties of a SignatureDef. */\nexport declare interface ISignatureDef {\n  /** SignatureDef inputs */\n  inputs?: ({[k: string]: ITensorInfo}|null);\n\n  /** SignatureDef outputs */\n  outputs?: ({[k: string]: ITensorInfo}|null);\n\n  /** SignatureDef methodName */\n  methodName?: (string|null);\n}\n\n/** Properties of an AssetFileDef. */\nexport declare interface IAssetFileDef {\n  /** AssetFileDef tensorInfo */\n  tensorInfo?: (ITensorInfo|null);\n\n  /** AssetFileDef filename */\n  filename?: (string|null);\n}\n\n/** Properties of an OpDef. */\nexport declare interface IOpDef {\n  /** OpDef name */\n  name?: (string|null);\n\n  /** OpDef inputArg */\n  inputArg?: (OpDef.IArgDef[]|null);\n\n  /** OpDef outputArg */\n  outputArg?: (OpDef.IArgDef[]|null);\n\n  /** OpDef attr */\n  attr?: (OpDef.IAttrDef[]|null);\n\n  /** OpDef deprecation */\n  deprecation?: (OpDef.IOpDeprecation|null);\n\n  /** OpDef summary */\n  summary?: (string|null);\n\n  /** OpDef description */\n  description?: (string|null);\n\n  /** OpDef isCommutative */\n  isCommutative?: (boolean|null);\n\n  /** OpDef isAggregate */\n  isAggregate?: (boolean|null);\n\n  /** OpDef isStateful */\n  isStateful?: (boolean|null);\n\n  /** OpDef allowsUninitializedInput */\n  allowsUninitializedInput?: (boolean|null);\n}\n\nexport namespace OpDef {\n  /** Properties of an ArgDef. */\n  export declare interface IArgDef {\n    /** ArgDef name */\n    name?: (string|null);\n\n    /** ArgDef description */\n    description?: (string|null);\n\n    /** ArgDef type */\n    type?: (DataType|null);\n\n    /** ArgDef typeAttr */\n    typeAttr?: (string|null);\n\n    /** ArgDef numberAttr */\n    numberAttr?: (string|null);\n\n    /** ArgDef typeListAttr */\n    typeListAttr?: (string|null);\n\n    /** ArgDef isRef */\n    isRef?: (boolean|null);\n  }\n\n  /** Properties of an AttrDef. */\n  export declare interface IAttrDef {\n    /** AttrDef name */\n    name?: (string|null);\n\n    /** AttrDef type */\n    type?: (string|null);\n\n    /** AttrDef defaultValue */\n    defaultValue?: (IAttrValue|null);\n\n    /** AttrDef description */\n    description?: (string|null);\n\n    /** AttrDef hasMinimum */\n    hasMinimum?: (boolean|null);\n\n    /** AttrDef minimum */\n    minimum?: (number|string|null);\n\n    /** AttrDef allowedValues */\n    allowedValues?: (IAttrValue|null);\n  }\n\n  /** Properties of an OpDeprecation. */\n  export declare interface IOpDeprecation {\n    /** OpDeprecation version */\n    version?: (number|null);\n\n    /** OpDeprecation explanation */\n    explanation?: (string|null);\n  }\n}\n\n/** Properties of an OpList. */\nexport declare interface IOpList {\n  /** OpList op */\n  op?: (IOpDef[]|null);\n}\n\n/** Properties of a MetaGraphDef. */\nexport declare interface IMetaGraphDef {\n  /** MetaGraphDef metaInfoDef */\n  metaInfoDef?: (MetaGraphDef.IMetaInfoDef|null);\n\n  /** MetaGraphDef graphDef */\n  graphDef?: (IGraphDef|null);\n\n  /** MetaGraphDef saverDef */\n  saverDef?: (ISaverDef|null);\n\n  /** MetaGraphDef collectionDef */\n  collectionDef?: ({[k: string]: ICollectionDef}|null);\n\n  /** MetaGraphDef signatureDef */\n  signatureDef?: ({[k: string]: ISignatureDef}|null);\n\n  /** MetaGraphDef assetFileDef */\n  assetFileDef?: (IAssetFileDef[]|null);\n}\n\nexport namespace MetaGraphDef {\n  /** Properties of a MetaInfoDef. */\n  export declare interface IMetaInfoDef {\n    /** MetaInfoDef metaGraphVersion */\n    metaGraphVersion?: (string|null);\n\n    /** MetaInfoDef strippedOpList */\n    strippedOpList?: (IOpList|null);\n\n    /** MetaInfoDef anyInfo */\n    anyInfo?: (IAny|null);\n\n    /** MetaInfoDef tags */\n    tags?: (string[]|null);\n\n    /** MetaInfoDef tensorflowVersion */\n    tensorflowVersion?: (string|null);\n\n    /** MetaInfoDef tensorflowGitVersion */\n    tensorflowGitVersion?: (string|null);\n  }\n}\n\n/** Properties of a SavedModel. */\nexport declare interface ISavedModel {\n  /** SavedModel savedModelSchemaVersion */\n  savedModelSchemaVersion?: (number|string|null);\n\n  /** SavedModel metaGraphs */\n  metaGraphs?: (IMetaGraphDef[]|null);\n}\n\n/** Properties of a FunctionDefLibrary. */\nexport declare interface IFunctionDefLibrary {\n  /** FunctionDefLibrary function */\n  'function'?: (IFunctionDef[]|null);\n\n  /** FunctionDefLibrary gradient */\n  gradient?: (IGradientDef[]|null);\n}\n\n/** Properties of a FunctionDef. */\nexport declare interface IFunctionDef {\n  /** FunctionDef signature */\n  signature?: (IOpDef|null);\n\n  /** FunctionDef attr */\n  attr?: ({[k: string]: IAttrValue}|null);\n\n  /** FunctionDef nodeDef */\n  nodeDef?: (INodeDef[]|null);\n\n  /** FunctionDef ret */\n  ret?: ({[k: string]: string}|null);\n}\n\n/** Properties of a GradientDef. */\nexport declare interface IGradientDef {\n  /** GradientDef functionName */\n  functionName?: (string|null);\n\n  /** GradientDef gradientFunc */\n  gradientFunc?: (string|null);\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {env} from '@tensorflow/tfjs-core';\n\nconst ENV = env();\n\n/** Whether to keep intermediate tensors. */\nENV.registerFlag('KEEP_INTERMEDIATE_TENSORS', () => false, debugValue => {\n  if (debugValue) {\n    console.warn(\n        'Keep intermediate tensors is ON. This will print the values of all ' +\n        'intermediate tensors during model inference. Not all models ' +\n        'support this mode. For details, check e2e/benchmarks/ ' +\n        'model_config.js. This significantly impacts performance.');\n  }\n});\n","\n/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {OpExecutor, OpMapper} from '../types';\n\nconst CUSTOM_OPS: {[key: string]: OpMapper} = {};\n\n/**\n * Register an Op for graph model executor. This allows you to register\n * TensorFlow custom op or override existing op.\n *\n * Here is an example of registering a new MatMul Op.\n * ```js\n * const customMatmul = (node) =>\n *    tf.matMul(\n *        node.inputs[0], node.inputs[1],\n *        node.attrs['transpose_a'], node.attrs['transpose_b']);\n *\n * tf.registerOp('MatMul', customMatmul);\n * ```\n * The inputs and attrs of the node object are based on the TensorFlow op\n * registry.\n *\n * @param name The Tensorflow Op name.\n * @param opFunc An op function which is called with the current graph node\n * during execution and needs to return a tensor or a list of tensors. The node\n * has the following attributes:\n *    - attr: A map from attribute name to its value\n *    - inputs: A list of input tensors\n *\n * @doc {heading: 'Models', subheading: 'Op Registry'}\n */\nexport function registerOp(name: string, opFunc: OpExecutor) {\n  const opMapper: OpMapper = {\n    tfOpName: name,\n    category: 'custom',\n    inputs: [],\n    attrs: [],\n    customExecutor: opFunc\n  };\n\n  CUSTOM_OPS[name] = opMapper;\n}\n\n/**\n * Retrieve the OpMapper object for the registered op.\n *\n * @param name The Tensorflow Op name.\n *\n * @doc {heading: 'Models', subheading: 'Op Registry'}\n */\nexport function getRegisteredOp(name: string): OpMapper {\n  return CUSTOM_OPS[name];\n}\n\n/**\n * Deregister the Op for graph model executor.\n *\n * @param name The Tensorflow Op name.\n *\n * @doc {heading: 'Models', subheading: 'Op Registry'}\n */\nexport function deregisterOp(name: string) {\n  delete CUSTOM_OPS[name];\n}\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {clone, Tensor, util} from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {ResourceManager} from '../../executor/resource_manager';\nimport {Node, ValueType} from '../types';\n\nexport function getParamValue(\n    paramName: string, node: Node, tensorMap: NamedTensorsMap,\n    context: ExecutionContext, resourceManager?: ResourceManager): ValueType {\n  const inputParam = node.inputParams[paramName];\n  if (inputParam && inputParam.inputIndexStart !== undefined) {\n    const start = inputParam.inputIndexStart;\n    const end = inputParam.inputIndexEnd === 0 ?\n        undefined :\n        (inputParam.inputIndexEnd === undefined ? start + 1 :\n                                                  inputParam.inputIndexEnd);\n    if (inputParam.type === 'tensor') {\n      return getTensor(\n          node.inputNames[inputParam.inputIndexStart], tensorMap, context,\n          resourceManager);\n    }\n    if (inputParam.type === 'tensors') {\n      const inputs = node.inputNames.slice(start, end);\n\n      return inputs.map(\n          name => getTensor(name, tensorMap, context, resourceManager));\n    }\n    const tensor = getTensor(\n        node.inputNames.slice(start)[0], tensorMap, context, resourceManager);\n    const data = tensor.dataSync();\n    return inputParam.type === 'number' ?\n        data[0] :\n        util.toNestedArray(tensor.shape, data);\n  }\n  const attrParam = node.attrParams[paramName];\n  return attrParam && attrParam.value;\n}\n\n/**\n * Retrieve the tensor from tensorsMap based on input name.\n * @param name Node input name\n * @param tensorsMap Tensors map keyed by the node\n * @param context contains tensors and information for running the current node.\n * @param resourceManager Optional. Contains global resources of the model.\n */\nexport function getTensor(\n    name: string, tensorsMap: NamedTensorsMap, context: ExecutionContext,\n    resourceManager?: ResourceManager): Tensor {\n  const [nodeName, index] = parseNodeName(name);\n\n  if (resourceManager != null) {\n    const tensor = resourceManager.getHashTableHandleByName(nodeName);\n    if (tensor != null) {\n      return tensor;\n    }\n  }\n\n  const contextId = context.currentContextIds.find(contextId => {\n    return !!tensorsMap[getNodeNameWithContextId(nodeName, contextId)];\n  });\n\n  return contextId !== undefined ?\n      tensorsMap[getNodeNameWithContextId(nodeName, contextId)][index] :\n      undefined;\n}\n\n/**\n * Retrieve the tensors based on input name for current context.\n * @param name Node input name\n * @param tensorsMap Tensors map keyed by the node\n */\nexport function getTensorsForCurrentContenxt(\n    name: string, tensorsMap: NamedTensorsMap,\n    context: ExecutionContext): Tensor[] {\n  return tensorsMap[getNodeNameWithContextId(name, context.currentContextId)];\n}\n\n/**\n * Returns the node name, outputName and index from the Node input name.\n * @param inputName The input name of the node, in format of\n * node_name:output_index, i.e. MatMul:0, if the output_index is not set, it is\n * default to 0.\n * If the input name contains output name i.e. StringSplit:indices:0, it will\n * return ['StringSplit', 0, 'indices'].\n */\nexport function getNodeNameAndIndex(\n    inputName: string, context?: ExecutionContext): [string, number, string] {\n  const [nodeName, index, outputName] = parseNodeName(inputName);\n\n  return [\n    getNodeNameWithContextId(nodeName, context && context.currentContextId),\n    index, outputName\n  ];\n}\n\nfunction getNodeNameWithContextId(name: string, contextId?: string): string {\n  return !!contextId ? `${name}-${contextId}` : name;\n}\n\nexport function parseNodeName(name: string): [string, number, string] {\n  const parts = name.split(':');\n  if (parts.length === 1) {\n    return [name, 0, undefined];\n  }\n\n  const nodeName = parts[0];\n  const outputName = parts.length === 3 ? parts[1] : undefined;\n  const index = Number(parts[parts.length - 1]);\n  return [nodeName, index, outputName];\n}\n\nexport function split(arr: number[], size: number) {\n  const res = [];\n  for (let i = 0; i < arr.length; i += size) {\n    res.push(arr.slice(i, i + size));\n  }\n  return res;\n}\nexport function getPadding(\n    node: Node, tensorMap: NamedTensorsMap,\n    context: ExecutionContext): ValueType {\n  let pad = getParamValue('pad', node, tensorMap, context);\n  if (pad === 'explicit') {\n    // This is 1d array, we need to convert it to 2d array\n    pad = getParamValue('explicitPaddings', node, tensorMap, context);\n    const explicitPadding: [\n      [number, number], [number, number], [number, number], [number, number]\n    ] = [[0, 0], [0, 0], [0, 0], [0, 0]];\n    for (let i = 0; i < 4; i++) {\n      explicitPadding[i][0] = (pad as number[])[i * 2];\n      explicitPadding[i][1] = (pad as number[])[i * 2 + 1];\n    }\n    return explicitPadding;\n  }\n  return pad;\n}\n\n/**\n *  Reuse the tensor if it is marked as keep, otherwise clone the tensor to\n *  avoid disposal. This is important for TensorArray and TensorList ops, since\n *  internally they use a tensor as the id for TensorArray and TensorList, and\n * to simplify lookup, they also use Tensor.id as the key to the internal map.\n * These id tensors have been marked as kept in the backend, we need avoid clone\n * them in order to create new Tensor.id.\n * @param tensor\n */\nexport function cloneTensor(tensor: Tensor): Tensor {\n  return tensor.kept ? tensor : clone(tensor);\n}\n","\n/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {OpMapper} from '../types';\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'Add',\n    'category': 'arithmetic',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'a',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'b',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'AddV2',\n    'category': 'arithmetic',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'a',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'b',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'AddN',\n    'category': 'arithmetic',\n    'inputs': [\n      {\n        'start': 0,\n        'end': 0,\n        'name': 'tensors',\n        'type': 'tensors'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'BiasAdd',\n    'category': 'arithmetic',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'a',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'b',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      },\n      {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Sub',\n    'category': 'arithmetic',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'a',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'b',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'RealDiv',\n    'category': 'arithmetic',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'a',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'b',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Div',\n    'category': 'arithmetic',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'a',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'b',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'DivNoNan',\n    'category': 'arithmetic',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'a',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'b',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'FloorDiv',\n    'category': 'arithmetic',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'a',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'b',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Mul',\n    'category': 'arithmetic',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'a',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'b',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Maximum',\n    'category': 'arithmetic',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'a',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'b',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Minimum',\n    'category': 'arithmetic',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'a',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'b',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Pow',\n    'category': 'arithmetic',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'a',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'b',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'SquaredDifference',\n    'category': 'arithmetic',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'a',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'b',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Mod',\n    'category': 'arithmetic',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'a',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'b',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'FloorMod',\n    'category': 'arithmetic',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'a',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'b',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  }\n];\n","\n/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {OpMapper} from '../types';\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'Abs',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Acos',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Asin',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Atan',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Atan2',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'y',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Ceil',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'ClipByValue',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'clipValueMin',\n        'type': 'number'\n      },\n      {\n        'start': 2,\n        'name': 'clipValueMax',\n        'type': 'number'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Complex',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'real',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'imag',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'ComplexAbs',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Cos',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Cosh',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Elu',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Exp',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Floor',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Log',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Imag',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      },\n      {\n        'tfName': 'Tout',\n        'name': 'outputType',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Neg',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Real',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      },\n      {\n        'tfName': 'Tout',\n        'name': 'outputType',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Prelu',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'alpha',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Relu',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Relu6',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Selu',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Sigmoid',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Sin',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Sinh',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Sqrt',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Rsqrt',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Square',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Tan',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Tanh',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Sign',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Round',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Expm1',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Log1p',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Reciprocal',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Softplus',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Asinh',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Acosh',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Atanh',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Erf',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Prod',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'axes',\n        'type': 'number[]'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'keep_dims',\n        'name': 'keepDims',\n        'type': 'bool',\n        'notSupported': true\n      },\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'LeakyRelu',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'alpha',\n        'name': 'alpha',\n        'type': 'number',\n        'defaultValue': 0.2\n      },\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'IsNan',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  }\n];\n","\n/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {OpMapper} from '../types';\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'EmptyTensorList',\n    'category': 'control',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'elementShape',\n        'type': 'shape'\n      },\n      {\n        'start': 1,\n        'name': 'maxNumElements',\n        'type': 'number'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'element_dtype',\n        'name': 'elementDType',\n        'type': 'dtype'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'LoopCond',\n    'category': 'control',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'pred',\n        'type': 'tensor'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Switch',\n    'category': 'control',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'data',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'pred',\n        'type': 'tensor'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Merge',\n    'category': 'control',\n    'inputs': [\n      {\n        'start': 0,\n        'end': 0,\n        'name': 'tensors',\n        'type': 'tensors'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Enter',\n    'category': 'control',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'tensor',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      },\n      {\n        'tfName': 'frame_name',\n        'name': 'frameName',\n        'type': 'string'\n      },\n      {\n        'tfName': 'is_constant',\n        'name': 'isConstant',\n        'type': 'bool'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Exit',\n    'category': 'control',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'tensor',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'NextIteration',\n    'category': 'control',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'tensor',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'TensorArrayV3',\n    'category': 'control',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'size',\n        'type': 'number'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'dtype',\n        'name': 'dtype',\n        'type': 'dtype'\n      },\n      {\n        'tfName': 'element_shape',\n        'name': 'elementShape',\n        'type': 'shape'\n      },\n      {\n        'tfName': 'dynamic_size',\n        'name': 'dynamicSize',\n        'type': 'bool'\n      },\n      {\n        'tfName': 'clear_after_read',\n        'name': 'clearAfterRead',\n        'type': 'bool'\n      },\n      {\n        'tfName': 'identical_element_shapes',\n        'name': 'identicalElementShapes',\n        'type': 'bool'\n      },\n      {\n        'tfName': 'tensor_array_name',\n        'name': 'name',\n        'type': 'string'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'TensorArrayWriteV3',\n    'category': 'control',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'tensorArrayId',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'index',\n        'type': 'number'\n      },\n      {\n        'start': 2,\n        'name': 'tensor',\n        'type': 'tensor'\n      },\n      {\n        'start': 3,\n        'name': 'flowIn',\n        'type': 'number'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'TensorArrayReadV3',\n    'category': 'control',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'tensorArrayId',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'index',\n        'type': 'number'\n      },\n      {\n        'start': 2,\n        'name': 'flowIn',\n        'type': 'number'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'dtype',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'TensorArrayGatherV3',\n    'category': 'control',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'tensorArrayId',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'indices',\n        'type': 'number[]'\n      },\n      {\n        'start': 2,\n        'name': 'flowIn',\n        'type': 'number'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'dtype',\n        'name': 'dtype',\n        'type': 'dtype'\n      },\n      {\n        'tfName': 'element_shape',\n        'name': 'elementShape',\n        'type': 'shape'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'TensorArrayScatterV3',\n    'category': 'control',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'tensorArrayId',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'indices',\n        'type': 'number[]'\n      },\n      {\n        'start': 2,\n        'name': 'tensor',\n        'type': 'tensor'\n      },\n      {\n        'start': 3,\n        'name': 'flowIn',\n        'type': 'number'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'TensorArrayConcatV3',\n    'category': 'control',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'tensorArrayId',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'flowIn',\n        'type': 'number'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'dtype',\n        'name': 'dtype',\n        'type': 'dtype'\n      },\n      {\n        'tfName': 'element_shape_except0',\n        'name': 'elementShapeExcept0',\n        'type': 'shape',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'TensorArraySplitV3',\n    'category': 'control',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'tensorArrayId',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'tensor',\n        'type': 'tensor'\n      },\n      {\n        'start': 2,\n        'name': 'lengths',\n        'type': 'number[]'\n      },\n      {\n        'start': 3,\n        'name': 'flowIn',\n        'type': 'number'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'TensorArraySizeV3',\n    'category': 'control',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'tensorArrayId',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'flowIn',\n        'type': 'number'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'TensorArrayCloseV3',\n    'category': 'control',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'tensorArrayId',\n        'type': 'tensor'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'StatelessIf',\n    'category': 'control',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'cond',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'end': 0,\n        'name': 'args',\n        'type': 'tensors'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'then_branch',\n        'name': 'thenBranch',\n        'type': 'func'\n      },\n      {\n        'tfName': 'else_branch',\n        'name': 'elseBranch',\n        'type': 'func'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'If',\n    'category': 'control',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'cond',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'end': 0,\n        'name': 'args',\n        'type': 'tensors'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'then_branch',\n        'name': 'thenBranch',\n        'type': 'func'\n      },\n      {\n        'tfName': 'else_branch',\n        'name': 'elseBranch',\n        'type': 'func'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'StatelessWhile',\n    'category': 'control',\n    'inputs': [\n      {\n        'start': 0,\n        'end': 0,\n        'name': 'args',\n        'type': 'tensors'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'cond',\n        'name': 'cond',\n        'type': 'func'\n      },\n      {\n        'tfName': 'body',\n        'name': 'body',\n        'type': 'func'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'While',\n    'category': 'control',\n    'inputs': [\n      {\n        'start': 0,\n        'end': 0,\n        'name': 'args',\n        'type': 'tensors'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'cond',\n        'name': 'cond',\n        'type': 'func'\n      },\n      {\n        'tfName': 'body',\n        'name': 'body',\n        'type': 'func'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'TensorListScatter',\n    'category': 'control',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'tensor',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'indices',\n        'type': 'number[]'\n      },\n      {\n        'start': 2,\n        'name': 'elementShape',\n        'type': 'shape'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'element_dtype',\n        'name': 'elementDType',\n        'type': 'dtype'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'TensorListScatterV2',\n    'category': 'control',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'tensor',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'indices',\n        'type': 'number[]'\n      },\n      {\n        'start': 2,\n        'name': 'elementShape',\n        'type': 'shape'\n      },\n      {\n        'start': 3,\n        'name': 'numElements',\n        'type': 'number'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'element_dtype',\n        'name': 'elementDType',\n        'type': 'dtype'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'TensorListGather',\n    'category': 'control',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'tensorListId',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'indices',\n        'type': 'number[]'\n      },\n      {\n        'start': 2,\n        'name': 'elementShape',\n        'type': 'shape'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'element_dtype',\n        'name': 'elementDType',\n        'type': 'dtype'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'TensorListGetItem',\n    'category': 'control',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'tensorListId',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'index',\n        'type': 'number'\n      },\n      {\n        'start': 2,\n        'name': 'elementShape',\n        'type': 'shape'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'element_dtype',\n        'name': 'elementDType',\n        'type': 'dtype'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'TensorListSetItem',\n    'category': 'control',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'tensorListId',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'index',\n        'type': 'number'\n      },\n      {\n        'start': 2,\n        'name': 'tensor',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'element_dtype',\n        'name': 'elementDType',\n        'type': 'dtype'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'TensorListReserve',\n    'category': 'control',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'elementShape',\n        'type': 'shape'\n      },\n      {\n        'start': 1,\n        'name': 'numElements',\n        'type': 'number'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'element_dtype',\n        'name': 'elementDType',\n        'type': 'dtype'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'TensorListFromTensor',\n    'category': 'control',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'tensor',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'elementShape',\n        'type': 'shape'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'element_dtype',\n        'name': 'elementDType',\n        'type': 'dtype'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'TensorListStack',\n    'category': 'control',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'tensorListId',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'elementShape',\n        'type': 'shape'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'element_dtype',\n        'name': 'elementDType',\n        'type': 'dtype'\n      },\n      {\n        'tfName': 'num_elements',\n        'name': 'numElements',\n        'type': 'dtype'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'TensorListSplit',\n    'category': 'control',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'tensor',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'elementShape',\n        'type': 'shape'\n      },\n      {\n        'start': 2,\n        'name': 'lengths',\n        'type': 'number[]'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'element_dtype',\n        'name': 'elementDType',\n        'type': 'dtype'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'TensorListConcat',\n    'category': 'control',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'tensorListId',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'element_shape',\n        'name': 'elementShape',\n        'type': 'shape'\n      },\n      {\n        'tfName': 'element_dtype',\n        'name': 'elementDType',\n        'type': 'dtype'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'TensorListConcatV2',\n    'category': 'control',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'tensorListId',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'element_shape',\n        'name': 'elementShape',\n        'type': 'shape'\n      },\n      {\n        'tfName': 'element_dtype',\n        'name': 'elementDType',\n        'type': 'dtype'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'TensorListPopBack',\n    'category': 'control',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'tensorListId',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'elementShape',\n        'type': 'shape'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'element_dtype',\n        'name': 'elementDType',\n        'type': 'dtype'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'TensorListPushBack',\n    'category': 'control',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'tensorListId',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'tensor',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'element_dtype',\n        'name': 'elementDType',\n        'type': 'dtype'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'TensorListLength',\n    'category': 'control',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'tensorListId',\n        'type': 'tensor'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'TensorListResize',\n    'category': 'control',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'tensorListId',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'size',\n        'type': 'number'\n      }\n    ]\n  }\n]\n;\n","\n/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {OpMapper} from '../types';\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'AvgPool',\n    'category': 'convolution',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'strides',\n        'name': 'strides',\n        'type': 'number[]'\n      },\n      {\n        'tfName': 'padding',\n        'name': 'pad',\n        'type': 'string'\n      },\n      {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'notSupported': true\n      },\n      {\n        'tfName': 'ksize',\n        'name': 'kernelSize',\n        'type': 'number[]'\n      },\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'MaxPool',\n    'category': 'convolution',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'strides',\n        'name': 'strides',\n        'type': 'number[]'\n      },\n      {\n        'tfName': 'padding',\n        'name': 'pad',\n        'type': 'string'\n      },\n      {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'notSupported': true\n      },\n      {\n        'tfName': 'ksize',\n        'name': 'kernelSize',\n        'type': 'number[]'\n      },\n      {\n        'tfName': 'explicit_paddings',\n        'name': 'explicitPaddings',\n        'type': 'number[]',\n        'defaultValue': [],\n        'notSupported': true\n      },\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'MaxPoolWithArgmax',\n    'category': 'convolution',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'strides',\n        'name': 'strides',\n        'type': 'number[]'\n      },\n      {\n        'tfName': 'padding',\n        'name': 'pad',\n        'type': 'string'\n      },\n      {\n        'tfName': 'ksize',\n        'name': 'kernelSize',\n        'type': 'number[]'\n      },\n      {\n        'tfName': 'include_batch_in_index',\n        'name': 'includeBatchInIndex',\n        'type': 'bool'\n      },\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'AvgPool3D',\n    'category': 'convolution',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'strides',\n        'name': 'strides',\n        'type': 'number[]'\n      },\n      {\n        'tfName': 'padding',\n        'name': 'pad',\n        'type': 'string'\n      },\n      {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'notSupported': true\n      },\n      {\n        'tfName': 'ksize',\n        'name': 'kernelSize',\n        'type': 'number[]'\n      },\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'MaxPool3D',\n    'category': 'convolution',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'strides',\n        'name': 'strides',\n        'type': 'number[]'\n      },\n      {\n        'tfName': 'padding',\n        'name': 'pad',\n        'type': 'string'\n      },\n      {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'notSupported': true\n      },\n      {\n        'tfName': 'ksize',\n        'name': 'kernelSize',\n        'type': 'number[]'\n      },\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Conv1D',\n    'category': 'convolution',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'filter',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'stride',\n        'name': 'stride',\n        'type': 'number'\n      },\n      {\n        'tfName': 'padding',\n        'name': 'pad',\n        'type': 'string'\n      },\n      {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'defaultValue': 'NWC'\n      },\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      },\n      {\n        'tfName': 'dilation',\n        'name': 'dilation',\n        'type': 'number',\n        'defaultValue': 1\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Conv2D',\n    'category': 'convolution',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'filter',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      },\n      {\n        'tfName': 'strides',\n        'name': 'strides',\n        'type': 'number[]'\n      },\n      {\n        'tfName': 'padding',\n        'name': 'pad',\n        'type': 'string'\n      },\n      {\n        'tfName': 'useCudnnOnGpu',\n        'name': 'useCudnnOnGpu',\n        'type': 'bool'\n      },\n      {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'defaultValue': 'NHWC'\n      },\n      {\n        'tfName': 'explicit_paddings',\n        'name': 'explicitPaddings',\n        'type': 'number[]',\n        'defaultValue': []\n      },\n      {\n        'tfName': 'dilations',\n        'name': 'dilations',\n        'type': 'number[]'\n      }\n    ]\n  },\n  {\n    'tfOpName': '_FusedConv2D',\n    'category': 'convolution',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'filter',\n        'type': 'tensor'\n      },\n      {\n        'start': 2,\n        'end': 0,\n        'name': 'args',\n        'type': 'tensors'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'num_args',\n        'name': 'numArgs',\n        'type': 'number'\n      },\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      },\n      {\n        'tfName': 'strides',\n        'name': 'strides',\n        'type': 'number[]'\n      },\n      {\n        'tfName': 'padding',\n        'name': 'pad',\n        'type': 'string'\n      },\n      {\n        'tfName': 'explicit_paddings',\n        'name': 'explicitPaddings',\n        'type': 'number[]',\n        'defaultValue': []\n      },\n      {\n        'tfName': 'use_cudnn_on_gpu',\n        'name': 'useCudnnOnGpu',\n        'type': 'bool',\n        'defaultValue': true\n      },\n      {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'defaultValue': 'NHWC'\n      },\n      {\n        'tfName': 'dilations',\n        'name': 'dilations',\n        'type': 'number[]',\n        'defaultValue': [\n          1,\n          1,\n          1,\n          1\n        ]\n      },\n      {\n        'tfName': 'fused_ops',\n        'name': 'fusedOps',\n        'type': 'string[]',\n        'defaultValue': []\n      },\n      {\n        'tfName': 'epsilon',\n        'name': 'epsilon',\n        'type': 'number',\n        'defaultValue': 0.0001\n      },\n      {\n        'tfName': 'leakyrelu_alpha',\n        'name': 'leakyreluAlpha',\n        'type': 'number',\n        'defaultValue': 0.2\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Conv2DBackpropInput',\n    'category': 'convolution',\n    'inputs': [\n      {\n        'start': 2,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'filter',\n        'type': 'tensor'\n      },\n      {\n        'start': 0,\n        'name': 'outputShape',\n        'type': 'number[]'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'strides',\n        'name': 'strides',\n        'type': 'number[]'\n      },\n      {\n        'tfName': 'padding',\n        'name': 'pad',\n        'type': 'string'\n      },\n      {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'notSupported': true\n      },\n      {\n        'tfName': 'explicit_paddings',\n        'name': 'explicitPaddings',\n        'type': 'number[]',\n        'defaultValue': []\n      },\n      {\n        'tfName': 'dilations',\n        'name': 'dilations',\n        'type': 'number[]',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'DepthwiseConv2d',\n    'category': 'convolution',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'input',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'filter',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'strides',\n        'name': 'strides',\n        'type': 'number[]'\n      },\n      {\n        'tfName': 'padding',\n        'name': 'pad',\n        'type': 'string'\n      },\n      {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'defaultValue': 'NHWC'\n      },\n      {\n        'tfName': 'explicit_paddings',\n        'name': 'explicitPaddings',\n        'type': 'number[]',\n        'defaultValue': []\n      },\n      {\n        'tfName': 'dilations',\n        'name': 'dilations',\n        'type': 'number[]'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'DepthwiseConv2dNative',\n    'category': 'convolution',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'input',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'filter',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'strides',\n        'name': 'strides',\n        'type': 'number[]'\n      },\n      {\n        'tfName': 'padding',\n        'name': 'pad',\n        'type': 'string'\n      },\n      {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'defaultValue': 'NHWC'\n      },\n      {\n        'tfName': 'explicit_paddings',\n        'name': 'explicitPaddings',\n        'type': 'number[]',\n        'defaultValue': []\n      },\n      {\n        'tfName': 'dilations',\n        'name': 'dilations',\n        'type': 'number[]'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'FusedDepthwiseConv2dNative',\n    'category': 'convolution',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'filter',\n        'type': 'tensor'\n      },\n      {\n        'start': 2,\n        'end': 0,\n        'name': 'args',\n        'type': 'tensors'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'num_args',\n        'name': 'numArgs',\n        'type': 'number'\n      },\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      },\n      {\n        'tfName': 'strides',\n        'name': 'strides',\n        'type': 'number[]'\n      },\n      {\n        'tfName': 'padding',\n        'name': 'pad',\n        'type': 'string'\n      },\n      {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'defaultValue': 'NHWC'\n      },\n      {\n        'tfName': 'dilations',\n        'name': 'dilations',\n        'type': 'number[]',\n        'defaultValue': [\n          1,\n          1,\n          1,\n          1\n        ]\n      },\n      {\n        'tfName': 'fused_ops',\n        'name': 'fusedOps',\n        'type': 'string[]',\n        'defaultValue': []\n      },\n      {\n        'tfName': 'explicit_paddings',\n        'name': 'explicitPaddings',\n        'type': 'number[]',\n        'defaultValue': []\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Conv3D',\n    'category': 'convolution',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'filter',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'strides',\n        'name': 'strides',\n        'type': 'number[]'\n      },\n      {\n        'tfName': 'padding',\n        'name': 'pad',\n        'type': 'string'\n      },\n      {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'defaultValue': 'NHWC'\n      },\n      {\n        'tfName': 'dilations',\n        'name': 'dilations',\n        'type': 'number[]'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Dilation2D',\n    'category': 'convolution',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'filter',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'strides',\n        'name': 'strides',\n        'type': 'number[]'\n      },\n      {\n        'tfName': 'rates',\n        'name': 'dilations',\n        'type': 'number[]'\n      },\n      {\n        'tfName': 'padding',\n        'name': 'pad',\n        'type': 'string'\n      }\n    ]\n  }\n]\n;\n","\n/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {OpMapper} from '../types';\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'Fill',\n    'category': 'creation',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'shape',\n        'type': 'number[]'\n      },\n      {\n        'start': 1,\n        'name': 'value',\n        'type': 'number'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'LinSpace',\n    'category': 'creation',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'start',\n        'type': 'number'\n      },\n      {\n        'start': 1,\n        'name': 'stop',\n        'type': 'number'\n      },\n      {\n        'start': 2,\n        'name': 'num',\n        'type': 'number'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'OneHot',\n    'category': 'creation',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'indices',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'depth',\n        'type': 'number'\n      },\n      {\n        'start': 2,\n        'name': 'onValue',\n        'type': 'number',\n        'defaultValue': 1\n      },\n      {\n        'start': 3,\n        'name': 'offValue',\n        'type': 'number',\n        'defaultValue': 0\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'axis',\n        'name': 'axis',\n        'type': 'number',\n        'notSupported': true\n      },\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Ones',\n    'category': 'creation',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'shape',\n        'type': 'number[]'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'OnesLike',\n    'category': 'creation',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'dtype',\n        'name': 'dtype',\n        'type': 'dtype'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'RandomStandardNormal',\n    'category': 'creation',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'shape',\n        'type': 'number[]'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'seed',\n        'name': 'seed',\n        'type': 'number',\n        'defaultValue': 0\n      },\n      {\n        'tfName': 'seed2',\n        'name': 'seed2',\n        'type': 'number',\n        'defaultValue': 0,\n        'notSupported': true\n      },\n      {\n        'tfName': 'dtype',\n        'name': 'dtype',\n        'type': 'dtype'\n      },\n      {\n        'tfName': 'T',\n        'name': 'T',\n        'type': 'number',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'RandomUniform',\n    'category': 'creation',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'shape',\n        'type': 'number[]'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'minval',\n        'name': 'minval',\n        'type': 'number',\n        'defaultValue': 0\n      },\n      {\n        'tfName': 'maxval',\n        'name': 'maxval',\n        'type': 'number',\n        'defaultValue': 1\n      },\n      {\n        'tfName': 'dtype',\n        'name': 'dtype',\n        'type': 'dtype'\n      },\n      {\n        'tfName': 'seed',\n        'name': 'seed',\n        'type': 'number',\n        'defaultValue': 0\n      },\n      {\n        'tfName': 'seed2',\n        'name': 'seed2',\n        'type': 'number',\n        'defaultValue': 0,\n        'notSupported': true\n      },\n      {\n        'tfName': 'T',\n        'name': 'T',\n        'type': 'number',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Range',\n    'category': 'creation',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'start',\n        'type': 'number'\n      },\n      {\n        'start': 1,\n        'name': 'stop',\n        'type': 'number'\n      },\n      {\n        'start': 2,\n        'name': 'step',\n        'type': 'number',\n        'defaultValue': 0\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'Tidx',\n        'name': 'dtype',\n        'type': 'dtype'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'TruncatedNormal',\n    'category': 'creation',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'shape',\n        'type': 'number[]'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'means',\n        'name': 'mean',\n        'type': 'number',\n        'defaultValue': 0\n      },\n      {\n        'tfName': 'stddev',\n        'name': 'stdDev',\n        'type': 'number',\n        'defaultValue': 1\n      },\n      {\n        'tfName': 'seed',\n        'name': 'seed',\n        'type': 'number'\n      },\n      {\n        'tfName': 'seed2',\n        'name': 'seed2',\n        'type': 'number',\n        'defaultValue': 0,\n        'notSupported': true\n      },\n      {\n        'tfName': 'dtype',\n        'name': 'dtype',\n        'type': 'dtype'\n      },\n      {\n        'tfName': 'T',\n        'name': 'T',\n        'type': 'number',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Zeros',\n    'category': 'creation',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'shape',\n        'type': 'number[]'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'ZerosLike',\n    'category': 'creation',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Multinomial',\n    'category': 'creation',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'logits',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'numSamples',\n        'type': 'number'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'seed',\n        'name': 'seed',\n        'type': 'number'\n      },\n      {\n        'tfName': 'seed2',\n        'name': 'seed2',\n        'type': 'number'\n      },\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype'\n      },\n      {\n        'tfName': 'output_dtype',\n        'name': 'output_dtype',\n        'type': 'dtype'\n      }\n    ]\n  }\n]\n;\n","\n/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {OpMapper} from '../types';\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'NonMaxSuppressionV2',\n    'category': 'dynamic',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'boxes',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'scores',\n        'type': 'tensor'\n      },\n      {\n        'start': 2,\n        'name': 'maxOutputSize',\n        'type': 'number'\n      },\n      {\n        'start': 3,\n        'name': 'iouThreshold',\n        'type': 'number'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'NonMaxSuppressionV3',\n    'category': 'dynamic',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'boxes',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'scores',\n        'type': 'tensor'\n      },\n      {\n        'start': 2,\n        'name': 'maxOutputSize',\n        'type': 'number'\n      },\n      {\n        'start': 3,\n        'name': 'iouThreshold',\n        'type': 'number'\n      },\n      {\n        'start': 4,\n        'name': 'scoreThreshold',\n        'type': 'number'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'NonMaxSuppressionV4',\n    'category': 'dynamic',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'boxes',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'scores',\n        'type': 'tensor'\n      },\n      {\n        'start': 2,\n        'name': 'maxOutputSize',\n        'type': 'number'\n      },\n      {\n        'start': 3,\n        'name': 'iouThreshold',\n        'type': 'number'\n      },\n      {\n        'start': 4,\n        'name': 'scoreThreshold',\n        'type': 'number'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      },\n      {\n        'tfName': 'T_threshold',\n        'name': 'threshold',\n        'type': 'dtype',\n        'notSupported': true\n      },\n      {\n        'tfName': 'pad_to_max_output_size',\n        'name': 'padToMaxOutputSize',\n        'type': 'bool'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'NonMaxSuppressionV5',\n    'category': 'dynamic',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'boxes',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'scores',\n        'type': 'tensor'\n      },\n      {\n        'start': 2,\n        'name': 'maxOutputSize',\n        'type': 'number'\n      },\n      {\n        'start': 3,\n        'name': 'iouThreshold',\n        'type': 'number'\n      },\n      {\n        'start': 4,\n        'name': 'scoreThreshold',\n        'type': 'number'\n      },\n      {\n        'start': 5,\n        'name': 'softNmsSigma',\n        'type': 'number'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Where',\n    'category': 'dynamic',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'condition',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'ListDiff',\n    'category': 'dynamic',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'y',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  }\n];\n","\n/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {OpMapper} from '../types';\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'LowerBound',\n    'category': 'evaluation',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'sortedSequence',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'values',\n        'type': 'tensor'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'TopKV2',\n    'category': 'evaluation',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'k',\n        'type': 'number'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'sorted',\n        'name': 'sorted',\n        'type': 'bool'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'UpperBound',\n    'category': 'evaluation',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'sortedSequence',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'values',\n        'type': 'tensor'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Unique',\n    'category': 'evaluation',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'UniqueV2',\n    'category': 'evaluation',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'axis',\n        'type': 'number'\n      }\n    ]\n  }\n]\n;\n","\n/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {OpMapper} from '../types';\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'PlaceholderWithDefault',\n    'category': 'graph',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'default',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'shape',\n        'name': 'shape',\n        'type': 'shape'\n      },\n      {\n        'tfName': 'dtype',\n        'name': 'dtype',\n        'type': 'dtype'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Placeholder',\n    'category': 'graph',\n    'attrs': [\n      {\n        'tfName': 'shape',\n        'name': 'shape',\n        'type': 'shape'\n      },\n      {\n        'tfName': 'dtype',\n        'name': 'dtype',\n        'type': 'dtype'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Const',\n    'category': 'graph'\n  },\n  {\n    'tfOpName': 'Identity',\n    'category': 'graph',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'IdentityN',\n    'category': 'graph',\n    'inputs': [\n      {\n        'start': 0,\n        'end': 0,\n        'name': 'x',\n        'type': 'tensors'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Snapshot',\n    'category': 'graph',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Rank',\n    'category': 'graph',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Size',\n    'category': 'graph',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Shape',\n    'category': 'graph',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'ShapeN',\n    'category': 'graph',\n    'inputs': [\n      {\n        'start': 0,\n        'end': 0,\n        'name': 'x',\n        'type': 'tensors'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Print',\n    'category': 'graph',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'data',\n        'type': 'tensors'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'message',\n        'name': 'message',\n        'type': 'string'\n      },\n      {\n        'tfName': 'first_n',\n        'name': 'firstN',\n        'type': 'number',\n        'notSupported': true\n      },\n      {\n        'tfName': 'summarize',\n        'name': 'summarize',\n        'type': 'number',\n        'defaultValue': 3\n      }\n    ]\n  },\n  {\n    'tfOpName': 'NoOp',\n    'category': 'graph',\n    'inputs': []\n  },\n  {\n    'tfOpName': 'StopGradient',\n    'category': 'graph',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'FakeQuantWithMinMaxVars',\n    'category': 'graph',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'min',\n        'name': 'min',\n        'type': 'number'\n      },\n      {\n        'tfName': 'max',\n        'name': 'max',\n        'type': 'number'\n      }\n    ]\n  }\n];\n","\n/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {OpMapper} from '../types';\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'HashTable',\n    'category': 'hash_table',\n    'inputs': [],\n    'attrs': [\n      {\n        'tfName': 'shared_name',\n        'name': 'sharedName',\n        'type': 'string'\n      },\n      {\n        'tfName': 'use_node_name_sharing',\n        'name': 'useNodeNameSharing',\n        'type': 'bool'\n      },\n      {\n        'tfName': 'key_dtype',\n        'name': 'keyDType',\n        'type': 'dtype'\n      },\n      {\n        'tfName': 'value_dtype',\n        'name': 'valueDType',\n        'type': 'dtype'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'HashTableV2',\n    'category': 'hash_table',\n    'inputs': [],\n    'attrs': [\n      {\n        'tfName': 'shared_name',\n        'name': 'sharedName',\n        'type': 'string'\n      },\n      {\n        'tfName': 'use_node_name_sharing',\n        'name': 'useNodeNameSharing',\n        'type': 'bool'\n      },\n      {\n        'tfName': 'key_dtype',\n        'name': 'keyDType',\n        'type': 'dtype'\n      },\n      {\n        'tfName': 'value_dtype',\n        'name': 'valueDType',\n        'type': 'dtype'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'LookupTableImport',\n    'category': 'hash_table',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'tableHandle',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'keys',\n        'type': 'tensor'\n      },\n      {\n        'start': 2,\n        'name': 'values',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'Tin',\n        'name': 'tIn',\n        'type': 'dtype',\n        'notSupported': true\n      },\n      {\n        'tfName': 'Tout',\n        'name': 'tOut',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'LookupTableImportV2',\n    'category': 'hash_table',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'tableHandle',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'keys',\n        'type': 'tensor'\n      },\n      {\n        'start': 2,\n        'name': 'values',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'Tin',\n        'name': 'tIn',\n        'type': 'dtype',\n        'notSupported': true\n      },\n      {\n        'tfName': 'Tout',\n        'name': 'tOut',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'LookupTableFind',\n    'category': 'hash_table',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'tableHandle',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'keys',\n        'type': 'tensor'\n      },\n      {\n        'start': 2,\n        'name': 'defaultValue',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'Tin',\n        'name': 'tIn',\n        'type': 'dtype',\n        'notSupported': true\n      },\n      {\n        'tfName': 'Tout',\n        'name': 'tOut',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'LookupTableFindV2',\n    'category': 'hash_table',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'tableHandle',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'keys',\n        'type': 'tensor'\n      },\n      {\n        'start': 2,\n        'name': 'defaultValue',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'Tin',\n        'name': 'tIn',\n        'type': 'dtype',\n        'notSupported': true\n      },\n      {\n        'tfName': 'Tout',\n        'name': 'tOut',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'LookupTableSize',\n    'category': 'hash_table',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'tableHandle',\n        'type': 'tensor'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'LookupTableSizeV2',\n    'category': 'hash_table',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'tableHandle',\n        'type': 'tensor'\n      }\n    ]\n  }\n];\n","\n/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {OpMapper} from '../types';\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'ResizeBilinear',\n    'category': 'image',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'images',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'size',\n        'type': 'number[]'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'align_corners',\n        'name': 'alignCorners',\n        'type': 'bool'\n      },\n      {\n        'tfName': 'half_pixel_centers',\n        'name': 'halfPixelCenters',\n        'type': 'bool'\n      },\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'ResizeNearestNeighbor',\n    'category': 'image',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'images',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'size',\n        'type': 'number[]'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'align_corners',\n        'name': 'alignCorners',\n        'type': 'bool'\n      },\n      {\n        'tfName': 'half_pixel_centers',\n        'name': 'halfPixelCenters',\n        'type': 'bool'\n      },\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'CropAndResize',\n    'category': 'image',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'image',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'boxes',\n        'type': 'tensor'\n      },\n      {\n        'start': 2,\n        'name': 'boxInd',\n        'type': 'tensor'\n      },\n      {\n        'start': 3,\n        'name': 'cropSize',\n        'type': 'number[]'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'method',\n        'name': 'method',\n        'type': 'string'\n      },\n      {\n        'tfName': 'extrapolation_value',\n        'name': 'extrapolationValue',\n        'type': 'number'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'ImageProjectiveTransformV3',\n    'category': 'image',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'images',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'transforms',\n        'type': 'tensor'\n      },\n      {\n        'start': 2,\n        'name': 'outputShape',\n        'type': 'number[]'\n      },\n      {\n        'start': 3,\n        'name': 'fillValue',\n        'type': 'number'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'interpolation',\n        'name': 'interpolation',\n        'type': 'string'\n      },\n      {\n        'tfName': 'fill_mode',\n        'name': 'fillMode',\n        'type': 'string'\n      }\n    ]\n  }\n];\n","\n/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {OpMapper} from '../types';\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'Equal',\n    'category': 'logical',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'a',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'b',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'NotEqual',\n    'category': 'logical',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'a',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'b',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Greater',\n    'category': 'logical',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'a',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'b',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'GreaterEqual',\n    'category': 'logical',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'a',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'b',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Less',\n    'category': 'logical',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'a',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'b',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'LessEqual',\n    'category': 'logical',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'a',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'b',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'LogicalAnd',\n    'category': 'logical',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'a',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'b',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'LogicalNot',\n    'category': 'logical',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'a',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'LogicalOr',\n    'category': 'logical',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'a',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'b',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Select',\n    'category': 'logical',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'condition',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'a',\n        'type': 'tensor'\n      },\n      {\n        'start': 2,\n        'name': 'b',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'SelectV2',\n    'category': 'logical',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'condition',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'a',\n        'type': 'tensor'\n      },\n      {\n        'start': 2,\n        'name': 'b',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  }\n];\n","\n/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {OpMapper} from '../types';\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': '_FusedMatMul',\n    'category': 'matrices',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'a',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'b',\n        'type': 'tensor'\n      },\n      {\n        'start': 2,\n        'end': 0,\n        'name': 'args',\n        'type': 'tensors'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'num_args',\n        'name': 'numArgs',\n        'type': 'number'\n      },\n      {\n        'tfName': 'fused_ops',\n        'name': 'fusedOps',\n        'type': 'string[]',\n        'defaultValue': []\n      },\n      {\n        'tfName': 'epsilon',\n        'name': 'epsilon',\n        'type': 'number',\n        'defaultValue': 0.0001\n      },\n      {\n        'tfName': 'transpose_a',\n        'name': 'transposeA',\n        'type': 'bool',\n        'defaultValue': false\n      },\n      {\n        'tfName': 'transpose_b',\n        'name': 'transposeB',\n        'type': 'bool',\n        'defaultValue': false\n      },\n      {\n        'tfName': 'leakyrelu_alpha',\n        'name': 'leakyreluAlpha',\n        'type': 'number',\n        'defaultValue': 0.2\n      },\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'MatMul',\n    'category': 'matrices',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'a',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'b',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'transpose_a',\n        'name': 'transposeA',\n        'type': 'bool',\n        'defaultValue': false\n      },\n      {\n        'tfName': 'transpose_b',\n        'name': 'transposeB',\n        'type': 'bool',\n        'defaultValue': false\n      },\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'BatchMatMul',\n    'category': 'matrices',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'a',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'b',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'adj_x',\n        'name': 'transposeA',\n        'type': 'bool',\n        'defaultValue': false\n      },\n      {\n        'tfName': 'adj_y',\n        'name': 'transposeB',\n        'type': 'bool',\n        'defaultValue': false\n      },\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'BatchMatMulV2',\n    'category': 'matrices',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'a',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'b',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'adj_x',\n        'name': 'transposeA',\n        'type': 'bool',\n        'defaultValue': false\n      },\n      {\n        'tfName': 'adj_y',\n        'name': 'transposeB',\n        'type': 'bool',\n        'defaultValue': false\n      },\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Transpose',\n    'category': 'matrices',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'perm',\n        'type': 'number[]'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Einsum',\n    'category': 'matrices',\n    'inputs': [\n      {\n        'start': 0,\n        'end': 0,\n        'name': 'tensors',\n        'type': 'tensors'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'equation',\n        'name': 'equation',\n        'type': 'string'\n      },\n      {\n        'tfName': 'N',\n        'name': 'n',\n        'type': 'number',\n        'defaultValue': 2\n      },\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype'\n      }\n    ]\n  }\n]\n;\n","\n/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {OpMapper} from '../types';\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'EuclideanNorm',\n    'category': 'normalization',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'axis',\n        'type': 'number[]'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'keep_dims',\n        'name': 'keepDims',\n        'type': 'bool',\n        'defaultValue': false\n      }\n    ]\n  },\n  {\n    'tfOpName': 'FusedBatchNorm',\n    'category': 'normalization',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'scale',\n        'type': 'tensor'\n      },\n      {\n        'start': 2,\n        'name': 'offset',\n        'type': 'tensor'\n      },\n      {\n        'start': 3,\n        'name': 'mean',\n        'type': 'tensor'\n      },\n      {\n        'start': 4,\n        'name': 'variance',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'epsilon',\n        'name': 'epsilon',\n        'type': 'number',\n        'defaultValue': 0.001\n      },\n      {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'FusedBatchNormV2',\n    'category': 'normalization',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'scale',\n        'type': 'tensor'\n      },\n      {\n        'start': 2,\n        'name': 'offset',\n        'type': 'tensor'\n      },\n      {\n        'start': 3,\n        'name': 'mean',\n        'type': 'tensor'\n      },\n      {\n        'start': 4,\n        'name': 'variance',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'epsilon',\n        'name': 'epsilon',\n        'type': 'number',\n        'defaultValue': 0.001\n      },\n      {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'FusedBatchNormV3',\n    'category': 'normalization',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'scale',\n        'type': 'tensor'\n      },\n      {\n        'start': 2,\n        'name': 'offset',\n        'type': 'tensor'\n      },\n      {\n        'start': 3,\n        'name': 'mean',\n        'type': 'tensor'\n      },\n      {\n        'start': 4,\n        'name': 'variance',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'epsilon',\n        'name': 'epsilon',\n        'type': 'number',\n        'defaultValue': 0.001\n      },\n      {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'LRN',\n    'category': 'normalization',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'depth_radius',\n        'name': 'radius',\n        'type': 'number',\n        'defaultValue': 5\n      },\n      {\n        'tfName': 'bias',\n        'name': 'bias',\n        'type': 'number',\n        'defaultValue': 1\n      },\n      {\n        'tfName': 'alpha',\n        'name': 'alpha',\n        'type': 'number',\n        'defaultValue': 1\n      },\n      {\n        'tfName': 'beta',\n        'name': 'beta',\n        'type': 'number',\n        'defaultValue': 0.5\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Softmax',\n    'category': 'normalization',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'LogSoftmax',\n    'category': 'normalization',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'SparseToDense',\n    'category': 'normalization',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'sparseIndices',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'outputShape',\n        'type': 'number[]'\n      },\n      {\n        'start': 2,\n        'name': 'sparseValues',\n        'type': 'tensor'\n      },\n      {\n        'start': 3,\n        'name': 'defaultValue',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'validate_indices',\n        'name': 'validateIndices',\n        'type': 'bool',\n        'defaultValue': true,\n        'notSupported': true\n      }\n    ]\n  }\n]\n;\n","\n/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {OpMapper} from '../types';\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'Bincount',\n    'category': 'reduction',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'size',\n        'type': 'number'\n      },\n      {\n        'start': 2,\n        'name': 'weights',\n        'type': 'tensor'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'DenseBincount',\n    'category': 'reduction',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'size',\n        'type': 'number'\n      },\n      {\n        'start': 2,\n        'name': 'weights',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'binary_output',\n        'name': 'binaryOutput',\n        'type': 'bool'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Max',\n    'category': 'reduction',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'axis',\n        'type': 'number[]'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'keep_dims',\n        'name': 'keepDims',\n        'type': 'bool'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Mean',\n    'category': 'reduction',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'axis',\n        'type': 'number[]'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'keep_dims',\n        'name': 'keepDims',\n        'type': 'bool'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Min',\n    'category': 'reduction',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'axis',\n        'type': 'number[]'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'keep_dims',\n        'name': 'keepDims',\n        'type': 'bool'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Sum',\n    'category': 'reduction',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'axis',\n        'type': 'number[]'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'keep_dims',\n        'name': 'keepDims',\n        'type': 'bool'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'All',\n    'category': 'reduction',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'axis',\n        'type': 'number[]'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'keep_dims',\n        'name': 'keepDims',\n        'type': 'bool'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Any',\n    'category': 'reduction',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'axis',\n        'type': 'number[]'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'keep_dims',\n        'name': 'keepDims',\n        'type': 'bool'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'ArgMax',\n    'category': 'reduction',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'axis',\n        'type': 'number'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'ArgMin',\n    'category': 'reduction',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'axis',\n        'type': 'number'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Prod',\n    'category': 'reduction',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'axis',\n        'type': 'number[]'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'keep_dims',\n        'name': 'keepDims',\n        'type': 'bool'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Cumprod',\n    'category': 'reduction',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'axis',\n        'type': 'number'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'exclusive',\n        'name': 'exclusive',\n        'type': 'bool'\n      },\n      {\n        'tfName': 'reverse',\n        'name': 'reverse',\n        'type': 'bool'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Cumsum',\n    'category': 'reduction',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'axis',\n        'type': 'number'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'exclusive',\n        'name': 'exclusive',\n        'type': 'bool'\n      },\n      {\n        'tfName': 'reverse',\n        'name': 'reverse',\n        'type': 'bool'\n      }\n    ]\n  }\n]\n;\n","\n/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {OpMapper} from '../types';\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'ConcatV2',\n    'category': 'slice_join',\n    'inputs': [\n      {\n        'start': 0,\n        'end': -1,\n        'name': 'tensors',\n        'type': 'tensors'\n      },\n      {\n        'start': -1,\n        'name': 'axis',\n        'type': 'number'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'N',\n        'name': 'n',\n        'type': 'number',\n        'defaultValue': 2\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Concat',\n    'category': 'slice_join',\n    'inputs': [\n      {\n        'start': 1,\n        'end': 0,\n        'name': 'tensors',\n        'type': 'tensors'\n      },\n      {\n        'start': 0,\n        'name': 'axis',\n        'type': 'number'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'N',\n        'name': 'n',\n        'type': 'number',\n        'defaultValue': 2\n      }\n    ]\n  },\n  {\n    'tfOpName': 'GatherV2',\n    'category': 'slice_join',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'indices',\n        'type': 'tensor'\n      },\n      {\n        'start': 2,\n        'name': 'axis',\n        'type': 'number',\n        'defaultValue': 0\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'batch_dims',\n        'name': 'batchDims',\n        'type': 'number',\n        'defaultValue': 0\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Gather',\n    'category': 'slice_join',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'indices',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'validate_indices',\n        'name': 'validateIndices',\n        'type': 'bool',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Reverse',\n    'category': 'slice_join',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'dims',\n        'type': 'bool[]'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'ReverseV2',\n    'category': 'slice_join',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'axis',\n        'type': 'number[]'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Slice',\n    'category': 'slice_join',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'begin',\n        'type': 'number[]'\n      },\n      {\n        'start': 2,\n        'name': 'size',\n        'type': 'number[]'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'StridedSlice',\n    'category': 'slice_join',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'begin',\n        'type': 'number[]'\n      },\n      {\n        'start': 2,\n        'name': 'end',\n        'type': 'number[]'\n      },\n      {\n        'start': 3,\n        'name': 'strides',\n        'type': 'number[]'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'begin_mask',\n        'name': 'beginMask',\n        'type': 'number',\n        'defaultValue': 0\n      },\n      {\n        'tfName': 'end_mask',\n        'name': 'endMask',\n        'type': 'number',\n        'defaultValue': 0\n      },\n      {\n        'tfName': 'new_axis_mask',\n        'name': 'newAxisMask',\n        'type': 'number',\n        'defaultValue': 0\n      },\n      {\n        'tfName': 'ellipsis_mask',\n        'name': 'ellipsisMask',\n        'type': 'number',\n        'defaultValue': 0\n      },\n      {\n        'tfName': 'shrink_axis_mask',\n        'name': 'shrinkAxisMask',\n        'type': 'number',\n        'defaultValue': 0\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Pack',\n    'category': 'slice_join',\n    'inputs': [\n      {\n        'start': 0,\n        'end': 0,\n        'name': 'tensors',\n        'type': 'tensors'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'axis',\n        'name': 'axis',\n        'type': 'number',\n        'defaultValue': 0\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Unpack',\n    'category': 'slice_join',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'tensor',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'axis',\n        'name': 'axis',\n        'type': 'number',\n        'defaultValue': 0\n      },\n      {\n        'tfName': 'num',\n        'name': 'num',\n        'type': 'number',\n        'defaultValue': 0,\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Tile',\n    'category': 'slice_join',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'reps',\n        'type': 'number[]'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Split',\n    'category': 'slice_join',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'axis',\n        'type': 'number',\n        'defaultValue': 0\n      },\n      {\n        'start': 1,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'num_split',\n        'name': 'numOrSizeSplits',\n        'type': 'number',\n        'defaultValue': 1\n      }\n    ]\n  },\n  {\n    'tfOpName': 'SplitV',\n    'category': 'slice_join',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'numOrSizeSplits',\n        'type': 'number[]'\n      },\n      {\n        'start': 2,\n        'name': 'axis',\n        'type': 'number',\n        'defaultValue': 0\n      }\n    ]\n  },\n  {\n    'tfOpName': 'ScatterNd',\n    'category': 'slice_join',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'indices',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'values',\n        'type': 'tensor'\n      },\n      {\n        'start': 2,\n        'name': 'shape',\n        'type': 'number[]'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'GatherNd',\n    'category': 'slice_join',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'indices',\n        'type': 'tensor'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'SparseToDense',\n    'category': 'slice_join',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'sparseIndices',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'outputShape',\n        'type': 'number[]'\n      },\n      {\n        'start': 2,\n        'name': 'sparseValues',\n        'type': 'tensor'\n      },\n      {\n        'start': 3,\n        'name': 'defaultValue',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'validate_indices',\n        'name': 'validateIndices',\n        'type': 'bool',\n        'defaultValue': false,\n        'notSupported': true\n      }\n    ]\n  }\n];\n","\n/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {OpMapper} from '../types';\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'SparseFillEmptyRows',\n    'category': 'sparse',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'indices',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'values',\n        'type': 'tensor'\n      },\n      {\n        'start': 2,\n        'name': 'denseShape',\n        'type': 'tensor'\n      },\n      {\n        'start': 3,\n        'name': 'defaultValue',\n        'type': 'tensor'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'SparseReshape',\n    'category': 'sparse',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'inputIndices',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'inputShape',\n        'type': 'tensor'\n      },\n      {\n        'start': 2,\n        'name': 'newShape',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'SparseSegmentMean',\n    'category': 'sparse',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'data',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'indices',\n        'type': 'tensor'\n      },\n      {\n        'start': 2,\n        'name': 'segmentIds',\n        'type': 'tensor'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'SparseSegmentSum',\n    'category': 'sparse',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'data',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'indices',\n        'type': 'tensor'\n      },\n      {\n        'start': 2,\n        'name': 'segmentIds',\n        'type': 'tensor'\n      }\n    ]\n  }\n];\n","\n/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {OpMapper} from '../types';\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'FFT',\n    'category': 'spectral',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'IFFT',\n    'category': 'spectral',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'RFFT',\n    'category': 'spectral',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'fft_length',\n        'type': 'number',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'IRFFT',\n    'category': 'spectral',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'fft_length',\n        'type': 'number',\n        'notSupported': true\n      }\n    ]\n  }\n];\n","\n/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {OpMapper} from '../types';\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'StringNGrams',\n    'category': 'string',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'data',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'dataSplits',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'separator',\n        'name': 'separator',\n        'type': 'string'\n      },\n      {\n        'tfName': 'ngram_widths',\n        'name': 'nGramWidths',\n        'type': 'number[]'\n      },\n      {\n        'tfName': 'left_pad',\n        'name': 'leftPad',\n        'type': 'string'\n      },\n      {\n        'tfName': 'right_pad',\n        'name': 'rightPad',\n        'type': 'string'\n      },\n      {\n        'tfName': 'pad_width',\n        'name': 'padWidth',\n        'type': 'number'\n      },\n      {\n        'tfName': 'preserve_short_sequences',\n        'name': 'preserveShortSequences',\n        'type': 'bool'\n      }\n    ],\n    'outputs': [\n      'ngrams',\n      'ngrams_splits'\n    ]\n  },\n  {\n    'tfOpName': 'StringSplit',\n    'category': 'string',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'input',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'delimiter',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'skip_empty',\n        'name': 'skipEmpty',\n        'type': 'bool'\n      }\n    ],\n    'outputs': [\n      'indices',\n      'values',\n      'shape'\n    ]\n  },\n  {\n    'tfOpName': 'StringToHashBucketFast',\n    'category': 'string',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'input',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'num_buckets',\n        'name': 'numBuckets',\n        'type': 'number'\n      }\n    ]\n  }\n];\n","\n/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {OpMapper} from '../types';\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'Cast',\n    'category': 'transformation',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'SrcT',\n        'name': 'sdtype',\n        'type': 'dtype',\n        'notSupported': true\n      },\n      {\n        'tfName': 'DstT',\n        'name': 'dtype',\n        'type': 'dtype'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'ExpandDims',\n    'category': 'transformation',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'axis',\n        'type': 'number'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'MirrorPad',\n    'category': 'transformation',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'padding',\n        'type': 'number[]'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'mode',\n        'name': 'mode',\n        'type': 'string'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Pad',\n    'category': 'transformation',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'padding',\n        'type': 'number[]'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'constant_value',\n        'name': 'constantValue',\n        'type': 'number',\n        'defaultValue': 0\n      }\n    ]\n  },\n  {\n    'tfOpName': 'PadV2',\n    'category': 'transformation',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'padding',\n        'type': 'number[]'\n      },\n      {\n        'start': 2,\n        'name': 'constantValue',\n        'type': 'number',\n        'defaultValue': 0\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Reshape',\n    'category': 'transformation',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'shape',\n        'type': 'number[]'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Squeeze',\n    'category': 'transformation',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'axis',\n        'tfDeprecatedName': 'squeeze_dims',\n        'name': 'axis',\n        'type': 'number[]'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'SpaceToBatchND',\n    'category': 'transformation',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'blockShape',\n        'type': 'number[]'\n      },\n      {\n        'start': 2,\n        'name': 'paddings',\n        'type': 'number[]'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'BatchToSpaceND',\n    'category': 'transformation',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'blockShape',\n        'type': 'number[]'\n      },\n      {\n        'start': 2,\n        'name': 'crops',\n        'type': 'number[]'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'DepthToSpace',\n    'category': 'transformation',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'block_size',\n        'name': 'blockSize',\n        'type': 'number'\n      },\n      {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'BroadcastTo',\n    'category': 'transformation',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'shape',\n        'type': 'number[]'\n      }\n    ],\n    'attrs': []\n  },\n  {\n    'tfOpName': 'BroadcastArgs',\n    'category': 'transformation',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 's0',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 's1',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': []\n  }\n];\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, env} from '@tensorflow/tfjs-core';\n\nimport * as tensorflow from '../data/compiled_api';\n\nimport {getRegisteredOp} from './custom_op/register';\nimport {getNodeNameAndIndex} from './executors/utils';\nimport * as arithmetic from './op_list/arithmetic';\nimport * as basicMath from './op_list/basic_math';\nimport * as control from './op_list/control';\nimport * as convolution from './op_list/convolution';\nimport * as creation from './op_list/creation';\nimport * as dynamic from './op_list/dynamic';\nimport * as evaluation from './op_list/evaluation';\nimport * as graph from './op_list/graph';\nimport * as hashTable from './op_list/hash_table';\nimport * as image from './op_list/image';\nimport * as logical from './op_list/logical';\nimport * as matrices from './op_list/matrices';\nimport * as normalization from './op_list/normalization';\nimport * as reduction from './op_list/reduction';\nimport * as sliceJoin from './op_list/slice_join';\nimport * as sparse from './op_list/sparse';\nimport * as spectral from './op_list/spectral';\nimport * as string from './op_list/string';\nimport * as transformation from './op_list/transformation';\nimport {Graph, InputParamValue, Node, OpMapper, ParamValue} from './types';\n\nexport class OperationMapper {\n  private static _instance: OperationMapper;\n\n  private opMappers: {[key: string]: OpMapper};\n\n  // Singleton instance for the mapper\n  public static get Instance() {\n    return this._instance || (this._instance = new this());\n  }\n\n  // Loads the op mapping from the JSON file.\n  private constructor() {\n    const ops = [\n      arithmetic, basicMath, control, convolution, creation, dynamic,\n      evaluation, graph, hashTable, image, logical, matrices, normalization,\n      reduction, sliceJoin, sparse, spectral, string, transformation\n    ];\n    const mappersJson: OpMapper[] = [].concat(...ops.map(op => op.json));\n\n    this.opMappers = mappersJson.reduce<{[key: string]: OpMapper}>(\n        (map, mapper: OpMapper) => {\n          map[mapper.tfOpName] = mapper;\n          return map;\n        },\n        {});\n  }\n\n  // Converts the model inference graph from Tensorflow GraphDef to local\n  // representation for TensorFlow.js API\n  transformGraph(\n      graph: tensorflow.IGraphDef,\n      signature: tensorflow.ISignatureDef = {}): Graph {\n    const tfNodes = graph.node;\n    const placeholders: Node[] = [];\n    const weights: Node[] = [];\n    const initNodes: Node[] = [];\n    const nodes = tfNodes.reduce<{[key: string]: Node}>((map, node) => {\n      map[node.name] = this.mapNode(node);\n      if (node.op.startsWith('Placeholder')) {\n        placeholders.push(map[node.name]);\n      } else if (node.op === 'Const') {\n        weights.push(map[node.name]);\n      } else if (node.input == null || node.input.length === 0) {\n        initNodes.push(map[node.name]);\n      }\n      return map;\n    }, {});\n\n    let inputs: Node[] = [];\n    const outputs: Node[] = [];\n    let inputNodeNameToKey: {[key: string]: string} = {};\n    let outputNodeNameToKey: {[key: string]: string} = {};\n    if (signature != null) {\n      inputNodeNameToKey = this.mapSignatureEntries(signature.inputs);\n      outputNodeNameToKey = this.mapSignatureEntries(signature.outputs);\n    }\n    const allNodes = Object.keys(nodes);\n    allNodes.forEach(key => {\n      const node = nodes[key];\n      node.inputNames.forEach((name, index) => {\n        const [nodeName, , outputName] = getNodeNameAndIndex(name);\n        const inputNode = nodes[nodeName];\n        if (inputNode.outputs != null) {\n          const outputIndex = inputNode.outputs.indexOf(outputName);\n          if (outputIndex !== -1) {\n            const inputName = `${nodeName}:${outputIndex}`;\n            // update the input name to use the mapped output index directly.\n            node.inputNames[index] = inputName;\n          }\n        }\n        node.inputs.push(inputNode);\n        inputNode.children.push(node);\n      });\n    });\n\n    // if signature has not outputs set, add any node that does not have\n    // outputs.\n    if (Object.keys(outputNodeNameToKey).length === 0) {\n      allNodes.forEach(key => {\n        const node = nodes[key];\n        if (node.children.length === 0) {\n          outputs.push(node);\n        }\n      });\n    } else {\n      Object.keys(outputNodeNameToKey).forEach(name => {\n        const [nodeName, ] = getNodeNameAndIndex(name);\n        const node = nodes[nodeName];\n        if (node != null) {\n          node.signatureKey = outputNodeNameToKey[name];\n          outputs.push(node);\n        }\n      });\n    }\n\n    if (Object.keys(inputNodeNameToKey).length > 0) {\n      Object.keys(inputNodeNameToKey).forEach(name => {\n        const [nodeName, ] = getNodeNameAndIndex(name);\n        const node = nodes[nodeName];\n        if (node) {\n          node.signatureKey = inputNodeNameToKey[name];\n          inputs.push(node);\n        }\n      });\n    } else {\n      inputs = placeholders;\n    }\n\n    let functions = {};\n    if (graph.library != null && graph.library.function != null) {\n      functions = graph.library.function.reduce((functions, func) => {\n        functions[func.signature.name] = this.mapFunction(func);\n        return functions;\n      }, {} as {[key: string]: Graph});\n    }\n\n    const result: Graph =\n        {nodes, inputs, outputs, weights, placeholders, signature, functions};\n\n    if (initNodes.length > 0) {\n      result.initNodes = initNodes;\n    }\n\n    return result;\n  }\n\n  private mapSignatureEntries(entries: {[k: string]: tensorflow.ITensorInfo}) {\n    return Object.keys(entries || {})\n        .reduce<{[key: string]: string}>((prev, curr) => {\n          prev[entries[curr].name] = curr;\n          return prev;\n        }, {});\n  }\n\n  private mapNode(node: tensorflow.INodeDef): Node {\n    // Unsupported ops will cause an error at run-time (not parse time), since\n    // they may not be used by the actual execution subgraph.\n    const mapper =\n        getRegisteredOp(node.op) || this.opMappers[node.op] || {} as OpMapper;\n    if (node.attr == null) {\n      node.attr = {};\n    }\n\n    const newNode: Node = {\n      name: node.name,\n      op: node.op,\n      category: mapper.category,\n      inputNames:\n          (node.input ||\n           []).map(input => input.startsWith('^') ? input.slice(1) : input),\n      inputs: [],\n      children: [],\n      inputParams: {},\n      attrParams: {},\n      rawAttrs: node.attr,\n      outputs: mapper.outputs\n    };\n\n    if (mapper.inputs != null) {\n      newNode.inputParams =\n          mapper.inputs.reduce<{[key: string]: InputParamValue}>(\n              (map, param) => {\n                map[param.name] = {\n                  type: param.type,\n                  inputIndexStart: param.start,\n                  inputIndexEnd: param.end\n                };\n                return map;\n              },\n              {});\n    }\n    if (mapper.attrs != null) {\n      newNode.attrParams =\n          mapper.attrs.reduce<{[key: string]: ParamValue}>((map, param) => {\n            const type = param.type;\n            let value = undefined;\n            switch (param.type) {\n              case 'string':\n                value = getStringParam(\n                    node.attr, param.tfName, param.defaultValue as string);\n\n                if (value === undefined && !!param.tfDeprecatedName) {\n                  value = getStringParam(\n                      node.attr, param.tfDeprecatedName,\n                      param.defaultValue as string);\n                }\n                break;\n              case 'string[]':\n                value = getStringArrayParam(\n                    node.attr, param.tfName, param.defaultValue as string[]);\n\n                if (value === undefined && !!param.tfDeprecatedName) {\n                  value = getStringArrayParam(\n                      node.attr, param.tfDeprecatedName,\n                      param.defaultValue as string[]);\n                }\n                break;\n              case 'number':\n                value = getNumberParam(\n                    node.attr, param.tfName,\n                    (param.defaultValue || 0) as number);\n                if (value === undefined && !!param.tfDeprecatedName) {\n                  value = getNumberParam(\n                      node.attr, param.tfDeprecatedName,\n                      param.defaultValue as number);\n                }\n                break;\n              case 'number[]':\n                value = getNumericArrayParam(\n                    node.attr, param.tfName, param.defaultValue as number[]);\n                if (value === undefined && !!param.tfDeprecatedName) {\n                  value = getNumericArrayParam(\n                      node.attr, param.tfDeprecatedName,\n                      param.defaultValue as number[]);\n                }\n                break;\n              case 'bool':\n                value = getBoolParam(\n                    node.attr, param.tfName, param.defaultValue as boolean);\n                if (value === undefined && !!param.tfDeprecatedName) {\n                  value = getBoolParam(\n                      node.attr, param.tfDeprecatedName,\n                      param.defaultValue as boolean);\n                }\n                break;\n              case 'bool[]':\n                value = getBoolArrayParam(\n                    node.attr, param.tfName, param.defaultValue as boolean[]);\n                if (value === undefined && !!param.tfDeprecatedName) {\n                  value = getBoolArrayParam(\n                      node.attr, param.tfDeprecatedName,\n                      param.defaultValue as boolean[]);\n                }\n                break;\n              case 'shape':\n                value = getTensorShapeParam(\n                    node.attr, param.tfName, param.defaultValue as number[]);\n                if (value === undefined && !!param.tfDeprecatedName) {\n                  value = getTensorShapeParam(\n                      node.attr, param.tfDeprecatedName,\n                      param.defaultValue as number[]);\n                }\n                break;\n              case 'shape[]':\n                value = getTensorShapeArrayParam(\n                    node.attr, param.tfName, param.defaultValue as number[][]);\n                if (value === undefined && !!param.tfDeprecatedName) {\n                  value = getTensorShapeArrayParam(\n                      node.attr, param.tfDeprecatedName,\n                      param.defaultValue as number[][]);\n                }\n                break;\n              case 'dtype':\n                value = getDtypeParam(\n                    node.attr, param.tfName, param.defaultValue as DataType);\n                if (value === undefined && !!param.tfDeprecatedName) {\n                  value = getDtypeParam(\n                      node.attr, param.tfDeprecatedName,\n                      param.defaultValue as DataType);\n                }\n                break;\n              case 'dtype[]':\n                value = getDtypeArrayParam(\n                    node.attr, param.tfName, param.defaultValue as DataType[]);\n                if (value === undefined && !!param.tfDeprecatedName) {\n                  value = getDtypeArrayParam(\n                      node.attr, param.tfDeprecatedName,\n                      param.defaultValue as DataType[]);\n                }\n                break;\n              case 'func':\n                value = getFuncParam(\n                    node.attr, param.tfName, param.defaultValue as string);\n                if (value === undefined && !!param.tfDeprecatedName) {\n                  value = getFuncParam(\n                      node.attr, param.tfDeprecatedName,\n                      param.defaultValue as string);\n                }\n                break;\n              case 'tensor':\n              case 'tensors':\n                break;\n              default:\n                throw new Error(\n                    `Unsupported param type: ${param.type} for op: ${node.op}`);\n            }\n            map[param.name] = {value, type};\n            return map;\n          }, {});\n    }\n    return newNode;\n  }\n\n  // map the TFunctionDef to TFJS graph object\n  private mapFunction(functionDef: tensorflow.IFunctionDef): Graph {\n    const tfNodes = functionDef.nodeDef;\n    const placeholders: Node[] = [];\n    const weights: Node[] = [];\n    let nodes: {[key: string]: Node} = {};\n    if (tfNodes != null) {\n      nodes = tfNodes.reduce<{[key: string]: Node}>((map, node) => {\n        map[node.name] = this.mapNode(node);\n        if (node.op === 'Const') {\n          weights.push(map[node.name]);\n        }\n        return map;\n      }, {});\n    }\n    const inputs: Node[] = [];\n    const outputs: Node[] = [];\n\n    functionDef.signature.inputArg.forEach(arg => {\n      const [nodeName, ] = getNodeNameAndIndex(arg.name);\n      const node: Node = {\n        name: nodeName,\n        op: 'Placeholder',\n        inputs: [],\n        inputNames: [],\n        category: 'graph',\n        inputParams: {},\n        attrParams: {dtype: {value: parseDtypeParam(arg.type), type: 'dtype'}},\n        children: []\n      };\n      node.signatureKey = arg.name;\n      inputs.push(node);\n      nodes[nodeName] = node;\n    });\n\n    const allNodes = Object.keys(nodes);\n    allNodes.forEach(key => {\n      const node = nodes[key];\n      node.inputNames.forEach((name, index) => {\n        const [nodeName, , outputName] = getNodeNameAndIndex(name);\n        const inputNode = nodes[nodeName];\n        if (inputNode.outputs != null) {\n          const outputIndex = inputNode.outputs.indexOf(outputName);\n          if (outputIndex !== -1) {\n            const inputName = `${nodeName}:${outputIndex}`;\n            // update the input name to use the mapped output index directly.\n            node.inputNames[index] = inputName;\n          }\n        }\n        node.inputs.push(inputNode);\n        inputNode.children.push(node);\n      });\n    });\n\n    const returnNodeMap = functionDef.ret;\n\n    functionDef.signature.outputArg.forEach(output => {\n      const [nodeName, index] = getNodeNameAndIndex(returnNodeMap[output.name]);\n      const node = nodes[nodeName];\n      if (node != null) {\n        node.defaultOutput = index;\n        outputs.push(node);\n      }\n    });\n\n    const signature = this.mapArgsToSignature(functionDef);\n    return {nodes, inputs, outputs, weights, placeholders, signature};\n  }\n\n  private mapArgsToSignature(functionDef: tensorflow.IFunctionDef):\n      tensorflow.ISignatureDef {\n    return {\n      methodName: functionDef.signature.name,\n      inputs: functionDef.signature.inputArg.reduce(\n          (map, arg) => {\n            map[arg.name] = this.mapArgToTensorInfo(arg);\n            return map;\n          },\n          {} as {[key: string]: tensorflow.ITensorInfo}),\n      outputs: functionDef.signature.outputArg.reduce(\n          (map, arg) => {\n            map[arg.name] = this.mapArgToTensorInfo(arg, functionDef.ret);\n            return map;\n          },\n          {} as {[key: string]: tensorflow.ITensorInfo}),\n    };\n  }\n\n  private mapArgToTensorInfo(\n      arg: tensorflow.OpDef.IArgDef,\n      nameMap?: {[key: string]: string}): tensorflow.ITensorInfo {\n    let name = arg.name;\n    if (nameMap != null) {\n      name = nameMap[name];\n    }\n    return {name, dtype: arg.type};\n  }\n}\n\nexport function decodeBase64(text: string): string {\n  const global = env().global;\n  if (typeof global.atob !== 'undefined') {\n    return global.atob(text);\n  } else if (typeof Buffer !== 'undefined') {\n    return new Buffer(text, 'base64').toString();\n  } else {\n    throw new Error(\n        'Unable to decode base64 in this environment. ' +\n        'Missing built-in atob() or Buffer()');\n  }\n}\n\nexport function parseStringParam(s: []|string, keepCase: boolean): string {\n  const value =\n      Array.isArray(s) ? String.fromCharCode.apply(null, s) : decodeBase64(s);\n  return keepCase ? value : value.toLowerCase();\n}\n\nexport function getStringParam(\n    attrs: {[key: string]: tensorflow.IAttrValue}, name: string, def: string,\n    keepCase = false): string {\n  const param = attrs[name];\n  if (param != null) {\n    return parseStringParam(param.s, keepCase);\n  }\n  return def;\n}\n\nexport function getBoolParam(\n    attrs: {[key: string]: tensorflow.IAttrValue}, name: string,\n    def: boolean): boolean {\n  const param = attrs[name];\n  return param ? param.b : def;\n}\n\nexport function getNumberParam(\n    attrs: {[key: string]: tensorflow.IAttrValue}, name: string,\n    def: number): number {\n  const param = attrs[name] || {};\n  const value =\n      param['i'] != null ? param['i'] : (param['f'] != null ? param['f'] : def);\n  return (typeof value === 'number') ? value : parseInt(value, 10);\n}\n\nexport function parseDtypeParam(value: string|tensorflow.DataType): DataType {\n  if (typeof (value) === 'string') {\n    // tslint:disable-next-line:no-any\n    value = tensorflow.DataType[value as any];\n  }\n  switch (value) {\n    case tensorflow.DataType.DT_FLOAT:\n    case tensorflow.DataType.DT_HALF:\n      return 'float32';\n    case tensorflow.DataType.DT_INT32:\n    case tensorflow.DataType.DT_INT64:\n    case tensorflow.DataType.DT_INT8:\n    case tensorflow.DataType.DT_UINT8:\n      return 'int32';\n    case tensorflow.DataType.DT_BOOL:\n      return 'bool';\n    case tensorflow.DataType.DT_DOUBLE:\n      return 'float32';\n    case tensorflow.DataType.DT_STRING:\n      return 'string';\n    default:\n      // Unknown dtype error will happen at runtime (instead of parse time),\n      // since these nodes might not be used by the actual subgraph execution.\n      return null;\n  }\n}\n\nexport function getFuncParam(\n    attrs: {[key: string]: tensorflow.IAttrValue}, name: string,\n    def: string): string {\n  const param = attrs[name];\n  if (param && param.func) {\n    return param.func.name;\n  }\n  return def;\n}\n\nexport function getDtypeParam(\n    attrs: {[key: string]: tensorflow.IAttrValue}, name: string,\n    def: DataType): DataType {\n  const param = attrs[name];\n  if (param && param.type) {\n    return parseDtypeParam(param.type);\n  }\n  return def;\n}\n\nexport function getDtypeArrayParam(\n    attrs: {[key: string]: tensorflow.IAttrValue}, name: string,\n    def: DataType[]): DataType[] {\n  const param = attrs[name];\n  if (param && param.list && param.list.type) {\n    return param.list.type.map(v => parseDtypeParam(v));\n  }\n  return def;\n}\n\nexport function parseTensorShapeParam(shape: tensorflow.ITensorShape): number[]|\n    undefined {\n  if (shape.unknownRank) {\n    return undefined;\n  }\n  if (shape.dim != null) {\n    return shape.dim.map(\n        dim =>\n            (typeof dim.size === 'number') ? dim.size : parseInt(dim.size, 10));\n  }\n  return [];\n}\n\nexport function getTensorShapeParam(\n    attrs: {[key: string]: tensorflow.IAttrValue}, name: string,\n    def?: number[]): number[]|undefined {\n  const param = attrs[name];\n  if (param && param.shape) {\n    return parseTensorShapeParam(param.shape);\n  }\n  return def;\n}\n\nexport function getNumericArrayParam(\n    attrs: {[key: string]: tensorflow.IAttrValue}, name: string,\n    def: number[]): number[] {\n  const param = attrs[name];\n  if (param) {\n    return ((param.list.f && param.list.f.length ? param.list.f :\n                                                   param.list.i) ||\n            [])\n        .map(v => (typeof v === 'number') ? v : parseInt(v, 10));\n  }\n  return def;\n}\n\nexport function getStringArrayParam(\n    attrs: {[key: string]: tensorflow.IAttrValue}, name: string, def: string[],\n    keepCase = false): string[] {\n  const param = attrs[name];\n  if (param && param.list && param.list.s) {\n    return param.list.s.map((v) => {\n      return parseStringParam(v, keepCase);\n    });\n  }\n  return def;\n}\n\nexport function getTensorShapeArrayParam(\n    attrs: {[key: string]: tensorflow.IAttrValue}, name: string,\n    def: number[][]): number[][] {\n  const param = attrs[name];\n  if (param && param.list && param.list.shape) {\n    return param.list.shape.map((v) => {\n      return parseTensorShapeParam(v);\n    });\n  }\n  return def;\n}\n\nexport function getBoolArrayParam(\n    attrs: {[key: string]: tensorflow.IAttrValue}, name: string,\n    def: boolean[]): boolean[] {\n  const param = attrs[name];\n  if (param && param.list && param.list.b) {\n    return param.list.b;\n  }\n  return def;\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, Tensor} from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {getTensor} from '../executors/utils';\nimport {getBoolArrayParam, getBoolParam, getDtypeArrayParam, getDtypeParam, getNumberParam, getNumericArrayParam, getStringArrayParam, getStringParam, getTensorShapeArrayParam, getTensorShapeParam} from '../operation_mapper';\nimport {GraphNode, Node, ValueType} from '../types';\n\n/**\n * Helper class for lookup inputs and params for nodes in the model graph.\n */\nexport class NodeValueImpl implements GraphNode {\n  public readonly inputs: Tensor[] = [];\n  public readonly attrs: {[key: string]: ValueType} = {};\n  constructor(\n      private node: Node, private tensorMap: NamedTensorsMap,\n      private context: ExecutionContext) {\n    this.inputs = node.inputNames.map(name => this.getInput(name));\n    if (node.rawAttrs != null) {\n      this.attrs = Object.keys(node.rawAttrs)\n                       .reduce((attrs: {[key: string]: ValueType}, key) => {\n                         attrs[key] = this.getAttr(key);\n                         return attrs;\n                       }, {});\n    }\n  }\n\n  /**\n   * Return the value of the attribute or input param.\n   * @param name String: name of attribute or input param.\n   */\n  private getInput(name: string): Tensor {\n    return getTensor(name, this.tensorMap, this.context);\n  }\n\n  /**\n   * Return the value of the attribute or input param.\n   * @param name String: name of attribute or input param.\n   */\n  private getAttr(name: string, defaultValue?: ValueType): ValueType {\n    const value = this.node.rawAttrs[name];\n    if (value.tensor != null) {\n      return getTensor(name, this.tensorMap, this.context);\n    }\n    if (value.i != null || value.f != null) {\n      return getNumberParam(this.node.rawAttrs, name, defaultValue as number);\n    }\n    if (value.s != null) {\n      return getStringParam(this.node.rawAttrs, name, defaultValue as string);\n    }\n    if (value.b != null) {\n      return getBoolParam(this.node.rawAttrs, name, defaultValue as boolean);\n    }\n    if (value.shape != null) {\n      return getTensorShapeParam(\n          this.node.rawAttrs, name, defaultValue as number[]);\n    }\n    if (value.type != null) {\n      return getDtypeParam(this.node.rawAttrs, name, defaultValue as DataType);\n    }\n    if (value.list != null) {\n      if (value.list.i != null || value.list.f != null) {\n        return getNumericArrayParam(\n            this.node.rawAttrs, name, defaultValue as number[]);\n      }\n      if (value.list.s != null) {\n        return getStringArrayParam(\n            this.node.rawAttrs, name, defaultValue as string[]);\n      }\n      if (value.list.shape != null) {\n        return getTensorShapeArrayParam(\n            this.node.rawAttrs, name, defaultValue as number[][]);\n      }\n      if (value.list.b != null) {\n        return getBoolArrayParam(\n            this.node.rawAttrs, name, defaultValue as boolean[]);\n      }\n      if (value.list.type != null) {\n        return getDtypeArrayParam(\n            this.node.rawAttrs, name, defaultValue as DataType[]);\n      }\n    }\n\n    return defaultValue;\n  }\n}\n","\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n/**\n * This differs from util.assertShapesMatch in that it allows values of\n * negative one, an undefined size of a dimensinon, in a shape to match\n * anything.\n */\n\nimport {Tensor, util} from '@tensorflow/tfjs-core';\n\n/**\n * Used by TensorList and TensorArray to verify if elementShape matches, support\n * negative value as the dim shape.\n * @param shapeA\n * @param shapeB\n * @param errorMessagePrefix\n */\nexport function assertShapesMatchAllowUndefinedSize(\n    shapeA: number|number[], shapeB: number|number[],\n    errorMessagePrefix = ''): void {\n  // constant shape means unknown rank\n  if (typeof shapeA === 'number' || typeof shapeB === 'number') {\n    return;\n  }\n  util.assert(\n      shapeA.length === shapeB.length,\n      () => errorMessagePrefix + ` Shapes ${shapeA} and ${shapeB} must match`);\n  for (let i = 0; i < shapeA.length; i++) {\n    const dim0 = shapeA[i];\n    const dim1 = shapeB[i];\n    util.assert(\n        dim0 < 0 || dim1 < 0 || dim0 === dim1,\n        () =>\n            errorMessagePrefix + ` Shapes ${shapeA} and ${shapeB} must match`);\n  }\n}\n\nexport function fullDefinedShape(elementShape: number|number[]): boolean {\n  if (typeof elementShape === 'number' || elementShape.some(dim => dim < 0)) {\n    return false;\n  }\n  return true;\n}\n/**\n * Generate the output element shape from the list elementShape, list tensors\n * and input param.\n * @param listElementShape\n * @param tensors\n * @param elementShape\n */\nexport function inferElementShape(\n    listElementShape: number|number[], tensors: Tensor[],\n    elementShape: number|number[]): number[] {\n  let partialShape = mergeElementShape(listElementShape, elementShape);\n  const notfullDefinedShape = !fullDefinedShape(partialShape);\n  if (notfullDefinedShape && tensors.length === 0) {\n    throw new Error(\n        `Tried to calculate elements of an empty list` +\n        ` with non-fully-defined elementShape: ${partialShape}`);\n  }\n  if (notfullDefinedShape) {\n    tensors.forEach(tensor => {\n      partialShape = mergeElementShape(tensor.shape, partialShape);\n    });\n  }\n  if (!fullDefinedShape(partialShape)) {\n    throw new Error(`Non-fully-defined elementShape: ${partialShape}`);\n  }\n  return partialShape as number[];\n}\n\nexport function mergeElementShape(\n    elementShapeA: number|number[], elementShapeB: number|number[]): number|\n    number[] {\n  if (typeof elementShapeA === 'number') {\n    return elementShapeB;\n  }\n  if (typeof elementShapeB === 'number') {\n    return elementShapeA;\n  }\n\n  if (elementShapeA.length !== elementShapeB.length) {\n    throw new Error(`Incompatible ranks during merge: ${elementShapeA} vs. ${\n        elementShapeB}`);\n  }\n\n  const result: number[] = [];\n  for (let i = 0; i < elementShapeA.length; ++i) {\n    const dim0 = elementShapeA[i];\n    const dim1 = elementShapeB[i];\n    if (dim0 >= 0 && dim1 >= 0 && dim0 !== dim1) {\n      throw new Error(`Incompatible shape during merge: ${elementShapeA} vs. ${\n          elementShapeB}`);\n    }\n    result[i] = dim0 >= 0 ? dim0 : dim1;\n  }\n  return result;\n}\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {concat, DataType, keep, reshape, scalar, slice, stack, Tensor, tensor, tidy, unstack} from '@tensorflow/tfjs-core';\n\nimport {assertShapesMatchAllowUndefinedSize} from './tensor_utils';\n\nexport interface TensorWithState {\n  tensor?: Tensor;\n  written?: boolean;\n  read?: boolean;\n  cleared?: boolean;\n}\n/**\n * The TensorArray object keeps an array of Tensors.  It\n * allows reading from the array and writing to the array.\n */\nexport class TensorArray {\n  private tensors: TensorWithState[] = [];\n  private closed_ = false;\n  readonly idTensor: Tensor;\n  constructor(\n      readonly name: string, readonly dtype: DataType, private maxSize: number,\n      private elementShape: number[], readonly identicalElementShapes: boolean,\n      readonly dynamicSize: boolean, readonly clearAfterRead: boolean) {\n    this.idTensor = scalar(0);\n    keep(this.idTensor);\n  }\n\n  get id() {\n    return this.idTensor.id;\n  }\n\n  get closed() {\n    return this.closed_;\n  }\n\n  /**\n   * Dispose the tensors and idTensor and mark the TensoryArray as closed.\n   */\n  clearAndClose(keepIds?: Set<number>) {\n    this.tensors.forEach(tensor => {\n      if (keepIds == null || !keepIds.has(tensor.tensor.id)) {\n        tensor.tensor.dispose();\n      }\n    });\n    this.tensors = [];\n    this.closed_ = true;\n    this.idTensor.dispose();\n  }\n\n  size(): number {\n    return this.tensors.length;\n  }\n\n  /**\n   * Read the value at location index in the TensorArray.\n   * @param index Number the index to read from.\n   */\n  read(index: number): Tensor {\n    if (this.closed_) {\n      throw new Error(`TensorArray ${this.name} has already been closed.`);\n    }\n\n    if (index < 0 || index >= this.size()) {\n      throw new Error(`Tried to read from index ${index}, but array size is: ${\n          this.size()}`);\n    }\n\n    const tensorWithState = this.tensors[index];\n    if (tensorWithState.cleared) {\n      throw new Error(\n          `TensorArray ${this.name}: Could not read index ${\n              index} twice because it was cleared after a previous read ` +\n          `(perhaps try setting clear_after_read = false?).`);\n    }\n\n    if (this.clearAfterRead) {\n      tensorWithState.cleared = true;\n    }\n\n    tensorWithState.read = true;\n    return tensorWithState.tensor;\n  }\n\n  /**\n   * Helper method to read multiple tensors from the specified indices.\n   */\n  readMany(indices: number[]): Tensor[] {\n    return indices.map(index => this.read(index));\n  }\n\n  /**\n   * Write value into the index of the TensorArray.\n   * @param index number the index to write to.\n   * @param tensor\n   */\n  write(index: number, tensor: Tensor) {\n    if (this.closed_) {\n      throw new Error(`TensorArray ${this.name} has already been closed.`);\n    }\n\n    if (index < 0 || !this.dynamicSize && index >= this.maxSize) {\n      throw new Error(`Tried to write to index ${\n          index}, but array is not resizeable and size is: ${this.maxSize}`);\n    }\n\n    const t = this.tensors[index] || {};\n\n    if (tensor.dtype !== this.dtype) {\n      throw new Error(`TensorArray ${\n          this.name}: Could not write to TensorArray index ${index},\n          because the value dtype is ${\n          tensor.dtype}, but TensorArray dtype is ${this.dtype}.`);\n    }\n\n    // Set the shape for the first time write to unknow shape tensor array\n    if (this.size() === 0 &&\n        (this.elementShape == null || this.elementShape.length === 0)) {\n      this.elementShape = tensor.shape;\n    }\n\n    assertShapesMatchAllowUndefinedSize(\n        this.elementShape, tensor.shape,\n        `TensorArray ${this.name}: Could not write to TensorArray index ${\n            index}.`);\n\n    if (t.read) {\n      throw new Error(\n          `TensorArray ${this.name}: Could not write to TensorArray index ${\n              index}, because it has already been read.`);\n    }\n\n    if (t.written) {\n      throw new Error(\n          `TensorArray ${this.name}: Could not write to TensorArray index ${\n              index}, because it has already been written.`);\n    }\n\n    t.tensor = tensor;\n    keep(tensor);\n    t.written = true;\n\n    this.tensors[index] = t;\n  }\n\n  /**\n   * Helper method to write multiple tensors to the specified indices.\n   */\n  writeMany(indices: number[], tensors: Tensor[]) {\n    if (indices.length !== tensors.length) {\n      throw new Error(\n          `TensorArray ${this.name}: could not write multiple tensors,` +\n          `because the index size: ${\n              indices.length} is not the same as tensors size: ${\n              tensors.length}.`);\n    }\n\n    indices.forEach((i, index) => this.write(i, tensors[index]));\n  }\n\n  /**\n   * Return selected values in the TensorArray as a packed Tensor. All of\n   * selected values must have been written and their shapes must all match.\n   * @param [indices] number[] Optional. Taking values in [0, max_value). If the\n   *    TensorArray is not dynamic, max_value=size(). If not specified returns\n   *    all tensors in the original order.\n   * @param [dtype]\n   */\n  gather(indices?: number[], dtype?: DataType): Tensor {\n    if (!!dtype && dtype !== this.dtype) {\n      throw new Error(`TensorArray dtype is ${\n          this.dtype} but gather requested dtype ${dtype}`);\n    }\n\n    if (!indices) {\n      indices = [];\n      for (let i = 0; i < this.size(); i++) {\n        indices.push(i);\n      }\n    } else {\n      indices = indices.slice(0, this.size());\n    }\n\n    if (indices.length === 0) {\n      return tensor([], [0].concat(this.elementShape));\n    }\n\n    // Read all the PersistentTensors into a vector to keep track of\n    // their memory.\n    const tensors = this.readMany(indices);\n\n    assertShapesMatchAllowUndefinedSize(\n        this.elementShape, tensors[0].shape, 'TensorArray shape mismatch: ');\n\n    return stack(tensors, 0);\n  }\n\n  /**\n   * Return the values in the TensorArray as a concatenated Tensor.\n   */\n  concat(dtype?: DataType): Tensor {\n    if (!!dtype && dtype !== this.dtype) {\n      throw new Error(`TensorArray dtype is ${\n          this.dtype} but concat requested dtype ${dtype}`);\n    }\n\n    if (this.size() === 0) {\n      return tensor([], [0].concat(this.elementShape));\n    }\n\n    const indices = [];\n    for (let i = 0; i < this.size(); i++) {\n      indices.push(i);\n    }\n    // Collect all the tensors from the tensors array.\n    const tensors = this.readMany(indices);\n\n    assertShapesMatchAllowUndefinedSize(\n        this.elementShape, tensors[0].shape,\n        `TensorArray shape mismatch: tensor array shape (${\n            this.elementShape}) vs first tensor shape (${tensors[0].shape})`);\n\n    return concat(tensors, 0);\n  }\n\n  /**\n   * Scatter the values of a Tensor in specific indices of a TensorArray.\n   * @param indices nummber[] values in [0, max_value). If the\n   *    TensorArray is not dynamic, max_value=size().\n   * @param tensor Tensor input tensor.\n   */\n  scatter(indices: number[], tensor: Tensor) {\n    if (tensor.dtype !== this.dtype) {\n      throw new Error(`TensorArray dtype is ${\n          this.dtype} but tensor has dtype ${tensor.dtype}`);\n    }\n\n    if (indices.length !== tensor.shape[0]) {\n      throw new Error(`Expected len(indices) == tensor.shape[0], but saw: ${\n          indices.length} vs. ${tensor.shape[0]}`);\n    }\n\n    const maxIndex = Math.max(...indices);\n\n    if (!this.dynamicSize && maxIndex >= this.maxSize) {\n      throw new Error(\n          `Max index must be < array size (${maxIndex}  vs. ${this.maxSize})`);\n    }\n\n    this.writeMany(indices, unstack(tensor, 0));\n  }\n\n  /**\n   * Split the values of a Tensor into the TensorArray.\n   * @param length number[] with the lengths to use when splitting value along\n   *    its first dimension.\n   * @param tensor Tensor, the tensor to split.\n   */\n  split(length: number[], tensor: Tensor) {\n    if (tensor.dtype !== this.dtype) {\n      throw new Error(`TensorArray dtype is ${\n          this.dtype} but tensor has dtype ${tensor.dtype}`);\n    }\n    let totalLength = 0;\n    const cumulativeLengths = length.map(len => {\n      totalLength += len;\n      return totalLength;\n    });\n\n    if (totalLength !== tensor.shape[0]) {\n      throw new Error(`Expected sum of lengths to be equal to\n          tensor.shape[0], but sum of lengths is\n        ${totalLength}, and tensor's shape is: ${tensor.shape}`);\n    }\n\n    if (!this.dynamicSize && length.length !== this.maxSize) {\n      throw new Error(\n          `TensorArray's size is not equal to the size of lengths (${\n              this.maxSize} vs. ${length.length}), ` +\n          'and the TensorArray is not marked as dynamically resizeable');\n    }\n\n    const elementPerRow = totalLength === 0 ? 0 : tensor.size / totalLength;\n    const tensors: Tensor[] = [];\n    tidy(() => {\n      tensor = reshape(tensor, [1, totalLength, elementPerRow]);\n      for (let i = 0; i < length.length; ++i) {\n        const previousLength = (i === 0) ? 0 : cumulativeLengths[i - 1];\n        const indices = [0, previousLength, 0];\n        const sizes = [1, length[i], elementPerRow];\n        tensors[i] = reshape(slice(tensor, indices, sizes), this.elementShape);\n      }\n      return tensors;\n    });\n    const indices = [];\n    for (let i = 0; i < length.length; i++) {\n      indices[i] = i;\n    }\n    this.writeMany(indices, tensors);\n  }\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {concat, DataType, keep, reshape, scalar, slice, stack, Tensor, tensor, tidy, unstack} from '@tensorflow/tfjs-core';\n\nimport {assertShapesMatchAllowUndefinedSize, inferElementShape, mergeElementShape} from './tensor_utils';\n\n/**\n * TensorList stores a container of `tf.Tensor` objects, which are accessible\n * via tensors field.\n *\n * In order to get a copy of the underlying list, use the copy method:\n * ```\n *    TensorList b = a.copy();\n *    b.tensors().pushBack(t);  // This does not modify a.tensors().\n * ```\n *\n * Note that this is not a deep copy: the memory locations of the underlying\n * tensors will still point to the same locations of the corresponding tensors\n * in the original.\n */\n\nexport class TensorList {\n  readonly idTensor: Tensor;\n  maxNumElements: number;\n\n  get id() {\n    return this.idTensor.id;\n  }\n  /**\n   *\n   * @param tensors list of tensors\n   * @param elementShape shape of each tensor, this can be a single number (any\n   * shape is allowed) or partial shape (dim = -1).\n   * @param elementDtype data type of each tensor\n   * @param maxNumElements The maximum allowed size of `tensors`. Defaults to -1\n   *   meaning that the size of `tensors` is unbounded.\n   */\n  constructor(\n      readonly tensors: Tensor[], readonly elementShape: number|number[],\n      readonly elementDtype: DataType, maxNumElements = -1) {\n    if (tensors != null) {\n      tensors.forEach(tensor => {\n        if (elementDtype !== tensor.dtype) {\n          throw new Error(`Invalid data types; op elements ${\n              elementDtype}, but list elements ${tensor.dtype}`);\n        }\n        assertShapesMatchAllowUndefinedSize(\n            elementShape, tensor.shape, 'TensorList shape mismatch: ');\n\n        keep(tensor);\n      });\n    }\n    this.idTensor = scalar(0);\n    this.maxNumElements = maxNumElements;\n    keep(this.idTensor);\n  }\n\n  /**\n   * Get a new TensorList containing a copy of the underlying tensor container.\n   */\n  copy(): TensorList {\n    return new TensorList(\n        [...this.tensors], this.elementShape, this.elementDtype);\n  }\n\n  /**\n   * Dispose the tensors and idTensor and clear the tensor list.\n   */\n  clearAndClose(keepIds?: Set<number>) {\n    this.tensors.forEach(tensor => {\n      if (keepIds == null || !keepIds.has(tensor.id)) {\n        tensor.dispose();\n      }\n    });\n    this.tensors.length = 0;\n    this.idTensor.dispose();\n  }\n  /**\n   * The size of the tensors in the tensor list.\n   */\n  size() {\n    return this.tensors.length;\n  }\n\n  /**\n   * Return a tensor that stacks a list of rank-R tf.Tensors into one rank-(R+1)\n   * tf.Tensor.\n   * @param elementShape shape of each tensor\n   * @param elementDtype data type of each tensor\n   * @param numElements the number of elements to stack\n   */\n  stack(elementShape: number[], elementDtype: DataType, numElements = -1):\n      Tensor {\n    if (elementDtype !== this.elementDtype) {\n      throw new Error(`Invalid data types; op elements ${\n          elementDtype}, but list elements ${this.elementDtype}`);\n    }\n    if (numElements !== -1 && this.tensors.length !== numElements) {\n      throw new Error(`Operation expected a list with ${\n          numElements} elements but got a list with ${\n          this.tensors.length} elements.`);\n    }\n    assertShapesMatchAllowUndefinedSize(\n        elementShape, this.elementShape, 'TensorList shape mismatch: ');\n    const outputElementShape =\n        inferElementShape(this.elementShape, this.tensors, elementShape);\n    return tidy(() => {\n      const reshapedTensors =\n          this.tensors.map(tensor => reshape(tensor, outputElementShape));\n      return stack(reshapedTensors, 0);\n    });\n  }\n\n  /**\n   * Pop a tensor from the end of the list.\n   * @param elementShape shape of the tensor\n   * @param elementDtype data type of the tensor\n   */\n  popBack(elementShape: number[], elementDtype: DataType): Tensor {\n    if (elementDtype !== this.elementDtype) {\n      throw new Error(`Invalid data types; op elements ${\n          elementDtype}, but list elements ${this.elementDtype}`);\n    }\n\n    if (this.size() === 0) {\n      throw new Error('Trying to pop from an empty list.');\n    }\n    const outputElementShape =\n        inferElementShape(this.elementShape, this.tensors, elementShape);\n    const tensor = this.tensors.pop();\n    tensor.kept = false;\n\n    assertShapesMatchAllowUndefinedSize(\n        tensor.shape, elementShape, 'TensorList shape mismatch: ');\n\n    return reshape(tensor, outputElementShape);\n  }\n\n  /**\n   * Push a tensor to the end of the list.\n   * @param tensor Tensor to be pushed.\n   */\n  pushBack(tensor: Tensor) {\n    if (tensor.dtype !== this.elementDtype) {\n      throw new Error(`Invalid data types; op elements ${\n          tensor.dtype}, but list elements ${this.elementDtype}`);\n    }\n\n    assertShapesMatchAllowUndefinedSize(\n        tensor.shape, this.elementShape, 'TensorList shape mismatch: ');\n\n    if (this.maxNumElements === this.size()) {\n      throw new Error(`Trying to push element into a full list.`);\n    }\n    keep(tensor);\n    this.tensors.push(tensor);\n  }\n\n  /**\n   * Update the size of the list.\n   * @param size the new size of the list.\n   */\n  resize(size: number) {\n    if (size < 0) {\n      throw new Error(\n          `TensorListResize expects size to be non-negative. Got: ${size}`);\n    }\n\n    if (this.maxNumElements !== -1 && size > this.maxNumElements) {\n      throw new Error(`TensorListResize input size ${\n          size} is greater maxNumElement ${this.maxNumElements}.`);\n    }\n\n    const destTensorList: TensorList = new TensorList(\n        [], this.elementShape, this.elementDtype, this.maxNumElements);\n    destTensorList.tensors.length = size;\n    for (let i = 0; i < Math.min(this.tensors.length, size); ++i) {\n      destTensorList.tensors[i] = this.tensors[i];\n    }\n    return destTensorList;\n  }\n\n  /**\n   * Retrieve the element at the provided index\n   * @param elementShape shape of the tensor\n   * @param elementDtype dtype of the tensor\n   * @param elementIndex index of the tensor\n   */\n  getItem(elementIndex: number, elementShape: number[], elementDtype: DataType):\n      Tensor {\n    if (elementDtype !== this.elementDtype) {\n      throw new Error(`Invalid data types; op elements ${\n          elementDtype}, but list elements ${this.elementDtype}`);\n    }\n    if (elementIndex < 0 || elementIndex > this.tensors.length) {\n      throw new Error(`Trying to access element ${\n          elementIndex} in a list with ${this.tensors.length} elements.`);\n    }\n\n    if (this.tensors[elementIndex] == null) {\n      throw new Error(`element at index ${elementIndex} is null.`);\n    }\n\n    assertShapesMatchAllowUndefinedSize(\n        this.tensors[elementIndex].shape, elementShape,\n        'TensorList shape mismatch: ');\n    const outputElementShape =\n        inferElementShape(this.elementShape, this.tensors, elementShape);\n    return reshape(this.tensors[elementIndex], outputElementShape);\n  }\n\n  /**\n   * Set the tensor at the index\n   * @param elementIndex index of the tensor\n   * @param tensor the tensor to be inserted into the list\n   */\n  setItem(elementIndex: number, tensor: Tensor) {\n    if (tensor.dtype !== this.elementDtype) {\n      throw new Error(`Invalid data types; op elements ${\n          tensor.dtype}, but list elements ${this.elementDtype}`);\n    }\n\n    if (elementIndex < 0 ||\n        this.maxNumElements !== -1 && elementIndex >= this.maxNumElements) {\n      throw new Error(`Trying to set element ${\n          elementIndex} in a list with max ${this.maxNumElements} elements.`);\n    }\n\n    assertShapesMatchAllowUndefinedSize(\n        this.elementShape, tensor.shape, 'TensorList shape mismatch: ');\n    keep(tensor);\n\n    // dispose the previous value if it is replacing.\n    if (this.tensors[elementIndex] != null) {\n      this.tensors[elementIndex].kept = false;\n    }\n\n    this.tensors[elementIndex] = tensor;\n  }\n\n  /**\n   * Return selected values in the TensorList as a stacked Tensor. All of\n   * selected values must have been written and their shapes must all match.\n   * @param indices indices of tensors to gather\n   * @param elementDtype output tensor dtype\n   * @param elementShape output tensor element shape\n   */\n  gather(indices: number[], elementDtype: DataType, elementShape: number[]):\n      Tensor {\n    if (elementDtype !== this.elementDtype) {\n      throw new Error(`Invalid data types; op elements ${\n          elementDtype}, but list elements ${this.elementDtype}`);\n    }\n\n    assertShapesMatchAllowUndefinedSize(\n        this.elementShape, elementShape, 'TensorList shape mismatch: ');\n\n    // When indices is greater than the size of the list, indices beyond the\n    // size of the list are ignored.\n    indices = indices.slice(0, this.size());\n    const outputElementShape =\n        inferElementShape(this.elementShape, this.tensors, elementShape);\n    if (indices.length === 0) {\n      return tensor([], [0].concat(outputElementShape));\n    }\n\n    return tidy(() => {\n      const tensors =\n          indices.map(i => reshape(this.tensors[i], outputElementShape));\n      return stack(tensors, 0);\n    });\n  }\n\n  /**\n   * Return the values in the TensorList as a concatenated Tensor.\n   * @param elementDtype output tensor dtype\n   * @param elementShape output tensor element shape\n   */\n  concat(elementDtype: DataType, elementShape: number[]): Tensor {\n    if (!!elementDtype && elementDtype !== this.elementDtype) {\n      throw new Error(`TensorList dtype is ${\n          this.elementDtype} but concat requested dtype ${elementDtype}`);\n    }\n\n    assertShapesMatchAllowUndefinedSize(\n        this.elementShape, elementShape, 'TensorList shape mismatch: ');\n    const outputElementShape =\n        inferElementShape(this.elementShape, this.tensors, elementShape);\n\n    if (this.size() === 0) {\n      return tensor([], [0].concat(outputElementShape));\n    }\n    return tidy(() => {\n      const tensors = this.tensors.map(t => reshape(t, outputElementShape));\n      return concat(tensors, 0);\n    });\n  }\n}\n\n/**\n * Creates a TensorList which, when stacked, has the value of tensor.\n * @param tensor from tensor\n * @param elementShape output tensor element shape\n */\nexport function fromTensor(\n    tensor: Tensor, elementShape: number[], elementDtype: DataType) {\n  const dtype = tensor.dtype;\n  if (tensor.shape.length < 1) {\n    throw new Error(\n        `Tensor must be at least a vector, but saw shape: ${tensor.shape}`);\n  }\n  if (tensor.dtype !== elementDtype) {\n    throw new Error(`Invalid data types; op elements ${\n        tensor.dtype}, but list elements ${elementDtype}`);\n  }\n  const tensorElementShape = tensor.shape.slice(1);\n  assertShapesMatchAllowUndefinedSize(\n      tensorElementShape, elementShape, 'TensorList shape mismatch: ');\n  const tensorList: Tensor[] = unstack(tensor);\n  return new TensorList(tensorList, elementShape, dtype);\n}\n\n/**\n * Return a TensorList of the given size with empty elements.\n * @param elementShape the shape of the future elements of the list\n * @param elementDtype the desired type of elements in the list\n * @param numElements the number of elements to reserve\n * @param maxNumElements the maximum number of elements in th list\n */\nexport function reserve(\n    elementShape: number[], elementDtype: DataType, numElements: number,\n    maxNumElements: number) {\n  return new TensorList([], elementShape, elementDtype, maxNumElements);\n}\n\n/**\n * Put tensors at specific indices of a stacked tensor into a TensorList.\n * @param indices list of indices on how to scatter the tensor.\n * @param tensor input tensor.\n * @param elementShape the shape of the future elements of the list\n * @param numElements the number of elements to scatter\n */\nexport function scatter(\n    tensor: Tensor, indices: number[], elementShape: number[],\n    numElements?: number): TensorList {\n  if (indices.length !== tensor.shape[0]) {\n    throw new Error(`Expected len(indices) == tensor.shape[0], but saw: ${\n        indices.length} vs. ${tensor.shape[0]}`);\n  }\n\n  const maxIndex = Math.max(...indices);\n\n  if (numElements != null && numElements !== -1 && maxIndex >= numElements) {\n    throw new Error(\n        `Max index must be < array size (${maxIndex}  vs. ${numElements})`);\n  }\n\n  const list = new TensorList([], elementShape, tensor.dtype, numElements);\n  const tensors = unstack(tensor, 0);\n  indices.forEach((value, index) => {\n    list.setItem(value, tensors[index]);\n  });\n  return list;\n}\n\n/**\n * Split the values of a Tensor into a TensorList.\n * @param length the lengths to use when splitting value along\n *    its first dimension.\n * @param tensor the tensor to split.\n * @param elementShape the shape of the future elements of the list\n */\nexport function split(\n    tensor: Tensor, length: number[], elementShape: number[]) {\n  let totalLength = 0;\n  const cumulativeLengths = length.map(len => {\n    totalLength += len;\n    return totalLength;\n  });\n\n  if (totalLength !== tensor.shape[0]) {\n    throw new Error(`Expected sum of lengths to be equal to\n          tensor.shape[0], but sum of lengths is\n        ${totalLength}, and tensor's shape is: ${tensor.shape}`);\n  }\n\n  const shapeWithoutFirstDim = tensor.shape.slice(1);\n  const outputElementShape =\n      mergeElementShape(shapeWithoutFirstDim, elementShape);\n  const elementPerRow = totalLength === 0 ? 0 : tensor.size / totalLength;\n  const tensors: Tensor[] = tidy(() => {\n    const tensors = [];\n    tensor = reshape(tensor, [1, totalLength, elementPerRow]);\n    for (let i = 0; i < length.length; ++i) {\n      const previousLength = (i === 0) ? 0 : cumulativeLengths[i - 1];\n      const indices = [0, previousLength, 0];\n      const sizes = [1, length[i], elementPerRow];\n      tensors[i] = reshape(\n          slice(tensor, indices, sizes), outputElementShape as number[]);\n    }\n    tensor.dispose();\n    return tensors;\n  });\n\n  const list = new TensorList([], elementShape, tensor.dtype, length.length);\n\n  for (let i = 0; i < tensors.length; i++) {\n    list.setItem(i, tensors[i]);\n  }\n  return list;\n}\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, scalar, Tensor} from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {TensorArray} from '../../executor/tensor_array';\nimport {fromTensor, reserve, scatter, split} from '../../executor/tensor_list';\nimport {InternalOpAsyncExecutor, Node} from '../types';\n\nimport {cloneTensor, getParamValue, getTensor} from './utils';\n\nexport const executeOp: InternalOpAsyncExecutor = async(\n    node: Node, tensorMap: NamedTensorsMap,\n    context: ExecutionContext): Promise<Tensor[]> => {\n  switch (node.op) {\n    case 'If':\n    case 'StatelessIf': {\n      const thenFunc =\n          getParamValue('thenBranch', node, tensorMap, context) as string;\n      const elseFunc =\n          getParamValue('elseBranch', node, tensorMap, context) as string;\n      const cond = getParamValue('cond', node, tensorMap, context) as Tensor;\n      const args = getParamValue('args', node, tensorMap, context) as Tensor[];\n      const condValue = await cond.data();\n      if (condValue[0]) {\n        return context.functionMap[thenFunc].executeFunctionAsync(\n            args, context.tensorArrayMap, context.tensorListMap);\n      } else {\n        return context.functionMap[elseFunc].executeFunctionAsync(\n            args, context.tensorArrayMap, context.tensorListMap);\n      }\n    }\n    case 'While':\n    case 'StatelessWhile': {\n      const bodyFunc =\n          getParamValue('body', node, tensorMap, context) as string;\n      const condFunc =\n          getParamValue('cond', node, tensorMap, context) as string;\n      const args = getParamValue('args', node, tensorMap, context) as Tensor[];\n\n      // Calculate the condition of the loop\n      const condResult =\n          (await context.functionMap[condFunc].executeFunctionAsync(\n              args, context.tensorArrayMap, context.tensorListMap));\n      const argIds = args.map(tensor => tensor.id);\n      let condValue = await condResult[0].data();\n      // Dispose the intermediate tensors for condition function\n      condResult.forEach(tensor => {\n        if (!tensor.kept && argIds.indexOf(tensor.id) === -1) {\n          tensor.dispose();\n        }\n      });\n\n      let result: Tensor[] = args;\n\n      while (condValue[0]) {\n        // Record the previous result for intermediate tensor tracking\n        const origResult = result;\n        // Execution the body of the loop\n        result = await context.functionMap[bodyFunc].executeFunctionAsync(\n            result, context.tensorArrayMap, context.tensorListMap);\n        const resultIds = result.map(tensor => tensor.id);\n\n        // Dispose the intermediate tensor for body function that is not global\n        // kept, not input/output of the body function\n        origResult.forEach(tensor => {\n          if (!tensor.kept && argIds.indexOf(tensor.id) === -1 &&\n              resultIds.indexOf(tensor.id) === -1) {\n            tensor.dispose();\n          }\n        });\n\n        // Recalcuate the condition of the loop using the latest results.\n        const condResult =\n            (await context.functionMap[condFunc].executeFunctionAsync(\n                result, context.tensorArrayMap, context.tensorListMap));\n        condValue = await condResult[0].data();\n        // Dispose the intermediate tensors for condition function\n        condResult.forEach(tensor => {\n          if (!tensor.kept && argIds.indexOf(tensor.id) === -1 &&\n              resultIds.indexOf(tensor.id) === -1) {\n            tensor.dispose();\n          }\n        });\n      }\n      return result;\n    }\n    case 'LoopCond': {\n      const pred = getParamValue('pred', node, tensorMap, context) as Tensor;\n      return [cloneTensor(pred)];\n    }\n    case 'Switch': {\n      const pred = getParamValue('pred', node, tensorMap, context) as Tensor;\n      let data = getParamValue('data', node, tensorMap, context) as Tensor;\n      if (!data.kept) {\n        data = cloneTensor(data);\n      }\n      // Outputs nodes :0 => false, :1 => true\n      return (await pred.data())[0] ? [undefined, data] : [data, undefined];\n    }\n    case 'Merge': {\n      const inputName = node.inputNames.find(\n          name => getTensor(name, tensorMap, context) !== undefined);\n      if (inputName) {\n        const data = getTensor(inputName, tensorMap, context);\n        return [cloneTensor(data)];\n      }\n      return undefined;\n    }\n    case 'Enter': {\n      const frameId =\n          getParamValue('frameName', node, tensorMap, context) as string;\n      const data = getParamValue('tensor', node, tensorMap, context) as Tensor;\n      context.enterFrame(frameId);\n      return [cloneTensor(data)];\n    }\n    case 'Exit': {\n      const data = getParamValue('tensor', node, tensorMap, context) as Tensor;\n      context.exitFrame();\n      return [cloneTensor(data)];\n    }\n    case 'NextIteration': {\n      const data = getParamValue('tensor', node, tensorMap, context) as Tensor;\n      context.nextIteration();\n      return [cloneTensor(data)];\n    }\n    case 'TensorArrayV3': {\n      const size = getParamValue('size', node, tensorMap, context) as number;\n      const dtype =\n          getParamValue('dtype', node, tensorMap, context) as DataType;\n      const elementShape =\n          getParamValue('elementShape', node, tensorMap, context) as number[];\n      const dynamicSize =\n          getParamValue('dynamicSize', node, tensorMap, context) as boolean;\n      const clearAfterRead =\n          getParamValue('clearAfterRead', node, tensorMap, context) as boolean;\n      const identicalElementShapes =\n          getParamValue('identicalElementShapes', node, tensorMap, context) as\n          boolean;\n      const name = getParamValue('name', node, tensorMap, context) as string;\n      const tensorArray = new TensorArray(\n          name, dtype, size, elementShape, identicalElementShapes, dynamicSize,\n          clearAfterRead);\n      context.addTensorArray(tensorArray);\n      return [tensorArray.idTensor, scalar(1.0)];\n    }\n    case 'TensorArrayWriteV3': {\n      const id =\n          getParamValue('tensorArrayId', node, tensorMap, context) as Tensor;\n      const index = getParamValue('index', node, tensorMap, context) as number;\n      const writeTensor =\n          getParamValue('tensor', node, tensorMap, context) as Tensor;\n      const writeTensorArray = context.getTensorArray(id.id);\n      writeTensorArray.write(index, writeTensor);\n      return [writeTensorArray.idTensor];\n    }\n    case 'TensorArrayReadV3': {\n      const readId =\n          getParamValue('tensorArrayId', node, tensorMap, context) as Tensor;\n      const readIndex =\n          getParamValue('index', node, tensorMap, context) as number;\n      const readTensorArray = context.getTensorArray(readId.id);\n      return [readTensorArray.read(readIndex)];\n    }\n    case 'TensorArrayGatherV3': {\n      const gatherId =\n          getParamValue('tensorArrayId', node, tensorMap, context) as Tensor;\n      const gatherIndices =\n          getParamValue('indices', node, tensorMap, context) as number[];\n      const gatherDtype =\n          getParamValue('dtype', node, tensorMap, context) as DataType;\n      const gatherTensorArray = context.getTensorArray(gatherId.id);\n      return [gatherTensorArray.gather(gatherIndices, gatherDtype)];\n    }\n    case 'TensorArrayScatterV3': {\n      const scatterId =\n          getParamValue('tensorArrayId', node, tensorMap, context) as Tensor;\n      const scatterIndices =\n          getParamValue('indices', node, tensorMap, context) as number[];\n      const scatterTensor =\n          getParamValue('tensor', node, tensorMap, context) as Tensor;\n      const scatterTensorArray = context.getTensorArray(scatterId.id);\n      scatterTensorArray.scatter(scatterIndices, scatterTensor);\n      return [scatterTensorArray.idTensor];\n    }\n    case 'TensorArrayConcatV3': {\n      const concatId =\n          getParamValue('tensorArrayId', node, tensorMap, context) as Tensor;\n      const concatTensorArray = context.getTensorArray(concatId.id);\n      const concatDtype =\n          getParamValue('dtype', node, tensorMap, context) as DataType;\n      return [concatTensorArray.concat(concatDtype)];\n    }\n    case 'TensorArraySplitV3': {\n      const splitId =\n          getParamValue('tensorArrayId', node, tensorMap, context) as Tensor;\n      const splitTensor =\n          getParamValue('tensor', node, tensorMap, context) as Tensor;\n      const lengths =\n          getParamValue('lengths', node, tensorMap, context) as number[];\n      const splitTensorArray = context.getTensorArray(splitId.id);\n      splitTensorArray.split(lengths, splitTensor);\n      return [splitTensorArray.idTensor];\n    }\n    case 'TensorArraySizeV3': {\n      const sizeId =\n          getParamValue('tensorArrayId', node, tensorMap, context) as Tensor;\n      const sizeTensorArray = context.getTensorArray(sizeId.id);\n      return [scalar(sizeTensorArray.size(), 'int32')];\n    }\n    case 'TensorArrayCloseV3': {\n      const closeId =\n          getParamValue('tensorArrayId', node, tensorMap, context) as Tensor;\n      const closeTensorArray = context.getTensorArray(closeId.id);\n      closeTensorArray.clearAndClose();\n      return [closeTensorArray.idTensor];\n    }\n    case 'TensorListSetItem': {\n      const idTensor =\n          getParamValue('tensorListId', node, tensorMap, context) as Tensor;\n      const index = getParamValue('index', node, tensorMap, context) as number;\n      const writeTensor =\n          getParamValue('tensor', node, tensorMap, context) as Tensor;\n      const tensorList = context.getTensorList(idTensor.id);\n      tensorList.setItem(index, writeTensor);\n      return [tensorList.idTensor];\n    }\n    case 'TensorListGetItem': {\n      const idTensor =\n          getParamValue('tensorListId', node, tensorMap, context) as Tensor;\n      const readIndex =\n          getParamValue('index', node, tensorMap, context) as number;\n      const elementShape =\n          getParamValue('elementShape', node, tensorMap, context) as number[];\n\n      const elementDType =\n          getParamValue('elementDType', node, tensorMap, context) as DataType;\n      const tensorList = context.getTensorList(idTensor.id);\n      return [tensorList.getItem(readIndex, elementShape, elementDType)];\n    }\n    case 'TensorListScatterV2':\n    case 'TensorListScatter': {\n      const scatterIndices =\n          getParamValue('indices', node, tensorMap, context) as number[];\n      const scatterTensor =\n          getParamValue('tensor', node, tensorMap, context) as Tensor;\n      const elementShape =\n          getParamValue('elementShape', node, tensorMap, context) as number[];\n      const numElements =\n          getParamValue('numElements', node, tensorMap, context) as number;\n      const tensorList =\n          scatter(scatterTensor, scatterIndices, elementShape, numElements);\n      context.addTensorList(tensorList);\n      return [tensorList.idTensor];\n    }\n    case 'TensorListReserve':\n    case 'EmptyTensorList': {\n      const elementShape =\n          getParamValue('elementShape', node, tensorMap, context) as number[];\n      const elementDtype =\n          getParamValue('elementDType', node, tensorMap, context) as DataType;\n      let numElementsParam;\n\n      if (node.op === 'TensorListReserve') {\n        numElementsParam = 'numElements';\n      } else {\n        numElementsParam = 'maxNumElements';\n      }\n\n      const numElements =\n          getParamValue(numElementsParam, node, tensorMap, context) as number;\n      const maxNumElements = node.op === 'TensorListReserve' ? -1 : numElements;\n      const tensorList =\n          reserve(elementShape, elementDtype, numElements, maxNumElements);\n      context.addTensorList(tensorList);\n      return [tensorList.idTensor];\n    }\n    case 'TensorListGather': {\n      const gatherId =\n          getParamValue('tensorListId', node, tensorMap, context) as Tensor;\n      const gatherIndices =\n          getParamValue('indices', node, tensorMap, context) as number[];\n      const elementShape =\n          getParamValue('elementShape', node, tensorMap, context) as number[];\n      const elementDtype =\n          getParamValue('elementDType', node, tensorMap, context) as DataType;\n      const tensorList = context.getTensorList(gatherId.id);\n      return [tensorList.gather(gatherIndices, elementDtype, elementShape)];\n    }\n    case 'TensorListStack': {\n      const idTensor =\n          getParamValue('tensorListId', node, tensorMap, context) as Tensor;\n      const elementShape =\n          getParamValue('elementShape', node, tensorMap, context) as number[];\n      const elementDtype =\n          getParamValue('elementDType', node, tensorMap, context) as DataType;\n      const numElements =\n          getParamValue('numElements', node, tensorMap, context) as number;\n      const tensorList = context.getTensorList(idTensor.id);\n      return [tensorList.stack(elementShape, elementDtype, numElements)];\n    }\n    case 'TensorListFromTensor': {\n      const tensor =\n          getParamValue('tensor', node, tensorMap, context) as Tensor;\n      const elementShape =\n          getParamValue('elementShape', node, tensorMap, context) as number[];\n      const elementDtype =\n          getParamValue('elementDType', node, tensorMap, context) as DataType;\n      const tensorList = fromTensor(tensor, elementShape, elementDtype);\n      context.addTensorList(tensorList);\n      return [tensorList.idTensor];\n    }\n    case 'TensorListConcat':\n    case 'TensorListConcatV2': {\n      const concatId =\n          getParamValue('tensorListId', node, tensorMap, context) as Tensor;\n      const tensorList = context.getTensorList(concatId.id);\n      const concatDtype =\n          getParamValue('dtype', node, tensorMap, context) as DataType;\n      const elementShape =\n          getParamValue('elementShape', node, tensorMap, context) as number[];\n      return [tensorList.concat(concatDtype, elementShape)];\n    }\n    case 'TensorListPushBack': {\n      const idTensor =\n          getParamValue('tensorListId', node, tensorMap, context) as Tensor;\n      const writeTensor =\n          getParamValue('tensor', node, tensorMap, context) as Tensor;\n      const tensorList = context.getTensorList(idTensor.id);\n      tensorList.pushBack(writeTensor);\n      return [tensorList.idTensor];\n    }\n    case 'TensorListPopBack': {\n      const idTensor =\n          getParamValue('tensorListId', node, tensorMap, context) as Tensor;\n      const elementShape =\n          getParamValue('elementShape', node, tensorMap, context) as number[];\n      const elementDType =\n          getParamValue('elementDType', node, tensorMap, context) as DataType;\n      const tensorList = context.getTensorList(idTensor.id);\n      return [tensorList.popBack(elementShape, elementDType)];\n    }\n    case 'TensorListSplit': {\n      const splitTensor =\n          getParamValue('tensor', node, tensorMap, context) as Tensor;\n      const elementShape =\n          getParamValue('elementShape', node, tensorMap, context) as number[];\n      const lengths =\n          getParamValue('lengths', node, tensorMap, context) as number[];\n\n      const tensorList = split(splitTensor, lengths, elementShape);\n      context.addTensorList(tensorList);\n      return [tensorList.idTensor];\n    }\n    case 'TensorListLength': {\n      const idTensor =\n          getParamValue('tensorListId', node, tensorMap, context) as Tensor;\n      const tensorList = context.getTensorList(idTensor.id);\n      return [scalar(tensorList.size(), 'int32')];\n    }\n    case 'TensorListResize': {\n      const idTensor =\n          getParamValue('tensorListId', node, tensorMap, context) as Tensor;\n      const size = getParamValue('size', node, tensorMap, context) as number;\n\n      const srcTensorList = context.getTensorList(idTensor.id);\n      const destTensorList = srcTensorList.resize(size);\n      context.addTensorList(destTensorList);\n      return [destTensorList.idTensor];\n    }\n    default:\n      throw TypeError(`Node type ${node.op} is not implemented`);\n  }\n};\n\nexport const CATEGORY = 'control';\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Rank, Tensor, Tensor3D, Tensor4D, Tensor5D} from '@tensorflow/tfjs-core';\n// tslint:disable-next-line: no-imports-from-dist\nimport * as tfOps from '@tensorflow/tfjs-core/dist/ops/ops_for_converter';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getPadding, getParamValue} from './utils';\n\nfunction fusedConvAndDepthWiseParams(\n    node: Node, tensorMap: NamedTensorsMap, context: ExecutionContext) {\n  const [extraOp, activationFunc] =\n      (getParamValue('fusedOps', node, tensorMap, context) as string[]);\n\n  const isBiasAdd = extraOp === 'biasadd';\n  const noBiasAdd = !isBiasAdd;\n  const isPrelu = activationFunc === 'prelu';\n  const isBatchNorm = extraOp === 'fusedbatchnorm';\n\n  const numArgs =\n      (getParamValue('numArgs', node, tensorMap, context) as number);\n  if (isBiasAdd) {\n    if (isPrelu && numArgs !== 2) {\n      throw new Error(\n          'FusedConv2d and DepthwiseConv2d with BiasAdd and Prelu ' +\n          'must have two extra arguments: bias and alpha.');\n    }\n    if (!isPrelu && isBiasAdd && numArgs !== 1) {\n      throw new Error(\n          'FusedConv2d and DepthwiseConv2d with BiasAdd must have ' +\n          'one extra argument: bias.');\n    }\n  }\n  if (isBatchNorm) {\n    throw new Error(\n        'FusedConv2d and DepthwiseConv2d with FusedBatchNorm is not supported');\n  }\n  const stride = getParamValue('strides', node, tensorMap, context) as number[];\n  const pad = getPadding(node, tensorMap, context);\n  const dataFormat =\n      (getParamValue('dataFormat', node, tensorMap, context) as string)\n          .toUpperCase();\n  const dilations =\n      getParamValue('dilations', node, tensorMap, context) as number[];\n  let [biasArg, preluArg] =\n      getParamValue('args', node, tensorMap, context) as Tensor[];\n  if (noBiasAdd) {\n    preluArg = biasArg;\n    biasArg = undefined;\n  }\n  const leakyreluAlpha =\n      getParamValue('leakyreluAlpha', node, tensorMap, context) as number;\n\n  return {\n    stride,\n    pad,\n    dataFormat,\n    dilations,\n    biasArg,\n    preluArg,\n    activationFunc,\n    leakyreluAlpha\n  };\n}\n\nexport const executeOp: InternalOpExecutor =\n    (node: Node, tensorMap: NamedTensorsMap,\n     context: ExecutionContext, ops = tfOps): Tensor[] => {\n      switch (node.op) {\n        case 'Conv1D': {\n          const stride =\n              getParamValue('stride', node, tensorMap, context) as number;\n          const pad = getParamValue('pad', node, tensorMap, context);\n          const dataFormat =\n              (getParamValue('dataFormat', node, tensorMap, context) as string)\n                  .toUpperCase();\n          const dilation =\n              getParamValue('dilation', node, tensorMap, context) as number;\n          return [ops.conv1d(\n              getParamValue('x', node, tensorMap, context) as Tensor3D,\n              getParamValue('filter', node, tensorMap, context) as Tensor3D,\n              stride, pad as 'valid' | 'same', dataFormat as 'NWC' | 'NCW',\n              dilation)];\n        }\n        case 'Conv2D': {\n          const stride =\n              getParamValue('strides', node, tensorMap, context) as number[];\n          const pad = getPadding(node, tensorMap, context);\n          const dataFormat =\n              (getParamValue('dataFormat', node, tensorMap, context) as string)\n                  .toUpperCase();\n          const dilations =\n              getParamValue('dilations', node, tensorMap, context) as number[];\n          return [ops.conv2d(\n              getParamValue('x', node, tensorMap, context) as Tensor3D |\n                  Tensor4D,\n              getParamValue('filter', node, tensorMap, context) as Tensor4D,\n              [stride[1], stride[2]], pad as 'valid' | 'same',\n              dataFormat as 'NHWC' | 'NCHW', [dilations[1], dilations[2]])];\n        }\n        case '_FusedConv2D': {\n          const {\n            stride,\n            pad,\n            dataFormat,\n            dilations,\n            biasArg,\n            preluArg,\n            activationFunc,\n            leakyreluAlpha\n          } = fusedConvAndDepthWiseParams(node, tensorMap, context);\n\n          return [ops.fused.conv2d({\n            x: getParamValue('x', node, tensorMap, context) as Tensor3D |\n                Tensor4D,\n            filter: getParamValue('filter', node, tensorMap, context) as\n                Tensor4D,\n            strides: [stride[1], stride[2]],\n            pad: pad as 'valid' | 'same',\n            dataFormat: dataFormat as 'NHWC' | 'NCHW',\n            dilations: [dilations[1], dilations[2]],\n            bias: biasArg,\n            activation: activationFunc as tfOps.fused.Activation,\n            preluActivationWeights: preluArg,\n            leakyreluAlpha\n          })];\n        }\n\n        case 'FusedDepthwiseConv2dNative': {\n          const {\n            stride,\n            pad,\n            dataFormat,\n            dilations,\n            biasArg,\n            preluArg,\n            activationFunc,\n            leakyreluAlpha,\n          } = fusedConvAndDepthWiseParams(node, tensorMap, context);\n\n          return [ops.fused.depthwiseConv2d({\n            x: getParamValue('x', node, tensorMap, context) as Tensor3D |\n                Tensor4D,\n            filter: getParamValue('filter', node, tensorMap, context) as\n                Tensor4D,\n            strides: [stride[1], stride[2]],\n            pad: pad as 'valid' | 'same',\n            dataFormat: dataFormat as 'NHWC' | 'NCHW',\n            dilations: [dilations[1], dilations[2]],\n            bias: biasArg,\n            activation: activationFunc as tfOps.fused.Activation,\n            preluActivationWeights: preluArg,\n            leakyreluAlpha\n          })];\n        }\n        case 'Conv2DBackpropInput':\n        case 'Conv2dTranspose': {\n          const shape = getParamValue(\n                            'outputShape', node, tensorMap,\n                            context) as [number, number, number] |\n              [number, number, number, number];\n          const stride =\n              getParamValue('strides', node, tensorMap, context) as number[];\n          const pad = getPadding(node, tensorMap, context);\n          return [ops.conv2dTranspose(\n              getParamValue('x', node, tensorMap, context) as Tensor3D |\n                  Tensor4D,\n              getParamValue('filter', node, tensorMap, context) as Tensor4D,\n              shape, [stride[1], stride[2]], pad as 'valid' | 'same')];\n        }\n        case 'DepthwiseConv2dNative':\n        case 'DepthwiseConv2d': {\n          const stride =\n              getParamValue('strides', node, tensorMap, context) as number[];\n          const pad = getPadding(node, tensorMap, context);\n          const dilations =\n              getParamValue('dilations', node, tensorMap, context) as number[];\n          const dataFormat =\n              (getParamValue('dataFormat', node, tensorMap, context) as string)\n                  .toUpperCase();\n\n          return [ops.depthwiseConv2d(\n              getParamValue('input', node, tensorMap, context) as Tensor3D |\n                  Tensor4D,\n              getParamValue('filter', node, tensorMap, context) as Tensor4D,\n              [stride[1], stride[2]], pad as 'valid' | 'same',\n              dataFormat as 'NHWC' | 'NCHW', [dilations[1], dilations[2]])];\n        }\n        case 'Conv3D': {\n          const stride =\n              getParamValue('strides', node, tensorMap, context) as number[];\n          const pad = getParamValue('pad', node, tensorMap, context);\n          const dataFormat =\n              (getParamValue('dataFormat', node, tensorMap, context) as string)\n                  .toUpperCase();\n          const dilations =\n              getParamValue('dilations', node, tensorMap, context) as number[];\n          return [ops.conv3d(\n              getParamValue('x', node, tensorMap, context) as Tensor4D |\n                  Tensor<Rank.R5>,\n              getParamValue('filter', node, tensorMap, context) as\n                  Tensor<Rank.R5>,\n              [stride[1], stride[2], stride[3]], pad as 'valid' | 'same',\n              dataFormat as 'NDHWC' | 'NCDHW',\n              [dilations[1], dilations[2], dilations[3]])];\n        }\n        case 'AvgPool': {\n          const stride =\n              getParamValue('strides', node, tensorMap, context) as number[];\n          const pad = getParamValue('pad', node, tensorMap, context);\n          const kernelSize =\n              getParamValue('kernelSize', node, tensorMap, context) as number[];\n\n          return [ops.avgPool(\n              getParamValue('x', node, tensorMap, context) as Tensor3D |\n                  Tensor4D,\n              [kernelSize[1], kernelSize[2]], [stride[1], stride[2]],\n              pad as 'valid' | 'same')];\n        }\n        case 'MaxPool': {\n          const stride =\n              getParamValue('strides', node, tensorMap, context) as number[];\n          const pad = getParamValue('pad', node, tensorMap, context);\n          const kernelSize =\n              getParamValue('kernelSize', node, tensorMap, context) as number[];\n\n          return [ops.maxPool(\n              getParamValue('x', node, tensorMap, context) as Tensor3D |\n                  Tensor4D,\n              [kernelSize[1], kernelSize[2]], [stride[1], stride[2]],\n              pad as 'valid' | 'same')];\n        }\n        case 'MaxPoolWithArgmax': {\n          const stride =\n              getParamValue('strides', node, tensorMap, context) as number[];\n          const pad = getParamValue('pad', node, tensorMap, context);\n          const kernelSize =\n              getParamValue('kernelSize', node, tensorMap, context) as number[];\n          const includeBatchInIndex =\n              getParamValue('includeBatchInIndex', node, tensorMap, context) as\n              boolean;\n          const {result, indexes} = ops.maxPoolWithArgmax(\n              getParamValue('x', node, tensorMap, context) as Tensor4D,\n              [kernelSize[1], kernelSize[2]], [stride[1], stride[2]],\n              pad as 'valid' | 'same', includeBatchInIndex);\n          return [result, indexes];\n        }\n        case 'AvgPool3D': {\n          const stride =\n              getParamValue('strides', node, tensorMap, context) as number[];\n          const pad = getParamValue('pad', node, tensorMap, context);\n          const kernelSize =\n              getParamValue('kernelSize', node, tensorMap, context) as number[];\n\n          return [ops.avgPool3d(\n              getParamValue('x', node, tensorMap, context) as Tensor5D,\n              [kernelSize[1], kernelSize[2], kernelSize[3]],\n              [stride[1], stride[2], stride[3]], pad as 'valid' | 'same')];\n        }\n\n        case 'MaxPool3D': {\n          const stride =\n              getParamValue('strides', node, tensorMap, context) as number[];\n          const pad = getParamValue('pad', node, tensorMap, context);\n          const kernelSize =\n              getParamValue('kernelSize', node, tensorMap, context) as number[];\n\n          return [ops.maxPool3d(\n              getParamValue('x', node, tensorMap, context) as Tensor5D,\n              [kernelSize[1], kernelSize[2], kernelSize[3]],\n              [stride[1], stride[2], stride[3]], pad as 'valid' | 'same')];\n        }\n\n        case 'Dilation2D': {\n          const strides =\n              getParamValue('strides', node, tensorMap, context) as number[];\n          const pad = getParamValue('pad', node, tensorMap, context);\n          const dilations =\n              getParamValue('dilations', node, tensorMap, context) as number[];\n\n          // strides: [1, stride_height, stride_width, 1].\n          const strideHeight = strides[1];\n          const strideWidth = strides[2];\n\n          // dilations: [1, dilation_height, dilation_width, 1].\n          const dilationHeight = dilations[1];\n          const dilationWidth = dilations[2];\n\n          return [ops.dilation2d(\n              getParamValue('x', node, tensorMap, context) as Tensor3D |\n                  Tensor4D,\n              getParamValue('filter', node, tensorMap, context) as Tensor3D,\n              [strideHeight, strideWidth], pad as 'valid' | 'same',\n              [dilationHeight, dilationWidth], 'NHWC' /* dataFormat */)];\n        }\n\n        default:\n          throw TypeError(`Node type ${node.op} is not implemented`);\n      }\n    };\n\nexport const CATEGORY = 'convolution';\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor, Tensor1D, Tensor2D} from '@tensorflow/tfjs-core';\n// tslint:disable-next-line: no-imports-from-dist\nimport * as tfOps from '@tensorflow/tfjs-core/dist/ops/ops_for_converter';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport { ResourceManager } from '../../executor/resource_manager';\nimport {InternalOpAsyncExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nfunction nmsParams(\n    node: Node, tensorMap: NamedTensorsMap, context: ExecutionContext) {\n  const boxes = getParamValue('boxes', node, tensorMap, context) as Tensor;\n  const scores = getParamValue('scores', node, tensorMap, context) as Tensor;\n  const maxOutputSize =\n      getParamValue('maxOutputSize', node, tensorMap, context) as number;\n  const iouThreshold =\n      getParamValue('iouThreshold', node, tensorMap, context) as number;\n  const scoreThreshold =\n      getParamValue('scoreThreshold', node, tensorMap, context) as number;\n  const softNmsSigma =\n      getParamValue('softNmsSigma', node, tensorMap, context) as number;\n\n  return {\n    boxes,\n    scores,\n    maxOutputSize,\n    iouThreshold,\n    scoreThreshold,\n    softNmsSigma\n  };\n}\n\nexport const executeOp: InternalOpAsyncExecutor = async(\n    node: Node, tensorMap: NamedTensorsMap,\n    context: ExecutionContext, resourceManager: ResourceManager,\n    ops = tfOps): Promise<Tensor[]> => {\n  switch (node.op) {\n    case 'NonMaxSuppressionV5': {\n      const {\n        boxes,\n        scores,\n        maxOutputSize,\n        iouThreshold,\n        scoreThreshold,\n        softNmsSigma\n      } = nmsParams(node, tensorMap, context);\n\n      const result = await ops.image.nonMaxSuppressionWithScoreAsync(\n          boxes as Tensor2D, scores as Tensor1D, maxOutputSize, iouThreshold,\n          scoreThreshold, softNmsSigma);\n\n      return [result.selectedIndices, result.selectedScores];\n    }\n    case 'NonMaxSuppressionV4': {\n      const {boxes, scores, maxOutputSize, iouThreshold, scoreThreshold} =\n          nmsParams(node, tensorMap, context);\n\n      const padToMaxOutputSize =\n          getParamValue('padToMaxOutputSize', node, tensorMap, context) as\n          boolean;\n\n      const result = await ops.image.nonMaxSuppressionPaddedAsync(\n          boxes as Tensor2D, scores as Tensor1D, maxOutputSize, iouThreshold,\n          scoreThreshold, padToMaxOutputSize);\n\n      return [result.selectedIndices, result.validOutputs];\n    }\n    case 'NonMaxSuppressionV3':\n    case 'NonMaxSuppressionV2': {\n      const {boxes, scores, maxOutputSize, iouThreshold, scoreThreshold} =\n          nmsParams(node, tensorMap, context);\n\n      return [await ops.image.nonMaxSuppressionAsync(\n          boxes as Tensor2D, scores as Tensor1D, maxOutputSize, iouThreshold,\n          scoreThreshold)];\n    }\n    case 'Where': {\n      const condition = ops.cast(\n          (getParamValue('condition', node, tensorMap, context) as Tensor),\n          'bool');\n      const result = [await ops.whereAsync(condition)];\n      condition.dispose();\n      return result;\n    }\n    case 'ListDiff': {\n      return ops.setdiff1dAsync(\n          getParamValue('x', node, tensorMap, context) as Tensor,\n          getParamValue('y', node, tensorMap, context) as Tensor);\n    }\n    default:\n      throw TypeError(`Node type ${node.op} is not implemented`);\n  }\n};\n\nexport const CATEGORY = 'dynamic';\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {DataType, keep, scalar, stack, Tensor, tidy, unstack, util} from '@tensorflow/tfjs-core';\n// tslint:disable-next-line: no-imports-from-dist\nimport * as tfOps from '@tensorflow/tfjs-core/dist/ops/ops_for_converter';\n\n/**\n * Hashtable contains a set of tensors, which can be accessed by key.\n */\nexport class HashTable {\n  readonly handle: Tensor;\n\n  // tslint:disable-next-line: no-any\n  private tensorMap: Map<any, Tensor>;\n\n  get id() {\n    return this.handle.id;\n  }\n\n  /**\n   * Constructor of HashTable. Creates a hash table.\n   *\n   * @param keyDType `dtype` of the table keys.\n   * @param valueDType `dtype` of the table values.\n   */\n  constructor(readonly keyDType: DataType, readonly valueDType: DataType) {\n    this.handle = scalar(0);\n    // tslint:disable-next-line: no-any\n    this.tensorMap = new Map<any, Tensor>();\n\n    keep(this.handle);\n  }\n\n  /**\n   * Dispose the tensors and handle and clear the hashtable.\n   */\n  clearAndClose() {\n    this.tensorMap.forEach(value => value.dispose());\n    this.tensorMap.clear();\n    this.handle.dispose();\n  }\n\n  /**\n   * The number of items in the hash table.\n   */\n  size(): number {\n    return this.tensorMap.size;\n  }\n\n  /**\n   * The number of items in the hash table as a rank-0 tensor.\n   */\n  tensorSize(): Tensor {\n    return tfOps.scalar(this.size(), 'int32');\n  }\n\n  /**\n   * Replaces the contents of the table with the specified keys and values.\n   * @param keys Keys to store in the hashtable.\n   * @param values Values to store in the hashtable.\n   */\n  async import(keys: Tensor, values: Tensor): Promise<Tensor> {\n    this.checkKeyAndValueTensor(keys, values);\n\n    // We only store the primitive values of the keys, this allows lookup\n    // to be O(1).\n    const $keys = await keys.data();\n\n    // Clear the hashTable before inserting new values.\n    this.tensorMap.forEach(value => value.dispose());\n    this.tensorMap.clear();\n\n    return tidy(() => {\n      const $values = unstack(values);\n\n      const keysLength = $keys.length;\n      const valuesLength = $values.length;\n\n      util.assert(\n          keysLength === valuesLength,\n          () => `The number of elements doesn't match, keys has ` +\n              `${keysLength} elements, the values has ${valuesLength} ` +\n              `elements.`);\n\n      for (let i = 0; i < keysLength; i++) {\n        const key = $keys[i];\n        const value = $values[i];\n\n        keep(value);\n        this.tensorMap.set(key, value);\n      }\n\n      return this.handle;\n    });\n  }\n\n  /**\n   * Looks up keys in a hash table, outputs the corresponding values.\n   *\n   * Performs batch lookups, for every element in the key tensor, `find`\n   * stacks the corresponding value into the return tensor.\n   *\n   * If an element is not present in the table, the given `defaultValue` is\n   * used.\n   *\n   * @param keys Keys to look up. Must have the same type as the keys of the\n   *     table.\n   * @param defaultValue The scalar `defaultValue` is the value output for keys\n   *     not present in the table. It must also be of the same type as the\n   *     table values.\n   */\n  async find(keys: Tensor, defaultValue: Tensor): Promise<Tensor> {\n    this.checkKeyAndValueTensor(keys, defaultValue);\n\n    const $keys = await keys.data();\n\n    return tidy(() => {\n      const result: Tensor[] = [];\n\n      for (let i = 0; i < $keys.length; i++) {\n        const key = $keys[i];\n\n        const value = this.findWithDefault(key, defaultValue);\n        result.push(value);\n      }\n\n      return stack(result);\n    });\n  }\n\n  // tslint:disable-next-line: no-any\n  private findWithDefault(key: any, defaultValue: Tensor): Tensor {\n    const result = this.tensorMap.get(key);\n\n    return result != null ? result : defaultValue;\n  }\n\n  private checkKeyAndValueTensor(key: Tensor, value: Tensor) {\n    if (key.dtype !== this.keyDType) {\n      throw new Error(\n          `Expect key dtype ${this.keyDType}, but got ` +\n          `${key.dtype}`);\n    }\n\n    if (value.dtype !== this.valueDType) {\n      throw new Error(\n          `Expect value dtype ${this.valueDType}, but got ` +\n          `${value.dtype}`);\n    }\n  }\n}\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tfc from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../data/types';\nimport {ExecutionContext} from '../executor/execution_context';\nimport {ResourceManager} from '../executor/resource_manager';\n\nimport {NodeValueImpl} from './custom_op/node_value_impl';\nimport {getRegisteredOp} from './custom_op/register';\nimport * as arithmetic from './executors/arithmetic_executor';\nimport * as basicMath from './executors/basic_math_executor';\nimport * as control from './executors/control_executor';\nimport * as convolution from './executors/convolution_executor';\nimport * as creation from './executors/creation_executor';\nimport * as dynamic from './executors/dynamic_executor';\nimport * as evaluation from './executors/evaluation_executor';\nimport * as graph from './executors/graph_executor';\nimport * as hashTable from './executors/hash_table_executor';\nimport * as image from './executors/image_executor';\nimport * as logical from './executors/logical_executor';\nimport * as matrices from './executors/matrices_executor';\nimport * as normalization from './executors/normalization_executor';\nimport * as reduction from './executors/reduction_executor';\nimport * as sliceJoin from './executors/slice_join_executor';\nimport * as sparse from './executors/sparse_executor';\nimport * as spectral from './executors/spectral_executor';\nimport * as string from './executors/string_executor';\nimport * as transformation from './executors/transformation_executor';\nimport {Node} from './types';\n\n/**\n * Executes the op defined by the node object.\n * @param node\n * @param tensorMap contains tensors for executed nodes and weights\n * @param context contains tensors and information for running the current node.\n * @param resourceManager Optional. Contains global resources of the model.\n */\nexport function executeOp(\n    node: Node, tensorMap: NamedTensorsMap, context: ExecutionContext,\n    resourceManager?: ResourceManager, tidy = tfc.tidy): tfc.Tensor[]|\n    Promise<tfc.Tensor[]> {\n  const value =\n      ((node: Node, tensorMap: NamedTensorsMap, context: ExecutionContext) => {\n        switch (node.category) {\n          case 'arithmetic':\n            return tidy(() => arithmetic.executeOp(node, tensorMap, context));\n          case 'basic_math':\n            return tidy(() => basicMath.executeOp(node, tensorMap, context));\n          case 'control':\n            return control.executeOp(node, tensorMap, context);\n          case 'convolution':\n            return tidy(() => convolution.executeOp(node, tensorMap, context));\n          case 'creation':\n            return tidy(() => creation.executeOp(node, tensorMap, context));\n          case 'dynamic':\n            return dynamic.executeOp(node, tensorMap, context);\n          case 'evaluation':\n            return tidy(() => evaluation.executeOp(node, tensorMap, context));\n          case 'image':\n            return tidy(() => image.executeOp(node, tensorMap, context));\n          case 'graph':\n            return tidy(() => graph.executeOp(node, tensorMap, context));\n          case 'logical':\n            return tidy(() => logical.executeOp(node, tensorMap, context));\n          case 'matrices':\n            return tidy(() => matrices.executeOp(node, tensorMap, context));\n          case 'normalization':\n            return tidy(\n                () => normalization.executeOp(node, tensorMap, context));\n          case 'reduction':\n            return tidy(() => reduction.executeOp(node, tensorMap, context));\n          case 'slice_join':\n            return tidy(() => sliceJoin.executeOp(node, tensorMap, context));\n          case 'sparse':\n            return tidy(() => sparse.executeOp(node, tensorMap, context));\n          case 'spectral':\n            return tidy(() => spectral.executeOp(node, tensorMap, context));\n          case 'string':\n            return tidy(() => string.executeOp(node, tensorMap, context));\n          case 'transformation':\n            return tidy(\n                () => transformation.executeOp(node, tensorMap, context));\n          case 'hash_table':\n            return hashTable.executeOp(\n                node, tensorMap, context, resourceManager);\n          case 'custom':\n            const opMapper = getRegisteredOp(node.op);\n            if (opMapper && opMapper.customExecutor) {\n              return opMapper.customExecutor(\n                  new NodeValueImpl(node, tensorMap, context));\n            } else {\n              throw TypeError(`Custom op ${node.op} is not registered.`);\n            }\n          default:\n            throw TypeError(\n                `Unknown op '${node.op}'. File an issue at ` +\n                `https://github.com/tensorflow/tfjs/issues so we can add it` +\n                `, or register a custom execution with tf.registerOp()`);\n        }\n      })(node, tensorMap, context);\n  if (tfc.util.isPromise(value)) {\n    return value.then((data) => [].concat(data));\n  }\n  return [].concat(value);\n}\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor} from '@tensorflow/tfjs-core';\n// tslint:disable-next-line: no-imports-from-dist\nimport * as tfOps from '@tensorflow/tfjs-core/dist/ops/ops_for_converter';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nexport const executeOp: InternalOpExecutor =\n    (node: Node, tensorMap: NamedTensorsMap,\n     context: ExecutionContext, ops = tfOps): Tensor[] => {\n      switch (node.op) {\n        case 'BiasAdd':\n        case 'AddV2':\n        case 'Add': {\n          return [ops.add(\n              (getParamValue('a', node, tensorMap, context) as Tensor),\n              getParamValue('b', node, tensorMap, context) as Tensor)];\n        }\n        case 'AddN': {\n          return [ops.addN((\n              getParamValue('tensors', node, tensorMap, context) as Tensor[]))];\n        }\n        case 'FloorMod':\n        case 'Mod':\n          return [ops.mod(\n              getParamValue('a', node, tensorMap, context) as Tensor,\n              getParamValue('b', node, tensorMap, context) as Tensor)];\n        case 'Mul':\n          return [ops.mul(\n              getParamValue('a', node, tensorMap, context) as Tensor,\n              getParamValue('b', node, tensorMap, context) as Tensor)];\n        case 'RealDiv':\n        case 'Div': {\n          return [ops.div(\n              getParamValue('a', node, tensorMap, context) as Tensor,\n              getParamValue('b', node, tensorMap, context) as Tensor)];\n        }\n        case 'DivNoNan': {\n          return [ops.divNoNan(\n              getParamValue('a', node, tensorMap, context) as Tensor,\n              getParamValue('b', node, tensorMap, context) as Tensor)];\n        }\n        case 'FloorDiv': {\n          return [ops.floorDiv(\n              getParamValue('a', node, tensorMap, context) as Tensor,\n              getParamValue('b', node, tensorMap, context) as Tensor)];\n        }\n        case 'Sub': {\n          return [ops.sub(\n              getParamValue('a', node, tensorMap, context) as Tensor,\n              getParamValue('b', node, tensorMap, context) as Tensor)];\n        }\n        case 'Minimum': {\n          return [ops.minimum(\n              getParamValue('a', node, tensorMap, context) as Tensor,\n              getParamValue('b', node, tensorMap, context) as Tensor)];\n        }\n        case 'Maximum': {\n          return [ops.maximum(\n              getParamValue('a', node, tensorMap, context) as Tensor,\n              getParamValue('b', node, tensorMap, context) as Tensor)];\n        }\n        case 'Pow': {\n          return [ops.pow(\n              getParamValue('a', node, tensorMap, context) as Tensor,\n              getParamValue('b', node, tensorMap, context) as Tensor)];\n        }\n        case 'SquaredDifference': {\n          return [ops.squaredDifference(\n              getParamValue('a', node, tensorMap, context) as Tensor,\n              getParamValue('b', node, tensorMap, context) as Tensor)];\n        }\n        default:\n          throw TypeError(`Node type ${node.op} is not implemented`);\n      }\n    };\n\nexport const CATEGORY = 'arithmetic';\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor} from '@tensorflow/tfjs-core';\n// tslint:disable-next-line: no-imports-from-dist\nimport * as tfOps from '@tensorflow/tfjs-core/dist/ops/ops_for_converter';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue, getTensor} from './utils';\n\nexport const executeOp: InternalOpExecutor =\n    (node: Node, tensorMap: NamedTensorsMap,\n     context: ExecutionContext, ops = tfOps): Tensor[] => {\n      switch (node.op) {\n        case 'Abs':\n        case 'ComplexAbs':\n          return [ops.abs(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        case 'Acos':\n          return [ops.acos(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        case 'Acosh':\n          return [ops.acosh(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        case 'Asin':\n          return [ops.asin(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        case 'Asinh':\n          return [ops.asinh(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        case 'Atan':\n          return [ops.atan(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        case 'Atan2':\n          return [ops.atan2(\n              getParamValue('x', node, tensorMap, context) as Tensor,\n              getParamValue('y', node, tensorMap, context) as Tensor)];\n        case 'Atanh':\n          return [ops.atanh(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        case 'Ceil':\n          return [ops.ceil(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        case 'Complex':\n          return [ops.complex(\n              getParamValue('real', node, tensorMap, context) as Tensor,\n              getParamValue('imag', node, tensorMap, context) as Tensor)];\n        case 'Cos':\n          return [ops.cos(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        case 'Cosh':\n          return [ops.cosh(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        case 'Elu':\n          return [ops.elu(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        case 'Erf':\n          return [ops.erf(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        case 'Exp':\n          return [ops.exp(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        case 'Expm1': {\n          return [ops.expm1(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        }\n        case 'Floor':\n          return [ops.floor(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        case 'Log':\n          return [ops.log(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        case 'Log1p': {\n          return [ops.log1p(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        }\n        case 'Imag':\n          return [ops.imag(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n\n        case 'Neg':\n          return [ops.neg(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        case 'Reciprocal': {\n          return [ops.reciprocal(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        }\n        case 'Real':\n          return [ops.real(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        case 'Relu':\n          return [ops.relu(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        case 'Round': {\n          return [ops.round(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        }\n        case 'Selu':\n          return [ops.selu(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        case 'Sigmoid':\n          return [ops.sigmoid(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        case 'Sin':\n          return [ops.sin(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        case 'Sign': {\n          return [ops.sign(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        }\n        case 'Sinh': {\n          return [ops.sinh(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        }\n        case 'Softplus': {\n          return [ops.softplus(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        }\n        case 'Sqrt': {\n          return [ops.sqrt(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        }\n        case 'Square': {\n          return [ops.square(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        }\n        case 'Tanh': {\n          return [ops.tanh(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        }\n        case 'Tan':\n          return [ops.tan(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        case 'ClipByValue':\n          return [ops.clipByValue(\n              getParamValue('x', node, tensorMap, context) as Tensor,\n              getParamValue('clipValueMin', node, tensorMap, context) as number,\n              getParamValue('clipValueMax', node, tensorMap, context) as\n                  number)];\n        case 'Relu6':\n          return [ops.relu6(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        case 'Rsqrt':\n          return [ops.rsqrt(\n              getTensor(node.inputNames[0], tensorMap, context))];\n        case 'Prod':\n          return [ops.prod(\n              getParamValue('x', node, tensorMap, context) as Tensor,\n              getParamValue('axes', node, tensorMap, context) as number[])];\n        case 'LeakyRelu':\n          return [ops.leakyRelu(\n              getParamValue('x', node, tensorMap, context) as Tensor,\n              getParamValue('alpha', node, tensorMap, context) as number)];\n        case 'Prelu':\n          return [ops.prelu(\n              getParamValue('x', node, tensorMap, context) as Tensor,\n              getParamValue('alpha', node, tensorMap, context) as Tensor)];\n        case 'IsNan':\n          return [ops.isNaN(\n              getTensor(node.inputNames[0], tensorMap, context))];\n        default:\n          throw TypeError(`Node type ${node.op} is not implemented`);\n      }\n    };\n\nexport const CATEGORY = 'basic_math';\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, Tensor, Tensor1D} from '@tensorflow/tfjs-core';\n// tslint:disable-next-line: no-imports-from-dist\nimport * as tfOps from '@tensorflow/tfjs-core/dist/ops/ops_for_converter';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nexport const executeOp: InternalOpExecutor =\n    (node: Node, tensorMap: NamedTensorsMap, context: ExecutionContext,\n     ops = tfOps): Tensor[] => {\n      switch (node.op) {\n        case 'Fill': {\n          const shape =\n              getParamValue('shape', node, tensorMap, context) as number[];\n          const dtype =\n              getParamValue('dtype', node, tensorMap, context) as DataType;\n          const value =\n              getParamValue('value', node, tensorMap, context) as number;\n          return [ops.fill(shape, value, dtype)];\n        }\n        case 'LinSpace': {\n          const start =\n              getParamValue('start', node, tensorMap, context) as number;\n          const stop =\n              getParamValue('stop', node, tensorMap, context) as number;\n          const num = getParamValue('num', node, tensorMap, context) as number;\n          return [ops.linspace(start, stop, num)];\n        }\n        case 'Multinomial': {\n          const logits =\n              getParamValue('logits', node, tensorMap, context) as Tensor1D;\n          const numSamples =\n              getParamValue('numSamples', node, tensorMap, context) as number;\n          const seed =\n              getParamValue('seed', node, tensorMap, context) as number;\n          return [ops.multinomial(logits, numSamples, seed)];\n        }\n        case 'OneHot': {\n          const indices =\n              getParamValue('indices', node, tensorMap, context) as Tensor1D;\n          const depth =\n              getParamValue('depth', node, tensorMap, context) as number;\n          const onValue =\n              getParamValue('onValue', node, tensorMap, context) as number;\n          const offValue =\n              getParamValue('offValue', node, tensorMap, context) as number;\n          const dtype =\n              getParamValue('dtype', node, tensorMap, context) as DataType;\n          return [ops.oneHot(indices, depth, onValue, offValue, dtype)];\n        }\n        case 'Ones': {\n          return [ops.ones(\n              getParamValue('shape', node, tensorMap, context) as number[],\n              getParamValue('dtype', node, tensorMap, context) as DataType)];\n        }\n        case 'OnesLike': {\n          return [ops.onesLike(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        }\n        case 'RandomStandardNormal': {\n          return [ops.randomStandardNormal(\n              getParamValue('shape', node, tensorMap, context) as number[],\n              getParamValue('dtype', node, tensorMap, context) as 'float32' |\n                  'int32',\n              getParamValue('seed', node, tensorMap, context) as number)];\n        }\n        case 'RandomUniform': {\n          return [ops.randomUniform(\n              // tslint:disable-next-line:no-any\n              getParamValue('shape', node, tensorMap, context) as any,\n              getParamValue('minval', node, tensorMap, context) as number,\n              getParamValue('maxval', node, tensorMap, context) as number,\n              getParamValue('dtype', node, tensorMap, context) as DataType)];\n        }\n        case 'Range': {\n          const start =\n              getParamValue('start', node, tensorMap, context) as number;\n          const stop =\n              getParamValue('stop', node, tensorMap, context) as number;\n          const step =\n              getParamValue('step', node, tensorMap, context) as number;\n          return [ops.range(\n              start, stop, step,\n              getParamValue('dtype', node, tensorMap, context) as 'float32' |\n                  'int32')];\n        }\n        case 'TruncatedNormal': {\n          const shape =\n              getParamValue('shape', node, tensorMap, context) as number[];\n          const mean =\n              getParamValue('mean', node, tensorMap, context) as number;\n          const stdDev =\n              getParamValue('stdDev', node, tensorMap, context) as number;\n          const seed =\n              getParamValue('seed', node, tensorMap, context) as number;\n          return [ops.truncatedNormal(\n              shape, mean, stdDev,\n              getParamValue('dtype', node, tensorMap, context) as 'float32' |\n                  'int32',\n              seed)];\n        }\n        case 'Zeros': {\n          return [ops.zeros(\n              getParamValue('shape', node, tensorMap, context) as number[],\n              getParamValue('dtype', node, tensorMap, context) as DataType)];\n        }\n        case 'ZerosLike': {\n          return [ops.zerosLike(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        }\n        default:\n          throw TypeError(`Node type ${node.op} is not implemented`);\n      }\n    };\n\nexport const CATEGORY = 'creation';\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor} from '@tensorflow/tfjs-core';\n// tslint:disable-next-line: no-imports-from-dist\nimport * as tfOps from '@tensorflow/tfjs-core/dist/ops/ops_for_converter';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nexport const executeOp: InternalOpExecutor =\n    (node: Node, tensorMap: NamedTensorsMap, context: ExecutionContext,\n     ops = tfOps):\n        Tensor[] => {\n          switch (node.op) {\n            case 'LowerBound': {\n              const sortedSequence =\n                  getParamValue('sortedSequence', node, tensorMap, context) as\n                  Tensor;\n              const values =\n                  getParamValue('values', node, tensorMap, context) as Tensor;\n              return [ops.lowerBound(sortedSequence, values)];\n            }\n            case 'TopKV2': {\n              const x = getParamValue('x', node, tensorMap, context) as Tensor;\n              const k = getParamValue('k', node, tensorMap, context) as number;\n              const sorted =\n                  getParamValue('sorted', node, tensorMap, context) as boolean;\n              const result = ops.topk(x, k, sorted);\n              return [result.values, result.indices];\n            }\n            case 'UpperBound': {\n              const sortedSequence =\n                  getParamValue('sortedSequence', node, tensorMap, context) as\n                  Tensor;\n              const values =\n                  getParamValue('values', node, tensorMap, context) as Tensor;\n              return [ops.upperBound(sortedSequence, values)];\n            }\n            case 'Unique': {\n              const x = getParamValue('x', node, tensorMap, context) as Tensor;\n              const result = ops.unique(x);\n              return [result.values, result.indices];\n            }\n            case 'UniqueV2': {\n              const x = getParamValue('x', node, tensorMap, context) as Tensor;\n              const axis =\n                  getParamValue('axis', node, tensorMap, context) as number;\n              const result = ops.unique(x, axis);\n              return [result.values, result.indices];\n            }\n            default:\n              throw TypeError(`Node type ${node.op} is not implemented`);\n          }\n        };\n\nexport const CATEGORY = 'evaluation';\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor, Tensor1D, Tensor2D, Tensor3D, Tensor4D} from '@tensorflow/tfjs-core';\n// tslint:disable-next-line: no-imports-from-dist\nimport * as tfOps from '@tensorflow/tfjs-core/dist/ops/ops_for_converter';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nexport const executeOp: InternalOpExecutor =\n    (node: Node, tensorMap: NamedTensorsMap,\n     context: ExecutionContext, ops = tfOps): Tensor[] => {\n      switch (node.op) {\n        case 'ResizeBilinear': {\n          const images =\n              getParamValue('images', node, tensorMap, context) as Tensor;\n          const size =\n              getParamValue('size', node, tensorMap, context) as number[];\n          const alignCorners =\n              getParamValue('alignCorners', node, tensorMap, context) as\n              boolean;\n          const halfPixelCenters =\n              getParamValue('halfPixelCenters', node, tensorMap, context) as\n              boolean;\n          return [ops.image.resizeBilinear(\n              images as Tensor3D | Tensor4D, [size[0], size[1]], alignCorners,\n              halfPixelCenters)];\n        }\n        case 'ResizeNearestNeighbor': {\n          const images =\n              getParamValue('images', node, tensorMap, context) as Tensor;\n          const size =\n              getParamValue('size', node, tensorMap, context) as number[];\n          const alignCorners =\n              getParamValue('alignCorners', node, tensorMap, context) as\n              boolean;\n          const halfPixelCenters =\n              getParamValue('halfPixelCenters', node, tensorMap, context) as\n              boolean;\n          return [ops.image.resizeNearestNeighbor(\n              images as Tensor3D | Tensor4D, [size[0], size[1]], alignCorners,\n              halfPixelCenters)];\n        }\n        case 'CropAndResize': {\n          const image =\n              getParamValue('image', node, tensorMap, context) as Tensor;\n          const boxes =\n              getParamValue('boxes', node, tensorMap, context) as Tensor;\n          const boxInd =\n              getParamValue('boxInd', node, tensorMap, context) as Tensor;\n          const cropSize =\n              getParamValue('cropSize', node, tensorMap, context) as number[];\n          const method =\n              getParamValue('method', node, tensorMap, context) as string;\n          const extrapolationValue =\n              getParamValue('extrapolationValue', node, tensorMap, context) as\n              number;\n          return [ops.image.cropAndResize(\n              image as Tensor4D, boxes as Tensor2D, boxInd as Tensor1D,\n              cropSize as [number, number], method as 'bilinear' | 'nearest',\n              extrapolationValue)];\n        }\n        case 'ImageProjectiveTransformV3': {\n          const images =\n              getParamValue('images', node, tensorMap, context) as Tensor;\n          const transforms =\n              getParamValue('transforms', node, tensorMap, context) as Tensor;\n          const outputShape =\n              getParamValue('outputShape', node, tensorMap, context) as\n              number[];\n          const fillValue =\n              getParamValue('fillValue', node, tensorMap, context) as number;\n          const interpolation =\n              getParamValue('interpolation', node, tensorMap, context) as\n              string;\n          const fillMode =\n              getParamValue('fillMode', node, tensorMap, context) as string;\n          return [ops.image.transform(\n              images as Tensor4D,\n              transforms as Tensor2D,\n              interpolation.toLowerCase() as 'bilinear' | 'nearest',\n              fillMode.toLowerCase() as 'constant' | 'reflect' | 'wrap' | 'nearest',\n              fillValue,\n              outputShape as [number, number])];\n        }\n        default:\n          throw TypeError(`Node type ${node.op} is not implemented`);\n      }\n    };\n\nexport const CATEGORY = 'image';\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor} from '@tensorflow/tfjs-core';\n// tslint:disable-next-line: no-imports-from-dist\nimport * as tfOps from '@tensorflow/tfjs-core/dist/ops/ops_for_converter';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {cloneTensor, getParamValue, getTensor} from './utils';\n\nexport const executeOp: InternalOpExecutor =\n    (node: Node, tensorMap: NamedTensorsMap,\n     context: ExecutionContext, ops = tfOps): Tensor[] => {\n      switch (node.op) {\n        case 'Const': {\n          return tensorMap[node.name];\n        }\n        case 'PlaceholderWithDefault':\n          const def =\n              getParamValue('default', node, tensorMap, context) as Tensor;\n          return [getTensor(node.name, tensorMap, context) || def];\n        case 'Placeholder':\n          return [getTensor(node.name, tensorMap, context)];\n        case 'Identity':\n        case 'StopGradient':\n        case 'FakeQuantWithMinMaxVars': {  // This op is currently ignored.\n          const data = getParamValue('x', node, tensorMap, context) as Tensor;\n          return [cloneTensor(data)];\n        }\n        case 'IdentityN':\n          return (getParamValue('x', node, tensorMap, context) as Tensor[])\n              .map((t: Tensor) => cloneTensor(t));\n        case 'Snapshot':\n          const snapshot =\n              (getParamValue('x', node, tensorMap, context) as Tensor);\n          return [cloneTensor(snapshot)];\n        case 'Shape':\n          return [ops.tensor1d(\n              (getParamValue('x', node, tensorMap, context) as Tensor).shape,\n              'int32')];\n        case 'ShapeN':\n          return (getParamValue('x', node, tensorMap, context) as Tensor[])\n              .map((t: Tensor) => ops.tensor1d(t.shape));\n        case 'Size':\n          return [ops.scalar(\n              (getParamValue('x', node, tensorMap, context) as Tensor).size,\n              'int32')];\n        case 'Rank':\n          return [ops.scalar(\n              (getParamValue('x', node, tensorMap, context) as Tensor).rank,\n              'int32')];\n        case 'NoOp':\n          return [ops.scalar(1)];\n        case 'Print':\n          const input = getParamValue('x', node, tensorMap, context) as Tensor;\n          const data =\n              getParamValue('data', node, tensorMap, context) as Tensor[];\n          const message =\n              getParamValue('message', node, tensorMap, context) as string;\n          const summarize =\n              getParamValue('summarize', node, tensorMap, context) as number;\n          console.warn(\n              'The graph has a tf.print() operation,' +\n              'usually used for debugging, which slows down performance.');\n          console.log(message);\n          for (let i = 0; i < data.length; i++) {\n            console.log(Array.prototype.slice.call(data[i].dataSync())\n                            .slice(0, summarize));\n          }\n          return [input];\n\n        default:\n          throw TypeError(`Node type ${node.op} is not implemented`);\n      }\n    };\n\nexport const CATEGORY = 'graph';\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor} from '@tensorflow/tfjs-core';\n// tslint:disable-next-line: no-imports-from-dist\nimport * as tfOps from '@tensorflow/tfjs-core/dist/ops/ops_for_converter';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nexport const executeOp: InternalOpExecutor =\n    (node: Node, tensorMap: NamedTensorsMap,\n     context: ExecutionContext, ops = tfOps): Tensor[] => {\n      switch (node.op) {\n        case 'Equal': {\n          return [ops.equal(\n              getParamValue('a', node, tensorMap, context) as Tensor,\n              getParamValue('b', node, tensorMap, context) as Tensor)];\n        }\n        case 'NotEqual': {\n          return [ops.notEqual(\n              getParamValue('a', node, tensorMap, context) as Tensor,\n              getParamValue('b', node, tensorMap, context) as Tensor)];\n        }\n        case 'Greater': {\n          return [ops.greater(\n              getParamValue('a', node, tensorMap, context) as Tensor,\n              getParamValue('b', node, tensorMap, context) as Tensor)];\n        }\n        case 'GreaterEqual': {\n          return [ops.greaterEqual(\n              getParamValue('a', node, tensorMap, context) as Tensor,\n              getParamValue('b', node, tensorMap, context) as Tensor)];\n        }\n        case 'Less': {\n          return [ops.less(\n              getParamValue('a', node, tensorMap, context) as Tensor,\n              getParamValue('b', node, tensorMap, context) as Tensor)];\n        }\n        case 'LessEqual': {\n          return [ops.lessEqual(\n              getParamValue('a', node, tensorMap, context) as Tensor,\n              getParamValue('b', node, tensorMap, context) as Tensor)];\n        }\n        case 'LogicalAnd': {\n          return [ops.logicalAnd(\n              getParamValue('a', node, tensorMap, context) as Tensor,\n              getParamValue('b', node, tensorMap, context) as Tensor)];\n        }\n        case 'LogicalNot': {\n          return [ops.logicalNot(\n              getParamValue('a', node, tensorMap, context) as Tensor)];\n        }\n        case 'LogicalOr': {\n          return [ops.logicalOr(\n              getParamValue('a', node, tensorMap, context) as Tensor,\n              getParamValue('b', node, tensorMap, context) as Tensor)];\n        }\n        case 'Select':\n        case 'SelectV2': {\n          return [ops.where(\n              getParamValue('condition', node, tensorMap, context) as Tensor,\n              getParamValue('a', node, tensorMap, context) as Tensor,\n              getParamValue('b', node, tensorMap, context) as Tensor)];\n        }\n        default:\n          throw TypeError(`Node type ${node.op} is not implemented`);\n      }\n    };\n\nexport const CATEGORY = 'logical';\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor, Tensor2D} from '@tensorflow/tfjs-core';\n// tslint:disable-next-line: no-imports-from-dist\nimport * as tfOps from '@tensorflow/tfjs-core/dist/ops/ops_for_converter';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nexport const executeOp: InternalOpExecutor =\n    (node: Node, tensorMap: NamedTensorsMap,\n     context: ExecutionContext, ops = tfOps): Tensor[] => {\n      switch (node.op) {\n        case 'BatchMatMul':\n        case 'BatchMatMulV2':\n        case 'MatMul':\n          return [ops.matMul(\n              getParamValue('a', node, tensorMap, context) as Tensor2D,\n              getParamValue('b', node, tensorMap, context) as Tensor2D,\n              getParamValue('transposeA', node, tensorMap, context) as boolean,\n              getParamValue('transposeB', node, tensorMap, context) as\n                  boolean)];\n\n        case 'Einsum':\n          return [ops.einsum(\n              getParamValue('equation', node, tensorMap, context) as string,\n              ...getParamValue('tensors', node, tensorMap, context) as\n                  Tensor[])];\n\n        case 'Transpose':\n          return [ops.transpose(\n              getParamValue('x', node, tensorMap, context) as Tensor,\n              getParamValue('perm', node, tensorMap, context) as number[])];\n\n        case '_FusedMatMul':\n          const [extraOp, activationFunc] =\n              (getParamValue('fusedOps', node, tensorMap, context) as string[]);\n\n          const isBiasAdd = extraOp === 'biasadd';\n          const isPrelu = activationFunc === 'prelu';\n\n          const numArgs =\n              (getParamValue('numArgs', node, tensorMap, context) as number);\n          const leakyreluAlpha =\n              getParamValue('leakyreluAlpha', node, tensorMap, context) as\n              number;\n\n          if (isBiasAdd) {\n            if (isPrelu && numArgs !== 2) {\n              throw new Error(\n                  'Fused MatMul with BiasAdd and Prelu must have two ' +\n                  'extra arguments: bias and alpha.');\n            }\n            if (!isPrelu && numArgs !== 1) {\n              throw new Error(\n                  'Fused MatMul with BiasAdd must have one extra argument: bias.');\n            }\n          }\n          const [biasArg, preluArg] =\n              getParamValue('args', node, tensorMap, context) as Tensor[];\n          return [ops.fused.matMul({\n            a: getParamValue('a', node, tensorMap, context) as Tensor2D,\n            b: getParamValue('b', node, tensorMap, context) as Tensor2D,\n            transposeA: getParamValue('transposeA', node, tensorMap, context) as\n                boolean,\n            transposeB: getParamValue('transposeB', node, tensorMap, context) as\n                boolean,\n            bias: biasArg,\n            activation: activationFunc as tfOps.fused.Activation,\n            preluActivationWeights: preluArg,\n            leakyreluAlpha\n          })];\n\n        default:\n          throw TypeError(`Node type ${node.op} is not implemented`);\n      }\n    };\n\nexport const CATEGORY = 'matrices';\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Scalar, Tensor, Tensor3D, Tensor4D} from '@tensorflow/tfjs-core';\n// tslint:disable-next-line: no-imports-from-dist\nimport * as tfOps from '@tensorflow/tfjs-core/dist/ops/ops_for_converter';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nexport const executeOp: InternalOpExecutor =\n    (node: Node, tensorMap: NamedTensorsMap,\n     context: ExecutionContext, ops = tfOps): Tensor[] => {\n      switch (node.op) {\n        case 'EuclideanNorm':\n          return [ops.euclideanNorm(\n              getParamValue('x', node, tensorMap, context) as Tensor,\n              getParamValue('axis', node, tensorMap, context) as number[],\n              getParamValue('keepDims', node, tensorMap, context) as boolean)];\n        case 'FusedBatchNorm':\n        case 'FusedBatchNormV2': {\n          return [ops.batchNorm(\n              getParamValue('x', node, tensorMap, context) as Tensor,\n              getParamValue('mean', node, tensorMap, context) as Tensor,\n              getParamValue('variance', node, tensorMap, context) as Tensor,\n              getParamValue('offset', node, tensorMap, context) as Tensor,\n              getParamValue('scale', node, tensorMap, context) as Tensor,\n              getParamValue('epsilon', node, tensorMap, context) as number)];\n        }\n        case 'FusedBatchNormV3': {\n          return [ops.batchNorm(\n              getParamValue('x', node, tensorMap, context) as Tensor,\n              getParamValue('mean', node, tensorMap, context) as Tensor,\n              getParamValue('variance', node, tensorMap, context) as Tensor,\n              getParamValue('offset', node, tensorMap, context) as Tensor,\n              getParamValue('scale', node, tensorMap, context) as Tensor,\n              getParamValue('epsilon', node, tensorMap, context) as number)];\n        }\n        case 'LRN': {\n          return [ops.localResponseNormalization(\n              getParamValue('x', node, tensorMap, context) as Tensor3D |\n                  Tensor4D,\n              getParamValue('radius', node, tensorMap, context) as number,\n              getParamValue('bias', node, tensorMap, context) as number,\n              getParamValue('alpha', node, tensorMap, context) as number,\n              getParamValue('beta', node, tensorMap, context) as number)];\n        }\n        case 'Softmax': {\n          return [ops.softmax(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        }\n        case 'LogSoftmax': {\n          return [ops.logSoftmax(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        }\n        case 'SparseToDense': {\n          return [ops.sparseToDense(\n              getParamValue('sparseIndices', node, tensorMap, context) as\n                  Tensor,\n              getParamValue('outputShape', node, tensorMap, context) as Tensor,\n              getParamValue('sparseValues', node, tensorMap, context) as\n                  number[],\n              getParamValue('defaultValue', node, tensorMap, context) as\n                  Scalar)];\n        }\n        default:\n          throw TypeError(`Node type ${node.op} is not implemented`);\n      }\n    };\n\nexport const CATEGORY = 'normalization';\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor, Tensor1D, Tensor2D} from '@tensorflow/tfjs-core';\n// tslint:disable-next-line: no-imports-from-dist\nimport * as tfOps from '@tensorflow/tfjs-core/dist/ops/ops_for_converter';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nexport const executeOp: InternalOpExecutor =\n    (node: Node, tensorMap: NamedTensorsMap,\n     context: ExecutionContext, ops = tfOps): Tensor[] => {\n      switch (node.op) {\n        case 'Max': {\n          const axis =\n              getParamValue('axis', node, tensorMap, context) as number[];\n          const keepDims =\n              getParamValue('keepDims', node, tensorMap, context) as boolean;\n          return [ops.max(\n              getParamValue('x', node, tensorMap, context) as Tensor, axis,\n              keepDims)];\n        }\n        case 'Mean': {\n          const axis =\n              getParamValue('axis', node, tensorMap, context) as number[];\n          const keepDims =\n              getParamValue('keepDims', node, tensorMap, context) as boolean;\n          return [ops.mean(\n              getParamValue('x', node, tensorMap, context) as Tensor, axis,\n              keepDims)];\n        }\n        case 'Min': {\n          const axis =\n              getParamValue('axis', node, tensorMap, context) as number[];\n          const keepDims =\n              getParamValue('keepDims', node, tensorMap, context) as boolean;\n          return [ops.min(\n              getParamValue('x', node, tensorMap, context) as Tensor, axis,\n              keepDims)];\n        }\n        case 'Sum': {\n          const axis =\n              getParamValue('axis', node, tensorMap, context) as number[];\n          const keepDims =\n              getParamValue('keepDims', node, tensorMap, context) as boolean;\n          return [ops.sum(\n              getParamValue('x', node, tensorMap, context) as Tensor, axis,\n              keepDims)];\n        }\n        case 'All': {\n          const axis =\n              getParamValue('axis', node, tensorMap, context) as number[];\n          const keepDims =\n              getParamValue('keepDims', node, tensorMap, context) as boolean;\n          return [ops.all(\n              getParamValue('x', node, tensorMap, context) as Tensor, axis,\n              keepDims)];\n        }\n        case 'Any': {\n          const axis =\n              getParamValue('axis', node, tensorMap, context) as number[];\n          const keepDims =\n              getParamValue('keepDims', node, tensorMap, context) as boolean;\n          return [ops.any(\n              getParamValue('x', node, tensorMap, context) as Tensor, axis,\n              keepDims)];\n        }\n        case 'ArgMax': {\n          const axis =\n              getParamValue('axis', node, tensorMap, context) as number;\n          return [ops.argMax(\n              getParamValue('x', node, tensorMap, context) as Tensor, axis)];\n        }\n        case 'ArgMin': {\n          const axis =\n              getParamValue('axis', node, tensorMap, context) as number;\n          return [ops.argMin(\n              getParamValue('x', node, tensorMap, context) as Tensor, axis)];\n        }\n        case 'Prod': {\n          const axis =\n              getParamValue('axis', node, tensorMap, context) as number[];\n          const keepDims =\n              getParamValue('keepDims', node, tensorMap, context) as boolean;\n          return [ops.prod(\n              getParamValue('x', node, tensorMap, context) as Tensor, axis,\n              keepDims)];\n        }\n        case 'Cumprod': {\n          const axis =\n              getParamValue('axis', node, tensorMap, context) as number;\n          const exclusive =\n              getParamValue('exclusive', node, tensorMap, context) as boolean;\n          const reverse =\n              getParamValue('reverse', node, tensorMap, context) as boolean;\n          return [ops.cumprod(\n              getParamValue('x', node, tensorMap, context) as Tensor, axis,\n              exclusive, reverse)];\n        }\n        case 'Cumsum': {\n          const axis =\n              getParamValue('axis', node, tensorMap, context) as number;\n          const exclusive =\n              getParamValue('exclusive', node, tensorMap, context) as boolean;\n          const reverse =\n              getParamValue('reverse', node, tensorMap, context) as boolean;\n          return [ops.cumsum(\n              getParamValue('x', node, tensorMap, context) as Tensor, axis,\n              exclusive, reverse)];\n        }\n        case 'Bincount':\n          const x = getParamValue('x', node, tensorMap, context) as Tensor1D;\n          const weights =\n              getParamValue('weights', node, tensorMap, context) as Tensor1D;\n          const size =\n              getParamValue('size', node, tensorMap, context) as number;\n\n          return [ops.bincount(x, weights, size)];\n        case 'DenseBincount': {\n          const x = getParamValue('x', node, tensorMap, context) as Tensor1D |\n              Tensor2D;\n          const weights =\n              getParamValue('weights', node, tensorMap, context) as Tensor1D |\n              Tensor2D;\n          const size =\n              getParamValue('size', node, tensorMap, context) as number;\n\n          const binaryOutput =\n              getParamValue('binaryOutput', node, tensorMap, context) as\n              boolean;\n\n          return [ops.denseBincount(x, weights, size, binaryOutput)];\n        }\n        default:\n          throw TypeError(`Node type ${node.op} is not implemented`);\n      }\n    };\n\nexport const CATEGORY = 'reduction';\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Scalar, Tensor, Tensor1D, tidy, util} from '@tensorflow/tfjs-core';\n// tslint:disable-next-line: no-imports-from-dist\nimport * as tfOps from '@tensorflow/tfjs-core/dist/ops/ops_for_converter';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nexport const executeOp: InternalOpExecutor =\n    (node: Node, tensorMap: NamedTensorsMap,\n     context: ExecutionContext, ops = tfOps): Tensor[] => {\n      switch (node.op) {\n        case 'ConcatV2':\n        case 'Concat': {\n          const n = getParamValue('n', node, tensorMap, context) as number;\n          const axis =\n              getParamValue('axis', node, tensorMap, context) as number;\n          let inputs =\n              getParamValue('tensors', node, tensorMap, context) as Tensor[];\n          inputs = inputs.slice(0, n);\n          return [ops.concat(inputs, axis)];\n        }\n        case 'Gather': {\n          const input = getParamValue('x', node, tensorMap, context) as Tensor;\n          const indices =\n              getParamValue('indices', node, tensorMap, context) as Tensor1D;\n          return [ops.gather(input, ops.cast(indices, 'int32'), 0)];\n        }\n        case 'GatherV2': {\n          const axis =\n              getParamValue('axis', node, tensorMap, context) as number;\n          const batchDims =\n              getParamValue('batchDims', node, tensorMap, context) as number;\n          const input = getParamValue('x', node, tensorMap, context) as Tensor;\n          const indices =\n              getParamValue('indices', node, tensorMap, context) as Tensor1D;\n          return [ops.gather(\n              input, ops.cast(indices, 'int32'), axis, batchDims)];\n        }\n        case 'Reverse': {\n          const dims =\n              getParamValue('dims', node, tensorMap, context) as boolean[];\n          const axis = [];\n          for (let i = 0; i < dims.length; i++) {\n            if (dims[i]) {\n              axis.push(i);\n            }\n          }\n          const input = getParamValue('x', node, tensorMap, context) as Tensor;\n          return [ops.reverse(input, axis)];\n        }\n        case 'ReverseV2': {\n          const axis =\n              getParamValue('axis', node, tensorMap, context) as number[];\n          const input = getParamValue('x', node, tensorMap, context) as Tensor;\n          return [ops.reverse(input, axis)];\n        }\n        case 'Slice': {\n          // tslint:disable-next-line:no-any\n          const begin = getParamValue('begin', node, tensorMap, context) as any;\n          // tslint:disable-next-line:no-any\n          const size = getParamValue('size', node, tensorMap, context) as any;\n          return [ops.slice(\n              getParamValue('x', node, tensorMap, context) as Tensor, begin,\n              size)];\n        }\n        case 'StridedSlice': {\n          const begin =\n              getParamValue('begin', node, tensorMap, context) as number[];\n          const end =\n              getParamValue('end', node, tensorMap, context) as number[];\n          const strides =\n              getParamValue('strides', node, tensorMap, context) as number[];\n          const beginMask =\n              getParamValue('beginMask', node, tensorMap, context) as number;\n          const endMask =\n              getParamValue('endMask', node, tensorMap, context) as number;\n          const ellipsisMask =\n              getParamValue('ellipsisMask', node, tensorMap, context) as number;\n          const newAxisMask =\n              getParamValue('newAxisMask', node, tensorMap, context) as number;\n          const shrinkAxisMask =\n              getParamValue('shrinkAxisMask', node, tensorMap, context) as\n              number;\n          const tensor = getParamValue('x', node, tensorMap, context) as Tensor;\n\n          return [ops.stridedSlice(\n              tensor, begin, end, strides, beginMask, endMask, ellipsisMask,\n              newAxisMask, shrinkAxisMask)];\n        }\n        case 'Pack': {\n          return tidy(() => {\n            const axis =\n                getParamValue('axis', node, tensorMap, context) as number;\n            const tensors =\n                getParamValue('tensors', node, tensorMap, context) as Tensor[];\n            // Reshape the tensors to the first tensor's shape if they don't\n            // match.\n            const shape = tensors[0].shape;\n            const squeezedShape = ops.squeeze(tensors[0]).shape;\n            const mapped = tensors.map(tensor => {\n              const sameShape = util.arraysEqual(tensor.shape, shape);\n              if (!sameShape &&\n                  !util.arraysEqual(\n                      ops.squeeze(tensor).shape, squeezedShape)) {\n                throw new Error('the input tensors shape does not match');\n              }\n              return sameShape ? tensor : ops.reshape(tensor, shape);\n            });\n            return [ops.stack(mapped, axis)];\n          });\n        }\n        case 'Unpack': {\n          const axis =\n              getParamValue('axis', node, tensorMap, context) as number;\n          const tensor =\n              getParamValue('tensor', node, tensorMap, context) as Tensor;\n          return ops.unstack(tensor, axis);\n        }\n        case 'Tile': {\n          const reps =\n              getParamValue('reps', node, tensorMap, context) as number[];\n          return [ops.tile(\n              getParamValue('x', node, tensorMap, context) as Tensor, reps)];\n        }\n        case 'Split':\n        case 'SplitV': {\n          const axis =\n              getParamValue('axis', node, tensorMap, context) as number;\n          const numOrSizeSplits =\n              getParamValue('numOrSizeSplits', node, tensorMap, context) as\n                  number |\n              number[];\n          const tensor = getParamValue('x', node, tensorMap, context) as Tensor;\n\n          return ops.split(tensor, numOrSizeSplits, axis);\n        }\n        case 'ScatterNd': {\n          const indices =\n              getParamValue('indices', node, tensorMap, context) as Tensor;\n          const values =\n              getParamValue('values', node, tensorMap, context) as Tensor;\n          const shape =\n              getParamValue('shape', node, tensorMap, context) as number[];\n          return [ops.scatterND(indices, values, shape)];\n        }\n        case 'GatherNd': {\n          const x = getParamValue('x', node, tensorMap, context) as Tensor;\n          const indices =\n              getParamValue('indices', node, tensorMap, context) as Tensor;\n          return [ops.gatherND(x, indices)];\n        }\n        case 'SparseToDense': {\n          const indices =\n              getParamValue('sparseIndices', node, tensorMap, context) as\n              Tensor;\n          const shape =\n              getParamValue('outputShape', node, tensorMap, context) as\n              number[];\n          const sparseValues =\n              getParamValue('sparseValues', node, tensorMap, context) as Tensor;\n          const defaultValue =\n              getParamValue('defaultValue', node, tensorMap, context) as Scalar;\n          return [ops.sparseToDense(\n              indices, sparseValues, shape,\n              sparseValues.dtype === defaultValue.dtype ?\n                  defaultValue :\n                  ops.cast(defaultValue, sparseValues.dtype))];\n        }\n        default:\n          throw TypeError(`Node type ${node.op} is not implemented`);\n      }\n    };\n\nexport const CATEGORY = 'slice_join';\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Scalar, Tensor, Tensor1D, Tensor2D} from '@tensorflow/tfjs-core';\n// tslint:disable-next-line: no-imports-from-dist\nimport * as tfOps from '@tensorflow/tfjs-core/dist/ops/ops_for_converter';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nexport const executeOp: InternalOpExecutor =\n    (node: Node, tensorMap: NamedTensorsMap,\n     context: ExecutionContext, ops = tfOps): Tensor[] => {\n      switch (node.op) {\n        case 'SparseFillEmptyRows': {\n          const {\n            outputIndices,\n            outputValues,\n            emptyRowIndicator,\n            reverseIndexMap\n          } =\n              ops.sparse.sparseFillEmptyRows(\n                  getParamValue('indices', node, tensorMap, context) as\n                      Tensor2D,\n                  getParamValue('values', node, tensorMap, context) as Tensor1D,\n                  getParamValue('denseShape', node, tensorMap, context) as\n                      Tensor1D,\n                  getParamValue('defaultValue', node, tensorMap, context) as\n                      Scalar);\n          return [\n            outputIndices, outputValues, emptyRowIndicator, reverseIndexMap\n          ];\n        }\n        case 'SparseReshape': {\n          const {outputIndices, outputShape} = ops.sparse.sparseReshape(\n              getParamValue('inputIndices', node, tensorMap, context) as\n                  Tensor2D,\n              getParamValue('inputShape', node, tensorMap, context) as Tensor1D,\n              getParamValue('newShape', node, tensorMap, context) as Tensor1D);\n          return [outputIndices, outputShape];\n        }\n        case 'SparseSegmentMean': {\n          const outputData = ops.sparse.sparseSegmentMean(\n              getParamValue('data', node, tensorMap, context) as Tensor,\n              getParamValue('indices', node, tensorMap, context) as Tensor1D,\n              getParamValue('segmentIds', node, tensorMap, context) as\n                  Tensor1D);\n          return [outputData];\n        }\n        case 'SparseSegmentSum': {\n          const outputData = ops.sparse.sparseSegmentSum(\n              getParamValue('data', node, tensorMap, context) as Tensor,\n              getParamValue('indices', node, tensorMap, context) as Tensor1D,\n              getParamValue('segmentIds', node, tensorMap, context) as\n                  Tensor1D);\n          return [outputData];\n        }\n        default:\n          throw TypeError(`Node type ${node.op} is not implemented`);\n      }\n    };\n\nexport const CATEGORY = 'sparse';\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor} from '@tensorflow/tfjs-core';\n// tslint:disable-next-line: no-imports-from-dist\nimport * as tfOps from '@tensorflow/tfjs-core/dist/ops/ops_for_converter';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nexport const executeOp: InternalOpExecutor =\n    (node: Node, tensorMap: NamedTensorsMap, context: ExecutionContext,\n     ops = tfOps): Tensor[] => {\n          switch (node.op) {\n            case 'FFT': {\n              return [ops.fft(\n                  getParamValue('x', node, tensorMap, context) as Tensor)];\n            }\n            case 'IFFT': {\n              return [ops.ifft(\n                  getParamValue('x', node, tensorMap, context) as Tensor)];\n            }\n            case 'RFFT': {\n              return [ops.rfft(\n                  getParamValue('x', node, tensorMap, context) as Tensor)];\n            }\n            case 'IRFFT': {\n              return [ops.irfft(\n                  getParamValue('x', node, tensorMap, context) as Tensor)];\n            }\n            default:\n              throw TypeError(`Node type ${node.op} is not implemented`);\n          }\n        };\n\nexport const CATEGORY = 'spectral';\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Scalar, Tensor, Tensor1D} from '@tensorflow/tfjs-core';\n// tslint:disable-next-line: no-imports-from-dist\nimport * as tfOps from '@tensorflow/tfjs-core/dist/ops/ops_for_converter';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nexport const executeOp: InternalOpExecutor =\n    (node: Node, tensorMap: NamedTensorsMap,\n     context: ExecutionContext, ops = tfOps): Tensor[] => {\n      switch (node.op) {\n        case 'StringNGrams': {\n          const {nGrams, nGramsSplits} = ops.string.stringNGrams(\n              getParamValue('data', node, tensorMap, context) as Tensor1D,\n              getParamValue('dataSplits', node, tensorMap, context) as Tensor,\n              getParamValue('separator', node, tensorMap, context) as string,\n              getParamValue('nGramWidths', node, tensorMap, context) as\n                  number[],\n              getParamValue('leftPad', node, tensorMap, context) as string,\n              getParamValue('rightPad', node, tensorMap, context) as string,\n              getParamValue('padWidth', node, tensorMap, context) as number,\n              getParamValue(\n                  'preserveShortSequences', node, tensorMap, context) as\n                  boolean);\n          return [nGrams, nGramsSplits];\n        }\n        case 'StringSplit': {\n          const {indices, values, shape} = ops.string.stringSplit(\n              getParamValue('input', node, tensorMap, context) as Tensor1D,\n              getParamValue('delimiter', node, tensorMap, context) as Scalar,\n              getParamValue('skipEmpty', node, tensorMap, context) as boolean);\n          return [indices, values, shape];\n        }\n        case 'StringToHashBucketFast': {\n          const output = ops.string.stringToHashBucketFast(\n              getParamValue('input', node, tensorMap, context) as Tensor,\n              getParamValue('numBuckets', node, tensorMap, context) as number);\n          return [output];\n        }\n        default:\n          throw TypeError(`Node type ${node.op} is not implemented`);\n      }\n    };\n\nexport const CATEGORY = 'string';\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor, Tensor4D} from '@tensorflow/tfjs-core';\n// tslint:disable-next-line: no-imports-from-dist\nimport * as tfOps from '@tensorflow/tfjs-core/dist/ops/ops_for_converter';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nexport const executeOp: InternalOpExecutor =\n    (node: Node, tensorMap: NamedTensorsMap,\n     context: ExecutionContext, ops = tfOps): Tensor[] => {\n      switch (node.op) {\n        case 'Cast': {\n          return [ops.cast(\n              getParamValue('x', node, tensorMap, context) as Tensor,\n              getParamValue('dtype', node, tensorMap, context) as 'int32' |\n                  'float32' | 'bool')];\n        }\n        case 'ExpandDims': {\n          const axis =\n              getParamValue('axis', node, tensorMap, context) as number;\n          return [ops.expandDims(\n              getParamValue('x', node, tensorMap, context) as Tensor, axis)];\n        }\n        case 'Squeeze': {\n          const axis =\n              getParamValue('axis', node, tensorMap, context) as number[];\n          return [ops.squeeze(\n              getParamValue('x', node, tensorMap, context) as Tensor, axis)];\n        }\n\n        case 'Reshape': {\n          return [ops.reshape(\n              getParamValue('x', node, tensorMap, context) as Tensor,\n              getParamValue('shape', node, tensorMap, context) as number[])];\n        }\n        case 'MirrorPad': {\n          return [ops.mirrorPad(\n              getParamValue('x', node, tensorMap, context) as Tensor,\n              getParamValue('padding', node, tensorMap, context) as\n                  Array<[number, number]>,\n              getParamValue('mode', node, tensorMap, context) as 'reflect' |\n                  'symmetric')];\n        }\n        case 'PadV2':\n        case 'Pad': {\n          return [ops.pad(\n              getParamValue('x', node, tensorMap, context) as Tensor,\n              getParamValue('padding', node, tensorMap, context) as\n                  Array<[number, number]>,\n              getParamValue('constantValue', node, tensorMap, context) as\n                  number)];\n        }\n        case 'SpaceToBatchND': {\n          const blockShape =\n              getParamValue('blockShape', node, tensorMap, context) as number[];\n          const paddings =\n              getParamValue('paddings', node, tensorMap, context) as number[][];\n          return [ops.spaceToBatchND(\n              getParamValue('x', node, tensorMap, context) as Tensor,\n              blockShape, paddings)];\n        }\n        case 'BatchToSpaceND': {\n          const blockShape =\n              getParamValue('blockShape', node, tensorMap, context) as number[];\n          const crops =\n              getParamValue('crops', node, tensorMap, context) as number[][];\n          return [ops.batchToSpaceND(\n              getParamValue('x', node, tensorMap, context) as Tensor,\n              blockShape, crops)];\n        }\n        case 'DepthToSpace': {\n          const blockSize =\n              getParamValue('blockSize', node, tensorMap, context) as number;\n          const dataFormat =\n              (getParamValue('dataFormat', node, tensorMap, context) as\n               string).toUpperCase() as 'NHWC' |\n              'NCHW';\n          return [ops.depthToSpace(\n              getParamValue('x', node, tensorMap, context) as Tensor4D,\n              blockSize, dataFormat)];\n        }\n        case 'BroadcastTo': {\n          return [ops.broadcastTo(\n              getParamValue('x', node, tensorMap, context) as Tensor,\n              getParamValue('shape', node, tensorMap, context) as number[])];\n        }\n        case 'BroadcastArgs': {\n          return [ops.broadcastArgs(\n              getParamValue('s0', node, tensorMap, context) as Tensor,\n              getParamValue('s1', node, tensorMap, context) as Tensor)];\n        }\n        default:\n          throw TypeError(`Node type ${node.op} is not implemented`);\n      }\n    };\n\nexport const CATEGORY = 'transformation';\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, Tensor} from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {HashTable} from '../../executor/hash_table';\nimport {ResourceManager} from '../../executor/resource_manager';\nimport {InternalOpAsyncExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nexport const executeOp: InternalOpAsyncExecutor = async(\n    node: Node, tensorMap: NamedTensorsMap, context: ExecutionContext,\n    resourceManager: ResourceManager): Promise<Tensor[]> => {\n  switch (node.op) {\n    case 'HashTable':\n    case 'HashTableV2': {\n      const keyDType =\n          getParamValue('keyDType', node, tensorMap, context) as DataType;\n      const valueDType =\n          getParamValue('valueDType', node, tensorMap, context) as DataType;\n\n      const hashTable = new HashTable(keyDType, valueDType);\n      resourceManager.addHashTable(node.name, hashTable);\n      return [hashTable.handle];\n    }\n    case 'LookupTableImport':\n    case 'LookupTableImportV2': {\n      const handle = getParamValue(\n                         'tableHandle', node, tensorMap, context,\n                         resourceManager) as Tensor;\n      const keys = getParamValue('keys', node, tensorMap, context) as Tensor;\n      const values =\n          getParamValue('values', node, tensorMap, context) as Tensor;\n\n      const hashTable = resourceManager.getHashTableById(handle.id);\n\n      return [await hashTable.import(keys, values)];\n    }\n    case 'LookupTableFind':\n    case 'LookupTableFindV2': {\n      const handle = getParamValue(\n                         'tableHandle', node, tensorMap, context,\n                         resourceManager) as Tensor;\n      const keys = getParamValue('keys', node, tensorMap, context) as Tensor;\n      const defaultValue =\n          getParamValue('defaultValue', node, tensorMap, context) as Tensor;\n\n      const hashTable = resourceManager.getHashTableById(handle.id);\n      return [await hashTable.find(keys, defaultValue)];\n    }\n    case 'LookupTableSize':\n    case 'LookupTableSizeV2': {\n      const handle = getParamValue(\n                         'tableHandle', node, tensorMap, context,\n                         resourceManager) as Tensor;\n\n      const hashTable = resourceManager.getHashTableById(handle.id);\n      return [hashTable.tensorSize()];\n    }\n    default:\n      throw TypeError(`Node type ${node.op} is not implemented`);\n  }\n};\n\nexport const CATEGORY = 'hash_table';\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {Tensor} from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap, TensorArrayMap, TensorListMap} from '../data/types';\n\nimport {TensorArray} from './tensor_array';\nimport {TensorList} from './tensor_list';\nimport {FunctionExecutor} from './types';\n\nexport interface ExecutionContextInfo {\n  id: number;           // the unique id of the context info\n  frameName: string;    // The frame name of the loop, this comes from\n                        // the TensorFlow NodeDef.\n  iterationId: number;  // The iteration id of the loop\n}\n\n/**\n * ExecutionContext captures the runtime environment of the node. It keeps\n * track of the current frame and iteration for the control flow ops.\n *\n * For example, typical Dynamic RNN model may contain loops, for which\n * TensorFlow will generate graphs with Enter/Exit nodes to control the\n * current execution frame, and NextIteration Nodes for iteration id increment.\n * For model with branch logic, TensorFLow will generate Switch/Merge ops.\n */\nexport class ExecutionContext {\n  private rootContext = {id: 0, frameName: '', iterationId: 0};\n  private contexts: ExecutionContextInfo[] = [this.rootContext];\n  private lastId = 0;\n  private _currentContextIds: string[];\n\n  constructor(\n      readonly weightMap: NamedTensorsMap = {},\n      readonly tensorArrayMap: TensorArrayMap = {},\n      readonly tensorListMap: TensorListMap = {},\n      readonly functionMap: {[key: string]: FunctionExecutor} = {}) {\n    this.generateCurrentContextIds();\n  }\n\n  private newFrame(id: number, frameName: string) {\n    return {id, frameName, iterationId: 0};\n  }\n\n  /**\n   * Set the current context\n   * @param contexts: ExecutionContextInfo[] the current path of execution\n   * frames\n   */\n  set currentContext(contexts: ExecutionContextInfo[]) {\n    if (this.contexts !== contexts) {\n      this.contexts = contexts;\n      this.generateCurrentContextIds();\n    }\n  }\n\n  get currentContext(): ExecutionContextInfo[] {\n    return this.contexts;\n  }\n\n  /**\n   * Returns the current context in string format.\n   */\n  get currentContextId(): string {\n    return this._currentContextIds[0];\n  }\n\n  /**\n   * Returns the current context and all parent contexts in string format.\n   * This allow access to the nodes in the current and parent frames.\n   */\n  get currentContextIds(): string[] {\n    return this._currentContextIds;\n  }\n\n  private generateCurrentContextIds() {\n    const names = [];\n    for (let i = 0; i < this.contexts.length - 1; i++) {\n      const contexts = this.contexts.slice(0, this.contexts.length - i);\n      names.push(this.contextIdforContexts(contexts));\n    }\n    names.push('');\n    this._currentContextIds = names;\n  }\n\n  private contextIdforContexts(contexts: ExecutionContextInfo[]) {\n    return contexts ?\n        contexts\n            .map(\n                context => (context.id === 0 && context.iterationId === 0) ?\n                    '' :\n                    `${context.frameName}-${context.iterationId}`)\n            .join('/') :\n        '';\n  }\n\n  /**\n   * Enter a new frame, a new context is pushed on the current context list.\n   * @param frameId new frame id\n   */\n  enterFrame(frameId: string) {\n    if (this.contexts) {\n      this.lastId++;\n      this.contexts = this.contexts.slice();\n      this.contexts.push(this.newFrame(this.lastId, frameId));\n      this._currentContextIds.unshift(this.contextIdforContexts(this.contexts));\n    }\n  }\n\n  /**\n   * Exit the current frame, the last context is removed from the current\n   * context list.\n   */\n  exitFrame() {\n    if (this.contexts && this.contexts.length > 1) {\n      this.contexts = this.contexts.slice();\n      this.contexts.splice(-1);\n      this.currentContextIds.shift();\n    } else {\n      throw new Error('Cannot exit frame, the context is empty');\n    }\n  }\n\n  /**\n   * Enter the next iteration of a loop, the iteration id of last context is\n   * increased.\n   */\n  nextIteration() {\n    if (this.contexts && this.contexts.length > 0) {\n      this.contexts = this.contexts.slice();\n      this.lastId++;\n      const context =\n          Object.assign({}, this.contexts[this.contexts.length - 1]);\n      context.iterationId += 1;\n      context.id = this.lastId;\n      this.contexts.splice(-1, 1, context);\n      this._currentContextIds.splice(\n          0, 1, this.contextIdforContexts(this.contexts));\n    } else {\n      throw new Error('Cannot increase frame iteration, the context is empty');\n    }\n  }\n\n  getWeight(name: string): Tensor[] {\n    return this.weightMap[name];\n  }\n\n  addTensorArray(tensorArray: TensorArray) {\n    this.tensorArrayMap[tensorArray.id] = tensorArray;\n  }\n\n  getTensorArray(id: number): TensorArray {\n    return this.tensorArrayMap[id];\n  }\n\n  addTensorList(tensorList: TensorList) {\n    this.tensorListMap[tensorList.id] = tensorList;\n  }\n\n  getTensorList(id: number): TensorList {\n    return this.tensorListMap[id];\n  }\n\n  dispose(keepIds: Set<number>) {\n    for (const key in this.tensorArrayMap) {\n      this.tensorArrayMap[key].clearAndClose(keepIds);\n    }\n\n    for (const key in this.tensorListMap) {\n      this.tensorListMap[key].clearAndClose(keepIds);\n    }\n  }\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {NamedTensorMap} from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../data/types';\nimport {parseNodeName} from '../operations/executors/utils';\nimport {Graph, Node} from '../operations/types';\n\nexport interface ExecutionInfo {\n  inputs: NamedTensorMap;\n  outputs: Node[];\n  usedNodes: Set<string>;\n  missingInputs: string[];\n  dynamicNode: Node;\n  syncInputs: string[];\n}\n\n/**\n * Given graph inputs and desired outputs, find the minimal set of nodes\n * to execute in order to compute the outputs. In addition return other useful\n * info such:\n * - Missing inputs needed to compute the output.\n * - Whether the subgraph contains dynamic ops (control flow, dynamic shape).\n * - Alternative inputs in order to avoid async (dynamic op) execution.\n */\nexport function getExecutionSubgraph(\n    inputs: NamedTensorMap, outputs: Node[], weightMap: NamedTensorsMap,\n    initNodes?: Node[]): ExecutionInfo {\n  const usedNodes = new Set<string>();\n  const missingInputs: string[] = [];\n  let dynamicNode: Node = null;\n  let syncInputs: string[] = null;\n\n  // Start with the outputs, going backwards and find all the nodes that are\n  // needed to compute those outputs.\n  const seen = new Set<string>();\n  const inputNodeNames =\n      Object.keys(inputs).map(name => parseNodeName(name)[0]);\n\n  let initNodeNames: string[] = [];\n  if (initNodes != null) {\n    initNodeNames = initNodes.map(node => parseNodeName(node.name)[0]);\n  }\n\n  const frontier = [...outputs];\n  while (frontier.length > 0) {\n    const node = frontier.pop();\n    if (isControlFlow(node) || isDynamicShape(node) || isHashTable(node)) {\n      if (dynamicNode == null) {\n        dynamicNode = node;\n        syncInputs = dynamicNode.children.map(child => child.name)\n                         .filter(name => usedNodes.has(name));\n      }\n    }\n    usedNodes.add(node.name);\n\n    // Weights are dead end since we already have their values.\n    if (weightMap[node.name] != null) {\n      continue;\n    }\n    // This node is a dead end since it's one of the user-provided inputs.\n    if (inputNodeNames.indexOf(node.name) !== -1) {\n      continue;\n    }\n    // This node is a dead end since it doesn't have any inputs.\n    if (initNodeNames.indexOf(node.name) !== -1) {\n      continue;\n    }\n    if (node.inputs.length === 0) {\n      missingInputs.push(node.name);\n      continue;\n    }\n    node.inputs.forEach(input => {\n      // Don't add to the frontier if it is already there.\n      if (seen.has(input.name)) {\n        return;\n      }\n      seen.add(input.name);\n      frontier.push(input);\n    });\n  }\n  return {inputs, outputs, usedNodes, missingInputs, dynamicNode, syncInputs};\n}\n\n/**\n * Given the execution info, return a list of nodes in topological order that\n * need to be executed to compute the output.\n */\nexport function getNodesInTopologicalOrder(\n    graph: Graph, weightMap: NamedTensorsMap,\n    executionInfo: ExecutionInfo): Node[] {\n  const {usedNodes, inputs} = executionInfo;\n  const frontier: Node[] = [];\n  const inputNodes = Object.keys(inputs)\n                         .map(name => parseNodeName(name)[0])\n                         .map(name => graph.nodes[name]);\n  const initNodes = graph.initNodes;\n\n  inputNodes.forEach(input => {\n    if (usedNodes.has(input.name)) {\n      frontier.push(input);\n    }\n  });\n  graph.weights.forEach(weight => {\n    if (usedNodes.has(weight.name)) {\n      frontier.push(weight);\n    }\n  });\n  if (initNodes != null) {\n    initNodes.forEach(node => {\n      if (usedNodes.has(node.name)) {\n        frontier.push(node);\n      }\n    });\n  }\n  const seen = new Set<string>();\n  const orderedNodes: Node[] = [];\n  while (frontier.length > 0) {\n    const node = frontier.pop();\n    seen.add(node.name);\n    if (!weightMap[node.name]) {\n      orderedNodes.push(node);\n    }\n    node.children.forEach(child => {\n      if (!seen.has(child.name) && usedNodes.has(child.name) &&\n          child.inputs.every(input => seen.has(input.name))) {\n        frontier.push(child);\n      }\n    });\n  }\n  return orderedNodes;\n}\n\nconst CONTROL_FLOW_OPS = [\n  'Switch', 'Merge', 'Enter', 'Exit', 'NextIteration', 'StatelessIf',\n  'StatelessWhile', 'if', 'While'\n];\nconst DYNAMIC_SHAPE_OPS = [\n  'NonMaxSuppressionV2', 'NonMaxSuppressionV3', 'NonMaxSuppressionV5', 'Where'\n];\nconst HASH_TABLE_OPS = [\n  'HashTable', 'HashTableV2', 'LookupTableImport', 'LookupTableImportV2',\n  'LookupTableFind', 'LookupTableFindV2', 'LookupTableSize', 'LookupTableSizeV2'\n];\n\nexport function isControlFlow(node: Node) {\n  return CONTROL_FLOW_OPS.indexOf(node.op) >= 0;\n}\n\nexport function isDynamicShape(node: Node) {\n  return DYNAMIC_SHAPE_OPS.indexOf(node.op) >= 0;\n}\n\nexport function isHashTable(node: Node) {\n  return HASH_TABLE_OPS.indexOf(node.op) >= 0;\n}\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, env, NamedTensorMap, Tensor, tidy, util} from '@tensorflow/tfjs-core';\n\nimport {ISignatureDef} from '../data/compiled_api';\nimport {NamedTensorsMap, TensorArrayMap, TensorInfo, TensorListMap} from '../data/types';\nimport {getNodeNameAndIndex, getParamValue, getTensor, getTensorsForCurrentContenxt, parseNodeName} from '../operations/executors/utils';\nimport {executeOp} from '../operations/operation_executor';\nimport {Graph, Node} from '../operations/types';\n\nimport {ExecutionContext, ExecutionContextInfo} from './execution_context';\nimport {getExecutionSubgraph, getNodesInTopologicalOrder, isControlFlow} from './model_analysis';\nimport {ResourceManager} from './resource_manager';\nimport {FunctionExecutor} from './types';\n\ninterface NodeWithContexts {\n  contexts: ExecutionContextInfo[];\n  node: Node;\n}\n\nexport class GraphExecutor implements FunctionExecutor {\n  private compiledMap: Map<string, Node[]> = new Map();\n  private _weightMap: NamedTensorsMap = {};\n  private _weightIds: number[];\n  private _signature: ISignatureDef;\n  private _inputs: Node[];\n  private _outputs: Node[];\n  private _initNodes: Node[];  // Internal init nodes to start initialization.\n  private SEPERATOR = ',';\n  private _functions: {[key: string]: Graph} = {};\n  private _functionExecutorMap: {[key: string]: FunctionExecutor} = {};\n  private _resourceManager: ResourceManager;\n  private intermediateTensors: NamedTensorsMap = {};\n  private keepIds: Set<number>;\n  private tensorsMap: NamedTensorsMap;\n  private keepTensorForDebug = false;\n\n  get weightIds(): number[] {\n    return this.parent ? this.parent.weightIds : this._weightIds;\n  }\n\n  get functionExecutorMap(): {[key: string]: FunctionExecutor} {\n    return this.parent ? this.parent.functionExecutorMap :\n                         this._functionExecutorMap;\n  }\n\n  get weightMap(): NamedTensorsMap {\n    return this.parent ? this.parent.weightMap : this._weightMap;\n  }\n\n  set weightMap(weightMap: NamedTensorsMap) {\n    const weightIds = Object.keys(weightMap).map(\n        key => weightMap[key].map(tensor => tensor.id));\n    this._weightIds = [].concat(...weightIds);\n    this._weightMap = weightMap;\n  }\n\n  /**\n   * Set `ResourceManager` shared by executors of a model.\n   * @param resourceManager: `ResourceManager` of the `GraphModel`.\n   */\n  set resourceManager(resourceManager: ResourceManager) {\n    this._resourceManager = resourceManager;\n  }\n\n  get inputs(): TensorInfo[] {\n    return this._inputs.map(node => {\n      return {\n        name: node.name,\n        shape: node.attrParams['shape'] ?\n            node.attrParams['shape'].value as number[] :\n            undefined,\n        dtype: node.attrParams['dtype'] ?\n            node.attrParams['dtype'].value as DataType :\n            undefined\n      };\n    });\n  }\n\n  get outputs(): TensorInfo[] {\n    return this._outputs.map(node => {\n      return {\n        name: node.name,\n        shape: node.attrParams['shape'] ?\n            node.attrParams['shape'].value as number[] :\n            undefined,\n        dtype: node.attrParams['dtype'] ?\n            node.attrParams['dtype'].value as DataType :\n            undefined\n      };\n    });\n  }\n\n  get inputNodes(): string[] {\n    return this._inputs.map(node => node.signatureKey || node.name);\n  }\n\n  get outputNodes(): string[] {\n    return this._outputs.map((node) => {\n      const name = node.signatureKey || node.name;\n      return node.defaultOutput ? (`${name}:${node.defaultOutput}`) : name;\n    });\n  }\n\n  get functions(): {[key: string]: ISignatureDef} {\n    return Object.keys(this._functions).reduce((map, key) => {\n      map[key] = this._functions[key].signature;\n      return map;\n    }, {} as {[key: string]: ISignatureDef});\n  }\n\n  /**\n   *\n   * @param graph Graph the model or function graph to be executed.\n   * @param parent When building function exector you need to set the parent\n   * executor. Since the weights and function executor maps are set at parant\n   * level, that function executor can access the function maps and weight maps\n   * through the parent.\n   */\n  constructor(private graph: Graph, private parent?: GraphExecutor) {\n    this._outputs = graph.outputs;\n    this._inputs = graph.inputs;\n    this._initNodes = graph.initNodes;\n    this._signature = graph.signature;\n    this._functions = graph.functions;\n    // create sub-graph executors\n    if (graph.functions != null) {\n      Object.keys(graph.functions).forEach(name => {\n        this._functionExecutorMap[name] =\n            new GraphExecutor(graph.functions[name], this);\n      });\n    }\n  }\n\n  private getCompilationKey(inputs: Node[], outputs: Node[]): string {\n    const sortedInputs = inputs.map(node => node.name).sort();\n    const sortedOutputs = outputs.map(node => node.name).sort();\n    return sortedInputs.join(this.SEPERATOR) + '--' +\n        sortedOutputs.join(this.SEPERATOR);\n  }\n\n  /**\n   * Compiles the inference graph and returns the minimal set of nodes that are\n   * required for execution, in the correct execution order.\n   */\n  private compile(inputs: NamedTensorMap, outputs: Node[]): Node[] {\n    const executionInfo =\n        getExecutionSubgraph(inputs, outputs, this.weightMap, this._initNodes);\n    const {missingInputs, dynamicNode, syncInputs} = executionInfo;\n    if (dynamicNode != null) {\n      throw new Error(\n          `This execution contains the node '${dynamicNode.name}', which has ` +\n          `the dynamic op '${dynamicNode.op}'. Please use ` +\n          `model.executeAsync() instead. Alternatively, to avoid the ` +\n          `dynamic ops, specify the inputs [${syncInputs}]`);\n    }\n\n    if (missingInputs.length > 0) {\n      const outNames = outputs.map(n => n.name);\n      const inNames = Object.keys(inputs);\n      throw new Error(\n          `Cannot compute the outputs [${outNames}] from the provided inputs ` +\n          `[${inNames}]. Missing the following inputs: [${missingInputs}]`);\n    }\n\n    return getNodesInTopologicalOrder(\n        this.graph, this.weightMap, executionInfo);\n  }\n\n  /**\n   * Executes the inference for given input tensors.\n   * @param inputs Tensor map for the model inputs, keyed by the input node\n   * names.\n   * @param outputs Optional. output node name from the Tensorflow model, if\n   * no outputs are specified, the default outputs of the model would be used.\n   * You can inspect intermediate nodes of the model by adding them to the\n   * outputs array.\n   */\n  execute(inputs: NamedTensorMap, outputs?: string[]): Tensor[] {\n    inputs = this.mapInputs(inputs);\n    const names = Object.keys(inputs).sort();\n    this.checkInputs(inputs);\n    this.checkInputShapeAndType(inputs);\n    outputs = this.mapOutputs(outputs);\n    this.checkOutputs(outputs);\n    const inputNodes =\n        names.map(name => this.graph.nodes[parseNodeName(name)[0]]);\n    const outputNodeNames = outputs.map(name => parseNodeName(name)[0]);\n    let outputNodes = outputNodeNames.map(name => this.graph.nodes[name]);\n    this.resetIntermediateTensors();\n    // If no outputs are specified, then use the default outputs of the model.\n    if (outputNodes.length === 0) {\n      outputNodes = this._outputs;\n    }\n\n    const compilationKey = this.getCompilationKey(inputNodes, outputNodes);\n\n    // Do nothing if the compiled graph cache contains the input.\n    let orderedNodes = this.compiledMap.get(compilationKey);\n    if (orderedNodes == null) {\n      orderedNodes = this.compile(inputs, outputNodes);\n      this.compiledMap.set(compilationKey, orderedNodes);\n    }\n\n    const tensorArrayMap: TensorArrayMap = {};\n    const tensorListMap: TensorListMap = {};\n\n    return tidy(() => {\n      const context = new ExecutionContext(\n          this.weightMap, tensorArrayMap, tensorListMap,\n          this.functionExecutorMap);\n      const tensorsMap: NamedTensorsMap = {...this.weightMap};\n\n      Object.keys(inputs).forEach(name => {\n        const [nodeName, index] = parseNodeName(name);\n        const tensors: Tensor[] = [];\n        tensors[index] = inputs[name];\n        tensorsMap[nodeName] = tensors;\n      });\n\n      const tensorsToKeep = this.getFrozenTensorIds(tensorsMap);\n      const intermediateTensorConsumerCount: {[key: number]: number} = {};\n      for (let i = 0; i < orderedNodes.length; i++) {\n        const node = orderedNodes[i];\n        if (!tensorsMap[node.name]) {\n          const tensors =\n              executeOp(node, tensorsMap, context, this._resourceManager) as\n              Tensor[];\n          if (util.isPromise(tensors)) {\n            throw new Error(\n                `The execution of the op '${node.op}' returned a promise. ` +\n                `Please use model.executeAsync() instead.`);\n          }\n          tensorsMap[node.name] = tensors;\n          this.checkTensorForDisposal(\n              node.name, node, tensorsMap, context, tensorsToKeep,\n              outputNodeNames, intermediateTensorConsumerCount);\n        }\n      }\n      // dispose the context for the root executor\n      if (this.parent == null) {\n        context.dispose(tensorsToKeep);\n      }\n      return outputs.map(name => getTensor(name, tensorsMap, context));\n    });\n  }\n\n  private getFrozenTensorIds(tensorMap: NamedTensorsMap): Set<number> {\n    const ids = [].concat.apply(\n        [],\n        Object.keys(tensorMap)\n            .map(key => tensorMap[key])\n            .map(tensors => tensors.map(tensor => tensor.id)));\n    return new Set(ids);\n  }\n  private checkTensorForDisposal(\n      nodeName: string, node: Node, tensorMap: NamedTensorsMap,\n      context: ExecutionContext, tensorsToKeep: Set<number>,\n      outputNames: string[],\n      intermediateTensorConsumerCount: {[key: string]: number}) {\n    // Skip output nodes and any control flow nodes, since its dependency is\n    // tricky to track correctly.\n    if (node.category === 'control' || outputNames.indexOf(nodeName) !== -1) {\n      return;\n    }\n\n    tensorMap[nodeName].forEach(tensor => {\n      if (tensor != null) {\n        intermediateTensorConsumerCount[tensor.id] =\n            (intermediateTensorConsumerCount[tensor.id] || 0) +\n            node.children.length;\n      }\n    });\n    node.inputs.forEach(input => {\n      // Skip any control flow nodes, since its dependency is tricky to track\n      // correctly.\n      if (input.category !== 'control') {\n        const tensors =\n            getTensorsForCurrentContenxt(input.name, tensorMap, context);\n        if (tensors != null) {\n          tensors.forEach(tensor => {\n            if (tensor && !tensor.kept && !tensorsToKeep.has(tensor.id)) {\n              const count = intermediateTensorConsumerCount[tensor.id];\n              if (count === 1) {\n                if (!this.keepTensorForDebug) {\n                  tensor.dispose();\n                } else {\n                  const [nodeName, index] =\n                      getNodeNameAndIndex(node.name, context);\n                  if (this.intermediateTensors[nodeName]) {\n                    this.intermediateTensors[nodeName][index] = tensor;\n                  } else {\n                    this.intermediateTensors[nodeName] = [];\n                    this.intermediateTensors[nodeName][index] = tensor;\n                  }\n                }\n                delete intermediateTensorConsumerCount[tensor.id];\n              } else if (count != null) {\n                // only intermediate nodes has count set, inputs and weights are\n                // not.\n                intermediateTensorConsumerCount[tensor.id]--;\n              }\n            }\n          });\n        }\n      }\n    });\n  }\n\n  /**\n   * Executes the inference for given input tensors in Async fashion.\n   * @param inputs Tensor map for the model inputs, keyed by the input node\n   * names.\n   * @param outputs output node name from the Tensorflow model, if no outputs\n   * are specified, the default outputs of the model would be used. You can\n   * inspect intermediate nodes of the model by adding them to the outputs\n   * array.\n   */\n  async executeAsync(inputs: NamedTensorMap, outputs?: string[]):\n      Promise<Tensor[]> {\n    return this._executeAsync(inputs, outputs);\n  }\n\n  disposeIntermediateTensors() {\n    if (!this.intermediateTensors) {\n      return;\n    }\n    Object.keys(this.intermediateTensors)\n        .forEach(\n            key => this.intermediateTensors[key].forEach(\n                tensor => tensor.dispose()));\n    this.disposeTensorsMap();\n  }\n\n  private disposeTensorsMap() {\n    if (!this.tensorsMap) {\n      return;\n    }\n    Object.keys(this.tensorsMap).forEach(key => {\n      const tensorArray = this.tensorsMap[key];\n      tensorArray.forEach(tensor => {\n        if (tensor && !tensor.kept && !tensor.isDisposed &&\n            !this.keepIds.has(tensor.id)) {\n          tensor.dispose();\n        }\n      });\n    });\n  }\n\n  getIntermediateTensors(): NamedTensorsMap {\n    return this.tensorsMap;\n  }\n\n  private resetIntermediateTensors() {\n    for (const key in this.intermediateTensors) {\n      this.intermediateTensors[key].forEach(tensor => tensor.dispose());\n      delete this.intermediateTensors[key];\n    }\n  }\n\n  /**\n   * Executes the inference for given input tensors in Async fashion.\n   * @param inputs Tensor map for the model inputs, keyed by the input node\n   * names.\n   * @param outputs Optional. output node name from the Tensorflow model,\n   * if no outputs are specified, the default outputs of the model would be\n   * used. You can inspect intermediate nodes of the model by adding them to the\n   * outputs array.\n   * @param isFunctionExecution Optional. Flag for executing a function.\n   * @param tensorArrayMap Optional, global TensorArray map by id. Used for\n   * function execution.\n   * @param tensorArrayMap Optinal global TensorList map by id. Used for\n   * function execution.\n   */\n  private async _executeAsync(\n      inputs: NamedTensorMap, outputs?: string[], isFunctionExecution = false,\n      tensorArrayMap: TensorArrayMap = {},\n      tensorListMap: TensorListMap = {}): Promise<Tensor[]> {\n    if (!isFunctionExecution) {\n      inputs = this.mapInputs(inputs);\n      this.checkInputs(inputs);\n      this.checkInputShapeAndType(inputs);\n      outputs = this.mapOutputs(outputs);\n      this.checkOutputs(outputs);\n    }\n\n    // For model debug.\n    try {\n      this.keepTensorForDebug = env().getBool('KEEP_INTERMEDIATE_TENSORS');\n    } catch (e) {\n      console.warn(e.message);\n    }\n    this.resetIntermediateTensors();\n\n    const context = new ExecutionContext(\n        this.weightMap, tensorArrayMap, tensorListMap,\n        this.functionExecutorMap);\n\n    // Graph with control flow op requires runtime evaluation of the execution\n    // order, while without control flow the execution order is pre-determined\n    // in the compile method.\n    this.tensorsMap = await this.executeWithControlFlow(\n        inputs, context, outputs, isFunctionExecution);\n    const results =\n        outputs.map(name => getTensor(name, this.tensorsMap, context));\n\n    // dispose all the intermediate tensors\n    const outputIds = results.map(t => t.id);\n    const inputIds = Object.keys(inputs).map(name => inputs[name].id);\n    this.keepIds =\n        new Set<number>([...outputIds, ...inputIds, ...this.weightIds]);\n    if (!this.keepTensorForDebug) {\n      this.disposeTensorsMap();\n    }\n\n    // dispose the context for the root executor\n    if (this.parent == null) {\n      context.dispose(this.keepIds);\n    }\n\n    return results;\n  }\n\n  async executeFunctionAsync(\n      inputs: Tensor[], tensorArrayMap: TensorArrayMap,\n      tensorListMap: TensorListMap): Promise<Tensor[]> {\n    const mappedInputs = inputs.reduce((map, tensor, index) => {\n      map[this.inputs[index].name] = tensor;\n      return map;\n    }, {} as NamedTensorMap);\n\n    return this._executeAsync(\n        mappedInputs, this.outputNodes, true, tensorArrayMap, tensorListMap);\n  }\n\n  /**\n   * When there are control flow nodes in the graph, the graph execution use\n   * ExecutionContext to keep track of the frames and loop iterators.\n   * @param inputs placeholder tensors for the graph.\n   * @param context the execution context object for current execution.\n   * @param outputNames Optional. output node name from the Tensorflow model,\n   * if no outputs are specified, the default outputs of the model would be\n   * used. You can inspect intermediate nodes of the model by adding them to the\n   * outputs array.\n   * @param isFunctionExecution Flag for executing a function.\n   */\n  private async executeWithControlFlow(\n      inputs: NamedTensorMap, context: ExecutionContext, outputNames?: string[],\n      isFunctionExecution?: boolean): Promise<NamedTensorsMap> {\n    const names = Object.keys(inputs);\n    const inputNodes =\n        names.map(name => this.graph.nodes[parseNodeName(name)[0]]);\n    const outputNodeNames = outputNames.map(name => parseNodeName(name)[0]);\n    let outputNodes = outputNodeNames.map(name => this.graph.nodes[name]);\n\n    // If no outputs are specified, then use the default outputs of the model.\n    if (outputNodes.length === 0) {\n      outputNodes = this._outputs;\n    }\n\n    const {usedNodes, missingInputs, dynamicNode, syncInputs} =\n        getExecutionSubgraph(\n            inputs, outputNodes, this.weightMap, this._initNodes);\n\n    // First nodes to execute include inputNodes, weights, and initNodes.\n    const stack: NodeWithContexts[] = [\n      ...inputNodes, ...this.graph.weights, ...(this._initNodes || [])\n    ].map(node => {\n      return {node, contexts: context.currentContext};\n    });\n    const tensorsMap: NamedTensorsMap = {...this.weightMap};\n    Object.keys(inputs).forEach(name => {\n      const [nodeName, index] = parseNodeName(name);\n      const tensors: Tensor[] = [];\n      tensors[index] = inputs[name];\n      tensorsMap[nodeName] = tensors;\n    });\n    const intermediateTensorConsumerCount: {[key: number]: number} = {};\n    const tensorsToKeep = this.getFrozenTensorIds(tensorsMap);\n    const added: {[key: string]: boolean} = {};\n    while (stack.length > 0) {\n      const promises = this.processStack(\n          inputNodes, stack, context, tensorsMap, added, tensorsToKeep,\n          outputNodeNames, intermediateTensorConsumerCount, usedNodes);\n      await Promise.all(promises);\n    }\n    if (dynamicNode == null && !isFunctionExecution) {\n      console.warn(\n          `This model execution did not contain any nodes with control flow ` +\n          `or dynamic output shapes. You can use model.execute() instead.`);\n    }\n    const missingOutputs =\n        outputNodes\n            .filter(\n                node => !isControlFlow(node) &&\n                    !getTensor(node.name, tensorsMap, context))\n            .map(node => node.name);\n    if (missingOutputs.length > 0) {\n      let alternativeMsg = '';\n      if (dynamicNode != null) {\n        alternativeMsg =\n            `Alternatively, to avoid the dynamic ops, use model.execute() ` +\n            `and specify the inputs [${syncInputs}]`;\n      }\n      throw new Error(\n          `Cannot compute the outputs [${missingOutputs}] from the provided ` +\n          `inputs [${names}]. Consider providing the following inputs: ` +\n          `[${missingInputs}]. ${alternativeMsg}`);\n    }\n    return tensorsMap;\n  }\n\n  private processStack(\n      inputNodes: Node[], stack: NodeWithContexts[], context: ExecutionContext,\n      tensorMap: NamedTensorsMap, added: {[key: string]: boolean},\n      tensorsToKeep: Set<number>, outputNames: string[],\n      intermediateTensorConsumerCount: {[key: number]: number},\n      usedNodes: Set<string>) {\n    const promises: Array<Promise<Tensor[]>> = [];\n    while (stack.length > 0) {\n      const item = stack.pop();\n      context.currentContext = item.contexts;\n      let nodeName = '';\n      // The tensor of the Enter op with isConstant set should be set\n      // in the parent scope, so it will be available as constant for the\n      // whole loop.\n      if (item.node.op === 'Enter' &&\n          getParamValue('isConstant', item.node, tensorMap, context)) {\n        [nodeName] = getNodeNameAndIndex(item.node.name, context);\n      }\n\n      // only process nodes that are not in the tensorMap yet, this include\n      // inputNodes and internal initNodes.\n      if (tensorMap[item.node.name] == null) {\n        const tensors =\n            executeOp(item.node, tensorMap, context, this._resourceManager);\n        if (!nodeName) {\n          [nodeName] = getNodeNameAndIndex(item.node.name, context);\n        }\n        const currentContext = context.currentContext;\n        if (util.isPromise(tensors)) {\n          promises.push(tensors.then(t => {\n            tensorMap[nodeName] = t;\n            context.currentContext = currentContext;\n            this.checkTensorForDisposal(\n                nodeName, item.node, tensorMap, context, tensorsToKeep,\n                outputNames, intermediateTensorConsumerCount);\n            this.processChildNodes(\n                item.node, stack, context, tensorMap, added, usedNodes);\n            return t;\n          }));\n        } else {\n          tensorMap[nodeName] = tensors;\n          this.checkTensorForDisposal(\n              nodeName, item.node, tensorMap, context, tensorsToKeep,\n              outputNames, intermediateTensorConsumerCount);\n          this.processChildNodes(\n              item.node, stack, context, tensorMap, added, usedNodes);\n        }\n      } else {\n        this.processChildNodes(\n            item.node, stack, context, tensorMap, added, usedNodes);\n      }\n    }\n    return promises;\n  }\n\n  private processChildNodes(\n      node: Node, stack: NodeWithContexts[], context: ExecutionContext,\n      tensorMap: NamedTensorsMap, added: {[key: string]: boolean},\n      usedNodes: Set<string>) {\n    node.children.forEach((childNode) => {\n      const [nodeName, ] = getNodeNameAndIndex(childNode.name, context);\n      if (added[nodeName] || !usedNodes.has(childNode.name)) {\n        return;\n      }\n      // Merge op can be pushed if any of its inputs has value.\n      if (childNode.op === 'Merge') {\n        if (childNode.inputNames.some(name => {\n              return !!getTensor(name, tensorMap, context);\n            })) {\n          added[nodeName] = true;\n          stack.push({contexts: context.currentContext, node: childNode});\n        }\n      } else  // Otherwise all inputs must to have value.\n          if (childNode.inputNames.every(name => {\n                return !!getTensor(name, tensorMap, context);\n              })) {\n        added[nodeName] = true;\n        stack.push({contexts: context.currentContext, node: childNode});\n      }\n    });\n  }\n\n  /**\n   * Releases the memory used by the weight tensors.\n   */\n  dispose() {\n    Object.keys(this.weightMap)\n        .forEach(\n            key => this.weightMap[key].forEach(tensor => tensor.dispose()));\n  }\n\n  private checkInputShapeAndType(inputs: NamedTensorMap) {\n    Object.keys(inputs).forEach(name => {\n      const input = inputs[name];\n      const [nodeName, ] = parseNodeName(name);\n      const node = this.graph.nodes[nodeName];\n      if (node.attrParams['shape'] && node.attrParams['shape'].value) {\n        const shape = node.attrParams['shape'].value as number[];\n        const match = shape.length === input.shape.length &&\n            input.shape.every(\n                (dim, index) => shape[index] === -1 || shape[index] === dim);\n        util.assert(\n            match,\n            () => `The shape of dict['${node.name}'] provided in ` +\n                `model.execute(dict) must be [${shape}], but was ` +\n                `[${input.shape}]`);\n      }\n      if (node.attrParams['dtype'] && node.attrParams['dtype'].value) {\n        util.assert(\n            input.dtype === node.attrParams['dtype'].value as string,\n            () => `The dtype of dict['${node.name}'] provided in ` +\n                `model.execute(dict) must be ` +\n                `${node.attrParams['dtype'].value}, but was ${input.dtype}`);\n      }\n    });\n  }\n\n  private mapInputs(inputs: NamedTensorMap) {\n    const result: NamedTensorMap = {};\n    for (const inputName in inputs) {\n      if (this._signature != null && this._signature.inputs != null &&\n          this._signature.inputs[inputName] != null) {\n        const tensor = this._signature.inputs[inputName];\n        result[tensor.name] = inputs[inputName];\n      } else {\n        result[inputName] = inputs[inputName];\n      }\n    }\n    return result;\n  }\n\n  private checkInputs(inputs: NamedTensorMap) {\n    const notInGraph = Object.keys(inputs).filter(name => {\n      const [nodeName] = parseNodeName(name);\n      return this.graph.nodes[nodeName] == null;\n    });\n    if (notInGraph.length > 0) {\n      throw new Error(\n          `The dict provided in model.execute(dict) has ` +\n          `keys: [${notInGraph}] that are not part of graph`);\n    }\n  }\n\n  private mapOutputs(outputs: string[]) {\n    return outputs.map(name => {\n      if (this._signature != null && this._signature.outputs != null &&\n          this._signature.outputs[name] != null) {\n        const tensor = this._signature.outputs[name];\n        return tensor.name;\n      }\n      return name;\n    }, {});\n  }\n\n  private checkOutputs(outputs: string[]): void {\n    outputs.forEach(name => {\n      const [normalizedName] = parseNodeName(name);\n      if (!this.graph.nodes[normalizedName]) {\n        throw new Error(`The output '${name}' is not found in the graph`);\n      }\n    });\n  }\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {HashTableMap, NamedTensorMap} from '../data/types';\nimport {HashTable} from './hash_table';\n\n/**\n * Contains global resources of a model.\n */\nexport class ResourceManager {\n  constructor(\n      readonly hashTableNameToHandle: NamedTensorMap = {},\n      readonly hashTableMap: HashTableMap = {}) {}\n\n  /**\n   * Register a `HashTable` in the resource manager.\n   *\n   * The `HashTable` can be retrieved by `resourceManager.getHashTableById`,\n   * where id is the table handle tensor's id.\n   *\n   * @param name Op node name that creates the `HashTable`.\n   * @param hashTable The `HashTable` to be added to resource manager.\n   */\n  addHashTable(name: string, hashTable: HashTable) {\n    this.hashTableNameToHandle[name] = hashTable.handle;\n    this.hashTableMap[hashTable.id] = hashTable;\n  }\n\n  /**\n   * Get the table handle by node name.\n   * @param name Op node name that creates the `HashTable`. This name is also\n   *     used in the inputs list of lookup and import `HashTable` ops.\n   */\n  getHashTableHandleByName(name: string) {\n    return this.hashTableNameToHandle[name];\n  }\n\n  /**\n   * Get the actual `HashTable` by its handle tensor's id.\n   * @param id The id of the handle tensor.\n   */\n  getHashTableById(id: number): HashTable {\n    return this.hashTableMap[id];\n  }\n\n  /**\n   * Dispose `ResourceManager`, including its hashTables and tensors in them.\n   */\n  dispose() {\n    for (const key in this.hashTableMap) {\n      this.hashTableMap[key].clearAndClose();\n      delete this.hashTableMap[key];\n    }\n\n    for (const name in this.hashTableNameToHandle) {\n      this.hashTableNameToHandle[name].dispose();\n      delete this.hashTableNameToHandle[name];\n    }\n  }\n}\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {InferenceModel, io, ModelPredictConfig, NamedTensorMap, Tensor, util} from '@tensorflow/tfjs-core';\n\nimport * as tensorflow from '../data/compiled_api';\nimport {NamedTensorsMap, TensorInfo} from '../data/types';\nimport {OperationMapper} from '../operations/operation_mapper';\n\nimport {GraphExecutor} from './graph_executor';\nimport {ResourceManager} from './resource_manager';\n\nexport const TFHUB_SEARCH_PARAM = '?tfjs-format=file';\nexport const DEFAULT_MODEL_NAME = 'model.json';\ntype Url = string|io.IOHandler|io.IOHandlerSync;\ntype UrlIOHandler<T extends Url> = T extends string ? io.IOHandler : T;\n\n/**\n * A `tf.GraphModel` is a directed, acyclic graph built from a\n * SavedModel GraphDef and allows inference execution.\n *\n * A `tf.GraphModel` can only be created by loading from a model converted from\n * a [TensorFlow SavedModel](https://www.tensorflow.org/guide/saved_model) using\n * the command line converter tool and loaded via `tf.loadGraphModel`.\n *\n * @doc {heading: 'Models', subheading: 'Classes'}\n */\nexport class GraphModel<ModelURL extends Url = string | io.IOHandler> implements\n    InferenceModel {\n  private executor: GraphExecutor;\n  private version = 'n/a';\n  private handler: UrlIOHandler<ModelURL>;\n  private artifacts: io.ModelArtifacts;\n  private initializer: GraphExecutor;\n  private resourceManager: ResourceManager;\n  private signature: tensorflow.ISignatureDef;\n  private structuredOutputKeys: string[];\n  private readonly io: typeof io;\n\n  // Returns the version information for the tensorflow model GraphDef.\n  get modelVersion(): string {\n    return this.version;\n  }\n\n  get inputNodes(): string[] {\n    return this.executor.inputNodes;\n  }\n\n  get outputNodes(): string[] {\n    return this.executor.outputNodes;\n  }\n\n  get inputs(): TensorInfo[] {\n    return this.executor.inputs;\n  }\n\n  get outputs(): TensorInfo[] {\n    return this.executor.outputs;\n  }\n\n  get weights(): NamedTensorsMap {\n    return this.executor.weightMap;\n  }\n\n  get metadata(): {} {\n    return this.artifacts.userDefinedMetadata;\n  }\n\n  get modelSignature(): {} {\n    return this.signature;\n  }\n\n  get modelStructuredOutputKeys(): {} {\n    return this.structuredOutputKeys;\n  }\n\n  /**\n   * @param modelUrl url for the model, or an `io.IOHandler`.\n   * @param weightManifestUrl url for the weight file generated by\n   * scripts/convert.py script.\n   * @param requestOption options for Request, which allows to send credentials\n   * and custom headers.\n   * @param onProgress Optional, progress callback function, fired periodically\n   * before the load is completed.\n   */\n  constructor(\n      private modelUrl: ModelURL, private loadOptions: io.LoadOptions = {},\n      tfio = io) {\n    this.io = tfio;\n    if (loadOptions == null) {\n      this.loadOptions = {};\n    }\n    this.resourceManager = new ResourceManager();\n  }\n\n  private findIOHandler() {\n    type IOHandler = UrlIOHandler<ModelURL>;\n    const path = this.modelUrl;\n    if ((path as io.IOHandler).load != null) {\n      // Path is an IO Handler.\n      this.handler = path as IOHandler;\n    } else if (this.loadOptions.requestInit != null) {\n      this.handler = this.io.browserHTTPRequest(\n                         path as string, this.loadOptions) as IOHandler;\n    } else {\n      const handlers =\n          this.io.getLoadHandlers(path as string, this.loadOptions);\n      if (handlers.length === 0) {\n        // For backward compatibility: if no load handler can be found,\n        // assume it is a relative http path.\n        handlers.push(\n            this.io.browserHTTPRequest(path as string, this.loadOptions));\n      } else if (handlers.length > 1) {\n        throw new Error(\n            `Found more than one (${handlers.length}) load handlers for ` +\n            `URL '${[path]}'`);\n      }\n      this.handler = handlers[0] as IOHandler;\n    }\n  }\n\n  /**\n   * Loads the model and weight files, construct the in memory weight map and\n   * compile the inference graph.\n   */\n  load(): UrlIOHandler<ModelURL> extends io.IOHandlerSync? boolean:\n                                             Promise<boolean> {\n    type IOHandler = UrlIOHandler<ModelURL>;\n    this.findIOHandler();\n    if (this.handler.load == null) {\n      throw new Error(\n          'Cannot proceed with model loading because the IOHandler provided ' +\n          'does not have the `load` method implemented.');\n    }\n\n    type Result =\n        IOHandler extends io.IOHandlerSync ? boolean : Promise<boolean>;\n\n    const loadResult = this.handler.load() as ReturnType<IOHandler['load']>;\n    if (util.isPromise(loadResult)) {\n      return loadResult.then(artifacts => this.loadSync(artifacts)) as Result;\n    }\n\n    return this.loadSync(loadResult) as Result;\n  }\n\n  /**\n   * Synchronously construct the in memory weight map and\n   * compile the inference graph. Also initialize hashtable if any.\n   *\n   * @doc {heading: 'Models', subheading: 'Classes', ignoreCI: true}\n   */\n  loadSync(artifacts: io.ModelArtifacts) {\n    this.artifacts = artifacts;\n    const graph = this.artifacts.modelTopology as tensorflow.IGraphDef;\n\n    let signature = this.artifacts.signature;\n    if (this.artifacts.userDefinedMetadata != null) {\n      const metadata = this.artifacts.userDefinedMetadata;\n      if (metadata.signature != null) {\n        signature = metadata.signature;\n      }\n\n      if (metadata.structuredOutputKeys != null) {\n        this.structuredOutputKeys = metadata.structuredOutputKeys as string[];\n      }\n    }\n    this.signature = signature;\n\n    this.version = `${graph.versions.producer}.${graph.versions.minConsumer}`;\n    const weightMap = this.io.decodeWeights(\n        this.artifacts.weightData, this.artifacts.weightSpecs);\n    this.executor = new GraphExecutor(\n        OperationMapper.Instance.transformGraph(graph, this.signature));\n    this.executor.weightMap = this.convertTensorMapToTensorsMap(weightMap);\n    // Attach a model-level resourceManager to each executor to share resources,\n    // such as `HashTable`.\n    this.executor.resourceManager = this.resourceManager;\n\n    if (artifacts.modelInitializer != null &&\n        (artifacts.modelInitializer as tensorflow.IGraphDef).node != null) {\n      const initializer =\n          OperationMapper.Instance.transformGraph(artifacts.modelInitializer);\n      this.initializer = new GraphExecutor(initializer);\n      this.initializer.weightMap = this.executor.weightMap;\n      // Attach a model-level resourceManager to the initializer, the\n      // hashTables created from when executing the initializer will be stored\n      // in the resourceManager.\n      this.initializer.resourceManager = this.resourceManager;\n      this.initializer.executeAsync({}, []);\n    }\n\n    return true;\n  }\n\n  /**\n   * Save the configuration and/or weights of the GraphModel.\n   *\n   * An `IOHandler` is an object that has a `save` method of the proper\n   * signature defined. The `save` method manages the storing or\n   * transmission of serialized data (\"artifacts\") that represent the\n   * model's topology and weights onto or via a specific medium, such as\n   * file downloads, local storage, IndexedDB in the web browser and HTTP\n   * requests to a server. TensorFlow.js provides `IOHandler`\n   * implementations for a number of frequently used saving mediums, such as\n   * `tf.io.browserDownloads` and `tf.io.browserLocalStorage`. See `tf.io`\n   * for more details.\n   *\n   * This method also allows you to refer to certain types of `IOHandler`s\n   * as URL-like string shortcuts, such as 'localstorage://' and\n   * 'indexeddb://'.\n   *\n   * Example 1: Save `model`'s topology and weights to browser [local\n   * storage](https://developer.mozilla.org/en-US/docs/Web/API/Window/localStorage);\n   * then load it back.\n   *\n   * ```js\n   * const modelUrl =\n   *    'https://storage.googleapis.com/tfjs-models/savedmodel/mobilenet_v2_1.0_224/model.json';\n   * const model = await tf.loadGraphModel(modelUrl);\n   * const zeros = tf.zeros([1, 224, 224, 3]);\n   * model.predict(zeros).print();\n   *\n   * const saveResults = await model.save('localstorage://my-model-1');\n   *\n   * const loadedModel = await tf.loadGraphModel('localstorage://my-model-1');\n   * console.log('Prediction from loaded model:');\n   * model.predict(zeros).print();\n   * ```\n   *\n   * @param handlerOrURL An instance of `IOHandler` or a URL-like,\n   * scheme-based string shortcut for `IOHandler`.\n   * @param config Options for saving the model.\n   * @returns A `Promise` of `SaveResult`, which summarizes the result of\n   * the saving, such as byte sizes of the saved artifacts for the model's\n   *   topology and weight values.\n   *\n   * @doc {heading: 'Models', subheading: 'Classes', ignoreCI: true}\n   */\n  async save(handlerOrURL: io.IOHandler|string, config?: io.SaveConfig):\n      Promise<io.SaveResult> {\n    if (typeof handlerOrURL === 'string') {\n      const handlers = this.io.getSaveHandlers(handlerOrURL);\n      if (handlers.length === 0) {\n        throw new Error(\n            `Cannot find any save handlers for URL '${handlerOrURL}'`);\n      } else if (handlers.length > 1) {\n        throw new Error(\n            `Found more than one (${handlers.length}) save handlers for ` +\n            `URL '${handlerOrURL}'`);\n      }\n      handlerOrURL = handlers[0];\n    }\n    if (handlerOrURL.save == null) {\n      throw new Error(\n          'GraphModel.save() cannot proceed because the IOHandler ' +\n          'provided does not have the `save` attribute defined.');\n    }\n\n    return handlerOrURL.save(this.artifacts);\n  }\n\n  /**\n   * Execute the inference for the input tensors.\n   *\n   * @param input The input tensors, when there is single input for the model,\n   * inputs param should be a `tf.Tensor`. For models with mutliple inputs,\n   * inputs params should be in either `tf.Tensor`[] if the input order is\n   * fixed, or otherwise NamedTensorMap format.\n   *\n   * For model with multiple inputs, we recommend you use NamedTensorMap as the\n   * input type, if you use `tf.Tensor`[], the order of the array needs to\n   * follow the\n   * order of inputNodes array. @see {@link GraphModel.inputNodes}\n   *\n   * You can also feed any intermediate nodes using the NamedTensorMap as the\n   * input type. For example, given the graph\n   *    InputNode => Intermediate => OutputNode,\n   * you can execute the subgraph Intermediate => OutputNode by calling\n   *    model.execute('IntermediateNode' : tf.tensor(...));\n   *\n   * This is useful for models that uses tf.dynamic_rnn, where the intermediate\n   * state needs to be fed manually.\n   *\n   * For batch inference execution, the tensors for each input need to be\n   * concatenated together. For example with mobilenet, the required input shape\n   * is [1, 244, 244, 3], which represents the [batch, height, width, channel].\n   * If we are provide a batched data of 100 images, the input tensor should be\n   * in the shape of [100, 244, 244, 3].\n   *\n   * @param config Prediction configuration for specifying the batch size.\n   * Currently the batch size option is ignored for graph model.\n   *\n   * @returns Inference result tensors. If the model is converted and it\n   * originally had structured_outputs in tensorflow, then a NamedTensorMap\n   * will be returned matching the structured_outputs. If no structured_outputs\n   * are present, the output will be single `tf.Tensor` if the model has single\n   * output node, otherwise Tensor[].\n   *\n   * @doc {heading: 'Models', subheading: 'Classes'}\n   */\n  predict(inputs: Tensor|Tensor[]|NamedTensorMap, config?: ModelPredictConfig):\n      Tensor|Tensor[]|NamedTensorMap {\n    const outputTensors = this.execute(inputs, this.outputNodes);\n    if (this.structuredOutputKeys) {\n      const outputTensorsArray =\n          outputTensors instanceof Tensor ? [outputTensors] : outputTensors;\n      const outputTensorMap: NamedTensorMap = {};\n\n      outputTensorsArray.forEach(\n          (outputTensor, i) => outputTensorMap[this.structuredOutputKeys[i]] =\n              outputTensor);\n\n      return outputTensorMap;\n    }\n    return outputTensors;\n  }\n\n  private normalizeInputs(inputs: Tensor|Tensor[]|\n                          NamedTensorMap): NamedTensorMap {\n    if (!(inputs instanceof Tensor) && !Array.isArray(inputs)) {\n      // The input is already a NamedTensorMap.\n      return inputs;\n    }\n    inputs = Array.isArray(inputs) ? inputs : [inputs];\n    if (inputs.length !== this.inputNodes.length) {\n      throw new Error(\n          'Input tensor count mismatch,' +\n          `the graph model has ${this.inputNodes.length} placeholders, ` +\n          `while there are ${inputs.length} input tensors.`);\n    }\n    return this.inputNodes.reduce((map, inputName, i) => {\n      map[inputName] = (inputs as Tensor[])[i];\n      return map;\n    }, {} as NamedTensorMap);\n  }\n\n  private normalizeOutputs(outputs: string|string[]): string[] {\n    outputs = outputs || this.outputNodes;\n    return !Array.isArray(outputs) ? [outputs] : outputs;\n  }\n\n  /**\n   * Executes inference for the model for given input tensors.\n   * @param inputs tensor, tensor array or tensor map of the inputs for the\n   * model, keyed by the input node names.\n   * @param outputs output node name from the TensorFlow model, if no\n   * outputs are specified, the default outputs of the model would be used.\n   * You can inspect intermediate nodes of the model by adding them to the\n   * outputs array.\n   *\n   * @returns A single tensor if provided with a single output or no outputs\n   * are provided and there is only one default output, otherwise return a\n   * tensor array. The order of the tensor array is the same as the outputs\n   * if provided, otherwise the order of outputNodes attribute of the model.\n   *\n   * @doc {heading: 'Models', subheading: 'Classes'}\n   */\n  execute(inputs: Tensor|Tensor[]|NamedTensorMap, outputs?: string|string[]):\n      Tensor|Tensor[] {\n    inputs = this.normalizeInputs(inputs);\n    outputs = this.normalizeOutputs(outputs);\n    const result = this.executor.execute(inputs, outputs);\n    return result.length > 1 ? result : result[0];\n  }\n  /**\n   * Executes inference for the model for given input tensors in async\n   * fashion, use this method when your model contains control flow ops.\n   * @param inputs tensor, tensor array or tensor map of the inputs for the\n   * model, keyed by the input node names.\n   * @param outputs output node name from the TensorFlow model, if no outputs\n   * are specified, the default outputs of the model would be used. You can\n   * inspect intermediate nodes of the model by adding them to the outputs\n   * array.\n   *\n   * @returns A Promise of single tensor if provided with a single output or\n   * no outputs are provided and there is only one default output, otherwise\n   * return a tensor map.\n   *\n   * @doc {heading: 'Models', subheading: 'Classes'}\n   */\n  async executeAsync(\n      inputs: Tensor|Tensor[]|NamedTensorMap,\n      outputs?: string|string[]): Promise<Tensor|Tensor[]> {\n    inputs = this.normalizeInputs(inputs);\n    outputs = this.normalizeOutputs(outputs);\n    const result = await this.executor.executeAsync(inputs, outputs);\n    return result.length > 1 ? result : result[0];\n  }\n\n  /**\n   * Get intermediate tensors for model debugging mode (flag\n   * KEEP_INTERMEDIATE_TENSORS is true).\n   *\n   * @doc {heading: 'Models', subheading: 'Classes'}\n   */\n  getIntermediateTensors(): NamedTensorsMap {\n    return this.executor.getIntermediateTensors();\n  }\n\n  /**\n   * Dispose intermediate tensors for model debugging mode (flag\n   * KEEP_INTERMEDIATE_TENSORS is true).\n   *\n   * @doc {heading: 'Models', subheading: 'Classes'}\n   */\n  disposeIntermediateTensors() {\n    this.executor.disposeIntermediateTensors();\n  }\n\n  private convertTensorMapToTensorsMap(map: NamedTensorMap): NamedTensorsMap {\n    return Object.keys(map).reduce((newMap: NamedTensorsMap, key) => {\n      newMap[key] = [map[key]];\n      return newMap;\n    }, {});\n  }\n\n  /**\n   * Releases the memory used by the weight tensors and resourceManager.\n   *\n   * @doc {heading: 'Models', subheading: 'Classes'}\n   */\n  dispose() {\n    this.executor.dispose();\n\n    if (this.initializer) {\n      this.initializer.dispose();\n    }\n\n    this.resourceManager.dispose();\n  }\n}\n\n/**\n * Load a graph model given a URL to the model definition.\n *\n * Example of loading MobileNetV2 from a URL and making a prediction with a\n * zeros input:\n *\n * ```js\n * const modelUrl =\n *    'https://storage.googleapis.com/tfjs-models/savedmodel/mobilenet_v2_1.0_224/model.json';\n * const model = await tf.loadGraphModel(modelUrl);\n * const zeros = tf.zeros([1, 224, 224, 3]);\n * model.predict(zeros).print();\n * ```\n *\n * Example of loading MobileNetV2 from a TF Hub URL and making a prediction\n * with a zeros input:\n *\n * ```js\n * const modelUrl =\n *    'https://tfhub.dev/google/imagenet/mobilenet_v2_140_224/classification/2';\n * const model = await tf.loadGraphModel(modelUrl, {fromTFHub: true});\n * const zeros = tf.zeros([1, 224, 224, 3]);\n * model.predict(zeros).print();\n * ```\n * @param modelUrl The url or an `io.IOHandler` that loads the model.\n * @param options Options for the HTTP request, which allows to send\n *     credentials\n *    and custom headers.\n *\n * @doc {heading: 'Models', subheading: 'Loading'}\n */\nexport async function loadGraphModel(\n    modelUrl: string|io.IOHandler, options: io.LoadOptions = {},\n    tfio = io): Promise<GraphModel> {\n  if (modelUrl == null) {\n    throw new Error(\n        'modelUrl in loadGraphModel() cannot be null. Please provide a url ' +\n        'or an IOHandler that loads the model');\n  }\n  if (options == null) {\n    options = {};\n  }\n\n  if (options.fromTFHub && typeof modelUrl === 'string') {\n    modelUrl = getTFHubUrl(modelUrl);\n  }\n  const model = new GraphModel(modelUrl, options, tfio);\n  await model.load();\n  return model;\n}\n\n/**\n * Load a graph model given a synchronous IO handler with a 'load' method.\n *\n * @param modelSource The `io.IOHandlerSync` that loads the model, or the\n *     `io.ModelArtifacts` that encode the model, or a tuple of\n *     `[io.ModelJSON, ArrayBuffer]` of which the first element encodes the\n *      model and the second contains the weights.\n *\n * @doc {heading: 'Models', subheading: 'Loading'}\n */\nexport function loadGraphModelSync(modelSource: io.IOHandlerSync\n  | io.ModelArtifacts | [io.ModelJSON, /* Weights */ ArrayBuffer]):\n  GraphModel<io.IOHandlerSync> {\n\n  if (modelSource == null) {\n    throw new Error(\n        'modelUrl in loadGraphModelSync() cannot be null. Please provide ' +\n        'model artifacts or an IOHandler that loads the model');\n  }\n\n  let ioHandler: io.IOHandlerSync;\n  if (modelSource instanceof Array) {\n    const [modelJSON, weights] = modelSource;\n    if (!modelJSON) {\n      throw new Error('modelJSON must be the first element of the array');\n    }\n    if (!weights || !(weights instanceof ArrayBuffer)) {\n      throw new Error('An ArrayBuffer of weights must be the second element of'\n                      + ' the array');\n    }\n    if (!('modelTopology' in modelJSON)) {\n      throw new Error('Model JSON is missing \\'modelTopology\\'');\n    }\n    if (!('weightsManifest' in modelJSON)) {\n      throw new Error('Model JSON is missing \\'weightsManifest\\'');\n    }\n\n    const weightSpecs = io.getWeightSpecs(modelJSON.weightsManifest);\n    const modelArtifacts = io.getModelArtifactsForJSONSync(modelJSON,\n                                                           weightSpecs,\n                                                           weights);\n    ioHandler = io.fromMemorySync(modelArtifacts);\n  } else if ('load' in modelSource) {\n    // Then modelSource is already an IOHandlerSync.\n    ioHandler = modelSource;\n  } else if ('modelTopology' in modelSource && 'weightSpecs' in modelSource\n      && 'weightData' in modelSource) {\n    // modelSource is of type ModelArtifacts.\n    ioHandler = io.fromMemorySync(modelSource);\n  } else {\n    throw new Error('Unknown model format');\n  }\n\n  const model = new GraphModel(ioHandler);\n  model.load();\n  return model;\n}\n\nfunction getTFHubUrl(modelUrl: string): string {\n  if (!modelUrl.endsWith('/')) {\n    modelUrl = (modelUrl) + '/';\n  }\n  return `${modelUrl}${DEFAULT_MODEL_NAME}${TFHUB_SEARCH_PARAM}`;\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tfconv from '@tensorflow/tfjs-converter';\nimport * as tf from '@tensorflow/tfjs-core';\nimport {PoseNetOutputStride} from './types';\n\n/**\n * PoseNet supports using various convolution neural network models\n * (e.g. ResNet and MobileNetV1) as its underlying base model.\n * The following BaseModel interface defines a unified interface for\n * creating such PoseNet base models. Currently both MobileNet (in\n * ./mobilenet.ts) and ResNet (in ./resnet.ts) implements the BaseModel\n * interface. New base models that conform to the BaseModel interface can be\n * added to PoseNet.\n */\nexport abstract class BaseModel {\n  constructor(\n      protected readonly model: tfconv.GraphModel,\n      public readonly outputStride: PoseNetOutputStride) {\n    const inputShape =\n        this.model.inputs[0].shape as [number, number, number, number];\n    tf.util.assert(\n        (inputShape[1] === -1) && (inputShape[2] === -1),\n        () => `Input shape [${inputShape[1]}, ${inputShape[2]}] ` +\n            `must both be equal to or -1`);\n  }\n\n  abstract preprocessInput(input: tf.Tensor3D): tf.Tensor3D;\n\n  /**\n   * Predicts intermediate Tensor representations.\n   *\n   * @param input The input RGB image of the base model.\n   * A Tensor of shape: [`inputResolution`, `inputResolution`, 3].\n   *\n   * @return A dictionary of base model's intermediate predictions.\n   * The returned dictionary should contains the following elements:\n   * heatmapScores: A Tensor3D that represents the heatmapScores.\n   * offsets: A Tensor3D that represents the offsets.\n   * displacementFwd: A Tensor3D that represents the forward displacement.\n   * displacementBwd: A Tensor3D that represents the backward displacement.\n   */\n  predict(input: tf.Tensor3D): {\n    heatmapScores: tf.Tensor3D,\n    offsets: tf.Tensor3D,\n    displacementFwd: tf.Tensor3D,\n    displacementBwd: tf.Tensor3D\n  } {\n    return tf.tidy(() => {\n      const asFloat = this.preprocessInput(tf.cast(input, 'float32'));\n      const asBatch = tf.expandDims(asFloat, 0);\n      const results = this.model.predict(asBatch) as tf.Tensor4D[];\n      const results3d: tf.Tensor3D[] = results.map(y => tf.squeeze(y, [0]));\n\n      const namedResults = this.nameOutputResults(results3d);\n\n      return {\n        heatmapScores: tf.sigmoid(namedResults.heatmap),\n        offsets: namedResults.offsets,\n        displacementFwd: namedResults.displacementFwd,\n        displacementBwd: namedResults.displacementBwd\n      };\n    });\n  }\n\n  // Because MobileNet and ResNet predict() methods output a different order for\n  // these values, we have a method that needs to be implemented to order them.\n  abstract nameOutputResults(results: tf.Tensor3D[]): {\n    heatmap: tf.Tensor3D,\n    offsets: tf.Tensor3D,\n    displacementFwd: tf.Tensor3D,\n    displacementBwd: tf.Tensor3D\n  };\n\n  /**\n   * Releases the CPU and GPU memory allocated by the model.\n   */\n  dispose() {\n    this.model.dispose();\n  }\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tf from '@tensorflow/tfjs-core';\nimport {BaseModel} from './base_model';\n\nexport class MobileNet extends BaseModel {\n  preprocessInput(input: tf.Tensor3D): tf.Tensor3D {\n    // Normalize the pixels [0, 255] to be between [-1, 1].\n    return tf.tidy(() => tf.sub(tf.div(input, 127.5), 1.0));\n  }\n\n  nameOutputResults(results: tf.Tensor3D[]) {\n    const [offsets, heatmap, displacementFwd, displacementBwd] = results;\n    return {offsets, heatmap, displacementFwd, displacementBwd};\n  }\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n// algorithm based on Coursera Lecture from Algorithms, Part 1:\n// https://www.coursera.org/learn/algorithms-part1/lecture/ZjoSM/heapsort\n\nfunction half(k: number) {\n  return Math.floor(k / 2);\n}\n\nexport class MaxHeap<T> {\n  private priorityQueue: T[];\n  private numberOfElements: number;\n  private getElementValue: (element: T) => number;\n\n  constructor(maxSize: number, getElementValue: (element: T) => number) {\n    this.priorityQueue = new Array(maxSize);\n    this.numberOfElements = -1;\n    this.getElementValue = getElementValue;\n  }\n\n  public enqueue(x: T): void {\n    this.priorityQueue[++this.numberOfElements] = x;\n    this.swim(this.numberOfElements);\n  }\n\n  public dequeue(): T {\n    const max = this.priorityQueue[0];\n    this.exchange(0, this.numberOfElements--);\n    this.sink(0);\n    this.priorityQueue[this.numberOfElements + 1] = null;\n    return max;\n  }\n\n  public empty(): boolean {\n    return this.numberOfElements === -1;\n  }\n\n  public size(): number {\n    return this.numberOfElements + 1;\n  }\n\n  public all(): T[] {\n    return this.priorityQueue.slice(0, this.numberOfElements + 1);\n  }\n\n  public max(): T {\n    return this.priorityQueue[0];\n  }\n\n  private swim(k: number): void {\n    while (k > 0 && this.less(half(k), k)) {\n      this.exchange(k, half(k));\n      k = half(k);\n    }\n  }\n\n  private sink(k: number): void {\n    while (2 * k <= this.numberOfElements) {\n      let j = 2 * k;\n      if (j < this.numberOfElements && this.less(j, j + 1)) {\n        j++;\n      }\n      if (!this.less(k, j)) {\n        break;\n      }\n      this.exchange(k, j);\n      k = j;\n    }\n  }\n\n  private getValueAt(i: number): number {\n    return this.getElementValue(this.priorityQueue[i]);\n  }\n\n  private less(i: number, j: number): boolean {\n    return this.getValueAt(i) < this.getValueAt(j);\n  }\n\n  private exchange(i: number, j: number): void {\n    const t = this.priorityQueue[i];\n    this.priorityQueue[i] = this.priorityQueue[j];\n    this.priorityQueue[j] = t;\n  }\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {PartWithScore, TensorBuffer3D} from '../types';\n\nimport {MaxHeap} from './max_heap';\n\nfunction scoreIsMaximumInLocalWindow(\n    keypointId: number, score: number, heatmapY: number, heatmapX: number,\n    localMaximumRadius: number, scores: TensorBuffer3D): boolean {\n  const [height, width] = scores.shape;\n\n  let localMaximum = true;\n  const yStart = Math.max(heatmapY - localMaximumRadius, 0);\n  const yEnd = Math.min(heatmapY + localMaximumRadius + 1, height);\n  for (let yCurrent = yStart; yCurrent < yEnd; ++yCurrent) {\n    const xStart = Math.max(heatmapX - localMaximumRadius, 0);\n    const xEnd = Math.min(heatmapX + localMaximumRadius + 1, width);\n    for (let xCurrent = xStart; xCurrent < xEnd; ++xCurrent) {\n      if (scores.get(yCurrent, xCurrent, keypointId) > score) {\n        localMaximum = false;\n        break;\n      }\n    }\n    if (!localMaximum) {\n      break;\n    }\n  }\n\n  return localMaximum;\n}\n\n/**\n * Builds a priority queue with part candidate positions for a specific image in\n * the batch. For this we find all local maxima in the score maps with score\n * values above a threshold. We create a single priority queue across all parts.\n */\nexport function buildPartWithScoreQueue(\n    scoreThreshold: number, localMaximumRadius: number,\n    scores: TensorBuffer3D): MaxHeap<PartWithScore> {\n  const [height, width, numKeypoints] = scores.shape;\n\n  const queue = new MaxHeap<PartWithScore>(\n      height * width * numKeypoints, ({score}) => score);\n\n  for (let heatmapY = 0; heatmapY < height; ++heatmapY) {\n    for (let heatmapX = 0; heatmapX < width; ++heatmapX) {\n      for (let keypointId = 0; keypointId < numKeypoints; ++keypointId) {\n        const score = scores.get(heatmapY, heatmapX, keypointId);\n\n        // Only consider parts with score greater or equal to threshold as\n        // root candidates.\n        if (score < scoreThreshold) {\n          continue;\n        }\n\n        // Only consider keypoints whose score is maximum in a local window.\n        if (scoreIsMaximumInLocalWindow(\n                keypointId, score, heatmapY, heatmapX, localMaximumRadius,\n                scores)) {\n          queue.enqueue({score, part: {heatmapY, heatmapX, id: keypointId}});\n        }\n      }\n    }\n  }\n\n  return queue;\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nexport type Tuple<T> = [T, T];\nexport type StringTuple = Tuple<string>;\nexport type NumberTuple = Tuple<number>;\n\nexport const partNames = [\n  'nose', 'leftEye', 'rightEye', 'leftEar', 'rightEar', 'leftShoulder',\n  'rightShoulder', 'leftElbow', 'rightElbow', 'leftWrist', 'rightWrist',\n  'leftHip', 'rightHip', 'leftKnee', 'rightKnee', 'leftAnkle', 'rightAnkle'\n];\n\nexport const NUM_KEYPOINTS = partNames.length;\n\nexport interface NumberDict {\n  [jointName: string]: number;\n}\n\nexport const partIds =\n    partNames.reduce((result: NumberDict, jointName, i): NumberDict => {\n      result[jointName] = i;\n      return result;\n    }, {}) as NumberDict;\n\nconst connectedPartNames: StringTuple[] = [\n  ['leftHip', 'leftShoulder'], ['leftElbow', 'leftShoulder'],\n  ['leftElbow', 'leftWrist'], ['leftHip', 'leftKnee'],\n  ['leftKnee', 'leftAnkle'], ['rightHip', 'rightShoulder'],\n  ['rightElbow', 'rightShoulder'], ['rightElbow', 'rightWrist'],\n  ['rightHip', 'rightKnee'], ['rightKnee', 'rightAnkle'],\n  ['leftShoulder', 'rightShoulder'], ['leftHip', 'rightHip']\n];\n\n/*\n * Define the skeleton. This defines the parent->child relationships of our\n * tree. Arbitrarily this defines the nose as the root of the tree, however\n * since we will infer the displacement for both parent->child and\n * child->parent, we can define the tree root as any node.\n */\nexport const poseChain: StringTuple[] = [\n  ['nose', 'leftEye'], ['leftEye', 'leftEar'], ['nose', 'rightEye'],\n  ['rightEye', 'rightEar'], ['nose', 'leftShoulder'],\n  ['leftShoulder', 'leftElbow'], ['leftElbow', 'leftWrist'],\n  ['leftShoulder', 'leftHip'], ['leftHip', 'leftKnee'],\n  ['leftKnee', 'leftAnkle'], ['nose', 'rightShoulder'],\n  ['rightShoulder', 'rightElbow'], ['rightElbow', 'rightWrist'],\n  ['rightShoulder', 'rightHip'], ['rightHip', 'rightKnee'],\n  ['rightKnee', 'rightAnkle']\n];\n\nexport const connectedPartIndices = connectedPartNames.map(\n    ([jointNameA, jointNameB]) => ([partIds[jointNameA], partIds[jointNameB]]));\n\nexport const partChannels: string[] = [\n  'left_face',\n  'right_face',\n  'right_upper_leg_front',\n  'right_lower_leg_back',\n  'right_upper_leg_back',\n  'left_lower_leg_front',\n  'left_upper_leg_front',\n  'left_upper_leg_back',\n  'left_lower_leg_back',\n  'right_feet',\n  'right_lower_leg_front',\n  'left_feet',\n  'torso_front',\n  'torso_back',\n  'right_upper_arm_front',\n  'right_upper_arm_back',\n  'right_lower_arm_back',\n  'left_lower_arm_front',\n  'left_upper_arm_front',\n  'left_upper_arm_back',\n  'left_lower_arm_back',\n  'right_hand',\n  'right_lower_arm_front',\n  'left_hand'\n];\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {NUM_KEYPOINTS} from '../keypoints';\nimport {Part, TensorBuffer3D, Vector2D} from '../types';\n\nexport function getOffsetPoint(\n    y: number, x: number, keypoint: number, offsets: TensorBuffer3D): Vector2D {\n  return {\n    y: offsets.get(y, x, keypoint),\n    x: offsets.get(y, x, keypoint + NUM_KEYPOINTS)\n  };\n}\n\nexport function getImageCoords(\n    part: Part, outputStride: number, offsets: TensorBuffer3D): Vector2D {\n  const {heatmapY, heatmapX, id: keypoint} = part;\n  const {y, x} = getOffsetPoint(heatmapY, heatmapX, keypoint, offsets);\n  return {\n    x: part.heatmapX * outputStride + x,\n    y: part.heatmapY * outputStride + y\n  };\n}\n\nexport function fillArray<T>(element: T, size: number): T[] {\n  const result: T[] = new Array(size);\n\n  for (let i = 0; i < size; i++) {\n    result[i] = element;\n  }\n\n  return result;\n}\n\nexport function clamp(a: number, min: number, max: number): number {\n  if (a < min) {\n    return min;\n  }\n  if (a > max) {\n    return max;\n  }\n  return a;\n}\n\nexport function squaredDistance(\n    y1: number, x1: number, y2: number, x2: number): number {\n  const dy = y2 - y1;\n  const dx = x2 - x1;\n  return dy * dy + dx * dx;\n}\n\nexport function addVectors(a: Vector2D, b: Vector2D): Vector2D {\n  return {x: a.x + b.x, y: a.y + b.y};\n}\n\nexport function clampVector(a: Vector2D, min: number, max: number): Vector2D {\n  return {y: clamp(a.y, min, max), x: clamp(a.x, min, max)};\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {NumberTuple, partIds, partNames, poseChain} from '../keypoints';\nimport {Keypoint, PartWithScore, TensorBuffer3D, Vector2D} from '../types';\n\nimport {clamp, getOffsetPoint} from './util';\nimport {addVectors, getImageCoords} from './util';\n\nconst parentChildrenTuples: NumberTuple[] = poseChain.map(\n    ([parentJoinName, childJoinName]): NumberTuple =>\n        ([partIds[parentJoinName], partIds[childJoinName]]));\n\nconst parentToChildEdges: number[] =\n    parentChildrenTuples.map(([, childJointId]) => childJointId);\n\nconst childToParentEdges: number[] =\n    parentChildrenTuples.map(([\n                               parentJointId,\n                             ]) => parentJointId);\n\nfunction getDisplacement(\n    edgeId: number, point: Vector2D, displacements: TensorBuffer3D): Vector2D {\n  const numEdges = displacements.shape[2] / 2;\n  return {\n    y: displacements.get(point.y, point.x, edgeId),\n    x: displacements.get(point.y, point.x, numEdges + edgeId)\n  };\n}\n\nfunction getStridedIndexNearPoint(\n    point: Vector2D, outputStride: number, height: number,\n    width: number): Vector2D {\n  return {\n    y: clamp(Math.round(point.y / outputStride), 0, height - 1),\n    x: clamp(Math.round(point.x / outputStride), 0, width - 1)\n  };\n}\n\n/**\n * We get a new keypoint along the `edgeId` for the pose instance, assuming\n * that the position of the `idSource` part is already known. For this, we\n * follow the displacement vector from the source to target part (stored in\n * the `i`-t channel of the displacement tensor). The displaced keypoint\n * vector is refined using the offset vector by `offsetRefineStep` times.\n */\nfunction traverseToTargetKeypoint(\n    edgeId: number, sourceKeypoint: Keypoint, targetKeypointId: number,\n    scoresBuffer: TensorBuffer3D, offsets: TensorBuffer3D, outputStride: number,\n    displacements: TensorBuffer3D, offsetRefineStep = 2): Keypoint {\n  const [height, width] = scoresBuffer.shape;\n\n  // Nearest neighbor interpolation for the source->target displacements.\n  const sourceKeypointIndices = getStridedIndexNearPoint(\n      sourceKeypoint.position, outputStride, height, width);\n\n  const displacement =\n      getDisplacement(edgeId, sourceKeypointIndices, displacements);\n\n  const displacedPoint = addVectors(sourceKeypoint.position, displacement);\n  let targetKeypoint = displacedPoint;\n  for (let i = 0; i < offsetRefineStep; i++) {\n    const targetKeypointIndices =\n        getStridedIndexNearPoint(targetKeypoint, outputStride, height, width);\n\n    const offsetPoint = getOffsetPoint(\n        targetKeypointIndices.y, targetKeypointIndices.x, targetKeypointId,\n        offsets);\n\n    targetKeypoint = addVectors(\n        {\n          x: targetKeypointIndices.x * outputStride,\n          y: targetKeypointIndices.y * outputStride\n        },\n        {x: offsetPoint.x, y: offsetPoint.y});\n  }\n  const targetKeyPointIndices =\n      getStridedIndexNearPoint(targetKeypoint, outputStride, height, width);\n  const score = scoresBuffer.get(\n      targetKeyPointIndices.y, targetKeyPointIndices.x, targetKeypointId);\n\n  return {position: targetKeypoint, part: partNames[targetKeypointId], score};\n}\n\n/**\n * Follows the displacement fields to decode the full pose of the object\n * instance given the position of a part that acts as root.\n *\n * @return An array of decoded keypoints and their scores for a single pose\n */\nexport function decodePose(\n    root: PartWithScore, scores: TensorBuffer3D, offsets: TensorBuffer3D,\n    outputStride: number, displacementsFwd: TensorBuffer3D,\n    displacementsBwd: TensorBuffer3D): Keypoint[] {\n  const numParts = scores.shape[2];\n  const numEdges = parentToChildEdges.length;\n\n  const instanceKeypoints: Keypoint[] = new Array(numParts);\n  // Start a new detection instance at the position of the root.\n  const {part: rootPart, score: rootScore} = root;\n  const rootPoint = getImageCoords(rootPart, outputStride, offsets);\n\n  instanceKeypoints[rootPart.id] = {\n    score: rootScore,\n    part: partNames[rootPart.id],\n    position: rootPoint\n  };\n\n  // Decode the part positions upwards in the tree, following the backward\n  // displacements.\n  for (let edge = numEdges - 1; edge >= 0; --edge) {\n    const sourceKeypointId = parentToChildEdges[edge];\n    const targetKeypointId = childToParentEdges[edge];\n    if (instanceKeypoints[sourceKeypointId] &&\n        !instanceKeypoints[targetKeypointId]) {\n      instanceKeypoints[targetKeypointId] = traverseToTargetKeypoint(\n          edge, instanceKeypoints[sourceKeypointId], targetKeypointId, scores,\n          offsets, outputStride, displacementsBwd);\n    }\n  }\n\n  // Decode the part positions downwards in the tree, following the forward\n  // displacements.\n  for (let edge = 0; edge < numEdges; ++edge) {\n    const sourceKeypointId = childToParentEdges[edge];\n    const targetKeypointId = parentToChildEdges[edge];\n    if (instanceKeypoints[sourceKeypointId] &&\n        !instanceKeypoints[targetKeypointId]) {\n      instanceKeypoints[targetKeypointId] = traverseToTargetKeypoint(\n          edge, instanceKeypoints[sourceKeypointId], targetKeypointId, scores,\n          offsets, outputStride, displacementsFwd);\n    }\n  }\n\n  return instanceKeypoints;\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Keypoint, Pose, TensorBuffer3D} from '../types';\n\nimport {buildPartWithScoreQueue} from './build_part_with_score_queue';\nimport {decodePose} from './decode_pose';\nimport {getImageCoords, squaredDistance} from './util';\n\nfunction withinNmsRadiusOfCorrespondingPoint(\n    poses: Pose[], squaredNmsRadius: number, {x, y}: {x: number, y: number},\n    keypointId: number): boolean {\n  return poses.some(({keypoints}) => {\n    const correspondingKeypoint = keypoints[keypointId].position;\n    return squaredDistance(\n               y, x, correspondingKeypoint.y, correspondingKeypoint.x) <=\n        squaredNmsRadius;\n  });\n}\n\n/* Score the newly proposed object instance without taking into account\n * the scores of the parts that overlap with any previously detected\n * instance.\n */\nfunction getInstanceScore(\n    existingPoses: Pose[], squaredNmsRadius: number,\n    instanceKeypoints: Keypoint[]): number {\n  let notOverlappedKeypointScores = instanceKeypoints.reduce(\n      (result, {position, score}, keypointId): number => {\n        if (!withinNmsRadiusOfCorrespondingPoint(\n                existingPoses, squaredNmsRadius, position, keypointId)) {\n          result += score;\n        }\n        return result;\n      }, 0.0);\n\n  return notOverlappedKeypointScores /= instanceKeypoints.length;\n}\n\n// A point (y, x) is considered as root part candidate if its score is a\n// maximum in a window |y - y'| <= kLocalMaximumRadius, |x - x'| <=\n// kLocalMaximumRadius.\nconst kLocalMaximumRadius = 1;\n\n/**\n * Detects multiple poses and finds their parts from part scores and\n * displacement vectors. It returns up to `maxDetections` object instance\n * detections in decreasing root score order. It works as follows: We first\n * create a priority queue with local part score maxima above\n * `scoreThreshold`, considering all parts at the same time. Then we\n * iteratively pull the top  element of the queue (in decreasing score order)\n * and treat it as a root candidate for a new object instance. To avoid\n * duplicate detections, we reject the root candidate if it is within a disk\n * of `nmsRadius` pixels from the corresponding part of a previously detected\n * instance, which is a form of part-based non-maximum suppression (NMS). If\n * the root candidate passes the NMS check, we start a new object instance\n * detection, treating the corresponding part as root and finding the\n * positions of the remaining parts by following the displacement vectors\n * along the tree-structured part graph. We assign to the newly detected\n * instance a score equal to the sum of scores of its parts which have not\n * been claimed by a previous instance (i.e., those at least `nmsRadius`\n * pixels away from the corresponding part of all previously detected\n * instances), divided by the total number of parts `numParts`.\n *\n * @param heatmapScores 3-D tensor with shape `[height, width, numParts]`.\n * The value of heatmapScores[y, x, k]` is the score of placing the `k`-th\n * object part at position `(y, x)`.\n *\n * @param offsets 3-D tensor with shape `[height, width, numParts * 2]`.\n * The value of [offsets[y, x, k], offsets[y, x, k + numParts]]` is the\n * short range offset vector of the `k`-th  object part at heatmap\n * position `(y, x)`.\n *\n * @param displacementsFwd 3-D tensor of shape\n * `[height, width, 2 * num_edges]`, where `num_edges = num_parts - 1` is the\n * number of edges (parent-child pairs) in the tree. It contains the forward\n * displacements between consecutive part from the root towards the leaves.\n *\n * @param displacementsBwd 3-D tensor of shape\n * `[height, width, 2 * num_edges]`, where `num_edges = num_parts - 1` is the\n * number of edges (parent-child pairs) in the tree. It contains the backward\n * displacements between consecutive part from the root towards the leaves.\n *\n * @param outputStride The output stride that was used when feed-forwarding\n * through the PoseNet model.  Must be 32, 16, or 8.\n *\n * @param maxPoseDetections Maximum number of returned instance detections per\n * image.\n *\n * @param scoreThreshold Only return instance detections that have root part\n * score greater or equal to this value. Defaults to 0.5.\n *\n * @param nmsRadius Non-maximum suppression part distance. It needs to be\n * strictly positive. Two parts suppress each other if they are less than\n * `nmsRadius` pixels away. Defaults to 20.\n *\n * @return An array of poses and their scores, each containing keypoints and\n * the corresponding keypoint scores.\n */\nexport function decodeMultiplePoses(\n    scoresBuffer: TensorBuffer3D, offsetsBuffer: TensorBuffer3D,\n    displacementsFwdBuffer: TensorBuffer3D,\n    displacementsBwdBuffer: TensorBuffer3D, outputStride: number,\n    maxPoseDetections: number, scoreThreshold = 0.5, nmsRadius = 20): Pose[] {\n  const poses: Pose[] = [];\n\n  const queue = buildPartWithScoreQueue(\n      scoreThreshold, kLocalMaximumRadius, scoresBuffer);\n\n  const squaredNmsRadius = nmsRadius * nmsRadius;\n\n  // Generate at most maxDetections object instances per image in\n  // decreasing root part score order.\n  while (poses.length < maxPoseDetections && !queue.empty()) {\n    // The top element in the queue is the next root candidate.\n    const root = queue.dequeue();\n\n    // Part-based non-maximum suppression: We reject a root candidate if it\n    // is within a disk of `nmsRadius` pixels from the corresponding part of\n    // a previously detected instance.\n    const rootImageCoords =\n        getImageCoords(root.part, outputStride, offsetsBuffer);\n    if (withinNmsRadiusOfCorrespondingPoint(\n            poses, squaredNmsRadius, rootImageCoords, root.part.id)) {\n      continue;\n    }\n\n    // Start a new detection instance at the position of the root.\n    const keypoints = decodePose(\n        root, scoresBuffer, offsetsBuffer, outputStride, displacementsFwdBuffer,\n        displacementsBwdBuffer);\n\n    const score = getInstanceScore(poses, squaredNmsRadius, keypoints);\n\n    poses.push({keypoints, score});\n  }\n\n  return poses;\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tf from '@tensorflow/tfjs-core';\n\nfunction mod(a: tf.Tensor1D, b: number): tf.Tensor1D {\n  return tf.tidy(() => {\n    const floored = tf.div(a, tf.scalar(b, 'int32'));\n\n    return tf.sub(a, tf.mul(floored, tf.scalar(b, 'int32')));\n  });\n}\n\nexport function argmax2d(inputs: tf.Tensor3D): tf.Tensor2D {\n  const [height, width, depth] = inputs.shape;\n\n  return tf.tidy(() => {\n    const reshaped = tf.reshape(inputs, [height * width, depth]);\n    const coords = tf.argMax(reshaped, 0);\n\n    const yCoords = tf.expandDims(tf.div(coords, tf.scalar(width, 'int32')), 1);\n    const xCoords = tf.expandDims(mod(coords as tf.Tensor1D, width), 1);\n\n    return tf.concat([yCoords, xCoords], 1);\n  }) as tf.Tensor2D;\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tf from '@tensorflow/tfjs-core';\nimport {NUM_KEYPOINTS} from '../keypoints';\nimport {Vector2D} from '../types';\n\nexport function getPointsConfidence(\n    heatmapScores: tf.TensorBuffer<tf.Rank.R3>,\n    heatMapCoords: tf.TensorBuffer<tf.Rank.R2>): Float32Array {\n  const numKeypoints = heatMapCoords.shape[0];\n  const result = new Float32Array(numKeypoints);\n\n  for (let keypoint = 0; keypoint < numKeypoints; keypoint++) {\n    const y = heatMapCoords.get(keypoint, 0);\n    const x = heatMapCoords.get(keypoint, 1);\n    result[keypoint] = heatmapScores.get(y, x, keypoint);\n  }\n\n  return result;\n}\n\nfunction getOffsetPoint(\n    y: number, x: number, keypoint: number,\n    offsetsBuffer: tf.TensorBuffer<tf.Rank.R3>): Vector2D {\n  return {\n    y: offsetsBuffer.get(y, x, keypoint),\n    x: offsetsBuffer.get(y, x, keypoint + NUM_KEYPOINTS)\n  };\n}\n\nexport function getOffsetVectors(\n    heatMapCoordsBuffer: tf.TensorBuffer<tf.Rank.R2>,\n    offsetsBuffer: tf.TensorBuffer<tf.Rank.R3>): tf.Tensor2D {\n  const result: number[] = [];\n\n  for (let keypoint = 0; keypoint < NUM_KEYPOINTS; keypoint++) {\n    const heatmapY = heatMapCoordsBuffer.get(keypoint, 0).valueOf();\n    const heatmapX = heatMapCoordsBuffer.get(keypoint, 1).valueOf();\n\n    const {x, y} = getOffsetPoint(heatmapY, heatmapX, keypoint, offsetsBuffer);\n\n    result.push(y);\n    result.push(x);\n  }\n\n  return tf.tensor2d(result, [NUM_KEYPOINTS, 2]);\n}\n\nexport function getOffsetPoints(\n    heatMapCoordsBuffer: tf.TensorBuffer<tf.Rank.R2>, outputStride: number,\n    offsetsBuffer: tf.TensorBuffer<tf.Rank.R3>): tf.Tensor2D {\n  return tf.tidy(() => {\n    const offsetVectors = getOffsetVectors(heatMapCoordsBuffer, offsetsBuffer);\n\n    return tf\n        .add(tf\n          .cast(tf\n            .mul(heatMapCoordsBuffer.toTensor(), tf.scalar(outputStride,\n              'int32')), 'float32'), offsetVectors);\n  });\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tf from '@tensorflow/tfjs-core';\n\nimport {partNames} from '../keypoints';\nimport {Keypoint, Pose, PoseNetOutputStride} from '../types';\n\nimport {argmax2d} from './argmax2d';\nimport {getOffsetPoints, getPointsConfidence} from './util';\n\n/**\n * Detects a single pose and finds its parts from part scores and offset\n * vectors. It returns a single pose detection. It works as follows:\n * argmax2d is done on the scores to get the y and x index in the heatmap\n * with the highest score for each part, which is essentially where the\n * part is most likely to exist. This produces a tensor of size 17x2, with\n * each row being the y and x index in the heatmap for each keypoint.\n * The offset vector for each for each part is retrieved by getting the\n * y and x from the offsets corresponding to the y and x index in the\n * heatmap for that part. This produces a tensor of size 17x2, with each\n * row being the offset vector for the corresponding keypoint.\n * To get the keypoint, each part’s heatmap y and x are multiplied\n * by the output stride then added to their corresponding offset vector,\n * which is in the same scale as the original image.\n *\n * @param heatmapScores 3-D tensor with shape `[height, width, numParts]`.\n * The value of heatmapScores[y, x, k]` is the score of placing the `k`-th\n * object part at position `(y, x)`.\n *\n * @param offsets 3-D tensor with shape `[height, width, numParts * 2]`.\n * The value of [offsets[y, x, k], offsets[y, x, k + numParts]]` is the\n * short range offset vector of the `k`-th  object part at heatmap\n * position `(y, x)`.\n *\n * @param outputStride The output stride that was used when feed-forwarding\n * through the PoseNet model.  Must be 32, 16, or 8.\n *\n * @return A promise that resolves with single pose with a confidence score,\n * which contains an array of keypoints indexed by part id, each with a score\n * and position.\n */\nexport async function decodeSinglePose(\n    heatmapScores: tf.Tensor3D, offsets: tf.Tensor3D,\n    outputStride: PoseNetOutputStride): Promise<Pose> {\n  let totalScore = 0.0;\n\n  const heatmapValues = argmax2d(heatmapScores);\n\n  const allTensorBuffers = await Promise.all(\n      [heatmapScores.buffer(), offsets.buffer(), heatmapValues.buffer()]);\n\n  const scoresBuffer = allTensorBuffers[0];\n  const offsetsBuffer = allTensorBuffers[1];\n  const heatmapValuesBuffer = allTensorBuffers[2];\n\n  const offsetPoints =\n      getOffsetPoints(heatmapValuesBuffer, outputStride, offsetsBuffer);\n  const offsetPointsBuffer = await offsetPoints.buffer();\n\n  const keypointConfidence =\n      Array.from(getPointsConfidence(scoresBuffer, heatmapValuesBuffer));\n\n  const keypoints = keypointConfidence.map((score, keypointId): Keypoint => {\n    totalScore += score;\n    return {\n      position: {\n        y: offsetPointsBuffer.get(keypointId, 0),\n        x: offsetPointsBuffer.get(keypointId, 1)\n      },\n      part: partNames[keypointId],\n      score\n    };\n  });\n\n  heatmapValues.dispose();\n  offsetPoints.dispose();\n\n  return {keypoints, score: totalScore / keypoints.length};\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nconst MOBILENET_BASE_URL =\n    'https://storage.googleapis.com/tfjs-models/savedmodel/posenet/mobilenet/';\nconst RESNET50_BASE_URL =\n    'https://storage.googleapis.com/tfjs-models/savedmodel/posenet/resnet50/';\n\n// The PoseNet 2.0 ResNet50 models use the latest TensorFlow.js 1.0 model\n// format.\nexport function resNet50Checkpoint(stride: number, quantBytes: number): string {\n  const graphJson = `model-stride${stride}.json`;\n  // quantBytes=4 corresponding to the non-quantized full-precision checkpoints.\n  if (quantBytes === 4) {\n    return RESNET50_BASE_URL + `float/` + graphJson;\n  } else {\n    return RESNET50_BASE_URL + `quant${quantBytes}/` + graphJson;\n  }\n}\n\n// The PoseNet 2.0 MobileNetV1 models use the latest TensorFlow.js 1.0 model\n// format.\nexport function mobileNetCheckpoint(\n    stride: number, multiplier: number, quantBytes: number): string {\n  const toStr: {[key: number]: string} = {1.0: '100', 0.75: '075', 0.50: '050'};\n  const graphJson = `model-stride${stride}.json`;\n  // quantBytes=4 corresponding to the non-quantized full-precision checkpoints.\n  if (quantBytes === 4) {\n    return MOBILENET_BASE_URL + `float/${toStr[multiplier]}/` + graphJson;\n  } else {\n    return MOBILENET_BASE_URL + `quant${quantBytes}/${toStr[multiplier]}/` +\n        graphJson;\n  }\n}\n","/**\n * @license\n * Copyright 2019 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tf from '@tensorflow/tfjs-core';\n\nimport {BaseModel} from './base_model';\n\nconst imageNetMean = [-123.15, -115.90, -103.06];\n\nexport class ResNet extends BaseModel {\n  preprocessInput(input: tf.Tensor3D): tf.Tensor3D {\n    return tf.add(input, imageNetMean);\n  }\n\n  nameOutputResults(results: tf.Tensor3D[]) {\n    const [displacementFwd, displacementBwd, offsets, heatmap] = results;\n    return {offsets, heatmap, displacementFwd, displacementBwd};\n  }\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tf from '@tensorflow/tfjs-core';\n\nimport {connectedPartIndices} from './keypoints';\nimport {InputResolution, Keypoint, Padding, Pose, PosenetInput, PoseNetOutputStride, TensorBuffer3D, Vector2D} from './types';\n\nfunction eitherPointDoesntMeetConfidence(\n    a: number, b: number, minConfidence: number): boolean {\n  return (a < minConfidence || b < minConfidence);\n}\n\nexport function getAdjacentKeyPoints(\n    keypoints: Keypoint[], minConfidence: number): Keypoint[][] {\n  return connectedPartIndices.reduce(\n      (result: Keypoint[][], [leftJoint, rightJoint]): Keypoint[][] => {\n        if (eitherPointDoesntMeetConfidence(\n                keypoints[leftJoint].score, keypoints[rightJoint].score,\n                minConfidence)) {\n          return result;\n        }\n\n        result.push([keypoints[leftJoint], keypoints[rightJoint]]);\n\n        return result;\n      }, []);\n}\n\nconst {NEGATIVE_INFINITY, POSITIVE_INFINITY} = Number;\nexport function getBoundingBox(keypoints: Keypoint[]):\n    {maxX: number, maxY: number, minX: number, minY: number} {\n  return keypoints.reduce(({maxX, maxY, minX, minY}, {position: {x, y}}) => {\n    return {\n      maxX: Math.max(maxX, x),\n      maxY: Math.max(maxY, y),\n      minX: Math.min(minX, x),\n      minY: Math.min(minY, y)\n    };\n  }, {\n    maxX: NEGATIVE_INFINITY,\n    maxY: NEGATIVE_INFINITY,\n    minX: POSITIVE_INFINITY,\n    minY: POSITIVE_INFINITY\n  });\n}\n\nexport function getBoundingBoxPoints(keypoints: Keypoint[]): Vector2D[] {\n  const {minX, minY, maxX, maxY} = getBoundingBox(keypoints);\n  return [\n    {x: minX, y: minY}, {x: maxX, y: minY}, {x: maxX, y: maxY},\n    {x: minX, y: maxY}\n  ];\n}\n\nexport async function toTensorBuffers3D(tensors: tf.Tensor3D[]):\n    Promise<TensorBuffer3D[]> {\n  return Promise.all(tensors.map(tensor => tensor.buffer()));\n}\n\nexport function scalePose(\n    pose: Pose, scaleY: number, scaleX: number, offsetY = 0,\n    offsetX = 0): Pose {\n  return {\n    score: pose.score,\n    keypoints: pose.keypoints.map(({score, part, position}) => ({\n                                    score,\n                                    part,\n                                    position: {\n                                      x: position.x * scaleX + offsetX,\n                                      y: position.y * scaleY + offsetY\n                                    }\n                                  }))\n  };\n}\n\nexport function scalePoses(\n    poses: Pose[], scaleY: number, scaleX: number, offsetY = 0, offsetX = 0) {\n  if (scaleX === 1 && scaleY === 1 && offsetY === 0 && offsetX === 0) {\n    return poses;\n  }\n  return poses.map(pose => scalePose(pose, scaleY, scaleX, offsetY, offsetX));\n}\n\nexport function flipPoseHorizontal(pose: Pose, imageWidth: number): Pose {\n  return {\n    score: pose.score,\n    keypoints: pose.keypoints.map(\n        ({score, part, position}) => ({\n          score,\n          part,\n          position: {x: imageWidth - 1 - position.x, y: position.y}\n        }))\n  };\n}\n\nexport function flipPosesHorizontal(poses: Pose[], imageWidth: number) {\n  if (imageWidth <= 0) {\n    return poses;\n  }\n  return poses.map(pose => flipPoseHorizontal(pose, imageWidth));\n}\n\nexport function toValidInputResolution(\n    inputResolution: number, outputStride: PoseNetOutputStride): number {\n  if (isValidInputResolution(inputResolution, outputStride)) {\n    return inputResolution;\n  }\n\n  return Math.floor(inputResolution / outputStride) * outputStride + 1;\n}\n\nexport function validateInputResolution(inputResolution: InputResolution) {\n  tf.util.assert(\n      typeof inputResolution === 'number' ||\n          typeof inputResolution === 'object',\n      () => `Invalid inputResolution ${inputResolution}. ` +\n          `Should be a number or an object with width and height`);\n\n  if (typeof inputResolution === 'object') {\n    tf.util.assert(\n        typeof inputResolution.width === 'number',\n        () => `inputResolution.width has a value of ${\n            inputResolution.width} which is invalid; it must be a number`);\n    tf.util.assert(\n        typeof inputResolution.height === 'number',\n        () => `inputResolution.height has a value of ${\n            inputResolution.height} which is invalid; it must be a number`);\n  }\n}\n\nexport function getValidInputResolutionDimensions(\n    inputResolution: InputResolution,\n    outputStride: PoseNetOutputStride): [number, number] {\n  validateInputResolution(inputResolution);\n  if (typeof inputResolution === 'object') {\n    return [\n      toValidInputResolution(inputResolution.height, outputStride),\n      toValidInputResolution(inputResolution.width, outputStride),\n    ];\n  } else {\n    return [\n      toValidInputResolution(inputResolution, outputStride),\n      toValidInputResolution(inputResolution, outputStride),\n    ];\n  }\n}\n\nconst VALID_OUTPUT_STRIDES: PoseNetOutputStride[] = [8, 16, 32];\nexport function assertValidOutputStride(outputStride: PoseNetOutputStride) {\n  tf.util.assert(\n      typeof outputStride === 'number', () => 'outputStride is not a number');\n  tf.util.assert(\n      VALID_OUTPUT_STRIDES.indexOf(outputStride) >= 0,\n      () => `outputStride of ${outputStride} is invalid. ` +\n          `It must be either 8, 16, or 32`);\n}\n\nfunction isValidInputResolution(\n    resolution: number, outputStride: number): boolean {\n  return (resolution - 1) % outputStride === 0;\n}\n\nexport function assertValidResolution(\n    resolution: [number, number], outputStride: number) {\n  tf.util.assert(\n      typeof resolution[0] === 'number' && typeof resolution[1] === 'number',\n      () => `both resolution values must be a number but had values ${\n          resolution}`);\n\n  tf.util.assert(\n      isValidInputResolution(resolution[0], outputStride),\n      () => `height of ${resolution[0]} is invalid for output stride ` +\n          `${outputStride}.`);\n\n  tf.util.assert(\n      isValidInputResolution(resolution[1], outputStride),\n      () => `width of ${resolution[1]} is invalid for output stride ` +\n          `${outputStride}.`);\n}\n\nexport function getInputTensorDimensions(input: PosenetInput):\n    [number, number] {\n  return input instanceof tf.Tensor ? [input.shape[0], input.shape[1]] :\n                                      [input.height, input.width];\n}\n\nexport function toInputTensor(input: PosenetInput) {\n  return input instanceof tf.Tensor ? input : tf.browser.fromPixels(input);\n}\n\nexport function toResizedInputTensor(\n    input: PosenetInput, resizeHeight: number, resizeWidth: number,\n    flipHorizontal: boolean): tf.Tensor3D {\n  return tf.tidy(() => {\n    const imageTensor = toInputTensor(input);\n\n    if (flipHorizontal) {\n      return tf.image.resizeBilinear(tf.reverse(imageTensor, 1), [resizeHeight, resizeWidth]);\n    } else {\n      return tf.image.resizeBilinear(imageTensor, [resizeHeight, resizeWidth]);\n    }\n  });\n}\n\nexport function padAndResizeTo(\n    input: PosenetInput, [targetH, targetW]: [number, number]):\n    {resized: tf.Tensor3D, padding: Padding} {\n  const [height, width] = getInputTensorDimensions(input);\n  const targetAspect = targetW / targetH;\n  const aspect = width / height;\n  let [padT, padB, padL, padR] = [0, 0, 0, 0];\n  if (aspect < targetAspect) {\n    // pads the width\n    padT = 0;\n    padB = 0;\n    padL = Math.round(0.5 * (targetAspect * height - width));\n    padR = Math.round(0.5 * (targetAspect * height - width));\n  } else {\n    // pads the height\n    padT = Math.round(0.5 * ((1.0 / targetAspect) * width - height));\n    padB = Math.round(0.5 * ((1.0 / targetAspect) * width - height));\n    padL = 0;\n    padR = 0;\n  }\n\n  const resized: tf.Tensor3D = tf.tidy(() => {\n    let imageTensor = toInputTensor(input);\n    imageTensor = tf.pad3d(imageTensor, [[padT, padB], [padL, padR], [0, 0]]);\n\n    return tf.image.resizeBilinear(imageTensor, [targetH, targetW]);\n  });\n\n  return {resized, padding: {top: padT, left: padL, right: padR, bottom: padB}};\n}\n\nexport function scaleAndFlipPoses(\n    poses: Pose[], [height, width]: [number, number],\n    [inputResolutionHeight, inputResolutionWidth]: [number, number],\n    padding: Padding, flipHorizontal: boolean): Pose[] {\n  const scaleY =\n      (height + padding.top + padding.bottom) / (inputResolutionHeight);\n  const scaleX =\n      (width + padding.left + padding.right) / (inputResolutionWidth);\n\n  const scaledPoses =\n      scalePoses(poses, scaleY, scaleX, -padding.top, -padding.left);\n\n  if (flipHorizontal) {\n    return flipPosesHorizontal(scaledPoses, width);\n  } else {\n    return scaledPoses;\n  }\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tfconv from '@tensorflow/tfjs-converter';\nimport * as tf from '@tensorflow/tfjs-core';\n\nimport {BaseModel} from './base_model';\nimport {mobileNetCheckpoint, resNet50Checkpoint} from './checkpoints';\nimport {MobileNet} from './mobilenet';\nimport {decodeMultiplePoses} from './multi_pose/decode_multiple_poses';\nimport {ResNet} from './resnet';\nimport {decodeSinglePose} from './single_pose/decode_single_pose';\nimport {InputResolution, MobileNetMultiplier, Pose, PoseNetArchitecture, PosenetInput, PoseNetOutputStride, PoseNetQuantBytes} from './types';\nimport {assertValidOutputStride, assertValidResolution, getInputTensorDimensions, getValidInputResolutionDimensions, padAndResizeTo, scaleAndFlipPoses, toTensorBuffers3D, validateInputResolution} from './util';\n\n/**\n * PoseNet model loading is configurable using the following config dictionary.\n *\n * `architecture`: PoseNetArchitecture. It determines wich PoseNet architecture\n * to load. The supported architectures are: MobileNetV1 and ResNet.\n *\n * `outputStride`: Specifies the output stride of the PoseNet model.\n * The smaller the value, the larger the output resolution, and more accurate\n * the model at the cost of speed.  Set this to a larger value to increase speed\n * at the cost of accuracy. Stride 32 is supported for ResNet and\n * stride 8,16,32 are supported for various MobileNetV1 models.\n *\n * * `inputResolution`: A number or an Object of type {width: number, height:\n * number}. Specifies the size the input image is scaled to before feeding it\n * through the PoseNet model.  The larger the value, more accurate the model at\n * the cost of speed. Set this to a smaller value to increase speed at the cost\n * of accuracy. If a number is provided, the input will be resized and padded to\n * be a square with the same width and height.  If width and height are\n * provided, the input will be resized and padded to the specified width and\n * height.\n *\n * `multiplier`: An optional number with values: 1.01, 1.0, 0.75, or\n * 0.50. The value is used only by MobileNet architecture. It is the float\n * multiplier for the depth (number of channels) for all convolution ops.\n * The larger the value, the larger the size of the layers, and more accurate\n * the model at the cost of speed. Set this to a smaller value to increase speed\n * at the cost of accuracy.\n *\n * `modelUrl`: An optional string that specifies custom url of the model. This\n * is useful for area/countries that don't have access to the model hosted on\n * GCP.\n *\n * `quantBytes`: An opional number with values: 1, 2, or 4.  This parameter\n * affects weight quantization in the models. The available options are\n * 1 byte, 2 bytes, and 4 bytes. The higher the value, the larger the model size\n * and thus the longer the loading time, the lower the value, the shorter the\n * loading time but lower the accuracy.\n */\nexport interface ModelConfig {\n  architecture: PoseNetArchitecture;\n  outputStride: PoseNetOutputStride;\n  inputResolution: InputResolution;\n  multiplier?: MobileNetMultiplier;\n  modelUrl?: string;\n  quantBytes?: PoseNetQuantBytes;\n}\n\n// The default configuration for loading MobileNetV1 based PoseNet.\n//\n// (And for references, the default configuration for loading ResNet\n// based PoseNet is also included).\n//\n// ```\n// const RESNET_CONFIG = {\n//   architecture: 'ResNet50',\n//   outputStride: 32,\n//   quantBytes: 2,\n// } as ModelConfig;\n// ```\nconst MOBILENET_V1_CONFIG: ModelConfig = {\n  architecture: 'MobileNetV1',\n  outputStride: 16,\n  multiplier: 0.75,\n  inputResolution: 257,\n} as ModelConfig;\n\nconst VALID_ARCHITECTURE = ['MobileNetV1', 'ResNet50'];\nconst VALID_STRIDE = {\n  'MobileNetV1': [8, 16, 32],\n  'ResNet50': [32, 16]\n};\n\nconst VALID_MULTIPLIER = {\n  'MobileNetV1': [0.50, 0.75, 1.0],\n  'ResNet50': [1.0]\n};\nconst VALID_QUANT_BYTES = [1, 2, 4];\n\nfunction validateModelConfig(config: ModelConfig) {\n  config = config || MOBILENET_V1_CONFIG;\n\n  if (config.architecture == null) {\n    config.architecture = 'MobileNetV1';\n  }\n  if (VALID_ARCHITECTURE.indexOf(config.architecture) < 0) {\n    throw new Error(\n        `Invalid architecture ${config.architecture}. ` +\n        `Should be one of ${VALID_ARCHITECTURE}`);\n  }\n\n  if (config.inputResolution == null) {\n    config.inputResolution = 257;\n  }\n\n  validateInputResolution(config.inputResolution);\n\n  if (config.outputStride == null) {\n    config.outputStride = 16;\n  }\n  if (VALID_STRIDE[config.architecture].indexOf(config.outputStride) < 0) {\n    throw new Error(\n        `Invalid outputStride ${config.outputStride}. ` +\n        `Should be one of ${VALID_STRIDE[config.architecture]} ` +\n        `for architecture ${config.architecture}.`);\n  }\n\n  if (config.multiplier == null) {\n    config.multiplier = 1.0;\n  }\n  if (VALID_MULTIPLIER[config.architecture].indexOf(config.multiplier) < 0) {\n    throw new Error(\n        `Invalid multiplier ${config.multiplier}. ` +\n        `Should be one of ${VALID_MULTIPLIER[config.architecture]} ` +\n        `for architecture ${config.architecture}.`);\n  }\n\n  if (config.quantBytes == null) {\n    config.quantBytes = 4;\n  }\n  if (VALID_QUANT_BYTES.indexOf(config.quantBytes) < 0) {\n    throw new Error(\n        `Invalid quantBytes ${config.quantBytes}. ` +\n        `Should be one of ${VALID_QUANT_BYTES} ` +\n        `for architecture ${config.architecture}.`);\n  }\n\n  if (config.architecture === 'MobileNetV1' && config.outputStride === 32 &&\n      config.multiplier !== 1) {\n    throw new Error(\n        `When using an output stride of 32, ` +\n        `you must select 1 as the multiplier.`);\n  }\n\n  return config;\n}\n\n/**\n * PoseNet inference is configurable using the following config dictionary.\n *\n * `flipHorizontal`: If the poses should be flipped/mirrored horizontally.\n * This should be set to true for videos where the video is by default flipped\n * horizontally (i.e. a webcam), and you want the poses to be returned in the\n * proper orientation.\n *\n */\nexport interface InferenceConfig {\n  flipHorizontal: boolean;\n}\n\n/**\n * Single Person Inference Config\n */\nexport interface SinglePersonInterfaceConfig extends InferenceConfig {}\n\n/**\n * Multiple Person Inference Config\n *\n * `maxDetections`: Maximum number of returned instance detections per image.\n *\n * `scoreThreshold`: Only return instance detections that have root part\n * score greater or equal to this value. Defaults to 0.5\n *\n * `nmsRadius`: Non-maximum suppression part distance in pixels. It needs\n * to be strictly positive. Two parts suppress each other if they are less\n * than `nmsRadius` pixels away. Defaults to 20.\n */\nexport interface MultiPersonInferenceConfig extends InferenceConfig {\n  maxDetections?: number;\n  scoreThreshold?: number;\n  nmsRadius?: number;\n}\n\n// these added back to not break the existing api.\nexport interface LegacyMultiPersonInferenceConfig extends\n    MultiPersonInferenceConfig {\n  decodingMethod: 'multi-person';\n}\n\nexport interface LegacySinglePersonInferenceConfig extends\n    SinglePersonInterfaceConfig {\n  decodingMethod: 'single-person';\n}\n\nexport const SINGLE_PERSON_INFERENCE_CONFIG: SinglePersonInterfaceConfig = {\n  flipHorizontal: false\n};\n\nexport const MULTI_PERSON_INFERENCE_CONFIG: MultiPersonInferenceConfig = {\n  flipHorizontal: false,\n  maxDetections: 5,\n  scoreThreshold: 0.5,\n  nmsRadius: 20\n};\n\nfunction validateSinglePersonInferenceConfig(\n    config: SinglePersonInterfaceConfig) {}\n\nfunction validateMultiPersonInputConfig(config: MultiPersonInferenceConfig) {\n  const {maxDetections, scoreThreshold, nmsRadius} = config;\n\n  if (maxDetections <= 0) {\n    throw new Error(\n        `Invalid maxDetections ${maxDetections}. ` +\n        `Should be > 0`);\n  }\n\n  if (scoreThreshold < 0.0 || scoreThreshold > 1.0) {\n    throw new Error(\n        `Invalid scoreThreshold ${scoreThreshold}. ` +\n        `Should be in range [0.0, 1.0]`);\n  }\n\n  if (nmsRadius <= 0) {\n    throw new Error(`Invalid nmsRadius ${nmsRadius}.`);\n  }\n}\n\nexport class PoseNet {\n  readonly baseModel: BaseModel;\n  readonly inputResolution: [number, number];\n\n  constructor(net: BaseModel, inputResolution: [number, number]) {\n    assertValidOutputStride(net.outputStride);\n    assertValidResolution(inputResolution, net.outputStride);\n\n    this.baseModel = net;\n    this.inputResolution = inputResolution;\n  }\n\n  /**\n   * Infer through PoseNet, and estimates multiple poses using the outputs.\n   * This does standard ImageNet pre-processing before inferring through the\n   * model. The image should pixels should have values [0-255]. It detects\n   * multiple poses and finds their parts from part scores and displacement\n   * vectors using a fast greedy decoding algorithm.  It returns up to\n   * `config.maxDetections` object instance detections in decreasing root\n   * score order.\n   *\n   * @param input\n   * ImageData|HTMLImageElement|HTMLCanvasElement|HTMLVideoElement) The input\n   * image to feed through the network.\n   *\n   * @param config MultiPoseEstimationConfig object that contains parameters\n   * for the PoseNet inference using multiple pose estimation.\n   *\n   * @return An array of poses and their scores, each containing keypoints and\n   * the corresponding keypoint scores.  The positions of the keypoints are\n   * in the same scale as the original image\n   */\n  async estimateMultiplePoses(\n      input: PosenetInput,\n      config: MultiPersonInferenceConfig = MULTI_PERSON_INFERENCE_CONFIG):\n      Promise<Pose[]> {\n    const configWithDefaults: MultiPersonInferenceConfig = {\n      ...MULTI_PERSON_INFERENCE_CONFIG,\n      ...config\n    };\n\n    validateMultiPersonInputConfig(config);\n\n    const outputStride = this.baseModel.outputStride;\n    const inputResolution = this.inputResolution;\n\n    const [height, width] = getInputTensorDimensions(input);\n\n    const {resized, padding} = padAndResizeTo(input, inputResolution);\n\n    const {heatmapScores, offsets, displacementFwd, displacementBwd} =\n        this.baseModel.predict(resized);\n\n    const allTensorBuffers = await toTensorBuffers3D(\n        [heatmapScores, offsets, displacementFwd, displacementBwd]);\n\n    const scoresBuffer = allTensorBuffers[0];\n    const offsetsBuffer = allTensorBuffers[1];\n    const displacementsFwdBuffer = allTensorBuffers[2];\n    const displacementsBwdBuffer = allTensorBuffers[3];\n\n    const poses = await decodeMultiplePoses(\n        scoresBuffer, offsetsBuffer, displacementsFwdBuffer,\n        displacementsBwdBuffer, outputStride, configWithDefaults.maxDetections,\n        configWithDefaults.scoreThreshold, configWithDefaults.nmsRadius);\n\n    const resultPoses = scaleAndFlipPoses(\n        poses, [height, width], inputResolution, padding,\n        configWithDefaults.flipHorizontal);\n\n    heatmapScores.dispose();\n    offsets.dispose();\n    displacementFwd.dispose();\n    displacementBwd.dispose();\n    resized.dispose();\n\n    return resultPoses;\n  }\n\n  /**\n   * Infer through PoseNet, and estimates a single pose using the outputs.\n   * This does standard ImageNet pre-processing before inferring through the\n   * model. The image should pixels should have values [0-255]. It detects\n   * multiple poses and finds their parts from part scores and displacement\n   * vectors using a fast greedy decoding algorithm.  It returns a single pose\n   *\n   * @param input\n   * ImageData|HTMLImageElement|HTMLCanvasElement|HTMLVideoElement) The input\n   * image to feed through the network.\n   *\n   * @param config SinglePersonEstimationConfig object that contains\n   * parameters for the PoseNet inference using single pose estimation.\n   *\n   * @return An pose and its scores, containing keypoints and\n   * the corresponding keypoint scores.  The positions of the keypoints are\n   * in the same scale as the original image\n   */\n  async estimateSinglePose(\n      input: PosenetInput,\n      config: SinglePersonInterfaceConfig = SINGLE_PERSON_INFERENCE_CONFIG):\n      Promise<Pose> {\n    const configWithDefaults = {...SINGLE_PERSON_INFERENCE_CONFIG, ...config};\n\n    validateSinglePersonInferenceConfig(configWithDefaults);\n\n    const outputStride = this.baseModel.outputStride;\n    const inputResolution = this.inputResolution;\n\n    const [height, width] = getInputTensorDimensions(input);\n\n    const {resized, padding} = padAndResizeTo(input, inputResolution);\n\n    const {heatmapScores, offsets, displacementFwd, displacementBwd} =\n        this.baseModel.predict(resized);\n\n    const pose = await decodeSinglePose(heatmapScores, offsets, outputStride);\n    const poses = [pose];\n\n    const resultPoses = scaleAndFlipPoses(\n        poses, [height, width], inputResolution, padding,\n        configWithDefaults.flipHorizontal);\n\n    heatmapScores.dispose();\n    offsets.dispose();\n    displacementFwd.dispose();\n    displacementBwd.dispose();\n    resized.dispose();\n\n    return resultPoses[0];\n  }\n\n  /** Deprecated: Use either estimateSinglePose or estimateMultiplePoses */\n  async estimatePoses(\n      input: PosenetInput,\n      config: LegacySinglePersonInferenceConfig|\n      LegacyMultiPersonInferenceConfig): Promise<Pose[]> {\n    if (config.decodingMethod === 'single-person') {\n      const pose = await this.estimateSinglePose(input, config);\n      return [pose];\n    } else {\n      return this.estimateMultiplePoses(input, config);\n    }\n  }\n\n  public dispose() {\n    this.baseModel.dispose();\n  }\n}\n\nasync function loadMobileNet(config: ModelConfig): Promise<PoseNet> {\n  const outputStride = config.outputStride;\n  const quantBytes = config.quantBytes;\n  const multiplier = config.multiplier;\n  if (tf == null) {\n    throw new Error(\n        `Cannot find TensorFlow.js. If you are using a <script> tag, please ` +\n        `also include @tensorflow/tfjs on the page before using this\n        model.`);\n  }\n\n  const url = mobileNetCheckpoint(outputStride, multiplier, quantBytes);\n  const graphModel = await tfconv.loadGraphModel(config.modelUrl || url);\n  const mobilenet = new MobileNet(graphModel, outputStride);\n\n  const validInputResolution = getValidInputResolutionDimensions(\n      config.inputResolution, mobilenet.outputStride);\n\n  return new PoseNet(mobilenet, validInputResolution);\n}\n\nasync function loadResNet(config: ModelConfig): Promise<PoseNet> {\n  const outputStride = config.outputStride;\n  const quantBytes = config.quantBytes;\n  if (tf == null) {\n    throw new Error(\n        `Cannot find TensorFlow.js. If you are using a <script> tag, please ` +\n        `also include @tensorflow/tfjs on the page before using this\n        model.`);\n  }\n\n  const url = resNet50Checkpoint(outputStride, quantBytes);\n  const graphModel = await tfconv.loadGraphModel(config.modelUrl || url);\n  const resnet = new ResNet(graphModel, outputStride);\n  const validInputResolution = getValidInputResolutionDimensions(\n      config.inputResolution, resnet.outputStride);\n  return new PoseNet(resnet, validInputResolution);\n}\n\n/**\n * Loads the PoseNet model instance from a checkpoint, with the ResNet\n * or MobileNet architecture. The model to be loaded is configurable using the\n * config dictionary ModelConfig. Please find more details in the\n * documentation of the ModelConfig.\n *\n * @param config ModelConfig dictionary that contains parameters for\n * the PoseNet loading process. Please find more details of each parameters\n * in the documentation of the ModelConfig interface. The predefined\n * `MOBILENET_V1_CONFIG` and `RESNET_CONFIG` can also be used as references\n * for defining your customized config.\n */\nexport async function load(config: ModelConfig = MOBILENET_V1_CONFIG):\n    Promise<PoseNet> {\n  config = validateModelConfig(config);\n  if (config.architecture === 'ResNet50') {\n    return loadResNet(config);\n  } else if (config.architecture === 'MobileNetV1') {\n    return loadMobileNet(config);\n  } else {\n    return null;\n  }\n}\n"],"names":["DataStorage","constructor","backend","dataMover","data","WeakMap","dataIdsCount","get","dataId","this","has","moveData","set","value","delete","numDataIds","KernelBackend","refCount","notYetImplemented","incRef","timerAvailable","time","f","read","readSync","readToGPU","options","disposeData","force","write","values","shape","dtype","move","memory","floatPrecision","epsilon","dispose","kernelName","Error","concat","shuffle","array","counter","length","index","Math","random","swap","shuffleCombo","array2","clamp","min","x","max","nearestLargerEven","val","object","left","right","temp","sum","arr","i","randUniform","a","b","r","distSquared","result","diff","Number","assert","expr","msg","assertShapesMatch","shapeA","shapeB","errorMessagePrefix","arguments","undefined","arraysEqual","assertNonNull","flatten","skipTypedArray","Array","isArray","isTypedArray","push","sizeFromShape","size","isScalarShape","n1","n2","isInt","tanh","Infinity","e2x","exp","sizeToSquarishShape","width","ceil","sqrt","createShuffledIndices","n","shuffledIndices","Uint32Array","rightPad","repeat","repeatedTry","checkFn","delayFn","maxCounter","scheduleFn","setTimeout","Promise","resolve","reject","tryCount","tryFn","nextBackoff","inferFromImplicitShape","shapeProd","implicitIdx","newShape","slice","parseAxisParam","axis","rank","map","s","every","ax","squeezeShape","keptDims","isEmptyArray","axes","sort","j","getTypedArrayFromDType","Float32Array","Int32Array","Uint8Array","getArrayFromDType","checkConversionForErrors","vals","num","isNaN","isFinite","isValidDtype","hasEncodingLoss","oldType","newType","Uint8ClampedArray","bytesPerElement","bytesFromStringArray","bytes","forEach","isString","String","isBoolean","isNumber","inferDtype","isFunction","call","apply","nearestDivisor","start","computeStrides","strides","createNestedArray","offset","isComplex","ret","d","rest","len","reduce","acc","c","toNestedArray","makeOnesTypedArray","makeZerosTypedArray","makeZerosNestedTypedArray","prev","curr","assertNonNegativeIntegerDimensions","dimSize","isInteger","locToIndex","locs","indexToLoc","floor","isPromise","then","TENSORFLOWJS_FLAGS_PREFIX","Environment","global","flags","flagRegistry","urlFlags","getQueryParams","populateURLFlags","setPlatform","platformName","platform","env","getBool","console","warn","registerFlag","flagName","evaluationFn","setHook","flagValue","getAsync","evaluateFlag","getNumber","getFlags","features","setFlags","Object","assign","reset","location","search","urlParams","split","keyValue","key","toLowerCase","parseValue","queryString","params","replace","_len","t","_key","name","decodeURIComponent","decodeParam","join","ENV","globalNameSpace","getGlobalNamespace","ns","window","process","self","getGlobal","init","globalMap","_tfGlobals","Map","getGlobalMap","singleton","Abs","Acos","Acosh","Add","AddN","All","Any","ArgMax","ArgMin","Asin","Asinh","Atan","Atanh","Atan2","AvgPool","AvgPoolGrad","AvgPool3D","AvgPool3DGrad","BatchMatMul","BatchToSpaceND","Bincount","BroadcastTo","BroadcastArgs","Cast","Ceil","ClipByValue","Complex","ComplexAbs","Concat","Conv2D","Conv2DBackpropFilter","Conv2DBackpropInput","Conv3D","Conv3DBackpropFilterV2","Conv3DBackpropInputV2","Cos","Cosh","Cumprod","Cumsum","CropAndResize","DenseBincount","DepthToSpace","DepthwiseConv2dNative","DepthwiseConv2dNativeBackpropFilter","DepthwiseConv2dNativeBackpropInput","Diag","Dilation2D","Dilation2DBackpropInput","Dilation2DBackpropFilter","RealDiv","Einsum","Elu","EluGrad","Erf","Equal","Exp","ExpandDims","Expm1","FFT","Fill","FlipLeftRight","Floor","FloorDiv","FusedBatchNorm","GatherV2","GatherNd","Greater","GreaterEqual","Identity","IFFT","Imag","IsFinite","IsInf","IsNan","LeakyRelu","Less","LessEqual","LinSpace","Log","Log1p","LogicalAnd","LogicalNot","LogicalOr","LogicalXor","LogSoftmax","LowerBound","LRN","LRNGrad","Max","Maximum","MaxPool","MaxPoolGrad","MaxPool3D","MaxPool3DGrad","MaxPoolWithArgmax","Mean","Min","Minimum","MirrorPad","Mod","Multinomial","Multiply","Neg","NotEqual","NonMaxSuppressionV3","NonMaxSuppressionV4","NonMaxSuppressionV5","OnesLike","OneHot","Pack","PadV2","Pool","Pow","Prelu","Prod","RaggedGather","RaggedTensorToTensor","Range","Real","Reciprocal","Relu","Reshape","ResizeNearestNeighbor","ResizeNearestNeighborGrad","ResizeBilinear","ResizeBilinearGrad","Relu6","Reverse","Round","Rsqrt","ScatterNd","SearchSorted","Select","Selu","Slice","Sin","Sinh","Sign","Sigmoid","Softplus","Sqrt","Sum","SpaceToBatchND","SplitV","Softmax","SparseFillEmptyRows","SparseReshape","SparseSegmentMean","SparseSegmentSum","SparseToDense","SquaredDifference","Square","StridedSlice","StringNGrams","StringSplit","StringToHashBucketFast","Sub","Tan","Tanh","Tile","TopK","Transform","Transpose","Unique","Unpack","UnsortedSegmentSum","UpperBound","ZerosLike","Step","FromPixels","RotateWithOffset","_FusedMatMul","FusedConv2D","FusedDepthwiseConv2D","log","kernelRegistry","gradRegistry","getKernel","backendName","makeKey","getGradient","getKernelsForBackend","it","entries","done","next","config","registerKernel","registerGradient","unregisterKernel","unregisterGradient","copyRegisteredKernels","registeredBackendName","newBackendName","kernelConfig","Long","LongExports","hexToLong","hex","fromString","k0","k1","k2","shiftMix","xor","shru","fetch","numBytes","fromBytes","from","fetch64","fetch32","rotate64","shift","or","shl","hashLen16","u","v","mul","weakHashLen32WithSeedsStr","w","y","z","add","weakHashLen32WithSeeds","fingerPrint64","seed","fromNumber","hashLen0to16","hashLen17to32","e","g","h","hashLen33to64","UZERO","end","last64","and","createScalarValue","encodeString","toTypedArray","base","noConversionNeeded","bool","round","now","path","requestInits","encoding","encode","decodeString","decode","Profiler","backendTimer","logger","Logger","profileKernel","inputs","outputs","holdResultWrapperFn","timer","util","output","dataSync","kernelMs","tensorVals","checkComputationForErrors","timeMs","timing","extraInfo","getExtraProfileInfo","logKernelProfile","kernelProfile","all","valueContainer","paddedName","toString","inputShapesDescription","input","inputShape","inputRank","tensorToString","verbose","padPerCol","numCols","fill","valuesOrTuples","createComplexTuples","row","valToString","computeMaxSizePerColumn","valsLines","subTensorToString","lines","l","pad","valStr","parseFloat","toFixed","boolNumToString","isLast","storagePerElement","firstValsSize","firstVals","lastVals","subshape","substrides","stride","sep","newLineSep","complexTuples","TensorBuffer","_len2","_key2","loc","toTensor","trackerFn","makeTensor","opHandler","deprecationWarningFn","Tensor","id","kept","isDisposedInternal","rankType","buffer","bufferSync","arraySync","throwIfDisposed","_a","dataToGPU","isDisposed","disposeTensor","print","clone","cast","variable","trainable","makeVariable","defineProperty","Symbol","hasInstance","instance","Variable","initialValue","tensorId","super","newValue","disposeVariable","Rank","UpcastInt32AndMap","UpcastBoolAndMap","UpcastFloat32AndMap","UpcastComplex64AndMap","Function","upcastTypeMap","upcastType","typeA","typeB","sumOutType","type","makeTypesMatch","assertTypesMatch","isTensorInList","tensor","tensorList","some","getTensorsInContainer","list","walkTensorContainer","Set","container","seen","obj","iterable","k","isRegisteredKernelInvocation","kernelInvocation","EngineState","registeredVariables","nextTapeNodeId","numTensors","numStringTensors","numDataBuffers","gradientDepth","kernelDepth","scopeStack","numDataMovesStack","nextScopeId","tensorInfo","profiling","activeProfile","newBytes","newTensors","peakBytes","kernels","kernelNames","variableName","Engine","registry","registryFactory","pendingBackendInitId","state","ready","pendingBackendInit","backendInstance","sortedBackends","getSortedBackends","initializeBackend","success","setBackend","asyncInit","initializeBackendsAndReturnBest","backendNames","keys","findBackend","findBackendFactory","factory","registerBackend","priority","setupRegisteredKernels","profiler","kernel","setupFunc","disposeRegisteredKernels","disposeFunc","registryFactoryEntry","promiseId","catch","err","stack","message","removeBackend","info","srcBackend","shouldCheckForMemLeaks","tidy","nameOrFn","fn","scopedRun","startScope","endScope","error","res","ex","nextTensorId","nextVariableId","ENGINE","runKernel","addTapeNode","activeScope","dy","gradInputs","attrs","runKernelFunc","checkKernelForMemLeak","numDataIdsBefore","outInfos","numDataIdsAfter","numOutputDataIds","numMoves","dataIdsLeaked","kernelParams","saved","isTapeOn","startingBytecount","startingNumTensors","kernelFunc","out","kernelOrScopeName","outTensors","outInfo","makeTensorFromTensorInfo","tensorsToSave","getTensorsForGradient","saveTensorsForBackwardMode","forwardFunc","saveFunc","tensors","keep","outs","backwardsFunc","bytesAdded","totalBytesSnapshot","tensorsAdded","totalTensorsSnapshot","inputShapes","outputShapes","item","kernelTimeMs","gradConfig","inputsToSave","outputsToSave","inputTensorsToSave","saveAllInputs","inputName","outputTensorsToSave","filter","_","backendVals","trackTensor","makeTensorFromDataId","track","removeDataId","disposeVariables","varName","unreliable","reasons","profile","query","startBytes","startNumTensors","gradientsFunc","tapeNode","gradFunc","gradient","dys","activeTape","startTape","endTape","scopeInfo","tensorsToTrackInParent","tensorsToTrackInParentSet","oldScope","pop","scopeId","gradients","xs","allowNoGradients","filteredTape","tape","tensorsFromX","nodesFromX","node","nodeInputs","anyInputFromX","tensorsLeadToY","nodesToY","prunedInputs","nodeInput","prunedNode","getFilteredNodesXToY","accumulatedGradientMap","ones","tensorAccumulatedGradientMap","o","gradTensor","inputGradients","dx","curGradient","backpropagateGradients","grads","customGrad","_this","inputMap","save","gradRes","gradMap","grad","timingInfo","wallMs","getOrMakeEngine","_tfengine","environment","isMobileMockValue","mockIsMobile","isMobile","nav","navigator","product","userAgent","vendor","opera","navAny","userAgentData","mobile","test","substr","isBrowser","document","WorkerGlobalScope","inferShape","firstElem","deepAssertShapeConsistency","indices","subShape","assertDtype","expectedDtype","actualDType","argName","functionName","convertToTensor","parseAsDtype","inferredDtype","indexOf","inferredShape","convertToTensorArray","arg","debugValue","device_util","versions","OP_SCOPE_SUFFIX","op","opName","endsWith","substring","f2","configurable","complex","complex_","real","imag","$real","$imag","providedSize","inferredSize","inferred","flatDimsDontMatch","DTYPE_VALUE_SIZE_MAP","NUM_BYTES_STRING_LENGTH","async","encodeWeights","group","specs","dataPromises","names","spec","utf8bytes","totalNumBytes","p","bytesOfLength","concatenateTypedArrays","decodeWeights","float16Decode","quantization","quantizationSizeFactor","byteBuffer","quantizedArray","Uint16Array","scale","getFloat16Decoder","byteLength","dtypeFactor","image","realTensor","imageTensor","JSON","stringify","totalByteLength","normalizedXs","useNodeBuffer","Buffer","Blob","atob","btoa","stringByteLength","str","concatenateArrayBuffers","buffers","basename","trim","items","getModelJSONForModelArtifacts","artifacts","manifest","modelTopology","format","generatedBy","convertedBy","weightsManifest","signature","userDefinedMetadata","modelInitializer","trainingConfig","getModelArtifactsForJSONSync","modelJSON","weightSpecs","weightData","modelArtifacts","getModelArtifactsForJSON","loadWeights","getModelArtifactsInfoForJSON","ArrayBuffer","dateSaved","Date","modelTopologyType","modelTopologyBytes","weightSpecsBytes","weightDataBytes","getWeightSpecs","entry","weights","mantisaTable","convertMantissa","m","computeFloat16MantisaTable","exponentTable","computeFloat16ExponentTable","offsetTable","computeFloat16OffsetTable","bufferUint32View","float16Bits","float32Bits","IORouterRegistry","saveRouters","loadRouters","getInstance","registerSaveRouter","saveRouter","registerLoadRouter","loadRouter","getSaveHandlers","url","getHandlers","getLoadHandlers","loadOptions","handlerType","validHandlers","router","handler","loudRouter","DATABASE_NAME","MODEL_STORE_NAME","INFO_STORE_NAME","getIndexedDBFactory","theWindow","indexedDB","mozIndexedDB","webkitIndexedDB","msIndexedDB","shimIndexedDB","setUpDatabase","openRequest","db","createObjectStore","keyPath","BrowserIndexedDB","modelPath","databaseAction","load","open","onupgradeneeded","onsuccess","modelTx","transaction","getRequest","objectStore","close","onerror","oncomplete","modelArtifactsInfo","infoTx","infoStore","putInfoRequest","put","putModelRequest","deleteInfoRequest","URL_SCHEME","indexedDBRouter","startsWith","BrowserIndexedDBManager","listModels","tx","getAllInfoRequest","getAll","removeModel","getInfoRequest","deleteModelData","deleteModelRequest","PATH_SEPARATOR","PATH_PREFIX","INFO_SUFFIX","MODEL_TOPOLOGY_SUFFIX","WEIGHT_SPECS_SUFFIX","WEIGHT_DATA_SUFFIX","MODEL_METADATA_SUFFIX","getModelKeys","topology","modelMetadata","removeItems","localStorage","removeItem","getModelPathFromKey","BrowserLocalStorage","LS","setItem","buf","fromCharCode","arrayBufferToBase64String","metadata","parse","getItem","metadataString","weightDataBase64","byteOffset","charCodeAt","base64StringToArrayBuffer","localStorageRouter","BrowserLocalStorageManager","prefix","suffix","URL_SCHEME_SUFFIX","ModelStoreManagerRegistry","managers","registerManager","scheme","manager","getManager","getSchemes","parseURL","cloneModelInternal","sourceURL","destURL","deleteSource","loadHandlers","loadHandler","saveHandlers","saveHandler","sourceScheme","sourcePath","sameMedium","saveResult","schemes","schemeOut","schemeAndPath","copyModel","moveModel","PlatformBrowser","messageName","functionRefs","handledMessageCount","hasEventListener","performance","text","textEncoder","TextEncoder","TextDecoder","setTimeoutCustom","functionRef","delay","postMessage","addEventListener","event","source","stopPropagation","getNodeFetch","importFetch","require","systemFetch","PlatformNode","hrtime","cast_","$x","clone_","defer","BrowserDownloads","fileNamePrefix","modelJsonFileName","weightDataFileName","weightsURL","URL","createObjectURL","paths","modelJsonURL","jsonAnchor","modelJsonAnchor","createElement","download","href","dispatchEvent","MouseEvent","weightDataAnchor","BrowserFiles","files","jsonFile","weightsFiles","jsonReader","FileReader","onload","target","modelArtifactsPromise","readAsText","pathToFile","checkManifestAndWeightFiles","promises","loadWeightsFile","file","weightFileReader","readAsArrayBuffer","basenames","fileNames","pathBasename","browserFiles","monitorPromisesProgress","onProgress","startFraction","endFraction","checkPromises","checkFraction","resolvedPromise","promise","fraction","loadWeightsAsArrayBuffer","fetchURLs","fetchFunc","requests","fetchURL","requestInit","isBinary","bufferPromises","response","arrayBuffer","filePathPrefix","weightNames","weightsLoaderFactory","fetchUrls","fetchWeightsFunction","groupIndicesToFetchMap","groupWeightsToFetch","weightsFound","allManifestWeightNames","manifestGroupConfig","groupIndex","groupOffset","weightsEntry","rawDtype","weightsBytes","enqueueWeightsForFetchingFn","manifestEntry","sizeBytes","weightName","weightIndex","found","weightsNotFound","groupIndicesToFetch","accumulator","shouldFetch","filepath","fetchUrl","weightsTensorMap","bufferIndexOffset","numBuffers","groupBytes","groupBuffer","groupByteBuffer","groupBufferOffset","nameToTensorMap","browserDownloads","HTTPRequest","DEFAULT_METHOD","weightPathPrefix","weightUrlConverter","body","method","FormData","modelTopologyAndWeightManifest","append","ok","responses","status","modelConfigRequest","json","weightPath","lastSlash","lastIndexOf","lastSearchParam","parseUrl","pathPrefix","urlPromises","weightsGroup","isHTTPScheme","match","URL_SCHEME_REGEX","httpRouter","isHTTP","urlItem","http","browserHTTPRequest","PassthroughLoader","PassthroughSaver","PassthroughAsync","fromMemory","fromMemorySync","withSaveHandler","withSaveHandlerSync","matMul","matMul_","transposeA","transposeB","$a","$b","oneHot","oneHot_","depth","onValue","offValue","enableProdMode","enableDebugMode","disableDeprecationWarnings","deprecationWarn","engine","getBackend","imag_","neg","neg_","real_","transpose","transpose_","perm","conjugate","reverse","confusionMatrix","confusionMatrix_","labels","predictions","numClasses","$labels","$predictions","oneHotLabels","oneHotPredictions","oneHotLabelsT","getBroadcastDims","inShape","outShape","inRank","dims","dim","unshift","getReductionAxes","inDim","outAxis","outDim","assertAndGetBroadcastShape","errMsg","tensor3d","fromPixels2DContext","fromPixels_","pixels","numChannels","isPixelData","isImageData","isVideo","isImage","isCanvasLike","isImageBitmap","ImageData","HTMLVideoElement","HTMLImageElement","getContext","ImageBitmap","height","videoWidth","videoHeight","getImageData","OffscreenCanvas","OffscreenCanvasRenderingContext2D","willReadFrequently","canvas","drawImage","numPixels","channel","canWrapPixelsToImageBitmap","hasOwnProperty","isNonEmptyPixels","fromPixelsAsync","imageBitmap","createImageBitmap","premultiplyAlpha","toPixels","img","$img","originalImgTensor","multiplier","rgba","ctx","imageData","putImageData","fromPixels","prepareAndValidate","tensorRank","indicesRank","indicesShape","sliceRank","nResult","resultShape","sliceSize","validateUpdateShape","updates","sliceDim","batchDim","shapeError","validateInput","calculateShapes","totalNd","safeSliceDim","numUpdates","outputSize","NEW_AXIS","SHRINK_AXIS","assertParamsValid","begin","maskToAxes","mask","computeOutShape","stridesWithElidedDims","ellipsisInsertionIndex","numElidedAxes","newStrides","splice","unnormalizeAxis","normalizedAxis","getElidedAxes","elidedAxes","getNormalizedAxes","ellipsisAxes","numInterpolatedAxes","beginMask","endMask","ellipsisMask","normalizedBegin","normalizedEnd","normalizedStrides","fullIndex","startIndicesWithElidedDims","stopIndicesWithElidedDims","startForAxis","stopForAxis","stridesForAxis","originalBegin","newIndices","originalAxis","originalValue","originalEnd","MAX_SAFE_INTEGER","axisSize","startIndices","MIN_SAFE_INTEGER","stopIndices","stop","isSliceContinous","firstNonOneAxis","computeFlatOffset","flatOffset","parseSliceParams","begin_","xRank","size_","sliceInfo","xShape","newAxisMask","shrinkAxisMask","stridesNonNull","ellipsisSeen","sparseSpec","numAddAxisAfterEllipsis","denseSpec","beginValid","endValid","sparse","dense","finalShapeGatherIndices","finalShapeGatherIndicesSparse","inputShapeGatherIndicesSparse","nextIndex","buildDenseSpec","isIdentity","sliceDim0","isSimpleSlice","processingShape","finalShape","shrinkI","dimI","masks","validRange","beginAndEndMasked","xFwd","canonical","takeAllInDimension","intervalLength","knownInterval","sizeI","trunc","denseDim","gatherIndex","finalShapeSparse","strideI","Serializable","getClassName","className","fromConfig","cls","SerializationMap","classNameMap","getMap","register","registerClass","TEST_EPSILON_FLOAT32","TEST_EPSILON_FLOAT16","expectArraysClose","actual","expected","testEpsilon","expectArraysPredicate","areClose","predicate","checkClassType","aType","bType","actualShape","expectedShape","actualFlat","expectedFlat","expect","nothing","expectPromiseToFail","fail","expectArraysEqual","expectNumbersClose","abs","expectValuesInRange","low","high","expectArrayBuffersEqual","actualArray","expectedArray","encodeStrings","createVideoElement","video","playsInline","muted","loop","style","position","top","preload","appendChild","play","requestVideoFrameCallback","version","add_","floorDiv","floorDiv_","div","div_","mul_","sqrt_","square","square_","zerosLike","zerosLike_","$dy","checkGrads","args","$args","valueAndGrad","valueAndGrads","variableGrads","varList","specifiedVarList","specifiedNonTrainable","originalVarCount","namedGrads","scalar","Optimizer","minimize","returnCost","computeGradients","gradArray","applyGradients","iterations","iterations_","incrementIterations","saveIterations","getWeights","setWeights","weightValues","extractIterations","AdadeltaOptimizer","learningRate","rho","accumulatedGrads","accumulatedUpdates","variableGradients","originalName","accumulatedGrad","accumulatedUpdate","newAccumulatedGrad","newAccumulatedUpdate","variables","variableCount","getConfig","AdagradOptimizer","initialAccumulatorValue","pow","pow_","$base","$exp","sub","sub_","AdamOptimizer","beta1","beta2","accumulatedFirstMoment","accumulatedSecondMoment","accBeta1","accBeta2","varNames","oneMinusAccBeta1","oneMinusAccBeta2","firstMoment","secondMoment","newFirstMoment","newSecondMoment","biasCorrectedFirstMoment","biasCorrectedSecondMoment","abs_","maximum","maximum_","AdamaxOptimizer","decay","accumulatedWeightedInfNorm","iteration","variableNames","lr","weightedInfNorm","ut0","ut1","newWeightedInfNorm","SGDOptimizer","setLearningRate","MomentumOptimizer","momentum","useNesterov","accumulations","accumulation","newAccumulation","setMomentum","RMSPropOptimizer","centered","accumulatedMeanSquares","accumulatedMoments","accumulatedMeanGrads","accumulatedMeanSquare","newAccumulatedMeanSquare","accumulatedMeanGrad","newAccumulatedMeanGrad","gradContribution","newAccumulatedMoments","OptimizerConstructors","sgd","rmsprop","adam","adadelta","adamax","adagrad","acos","acos_","acosh","acosh_","addN","addN_","$tensors","firstTensor","all_","keepDims","any","any_","argMax","argMax_","argMin","argMin_","asin","asin_","asinh","asinh_","atan","atan_","atan2","atan2_","atanh","atanh_","computeDilation2DInfo","filterShape","dataFormat","dilations","computeConv2DInfo","convertConv2DDataFormat","computePool2DInfo","filterSize","roundingMode","filterHeight","filterWidth","parseTupleParam","computePool3DInfo","filterDepth","parse3TupleParam","$dataFormat","computeConv3DInfo","depthwise","batchSize","inHeight","inWidth","inChannels","filterChannels","strideHeight","strideWidth","dilationHeight","dilationWidth","effectiveFilterHeight","getEffectiveFilterSize","effectiveFilterWidth","padInfo","outHeight","outWidth","bottom","fieldSize","zeroPad","computeDefaultPad","inputRows","inputCols","outputRows","outputCols","computeOutputShape2D","padAlongHeight","padAlongWidth","getPadAndOutInfo","outChannels","inDepth","strideDepth","dilationDepth","effectiveFilterDepth","outDepth","front","back","inputDepth","outputDepths","computeOutputShape4D","padAlongDepth","get3DPadAndOutInfo","effectiveFieldSize","param","dilation","tupleValuesAreOne","dimA","dimB","dimC","eitherStridesOrDilationsAreOne","checkPadOnDimRoundingMode","opDesc","dimRoundingMode","reshape","reshape_","avgPool","avgPool_","conv_util","x4D","reshapedTo4D","avgPool3d","avgPool3d_","x5D","reshapedTo5D","concat_","attr","sigmoid","sigmoid_","slice_","tanh_","basicLSTMCell","basicLSTMCell_","forgetBias","lstmKernel","lstmBias","$forgetBias","$lstmKernel","$lstmBias","$data","$c","$h","combined","weighted","sliceCols","newC","batchToSpaceND","batchToSpaceND_","blockShape","crops","prod","batchNorm","batchNorm_","mean","variance","varianceEpsilon","$mean","$variance","$scale","$offset","xAs4D","batchNorm2d","batchNorm2d_","batchNorm3d","batchNorm3d_","batchNorm4d","batchNorm4d_","bincount","bincount_","$weights","broadcastArgs","broadcastArgs_","s0","s1","shape1Input","shape2Input","broadcastTo","broadcastTo_","reps","ceil_","clipByValue","clipByValue_","clipValueMin","clipValueMax","concat1d","concat1d_","concat2d","concat2d_","concat3d","concat3d_","concat4d","concat4d_","conv2d","conv2d_","$filter","conv1d","conv1d_","x3D","reshapedTo3D","filter4D","input4D","conv2DBackpropInput","conv2DBackpropInput_","xShape4D","dy4D","conv2dTranspose","conv2dTranspose_","outputShape","conv3d","conv3d_","conv3DBackpropInput","conv3DBackpropInput_","xShape5D","dy5D","conv3dTranspose","conv3dTranspose_","cos","cos_","cosh","cosh_","cumprod","cumprod_","exclusive","cumsum","cumsum_","denseBincount","denseBincount_","binaryOutput","depthToSpace","depthToSpace_","blockSize","inputHeight","inputWidth","depthwiseConv2d","depthwiseConv2d_","diag","diag_","dilation2d","dilation2d_","equal","equal_","where","where_","condition","$condition","broadcastShape","divNoNan","divNoNan_","divResult","zeros","bEqualsZero","dot","dot_","t1","t2","$t1","$t2","t1Inner","t2Inner","t12D","t22D","t1t2","einsum","einsum_","equation","elu","elu_","erf","erf_","axesAreInnerMostDims","combineLocations","outputLoc","reduceLoc","outIdx","reduceIdx","computeOutAndReduceShapes","aShape","expandShapeToKeepDim","assertAxesAreInnerMostDims","getAxesPermutation","getUndoAxesPermutation","getInnerMostAxes","numAxes","max_","reductionIndices","min_","sum_","normImpl","norm","norm_","ord","keepDimsShape","axis_util","euclideanNorm","euclideanNorm_","exp_","expandDims","expandDims_","expm1","expm1_","tile","tile_","eye","eye_","numRows","numColumns","batchShape","buff","floor_","gather","gather_","batchDims","greater","greater_","greaterEqual","greaterEqual_","isFinite_","isInf","isInf_","isNaN_","leakyRelu","leakyRelu_","alpha","less","less_","lessEqual","lessEqual_","linspace","localResponseNormalization","localResponseNormalization_","depthRadius","bias","beta","log_","log1p","log1p_","softplus","softplus_","logSigmoid","logSigmoid_","customOp","logSoftmax","logSoftmax_","logits","$logits","xMax","shifted","softmax","logSumExp","logSumExp_","logicalAnd","logicalAnd_","logicalNot","logicalNot_","logicalOr","logicalOr_","logicalXor","logicalXor_","INT32_MAX","searchSorted","searchSorted_","sortedSequence","side","$sortedSequence","$values","sequenceSize","valuesSize","$sortedSequence2D","$values2D","lowerBound","maxPool","maxPool_","maxPool3d","maxPool3d_","maxPoolWithArgmax","maxPoolWithArgmax_","includeBatchInIndex","indexes","mean_","meshgrid","indexing","TypeError","$y","minimum","minimum_","mirrorPad","mirrorPad_","paddings","mode","shapeOffset","mod","mod_","moments","moments_","xMean","devSquared","multiRNNCell","multiRNNCell_","lstmCells","newStates","newH","multinomial","multinomial_","numSamples","normalized","numOutcomes","origRank","notEqual","notEqual_","onesLike","onesLike_","outerProduct","outerProduct_","v1","v2","$v1","$v2","v12D","v22D","pad_","constantValue","pad1d","pad1d_","pad2d","pad2d_","pad3d","pad3d_","pad4d","pad4d_","spaceToBatchND","spaceToBatchND_","pool","pool_","windowShape","poolingType","convInfo","basePadding","dilatedFilterShape","padExtraShape","padExtraStart","padExtraEnd","withSpaceToBatchBasePaddings","isDilationOne","adjustedPadding","adjustedCrops","padStart","origPadEnd","fullInputShape","padEndExtra","padEnd","requiredSpaceToBatchPaddings","convertedPad","convertedX","prelu","prelu_","prod_","raggedGather","raggedGather_","paramsNestedSplits","paramsDenseValues","outputRaggedRank","outputNestedSplits","outputDenseValues","raggedTensorToTensor","raggedTensorToTensor_","defaultValue","rowPartitionTensors","rowPartitionTypes","$shape","rand","rand_","randFunction","MPRandGauss","stdDeviation","truncated","stdDev","nextVal","NaN","upper","lower","seedValue","seedrandom","alea","nextValue","resultX","resultY","isValid","isValidTruncated","convertValue","RandGamma","randu","randn","x2","v0","UniformRandom","canReturnFloat","range","randomGamma","randomGamma_","rgamma","randomNormal","randomNormal_","randGauss","randomStandardNormal","randomStandardNormal_","randomUniform","randomUniform_","minval","maxval","step","reciprocal","reciprocal_","relu","relu_","relu6","relu6_","reverse_","reverse1d","reverse1d_","reverse2d","reverse2d_","reverse3d","reverse3d_","reverse4d","reverse4d_","round_","rsqrt","rsqrt_","selu","selu_","separableConv2d","separableConv2d_","depthwiseFilter","pointwiseFilter","$depthwiseFilter","$pointwiseFilter","channelMultiplier","setdiff1dAsync","xVals","yVals","ySet","sign","sign_","sin","sin_","sinh","sinh_","slice1d","slice1d_","slice2d","slice2d_","slice3d","slice3d_","slice4d","slice4d_","softmax_","fft","fft_","ifft","ifft_","irfft","irfft_","innerDimensionSize","batch","complexInput","realInput","imagInput","realConjugate","imagConjugate","split_","numOrSizeSplits","rfft","rfft_","fftLength","adjustedInput","zerosShape","zerosInput","half","realValues","imagValues","realComplexConjugate","imagComplexConjugate","squaredDifference","squaredDifference_","squeeze","squeeze_","stack_","step_","stridedSlice","stridedSlice_","tan","tan_","tensor1d","tensor2d","tensor4d","tensor5d","tensor6d","topk","topk_","sorted","lastDim","truncatedNormal","truncatedNormal_","unique","unique_","unsortedSegmentSum","unsortedSegmentSum_","segmentIds","numSegments","$segmentIds","unstack","unstack_","upperBound","whereImpl","condShape","condVals","inBuffer","whereAsync","booleanMaskAsync","$tensor","$mask","axisFrom","maskDim","tensorShape","leadingSize","targetTensorShape","reshapedTensor","reshapedMask","positivePositions","movingAverage","movingAverage_","zeroDebias","$v","$decay","one","oneMinusDecay","update","$step","scatterND","scatterND_","$indices","$updates","scatter_nd_util","sparseToDense","sparseToDense_","sparseIndices","sparseValues","$sparseIndices","$sparseValues","$defaultValue","defaultValues","numElems","numDims","numValues","sparse_to_dense","gatherND","gatherND_","dropout","dropout_","rate","noiseShape","$noiseShape","newDimension","getNoiseShape","keepProb","enclosingPowerOfTwo","cosineWindow","windowLength","even","newValues","cosArg","PI","inTopKAsync","targets","$targets","predictionsVals","targetsVals","precision","subarray","valAndInd","conv2DBackpropFilter","conv2DBackpropFilter_","getFusedDyActivation","activation","getFusedBiasGradient","dyActivation","reduceAxes","broadcast_util","applyActivation","preluActivationWeights","leakyreluAlpha","shouldFuse","fusedConv2d_","_ref","unfusedConv2d","inputChannels","$bias","$preluActivationWeights","alphaShape","der","biasDer","customOpWithBias","depthwiseConv2dNativeBackpropFilter","depthwiseConv2dNativeBackpropFilter_","depthwiseConv2dNativeBackpropInput","depthwiseConv2dNativeBackpropInput_","fusedDepthwiseConv2d_","unfusedDepthwiseConv2d","xDer","filterDer","fusedMatMul_","unfusedMatMul","innerShapeA","innerShapeB","outerShapeA","outerShapeB","outerDimsA","outerDimsB","batchDimA","batchDimB","a3D","b3D","aDer","bDer","hammingWindow","hammingWindow_","hannWindow","hannWindow_","frame","frame_","signal","frameLength","frameStep","padValue","padLen","stft","stft_","windowFn","framedSignal","windowedSignal","cropAndResize","cropAndResize_","boxes","boxInd","cropSize","extrapolationValue","$image","$boxes","$boxInd","numBoxes","flipLeftRight","flipLeftRight_","grayscaleToRGB","grayscaleToRGB_","lastDimsIdx","lastDims","rotateWithOffset","rotateWithOffset_","radians","fillValue","center","nonMaxSuppSanityCheck","scores","maxOutputSize","iouThreshold","scoreThreshold","softNmsSigma","NEGATIVE_INFINITY","nonMaxSuppression","nonMaxSuppression_","$scores","binaryInsert","element","comparator","middle","compareResult","binarySearch_","defaultComparator","binarySearch","insertionPoint","nonMaxSuppressionV3Impl","nonMaxSuppressionImpl_","nonMaxSuppressionV4Impl","padToMaxOutputSize","nonMaxSuppressionV5Impl","returnScoresTensor","returnValidOutputs","candidates","score","boxIndex","suppressBeginIndex","ascendingComparator","selectedIndices","selectedScores","candidate","originalScore","ignoreCandidate","iou","intersectionOverUnion","suppressWeight","validOutputs","elemsToPad","iCoord","jCoord","yminI","xminI","ymaxI","xmaxI","yminJ","xminJ","ymaxJ","xmaxJ","areaI","areaJ","intersectionYmin","intersectionXmin","intersectionYmax","intersectionXmax","intersectionArea","weight","c1","c2","nonMaxSuppressionAsync","boxesAndScores","boxesVals","scoresVals","nonMaxSuppressionWithScore","nonMaxSuppressionWithScore_","nonMaxSuppressionWithScoreAsync","nonMaxSuppressionPadded","nonMaxSuppressionPadded_","nonMaxSuppressionPaddedAsync","$maxOutputSize","$iouThreshold","$scoreThreshold","resizeBilinear","resizeBilinear_","images","alignCorners","halfPixelCenters","$images","batchImages","resizeNearestNeighbor","resizeNearestNeighbor_","threshold","threshold_","inverted","threshValue","totalPixelsInImage","grayscale","$threshold","$r","$g","histogram","total","classFirst","classSecond","meanFirst","meanSec","weightForeground","weightBack","bestThresh","bestInBetVar","cInBetVar","meanFirstDivA","meanSecFill","meanSecAdd","meanSecMul","cInBetVarSubA","cInBetVarSubB","cInBetVarMul","otsu","invCondition","transform","transform_","transforms","interpolation","fillMode","$transforms","bandPart","bandPart_","numLower","numUpper","M","N","ij","inBand","zero","mat","gramSchmidt","gramSchmidt_","inputIsTensor2D","ys","xs1d","proj","qr2d","fullMatrices","q","one2D","iters","rTemp","wTemp","qTemp","rjEnd1","normX","rjj","u1","wPre","tau","rjEndAll","tauTimesW","wT","rTimesTau","tawTimesWT","qAllJEnd","qTimesTau","qr","qr_","outerDimsProd","x2ds","q2ds","r2ds","x2d","q2d","r2d","Reduction","computeWeightedLoss","computeWeightedLoss_","losses","reduction","SUM_BY_NONZERO_WEIGHTS","$losses","weightedLoss","NONE","SUM","MEAN","broadcastFactor","broadcastedWeights","numNonZeros","absoluteDifference","absoluteDifference_","cosineDistance","cosineDistance_","hingeLoss","hingeLoss_","huberLoss","huberLoss_","delta","deltaScalar","quadratic","linear","logLoss","logLoss_","epsilonScalar","l1","l2","meanSquaredError","meanSquaredError_","sigmoidCrossEntropy","sigmoidCrossEntropy_","multiClassLabels","labelSmoothing","$multiClassLabels","labelSmoothingScalar","maxOutput","outputXTarget","sigmoidOutput","sigmoidCrossEntropyWithLogits_","softmaxCrossEntropy","softmaxCrossEntropy_","onehotLabels","$onehotLabels","lse","logResult","costVector","dyShape","softmaxCrossEntropyWithLogits_","sparseFillEmptyRows","sparseFillEmptyRows_","denseShape","$denseShape","outputIndices","outputValues","emptyRowIndicator","reverseIndexMap","sparseReshape","sparseReshape_","inputIndices","$inputIndices","$inputShape","$newShape","sparseSegmentMean","sparseSegmentMean_","sparseSegmentSum","sparseSegmentSum_","stringNGrams","stringNGrams_","dataSplits","separator","nGramWidths","leftPad","padWidth","preserveShortSequences","$dataSplits","nGrams","nGramsSplits","stringSplit","stringSplit_","delimiter","skipEmpty","$input","$delimiter","stringToHashBucketFast","stringToHashBucketFast_","numBuckets","spectral","linalg","string","train","delayCallback","requestAnimationFrame","setImmediate","nextFrame","assertParamsConsistent","shapes","firstShape","RowPartitionType","combineRaggedTensorToTensorShapes","raggedRank","valueShape","valueDim","outputShapeDimIndex","outputShapeDim","getRowPartitionTypesHelper","rowPartitionTypeStrings","stringToType","FIRST_DIM_SIZE","VALUE_ROWIDS","ROW_LENGTHS","ROW_SPLITS","ROW_LIMITS","ROW_STARTS","typeStr","getRaggedRank","validateDefaultValueShape","defaultValueShape","defaultNDims","valuesNDims","defaultDim","PARALLELIZE_THRESHOLD","computeOptimalWindowSize","inSize","getImageCenter","imageHeight","imageWidth","getReshaped","reshaped","spatialLength","getPermuted","reshapedRank","blockShapeRank","permuted","permutedBeforeBatch","permutedAfterBatch","getReshapedPermuted","batchToSpace","reshapedPermuted","getSliceBeginCoords","sliceBeginCoords","getSliceSize","uncroppedShape","SELU_SCALEALPHA","SELU_SCALE","ERF_P","ERF_A1","ERF_A2","ERF_A3","ERF_A4","ERF_A5","mergeRealAndImagArrays","splitRealAndImagArrays","complexWithEvenIndex","complexWithOddIndex","getComplexWithIndex","assignToTypedArray","exponents","inverse","exponent","ARROW","ARROW_REGEX","COMMA","ELLIPSIS","decodeEinsumEquation","numArrows","inputString","outputString","inputTerms","numInputs","allDims","dimName","inputTerm","idDims","summedDims","getEinsumPermutation","nDims","permutationIndices","checkEinsumDimSizes","dimSizes","getEinsumComputePath","steps","nSteps","computedTermIndices","termIndices","findTermsWithDim","termIndex","isIdentityPermutation","prepareSplitSize","splitSizes","count","negIndex","getSparseFillEmptyRowsIndicesDenseShapeMismatch","indicesLength","getSparseFillEmptyRowsNegativeIndexErrorMessage","getSparseFillEmptyRowsOutOfRangeIndexErrorMessage","limit","getSparseReshapeMultipleNegativeOneOutputDimErrorMessage","dim1","dim2","getSparseReshapeNegativeOutputDimErrorMessage","getSparseReshapeEmptyTensorZeroOutputDimErrorMessage","getSparseReshapeInputOutputMultipleErrorMessage","inputSize","getSparseReshapeInputOutputMismatchErrorMessage","getSparseSegmentReductionNegativeSegmentIdsErrorMessage","getSparseSegmentReductionNonIncreasingSegmentIdsErrorMessage","getSparseSegmentReductionSegmentIdOutOfRangeErrorMessage","segmentId","getSparseSegmentReductionIndicesOutOfRangeErrorMessage","indexValue","segOpComputeOptimalWindowSize","collectGatherOpShapeInfo","outerSize","fromUint8ToStringArray","fromStringArrayToUint8","strings","DataType","SaverDef","CheckpointFormatVersion","CUSTOM_OPS","getRegisteredOp","getParamValue","paramName","tensorMap","context","resourceManager","inputParam","inputParams","inputIndexStart","inputIndexEnd","getTensor","inputNames","attrParam","attrParams","tensorsMap","nodeName","parseNodeName","getHashTableHandleByName","contextId","currentContextIds","find","getNodeNameWithContextId","getNodeNameAndIndex","outputName","currentContextId","parts","getPadding","explicitPadding","cloneTensor","OperationMapper","Instance","_instance","mappersJson","arithmetic","basicMath","control","convolution","creation","dynamic","evaluation","graph","hashTable","logical","matrices","normalization","sliceJoin","transformation","opMappers","mapper","tfOpName","transformGraph","tfNodes","placeholders","initNodes","nodes","mapNode","inputNodeNameToKey","outputNodeNameToKey","mapSignatureEntries","allNodes","inputNode","outputIndex","children","signatureKey","functions","library","function","func","mapFunction","newNode","category","rawAttrs","getStringParam","tfName","tfDeprecatedName","getStringArrayParam","getNumberParam","getNumericArrayParam","getBoolParam","getBoolArrayParam","getTensorShapeParam","getTensorShapeArrayParam","getDtypeParam","getDtypeArrayParam","getFuncParam","functionDef","nodeDef","inputArg","parseDtypeParam","returnNodeMap","outputArg","defaultOutput","mapArgsToSignature","methodName","mapArgToTensorInfo","nameMap","parseStringParam","keepCase","decodeBase64","def","parseInt","tensorflow","DT_FLOAT","DT_HALF","DT_INT32","DT_INT64","DT_INT8","DT_UINT8","DT_BOOL","DT_DOUBLE","DT_STRING","parseTensorShapeParam","unknownRank","NodeValueImpl","getInput","getAttr","assertShapesMatchAllowUndefinedSize","dim0","fullDefinedShape","elementShape","inferElementShape","listElementShape","partialShape","mergeElementShape","notfullDefinedShape","elementShapeA","elementShapeB","TensorArray","maxSize","identicalElementShapes","dynamicSize","clearAfterRead","closed_","idTensor","closed","clearAndClose","keepIds","tensorWithState","cleared","readMany","written","writeMany","scatter","maxIndex","totalLength","cumulativeLengths","elementPerRow","sizes","TensorList","elementDtype","maxNumElements","copy","numElements","outputElementShape","reshapedTensors","popBack","pushBack","resize","destTensorList","elementIndex","executeOp","thenFunc","elseFunc","cond","functionMap","executeFunctionAsync","tensorArrayMap","tensorListMap","bodyFunc","condFunc","condResult","argIds","condValue","origResult","resultIds","pred","frameId","enterFrame","exitFrame","nextIteration","tensorArray","addTensorArray","writeTensor","writeTensorArray","getTensorArray","readId","readIndex","gatherId","gatherIndices","gatherDtype","scatterId","scatterIndices","scatterTensor","scatterTensorArray","concatId","concatTensorArray","concatDtype","splitId","splitTensor","lengths","splitTensorArray","sizeId","closeId","closeTensorArray","getTensorList","elementDType","addTensorList","numElementsParam","reserve","fromTensor","fusedConvAndDepthWiseParams","extraOp","activationFunc","isBiasAdd","noBiasAdd","isPrelu","isBatchNorm","numArgs","toUpperCase","biasArg","preluArg","nmsParams","HashTable","keyDType","valueDType","handle","clear","tensorSize","tfOps","import","checkKeyAndValueTensor","$keys","keysLength","valuesLength","findWithDefault","tfc","ops","fused","kernelSize","summarize","prototype","squeezedShape","mapped","sameShape","addHashTable","getHashTableById","opMapper","customExecutor","ExecutionContext","weightMap","rootContext","frameName","iterationId","contexts","lastId","generateCurrentContextIds","newFrame","currentContext","_currentContextIds","contextIdforContexts","getWeight","getExecutionSubgraph","usedNodes","missingInputs","dynamicNode","syncInputs","inputNodeNames","initNodeNames","frontier","isControlFlow","isDynamicShape","isHashTable","child","CONTROL_FLOW_OPS","DYNAMIC_SHAPE_OPS","HASH_TABLE_OPS","GraphExecutor","parent","compiledMap","_weightMap","SEPERATOR","_functions","_functionExecutorMap","intermediateTensors","keepTensorForDebug","_outputs","_inputs","_initNodes","_signature","weightIds","_weightIds","functionExecutorMap","_resourceManager","inputNodes","outputNodes","getCompilationKey","sortedInputs","sortedOutputs","compile","executionInfo","outNames","inNames","orderedNodes","getNodesInTopologicalOrder","execute","mapInputs","checkInputs","checkInputShapeAndType","mapOutputs","checkOutputs","outputNodeNames","resetIntermediateTensors","compilationKey","tensorsToKeep","getFrozenTensorIds","intermediateTensorConsumerCount","checkTensorForDisposal","ids","outputNames","getTensorsForCurrentContenxt","executeAsync","_executeAsync","disposeIntermediateTensors","disposeTensorsMap","getIntermediateTensors","isFunctionExecution","executeWithControlFlow","results","outputIds","inputIds","mappedInputs","added","processStack","missingOutputs","alternativeMsg","processChildNodes","childNode","notInGraph","normalizedName","ResourceManager","hashTableNameToHandle","hashTableMap","TFHUB_SEARCH_PARAM","DEFAULT_MODEL_NAME","GraphModel","modelUrl","tfio","io","modelVersion","executor","modelSignature","modelStructuredOutputKeys","structuredOutputKeys","findIOHandler","handlers","loadResult","loadSync","producer","minConsumer","convertTensorMapToTensorsMap","initializer","handlerOrURL","predict","outputTensors","outputTensorMap","outputTensor","normalizeInputs","normalizeOutputs","newMap","loadGraphModel","fromTFHub","getTFHubUrl","model","BaseModel","outputStride","preprocessInput","nameOutputResults","heatmapScores","heatmap","offsets","displacementFwd","displacementBwd","MobileNet","__extends","MaxHeap","priorityQueue","numberOfElements","getElementValue","enqueue","swim","dequeue","exchange","sink","empty","getValueAt","scoreIsMaximumInLocalWindow","partNames","NUM_KEYPOINTS","partIds","getOffsetPoint","getImageCoords","heatmapY","heatmapX","addVectors","parentChildrenTuples","parentToChildEdges","childToParentEdges","getStridedIndexNearPoint","traverseToTargetKeypoint","getDisplacement","part","decodePose","withinNmsRadiusOfCorrespondingPoint","keypoints","squaredDistance","getInstanceScore","decodeMultiplePoses","buildPartWithScoreQueue","argmax2d","getOffsetPoint$1","getOffsetPoints","valueOf","getOffsetVectors","decodeSinglePose","__awaiter","__generator","label","sent","getPointsConfidence","MOBILENET_BASE_URL","RESNET50_BASE_URL","imageNetMean","ResNet","POSITIVE_INFINITY","toTensorBuffers3D","toValidInputResolution","isValidInputResolution","validateInputResolution","getValidInputResolutionDimensions","VALID_OUTPUT_STRIDES","getInputTensorDimensions","padAndResizeTo","resized","browser","toInputTensor","padding","scaleAndFlipPoses","scalePose","scalePoses","flipPoseHorizontal","flipPosesHorizontal","MOBILENET_V1_CONFIG","architecture","inputResolution","VALID_ARCHITECTURE","VALID_STRIDE","MobileNetV1","ResNet50","VALID_MULTIPLIER","VALID_QUANT_BYTES","SINGLE_PERSON_INFERENCE_CONFIG","flipHorizontal","MULTI_PERSON_INFERENCE_CONFIG","maxDetections","nmsRadius","PoseNet","assertValidOutputStride","assertValidResolution","baseModel","estimateMultiplePoses","I","E","__assign","validateMultiPersonInputConfig","estimateSinglePose","estimatePoses","decodingMethod","loadMobileNet","quantBytes","tf","mobileNetCheckpoint","loadResNet","resNet50Checkpoint","validateModelConfig"],"sourceRoot":""}